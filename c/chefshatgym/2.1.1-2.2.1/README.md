# Comparing `tmp/chefshatgym-2.1.1-py3-none-any.whl.zip` & `tmp/chefshatgym-2.2.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,33 +1,33 @@
-Zip file size: 66236 bytes, number of entries: 31
+Zip file size: 66459 bytes, number of entries: 31
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Oct-22 21:52 ChefsHatGym/__init__.py
--rw-rw-rw-  2.0 fat     6314 b- defN 24-Feb-19 17:02 ChefsHatGym/KEF/DataSetManager.py
+-rw-rw-rw-  2.0 fat     6591 b- defN 24-Apr-21 12:26 ChefsHatGym/KEF/DataSetManager.py
 -rw-rw-rw-  2.0 fat     3943 b- defN 23-Oct-22 21:52 ChefsHatGym/KEF/ExperimentManager.py
 -rw-rw-rw-  2.0 fat     5439 b- defN 23-Oct-22 21:52 ChefsHatGym/KEF/LogManager.py
 -rw-rw-rw-  2.0 fat     2834 b- defN 23-Oct-22 21:52 ChefsHatGym/KEF/MetricsManager.py
 -rw-rw-rw-  2.0 fat    65452 b- defN 23-Oct-22 21:52 ChefsHatGym/KEF/PlotManager.py
 -rw-rw-rw-  2.0 fat    33311 b- defN 23-Oct-22 21:52 ChefsHatGym/KEF/RenderManager.py
 -rw-rw-rw-  2.0 fat    24979 b- defN 23-Oct-22 21:52 ChefsHatGym/KEF/StatisticsManager.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Oct-22 21:52 ChefsHatGym/KEF/__init__.py
 -rw-rw-rw-  2.0 fat      143 b- defN 23-Oct-22 21:52 ChefsHatGym/agents/__init__.py
 -rw-rw-rw-  2.0 fat     1638 b- defN 23-Oct-24 18:08 ChefsHatGym/agents/agent_random.py
--rw-rw-rw-  2.0 fat    12589 b- defN 24-Apr-17 11:54 ChefsHatGym/agents/chefs_hat_agent.py
+-rw-rw-rw-  2.0 fat    12573 b- defN 24-Apr-22 15:27 ChefsHatGym/agents/chefs_hat_agent.py
 -rw-rw-rw-  2.0 fat    12622 b- defN 24-Apr-16 22:11 ChefsHatGym/agents/chefs_hat_agent_socket.py
--rw-rw-rw-  2.0 fat    48325 b- defN 24-Apr-16 20:17 ChefsHatGym/env/ChefsHatEnv.py
+-rw-rw-rw-  2.0 fat    49009 b- defN 24-Apr-22 15:25 ChefsHatGym/env/ChefsHatEnv.py
 -rw-rw-rw-  2.0 fat      143 b- defN 23-Oct-22 21:52 ChefsHatGym/env/__init__.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Oct-22 21:52 ChefsHatGym/gameRooms/__init__.py
 -rw-rw-rw-  2.0 fat    10986 b- defN 24-Apr-17 11:39 ChefsHatGym/gameRooms/chefs_hat_room_local.py
 -rw-rw-rw-  2.0 fat    16986 b- defN 23-Oct-24 18:08 ChefsHatGym/gameRooms/chefs_hat_room_remote.py
--rw-rw-rw-  2.0 fat    19649 b- defN 24-Apr-16 22:09 ChefsHatGym/gameRooms/chefs_hat_room_server.py
+-rw-rw-rw-  2.0 fat    19917 b- defN 24-Apr-22 15:27 ChefsHatGym/gameRooms/chefs_hat_room_server.py
 -rw-rw-rw-  2.0 fat    12874 b- defN 23-Nov-04 19:10 ChefsHatGym/gameRooms/chefs_hat_tournament.py
 -rw-rw-rw-  2.0 fat      143 b- defN 23-Oct-22 21:52 ChefsHatGym/rewards/__init__.py
 -rw-rw-rw-  2.0 fat      419 b- defN 23-Oct-23 14:06 ChefsHatGym/rewards/only_winning.py
 -rw-rw-rw-  2.0 fat      488 b- defN 23-Oct-23 13:55 ChefsHatGym/rewards/performance_score.py
 -rw-rw-rw-  2.0 fat      261 b- defN 23-Oct-23 14:06 ChefsHatGym/rewards/reward.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Oct-22 21:52 ChefsHatGym/utils/__init__.py
 -rw-rw-rw-  2.0 fat      488 b- defN 23-Oct-23 13:55 ChefsHatGym/utils/utils.py
--rw-rw-rw-  2.0 fat     1089 b- defN 24-Apr-17 12:01 chefshatgym-2.1.1.dist-info/LICENSE
--rw-rw-rw-  2.0 fat     9259 b- defN 24-Apr-17 12:01 chefshatgym-2.1.1.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 24-Apr-17 12:01 chefshatgym-2.1.1.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       12 b- defN 24-Apr-17 12:01 chefshatgym-2.1.1.dist-info/top_level.txt
--rw-rw-r--  2.0 fat     2765 b- defN 24-Apr-17 12:01 chefshatgym-2.1.1.dist-info/RECORD
-31 files, 293243 bytes uncompressed, 61728 bytes compressed:  78.9%
+-rw-rw-rw-  2.0 fat     1089 b- defN 24-May-31 15:46 chefshatgym-2.2.1.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat     9259 b- defN 24-May-31 15:46 chefshatgym-2.2.1.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 24-May-31 15:46 chefshatgym-2.2.1.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       12 b- defN 24-May-31 15:46 chefshatgym-2.2.1.dist-info/top_level.txt
+-rw-rw-r--  2.0 fat     2765 b- defN 24-May-31 15:46 chefshatgym-2.2.1.dist-info/RECORD
+31 files, 294456 bytes uncompressed, 61951 bytes compressed:  79.0%
```

## zipnote {}

```diff
@@ -72,23 +72,23 @@
 
 Filename: ChefsHatGym/utils/__init__.py
 Comment: 
 
 Filename: ChefsHatGym/utils/utils.py
 Comment: 
 
-Filename: chefshatgym-2.1.1.dist-info/LICENSE
+Filename: chefshatgym-2.2.1.dist-info/LICENSE
 Comment: 
 
-Filename: chefshatgym-2.1.1.dist-info/METADATA
+Filename: chefshatgym-2.2.1.dist-info/METADATA
 Comment: 
 
-Filename: chefshatgym-2.1.1.dist-info/WHEEL
+Filename: chefshatgym-2.2.1.dist-info/WHEEL
 Comment: 
 
-Filename: chefshatgym-2.1.1.dist-info/top_level.txt
+Filename: chefshatgym-2.2.1.dist-info/top_level.txt
 Comment: 
 
-Filename: chefshatgym-2.1.1.dist-info/RECORD
+Filename: chefshatgym-2.2.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## ChefsHatGym/KEF/DataSetManager.py

```diff
@@ -82,37 +82,40 @@
         totalActions="",
         score=[],
         roles="",
         playersStatus=[],
         agentNames="",
         possibleActions=[],
         performanceScore=[],
+        currentlyAllowedActions=[],
     ):
 
         # Guarantee is a copy
         score = copy(score)
         playersHand = copy(playersHand)
         board = copy(board)
         reward = copy(reward)
         qvalues = copy(qvalues)
         loss = copy(loss)
         roles = copy(roles)
         playersStatus = copy(playersStatus)
         possibleActions = copy(possibleActions)
+        currentlyAllowedActions = copy(currentlyAllowedActions)
 
         date = str(datetime.datetime.now()).replace(" ", "_")
         dataframe = [
             date,
             gameNumber,
             roundNumber,
             player,
             actionType,
             playersHand,
             board,
             possibleActions,
+            currentlyAllowedActions,
             cardsAction,
             reward,
             qvalues,
             loss,
             wrongActions,
             totalActions,
             score,
@@ -133,14 +136,15 @@
             "Game Number",
             "Round Number",
             "Player",
             "Action Type",
             "Player Hand",
             "Board",
             "Possible Actions",
+            "Possible Actions Decoded",
             "Cards Action",
             "Reward",
             "Qvalues",
             "Loss",
             "Wrong Actions",
             "Total Actions",  # Current turn actions
             "Scores",
@@ -191,14 +195,15 @@
         roles,
         score,
         playersStatus,
         qValue,
         loss,
         totalActions,
         possibleActions,
+        currentlyAllowedActions,
     ):
 
         actionCards = ""
         actionType = action[0]
         actionCards = action[1]
 
         self.addDataFrame(
@@ -214,14 +219,15 @@
             loss=loss,
             wrongActions=wrongActions,
             totalActions=totalActions,
             score=score,
             roles=roles,
             playersStatus=playersStatus,
             possibleActions=possibleActions,
+            currentlyAllowedActions=currentlyAllowedActions,
         )
 
     def exchangeRolesAction(self, playersHand, roles, cardsAction, game):
         actionType = actionChangeRole
         self.addDataFrame(
             actionType=actionType,
             playersHand=playersHand,
```

## ChefsHatGym/agents/chefs_hat_agent.py

```diff
@@ -98,23 +98,23 @@
 
     # Remote agent functions
     def joinGame(
         self,
         room_pass: str = "",
         room_url: str = "localhost",
         room_port: int = 10000,
-        connection_timeout: int = 10,
+        connection_timeout: int = 300,
     ):
         """
-        Allows an agent to enter a remote room, using a specific url and port to a redis server.
+        Allows an agent to enter a remote room, using a specific url and port.
 
         Args:
             room_pass (str): Password fo the room you wanna conntect to
             redis_url (str, optional): _description_. Defaults to "localhost".
-            redis_port (str, optional): _description_. Defaults to "6379".
+            redis_port (str, optional): _description_. Defaults to "10000".
         """
 
         self.room_url = room_url
         self.room_port = room_port
         self.room_pass = room_pass
         self.connection_timeout = connection_timeout
```

## ChefsHatGym/env/ChefsHatEnv.py

```diff
@@ -337,15 +337,15 @@
 
         :return: The observation is an int data-type ndarray.
                     The observation array has information about the board game, the current player's hand, and current player possible actions.
                     This array must have the shape of (228, ) as follows:
                     The first 11 elements represent the board game card placeholder (the pizza area).
                     The game cards are represented by an integer, where 0 (zero) means no card.
                     The following 17 elements (from index 11 to 27) represent the current player hand cards in the sequence.
-                    By the end, the last 200 elements (from index 28 to 227) represent all possible actions in the game.
+                    By the end, the last 200 elements (from index 27 to 227) represent all possible actions in the game.
                     The allowed actions for the current player are filled with one, while invalid actions are filled with 0.
         :rtype: ndarray
         """
         board = numpy.array(self.board) / (self.maxCardNumber + 2)
         playersHand = numpy.array(self.playersHand[self.currentPlayer]) / (
             self.maxCardNumber + 2
         )
@@ -428,14 +428,24 @@
         random.shuffle(itemindex)
         aIndex = itemindex[0]
         a = numpy.zeros(200)
         a[aIndex] = 1
 
         return a.tolist()
 
+    def decode_possible_actions(self, possibleActions):
+
+        nonzeroElements = numpy.nonzero(possibleActions)
+
+        currentlyAllowedActions = list(
+            numpy.copy(numpy.array(self.highLevelActions)[nonzeroElements,])[0]
+        )
+
+        return currentlyAllowedActions
+
     def step(self, action):
         """Execute an action in the game.
 
         :param action: The action array with 200 elements, where the choosen action is the index of the highest value
         :type action: ndarray
         :return: a tuple cointaining:
                 observation - ndarray
@@ -471,14 +481,21 @@
         validAction = False
         isMatchOver = False
         isPizzaReady = False
         thisPlayerPosition = -1
         actionIsRandom = False
 
         possibleActions = self.getPossibleActions(self.currentPlayer)
+        # Calculate the currentlyAllowedActions in a high-level
+        nonzeroElements = numpy.nonzero(possibleActions)
+
+        currentlyAllowedActions = list(
+            numpy.copy(numpy.array(self.highLevelActions)[nonzeroElements,])[0]
+        )
+
         thisPlayer = copy.copy(self.currentPlayer)
         boardBefore = copy.copy(self.board)
 
         observationBefore = copy.copy(self.getObservation())
 
         stateBefore = copy.copy(self.getObservation())
 
@@ -593,14 +610,15 @@
                     self.currentRoles,
                     self.score,
                     self.lastActionPlayers,
                     action,
                     0,
                     0,
                     possibleActions,
+                    currentlyAllowedActions,
                 )
             # Verify if it is end of match
 
             boardAfter = self.getObservation()[0:11].tolist()
 
             if not thisPlayerStopByRound and self.makePizza():
                 isPizzaReady = True
@@ -638,39 +656,37 @@
             p in self.finishingOrder for p in range(self.numberPlayers)
         ]
         info["isPizzaReady"] = isPizzaReady
         info["boardBefore"] = observationBefore[0:11].tolist()
         info["boardAfter"] = boardAfter
         info["board"] = numpy.array(self.getObservation() * 13, dtype=int).tolist()[:11]
         info["possibleActions"] = possibleActions
+        info["possibleActionsDecoded"] = currentlyAllowedActions
         info["action"] = action
         info["thisPlayerPosition"] = int(thisPlayerPosition)
         info["lastActionPlayers"] = self.lastActionPlayers
         info["lastActionTypes"] = [
             "" if a == "" else a[0] for a in self.lastActionPlayers
         ]
         info["RemainingCardsPerPlayer"] = [
             len(list(filter(lambda a: a > 0, self.playersHand[i])))
             for i in range(self.numberPlayers)
         ]
         info["players"] = self.playerNames
         info["currentRoles"] = self.currentRoles
         info["currentPlayer"] = int(self.currentPlayer)
 
-        # stateAfter = copy.copy(self.getObservation())
-        # reward = self.rewardFunctions[thisPlayer](info, stateBefore, stateAfter)
         reward = 0
         return (
             numpy.array(self.getObservation()).astype(numpy.float32),
             reward,
             isMatchOver,
             False,
             info,
         )
-        # observation, reward, isMatchOver, {}
 
     def render(self, mode="human", close=False):
         pass
 
     def close(self):
         pass
 
@@ -804,14 +820,18 @@
             :type player: int
 
         :return: getPossibleActions - (ndarray)
             :rtype: (ndarray)
         """
         firstAction = self.playerStartedGame == self.currentPlayer and self.rounds == 1
 
+        # print(
+        #     f"First action = {firstAction} - Player started game ({self.playerStartedGame}) == currentPlayer ({self.currentPlayer}) and self.rounds({self.rounds}) == 1"
+        # )
+
         # print ("Player:", player)
         possibleActions = []
 
         unique, counts = numpy.unique(self.board, return_counts=True)
         currentBoard = dict(zip(unique, counts))
 
         unique, counts = numpy.unique(self.playersHand[player], return_counts=True)
```

## ChefsHatGym/gameRooms/chefs_hat_room_server.py

```diff
@@ -21,15 +21,15 @@
     "gameOver": "gameOver",
     "doSpecialAction": "doSpecialAction",
     "specialActionUpdate": "specialActionUpdate",
     "exchangeCards": "exchangeCards",
     "updateMatchStart": "updateMatchStart",
 }
 
-MESSAGE_TYPE = {"OK": 0, "ERROR": 1}
+MESSAGE_TYPE = {"OK": "OK", "ERROR": "ERROR"}
 
 
 class ChefsHatRoomServer:
     """
     Room environment where a game will be played with agents in different processes.
     """
 
@@ -93,16 +93,16 @@
             stop_criteria (int, optional): stop criteria for the game. Defaults to 10.
             max_rounds (int, optional): maximum rounds of the game, if -1 the game will play until it ends. Defaults to -1.
             verbose (bool, optional): room verbose. Defaults to True.
             verbose (bool, optional): game verbose. Defaults to True.
             save_dataset (bool, optional): save the game dataset .pkl. Defaults to True.
             save_game_log (bool, optional): save the game log. Defaults to True.
             log_directory (str, optional): directory to save the log. Defaults to None.
-            timeout_player_subscribers (int, optional): timeout of the player subscriptions to the room. Defaults to 30.
-            timeout_player_response (int, optional): timeout of the player response. Defaults to 5.
+            timeout_player_subscribers (int, optional): timeout of the player subscriptions to the room in seconds. Defaults to 30.
+            timeout_player_response (int, optional): timeout of the player response in seconds. Defaults to 5.
         """
         # Room parameters
         self.room_url = room_url
         self.room_port = room_port
         self.room_name = room_name
         self.room_pass = room_pass
 
@@ -193,14 +193,17 @@
         while True:
             player_message = connection.recv(1024)
 
             if player_message:
                 break
 
         player_message = json.loads(player_message.decode())
+
+        print(f"Received MEssage: {player_message}")
+
         player_name = player_message.get("playerName")
 
         room_message = {}
         if player_message["password"] == self.room_pass:
 
             if len(self.players) >= 4:
                 room_message["type"] = MESSAGE_TYPE["ERROR"]
@@ -239,29 +242,28 @@
         connection.sendall(bytes(room_message, encoding="utf-8"))
 
     def _wait_for_players(self):
         self.log("[Room]: - Waiting for players to connect...")
 
         self.server_socket.listen(4)
 
-        timenow = datetime.now()
         while len(self.players) < 4:
             try:
                 connection, client_address = self.server_socket.accept()
                 self.log(
                     f"[Room]: - Received a connection request from {client_address}"
                 )
                 self._add_player(connection)
                 time.sleep(0.001)
             except socket.timeout:
                 self.error(
                     f"[Room][ERROR]: Players subscription timeout! Current playes: {self.players.keys()}"
                 )
+
                 raise Exception("Player subscription timeout!")
-            break
 
         self.log(f"[Room]: - All four players online, starting the game!")
         self.ready_to_start = True
 
     def _broadcast_message(self, player, info):
 
         connection = self.players[player]
@@ -347,14 +349,15 @@
 
         self.log("[Room]:  - Environment initialized!")
 
         observations = self.env.reset()
 
         # Update each player about the begining of the match
         self.log("[Room]:  - Informing players about game start!")
+
         for p_index, p in enumerate(self.players.keys()):
             sendInfo = {}
             sendInfo["type"] = "updateMatchStart"
             sendInfo["cards"] = self.env.playersHand[p_index]
             sendInfo["players"] = list(self.players.keys())
             sendInfo["starting_player"] = list(self.players.keys())[
                 self.env.currentPlayer
@@ -371,25 +374,29 @@
             observations = self.env.getObservation()
 
             info = {"validAction": False}
             while not info["validAction"]:
 
                 sendInfo = {}
                 sendInfo["observations"] = observations.tolist()
+                sendInfo["possibleActionsDecoded"] = self.env.decode_possible_actions(
+                    sendInfo["observations"][28:]
+                )
                 sendInfo["type"] = REQUEST_TYPE["requestAction"]
                 action, time = self._request_message(currentPlayer, sendInfo)
 
                 self.log(
                     f"[Room]:  ---- Action (duration: {time}s): {np.argmax(action)}"
                 )
                 nextobs, reward, isMatchOver, truncated, info = self.env.step(action)
 
                 if not info["validAction"]:
                     self.error(f"[Room][ERROR]: ---- Invalid action!")
 
+            # break
             # Send action update to the current agent
             # self._send_action_update(currentPlayer, info)
             info["observation"] = observations.tolist()
             info["nextObservation"] = nextobs.tolist()
             info["type"] = REQUEST_TYPE[
                 "actionUpdate"
             ]  # Update the agents after the action was done
@@ -399,14 +406,15 @@
             )  # update the current player, with the information about his hand
 
             info["observation"] = ""
             info["nextObservation"] = ""
 
             info["actionIsRandom"] = ""
             info["possibleActions"] = ""
+            info["possibleActionsDecoded"] = ""
             info["type"] = REQUEST_TYPE[
                 "updateOthers"
             ]  # Update the othe players after the action was done
             # Observe others
             for p in self.players.keys():
                 if p != currentPlayer:
                     self._broadcast_message(
```

## Comparing `chefshatgym-2.1.1.dist-info/LICENSE` & `chefshatgym-2.2.1.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `chefshatgym-2.1.1.dist-info/METADATA` & `chefshatgym-2.2.1.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: chefshatgym
-Version: 2.1.1
+Version: 2.2.1
 Summary: A python interface for training Reinforcement Learning agents to play the Chef's Hat Card Game.
 Home-page: https://github.com/pablovin/ChefsHatGYM
 Author: Pablo Barros
 Author-email: Pablo Barros <pablovin@gmail.com>
 License: MIT
 Classifier: Development Status :: 3 - Alpha
 Classifier: Intended Audience :: Developers
```

## Comparing `chefshatgym-2.1.1.dist-info/RECORD` & `chefshatgym-2.2.1.dist-info/RECORD`

 * *Files 22% similar despite different names*

```diff
@@ -1,31 +1,31 @@
 ChefsHatGym/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-ChefsHatGym/KEF/DataSetManager.py,sha256=DHZYK2LnDFNrZ07zMS12C9Az5YsyW9U_ASa8sl3n9gU,6314
+ChefsHatGym/KEF/DataSetManager.py,sha256=ed9i5MHcK5U5zrEWUPX1xuLi87zUQNvfz5tNRGGCqvY,6591
 ChefsHatGym/KEF/ExperimentManager.py,sha256=Sg9zjeNkbPgRutk-558r7feJsdDR7bsgl1F2-gL3qGE,3943
 ChefsHatGym/KEF/LogManager.py,sha256=MlRIU6RlyIdK133kReAGRLyTeEBj8qjO63K0BVhjG5Y,5439
 ChefsHatGym/KEF/MetricsManager.py,sha256=5KlC1chrmhZCNvmivMq4ZD_UhCxju3UK5X7VkLdY_BI,2834
 ChefsHatGym/KEF/PlotManager.py,sha256=sAT5ZXjzPCtyHy5kFQOwRN2oiXrIT4dxNmL5llJIBfU,65452
 ChefsHatGym/KEF/RenderManager.py,sha256=wvNLEWSOKVQeqscmth6OzgZp-G7oz0B56kZ82a7B0Ec,33311
 ChefsHatGym/KEF/StatisticsManager.py,sha256=yGHFh25Z8z-bTQKeqGoE512SNlYxrTwHANGlIFSORFc,24979
 ChefsHatGym/KEF/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 ChefsHatGym/agents/__init__.py,sha256=vKCxNh8cHhItBsozALqDD1MsjU2G_VWhLsu34Ftyhfs,143
 ChefsHatGym/agents/agent_random.py,sha256=_rLQkbnQDHB2t_uQSk9BlJx6ZmxsyPefCRuCj2Xm6Co,1638
-ChefsHatGym/agents/chefs_hat_agent.py,sha256=NU8_W3owWtAy7mB_fq4_CCdm-7BPyFZNigaFeaqAahM,12589
+ChefsHatGym/agents/chefs_hat_agent.py,sha256=osMirTfanQAE0a6rK5Yzwmxk2G-DGl6e7KTSP_ICMR8,12573
 ChefsHatGym/agents/chefs_hat_agent_socket.py,sha256=bUmx-2TVIF8ETNqU2gRDUJ-QeYeiaVV93ws9v2u2SdE,12622
-ChefsHatGym/env/ChefsHatEnv.py,sha256=NaIn97bjoIJc2OenGPg7UkK3FMNllZTARQydNCihgnM,48325
+ChefsHatGym/env/ChefsHatEnv.py,sha256=DteQWpMm2W5xdgw9vWFKU4XeVK4oZpGFZqXPYeIZfC0,49009
 ChefsHatGym/env/__init__.py,sha256=vKCxNh8cHhItBsozALqDD1MsjU2G_VWhLsu34Ftyhfs,143
 ChefsHatGym/gameRooms/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 ChefsHatGym/gameRooms/chefs_hat_room_local.py,sha256=NLAEvoVq8cNm15buq9GQTOghCTLb9WEInEybiuNe5M0,10986
 ChefsHatGym/gameRooms/chefs_hat_room_remote.py,sha256=riqBg8BJVjvZsidc37dGtH-FcFlXjvBAvr7wlcnOiTo,16986
-ChefsHatGym/gameRooms/chefs_hat_room_server.py,sha256=RCLRMw6BcLHvXwIk7vTXf9zhnh3NCsJWtXzs8pnrsUk,19649
+ChefsHatGym/gameRooms/chefs_hat_room_server.py,sha256=NqxXjIaBRL1dIqWEZn-drkOGwOb8UqejuogOnVgub74,19917
 ChefsHatGym/gameRooms/chefs_hat_tournament.py,sha256=ZLF1S4QlS29bvDzk3a8LHK59zF0o3QnN5PbbY3Opwew,12874
 ChefsHatGym/rewards/__init__.py,sha256=vKCxNh8cHhItBsozALqDD1MsjU2G_VWhLsu34Ftyhfs,143
 ChefsHatGym/rewards/only_winning.py,sha256=4mdxRGt5-IsVJWZl9yAzScLLYcoyT0w3Y7euft1HTq4,419
 ChefsHatGym/rewards/performance_score.py,sha256=PaehIySmjlEllohRC7ip51cnFsrhZdG6SxSj7dcy-0o,488
 ChefsHatGym/rewards/reward.py,sha256=WW3VR7MuwrmTDSLfd5inDuOLDOEXSgi1rw7SdCftTP0,261
 ChefsHatGym/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 ChefsHatGym/utils/utils.py,sha256=sDE0Vijgcgprz-SxUjmcCW7JsyMrsTGjNwUAcx939kY,488
-chefshatgym-2.1.1.dist-info/LICENSE,sha256=hCCVx5b2fVwXmX_xxzdEFQu2-QRUOumXbw5K0Z7LvI0,1089
-chefshatgym-2.1.1.dist-info/METADATA,sha256=bXFkaQHhFPjVEvzJtDe5bfGLYUnXlOla-aNUKgjjREQ,9259
-chefshatgym-2.1.1.dist-info/WHEEL,sha256=yQN5g4mg4AybRjkgi-9yy4iQEFibGQmlz78Pik5Or-A,92
-chefshatgym-2.1.1.dist-info/top_level.txt,sha256=ekL7ntfrArepYZ6Sd1Omlh-xRAjzb7N5yp657GSMmJM,12
-chefshatgym-2.1.1.dist-info/RECORD,,
+chefshatgym-2.2.1.dist-info/LICENSE,sha256=hCCVx5b2fVwXmX_xxzdEFQu2-QRUOumXbw5K0Z7LvI0,1089
+chefshatgym-2.2.1.dist-info/METADATA,sha256=iZSltHi2fJN7FzFEGseFflSAQb7ARAXTduojLhzcMGA,9259
+chefshatgym-2.2.1.dist-info/WHEEL,sha256=yQN5g4mg4AybRjkgi-9yy4iQEFibGQmlz78Pik5Or-A,92
+chefshatgym-2.2.1.dist-info/top_level.txt,sha256=ekL7ntfrArepYZ6Sd1Omlh-xRAjzb7N5yp657GSMmJM,12
+chefshatgym-2.2.1.dist-info/RECORD,,
```

