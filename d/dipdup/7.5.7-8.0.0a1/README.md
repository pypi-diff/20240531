# Comparing `tmp/dipdup-7.5.7.tar.gz` & `tmp/dipdup-8.0.0a1.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "dipdup-7.5.7.tar", last modified: Thu May 30 22:27:35 2024, max compression
+gzip compressed data, was "dipdup-8.0.0a1.tar", last modified: Mon May  6 16:49:22 2024, max compression
```

## Comparing `dipdup-7.5.7.tar` & `dipdup-8.0.0a1.tar`

### file list

```diff
@@ -1,1336 +1,1339 @@
--rw-r--r--   0        0        0     1067 2024-05-30 22:20:27.197086 dipdup-7.5.7/LICENSE
--rw-r--r--   0        0        0     2581 2024-05-30 22:20:27.197086 dipdup-7.5.7/README.md
--rw-r--r--   0        0        0     5108 2024-05-30 22:27:35.624083 dipdup-7.5.7/pyproject.toml
--rw-r--r--   0        0        0      267 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/.dockerignore
--rw-r--r--   0        0        0      363 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/.gitignore
--rw-r--r--   0        0        0       35 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_auction/.ruff_cache/.gitignore
--rw-r--r--   0        0        0      146 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_auction/.ruff_cache/0.4.6/1014297332060801350
--rw-r--r--   0        0        0      245 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_auction/.ruff_cache/0.4.6/12038680413413916851
--rw-r--r--   0        0        0      267 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_auction/.ruff_cache/0.4.6/4259351632561215180
--rw-r--r--   0        0        0      306 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_auction/.ruff_cache/0.4.6/8609622175875379712
--rw-r--r--   0        0        0       43 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_auction/.ruff_cache/CACHEDIR.TAG
--rw-r--r--   0        0        0      936 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/Makefile
--rw-r--r--   0        0        0      910 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/README.md
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/abi/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/configs/.keep
--rw-r--r--   0        0        0      523 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/configs/dipdup.compose.yaml
--rw-r--r--   0        0        0       73 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/configs/dipdup.sqlite.yaml
--rw-r--r--   0        0        0      548 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/configs/dipdup.swarm.yaml
--rw-r--r--   0        0        0      559 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/configs/replay.yaml
--rw-r--r--   0        0        0      431 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/deploy/.env.default
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/deploy/.keep
--rw-r--r--   0        0        0      218 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/deploy/Dockerfile
--rw-r--r--   0        0        0      363 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/deploy/compose.sqlite.yaml
--rw-r--r--   0        0        0     2675 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/deploy/compose.swarm.yaml
--rw-r--r--   0        0        0     1261 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/deploy/compose.yaml
--rw-r--r--   0        0        0      242 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/deploy/sqlite.env.default
--rw-r--r--   0        0        0      456 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/deploy/swarm.env.default
--rw-r--r--   0        0        0     1077 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/dipdup.yaml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/graphql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/handlers/.keep
--rw-r--r--   0        0        0      913 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/handlers/on_bid.py
--rw-r--r--   0        0        0     1619 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/handlers/on_create_auction.py
--rw-r--r--   0        0        0      712 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/handlers/on_withdraw.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/hasura/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/hooks/.keep
--rw-r--r--   0        0        0      378 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/hooks/on_index_rollback.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/hooks/on_reindex.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/hooks/on_restart.py
--rw-r--r--   0        0        0      145 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/hooks/on_synchronized.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/models/.keep
--rw-r--r--   0        0        0     1445 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/models/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/py.typed
--rw-r--r--   0        0        0     1490 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/pyproject.toml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/sql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/sql/on_index_rollback/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/sql/on_reindex/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/sql/on_restart/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/sql/on_synchronized/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/types/.keep
--rw-r--r--   0        0        0      177 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/types/tzcolors_auction/tezos_parameters/bid.py
--rw-r--r--   0        0        0      381 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/types/tzcolors_auction/tezos_parameters/create_auction.py
--rw-r--r--   0        0        0      187 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/types/tzcolors_auction/tezos_parameters/withdraw.py
--rw-r--r--   0        0        0      499 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_auction/types/tzcolors_auction/tezos_storage.py
--rw-r--r--   0        0        0      268 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/.dockerignore
--rw-r--r--   0        0        0      364 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/.gitignore
--rw-r--r--   0        0        0       35 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_big_maps/.ruff_cache/.gitignore
--rw-r--r--   0        0        0      203 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_big_maps/.ruff_cache/0.4.6/1850800619147169163
--rw-r--r--   0        0        0      307 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_big_maps/.ruff_cache/0.4.6/9240050208903904737
--rw-r--r--   0        0        0      362 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_big_maps/.ruff_cache/0.4.6/9577707901167005866
--rw-r--r--   0        0        0       43 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_big_maps/.ruff_cache/CACHEDIR.TAG
--rw-r--r--   0        0        0      937 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/Makefile
--rw-r--r--   0        0        0      911 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/README.md
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/abi/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/configs/.keep
--rw-r--r--   0        0        0      523 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/configs/dipdup.compose.yaml
--rw-r--r--   0        0        0       74 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/configs/dipdup.sqlite.yaml
--rw-r--r--   0        0        0      550 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/configs/dipdup.swarm.yaml
--rw-r--r--   0        0        0      561 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/configs/replay.yaml
--rw-r--r--   0        0        0      431 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/deploy/.env.default
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/deploy/.keep
--rw-r--r--   0        0        0      220 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/deploy/Dockerfile
--rw-r--r--   0        0        0      365 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/deploy/compose.sqlite.yaml
--rw-r--r--   0        0        0     2677 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/deploy/compose.swarm.yaml
--rw-r--r--   0        0        0     1262 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/deploy/compose.yaml
--rw-r--r--   0        0        0      243 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/deploy/sqlite.env.default
--rw-r--r--   0        0        0      458 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/deploy/swarm.env.default
--rw-r--r--   0        0        0      725 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/dipdup.yaml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/graphql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/handlers/.keep
--rw-r--r--   0        0        0      846 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/handlers/on_update_expiry_map.py
--rw-r--r--   0        0        0     1690 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/handlers/on_update_records.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/hasura/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.213086 dipdup-7.5.7/src/demo_big_maps/hooks/.keep
--rw-r--r--   0        0        0      378 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_big_maps/hooks/on_index_rollback.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_big_maps/hooks/on_reindex.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_big_maps/hooks/on_restart.py
--rw-r--r--   0        0        0      145 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_big_maps/hooks/on_synchronized.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_big_maps/models/.keep
--rw-r--r--   0        0        0      667 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_big_maps/models/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_big_maps/py.typed
--rw-r--r--   0        0        0     1491 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_big_maps/pyproject.toml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_big_maps/sql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_big_maps/sql/on_index_rollback/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_big_maps/sql/on_reindex/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_big_maps/sql/on_restart/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_big_maps/sql/on_synchronized/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_big_maps/types/.keep
--rw-r--r--   0        0        0      199 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_big_maps/types/name_registry/tezos_big_maps/store_expiry_map_key.py
--rw-r--r--   0        0        0      203 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_big_maps/types/name_registry/tezos_big_maps/store_expiry_map_value.py
--rw-r--r--   0        0        0      194 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_big_maps/types/name_registry/tezos_big_maps/store_records_key.py
--rw-r--r--   0        0        0      427 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_big_maps/types/name_registry/tezos_big_maps/store_records_value.py
--rw-r--r--   0        0        0      265 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/.dockerignore
--rw-r--r--   0        0        0      361 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/.gitignore
--rw-r--r--   0        0        0       35 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_blank/.ruff_cache/.gitignore
--rw-r--r--   0        0        0      304 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_blank/.ruff_cache/0.4.6/3458681998132079222
--rw-r--r--   0        0        0       43 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_blank/.ruff_cache/CACHEDIR.TAG
--rw-r--r--   0        0        0      934 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/Makefile
--rw-r--r--   0        0        0      912 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/README.md
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/abi/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/configs/.keep
--rw-r--r--   0        0        0      523 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/configs/dipdup.compose.yaml
--rw-r--r--   0        0        0       71 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/configs/dipdup.sqlite.yaml
--rw-r--r--   0        0        0      544 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/configs/dipdup.swarm.yaml
--rw-r--r--   0        0        0      559 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/configs/replay.yaml
--rw-r--r--   0        0        0      402 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/deploy/.env.default
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/deploy/.keep
--rw-r--r--   0        0        0      214 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/deploy/Dockerfile
--rw-r--r--   0        0        0      359 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/deploy/compose.sqlite.yaml
--rw-r--r--   0        0        0     2671 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/deploy/compose.swarm.yaml
--rw-r--r--   0        0        0     1259 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/deploy/compose.yaml
--rw-r--r--   0        0        0      211 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/deploy/sqlite.env.default
--rw-r--r--   0        0        0      423 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/deploy/swarm.env.default
--rw-r--r--   0        0        0       37 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/dipdup.yaml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/graphql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/handlers/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/hasura/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/hooks/.keep
--rw-r--r--   0        0        0      378 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/hooks/on_index_rollback.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/hooks/on_reindex.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/hooks/on_restart.py
--rw-r--r--   0        0        0      145 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/hooks/on_synchronized.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/models/.keep
--rw-r--r--   0        0        0     1241 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/models/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/py.typed
--rw-r--r--   0        0        0     1492 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/pyproject.toml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/sql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/sql/on_index_rollback/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/sql/on_reindex/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/sql/on_restart/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/sql/on_synchronized/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_blank/types/.keep
--rw-r--r--   0        0        0      263 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/.dockerignore
--rw-r--r--   0        0        0      359 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/.gitignore
--rw-r--r--   0        0        0       35 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_dao/.ruff_cache/.gitignore
--rw-r--r--   0        0        0      145 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_dao/.ruff_cache/0.4.6/14332565594888191465
--rw-r--r--   0        0        0      185 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_dao/.ruff_cache/0.4.6/15843462123545375892
--rw-r--r--   0        0        0      302 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_dao/.ruff_cache/0.4.6/17001726698443768994
--rw-r--r--   0        0        0      134 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_dao/.ruff_cache/0.4.6/200896236354315765
--rw-r--r--   0        0        0       43 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_dao/.ruff_cache/CACHEDIR.TAG
--rw-r--r--   0        0        0      932 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/Makefile
--rw-r--r--   0        0        0      907 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/README.md
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/abi/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/configs/.keep
--rw-r--r--   0        0        0      523 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/configs/dipdup.compose.yaml
--rw-r--r--   0        0        0       69 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/configs/dipdup.sqlite.yaml
--rw-r--r--   0        0        0      540 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/configs/dipdup.swarm.yaml
--rw-r--r--   0        0        0      552 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/configs/replay.yaml
--rw-r--r--   0        0        0      431 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/deploy/.env.default
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/deploy/.keep
--rw-r--r--   0        0        0      210 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/deploy/Dockerfile
--rw-r--r--   0        0        0      355 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/deploy/compose.sqlite.yaml
--rw-r--r--   0        0        0     2667 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/deploy/compose.swarm.yaml
--rw-r--r--   0        0        0     1257 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/deploy/compose.yaml
--rw-r--r--   0        0        0      238 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/deploy/sqlite.env.default
--rw-r--r--   0        0        0      448 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/deploy/swarm.env.default
--rw-r--r--   0        0        0      643 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/dipdup.yaml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/graphql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/handlers/.keep
--rw-r--r--   0        0        0      408 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/handlers/on_origination.py
--rw-r--r--   0        0        0      506 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/handlers/on_propose.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/hasura/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/hooks/.keep
--rw-r--r--   0        0        0      378 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/hooks/on_index_rollback.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/hooks/on_reindex.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/hooks/on_restart.py
--rw-r--r--   0        0        0      145 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/hooks/on_synchronized.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/models/.keep
--rw-r--r--   0        0        0      782 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/models/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/py.typed
--rw-r--r--   0        0        0     1487 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/pyproject.toml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/sql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/sql/on_index_rollback/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/sql/on_reindex/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/sql/on_restart/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/sql/on_synchronized/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/types/.keep
--rw-r--r--   0        0        0      360 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/types/registry/tezos_parameters/propose.py
--rw-r--r--   0        0        0     2475 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dao/types/registry/tezos_storage.py
--rw-r--r--   0        0        0      263 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dex/.dockerignore
--rw-r--r--   0        0        0      359 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dex/.gitignore
--rw-r--r--   0        0        0       35 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_dex/.ruff_cache/.gitignore
--rw-r--r--   0        0        0      136 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_dex/.ruff_cache/0.4.6/11640690281099431128
--rw-r--r--   0        0        0      136 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_dex/.ruff_cache/0.4.6/12681781774939801388
--rw-r--r--   0        0        0      998 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_dex/.ruff_cache/0.4.6/12988769168536135837
--rw-r--r--   0        0        0      135 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_dex/.ruff_cache/0.4.6/15694300220048575261
--rw-r--r--   0        0        0      135 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_dex/.ruff_cache/0.4.6/17577906891574298503
--rw-r--r--   0        0        0      302 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_dex/.ruff_cache/0.4.6/2396607786007099989
--rw-r--r--   0        0        0      465 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_dex/.ruff_cache/0.4.6/7093863211754048792
--rw-r--r--   0        0        0      148 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_dex/.ruff_cache/0.4.6/8830336452362282550
--rw-r--r--   0        0        0      464 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_dex/.ruff_cache/0.4.6/9522331550671749042
--rw-r--r--   0        0        0      147 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_dex/.ruff_cache/0.4.6/9660755879577909108
--rw-r--r--   0        0        0       43 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_dex/.ruff_cache/CACHEDIR.TAG
--rw-r--r--   0        0        0      932 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dex/Makefile
--rw-r--r--   0        0        0      918 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dex/README.md
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dex/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.217086 dipdup-7.5.7/src/demo_dex/abi/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/configs/.keep
--rw-r--r--   0        0        0      523 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/configs/dipdup.compose.yaml
--rw-r--r--   0        0        0       69 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/configs/dipdup.sqlite.yaml
--rw-r--r--   0        0        0      540 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/configs/dipdup.swarm.yaml
--rw-r--r--   0        0        0      563 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/configs/replay.yaml
--rw-r--r--   0        0        0      402 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/deploy/.env.default
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/deploy/.keep
--rw-r--r--   0        0        0      210 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/deploy/Dockerfile
--rw-r--r--   0        0        0      355 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/deploy/compose.sqlite.yaml
--rw-r--r--   0        0        0     2667 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/deploy/compose.swarm.yaml
--rw-r--r--   0        0        0     1257 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/deploy/compose.yaml
--rw-r--r--   0        0        0      209 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/deploy/sqlite.env.default
--rw-r--r--   0        0        0      419 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/deploy/swarm.env.default
--rw-r--r--   0        0        0     4845 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/dipdup.yaml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/graphql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/handlers/.keep
--rw-r--r--   0        0        0     1829 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/handlers/on_fa12_divest_liquidity.py
--rw-r--r--   0        0        0     1737 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/handlers/on_fa12_invest_liquidity.py
--rw-r--r--   0        0        0      579 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/handlers/on_fa12_origination.py
--rw-r--r--   0        0        0     1610 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/handlers/on_fa12_tez_to_token.py
--rw-r--r--   0        0        0     1676 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/handlers/on_fa12_token_to_tez.py
--rw-r--r--   0        0        0     1022 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/handlers/on_fa12_transfer.py
--rw-r--r--   0        0        0      931 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/handlers/on_fa12_withdraw_profit.py
--rw-r--r--   0        0        0     1855 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/handlers/on_fa2_divest_liquidity.py
--rw-r--r--   0        0        0     1763 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/handlers/on_fa2_invest_liquidity.py
--rw-r--r--   0        0        0      573 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/handlers/on_fa2_origination.py
--rw-r--r--   0        0        0     1604 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/handlers/on_fa2_tez_to_token.py
--rw-r--r--   0        0        0     1642 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/handlers/on_fa2_token_to_tez.py
--rw-r--r--   0        0        0     1143 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/handlers/on_fa2_transfer.py
--rw-r--r--   0        0        0      927 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/handlers/on_fa2_withdraw_profit.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/hasura/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/hooks/.keep
--rw-r--r--   0        0        0      378 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/hooks/on_index_rollback.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/hooks/on_reindex.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/hooks/on_restart.py
--rw-r--r--   0        0        0      145 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/hooks/on_synchronized.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/models/.keep
--rw-r--r--   0        0        0      916 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/models/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/py.typed
--rw-r--r--   0        0        0     1498 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/pyproject.toml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/sql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/sql/on_index_rollback/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/sql/on_reindex/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/sql/on_restart/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/sql/on_synchronized/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/types/.keep
--rw-r--r--   0        0        0      340 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/types/fa12_token/tezos_parameters/transfer.py
--rw-r--r--   0        0        0      714 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/types/fa12_token/tezos_storage.py
--rw-r--r--   0        0        0      479 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/types/fa2_token/tezos_parameters/transfer.py
--rw-r--r--   0        0        0     1045 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/types/fa2_token/tezos_storage.py
--rw-r--r--   0        0        0      311 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/types/quipu_fa12/tezos_parameters/divest_liquidity.py
--rw-r--r--   0        0        0      201 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/types/quipu_fa12/tezos_parameters/invest_liquidity.py
--rw-r--r--   0        0        0      297 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/types/quipu_fa12/tezos_parameters/tez_to_token_payment.py
--rw-r--r--   0        0        0      313 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/types/quipu_fa12/tezos_parameters/token_to_tez_payment.py
--rw-r--r--   0        0        0      340 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/types/quipu_fa12/tezos_parameters/transfer.py
--rw-r--r--   0        0        0      199 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/types/quipu_fa12/tezos_parameters/withdraw_profit.py
--rw-r--r--   0        0        0     1393 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/types/quipu_fa12/tezos_storage.py
--rw-r--r--   0        0        0      311 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/types/quipu_fa2/tezos_parameters/divest_liquidity.py
--rw-r--r--   0        0        0      201 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/types/quipu_fa2/tezos_parameters/invest_liquidity.py
--rw-r--r--   0        0        0      297 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/types/quipu_fa2/tezos_parameters/tez_to_token_payment.py
--rw-r--r--   0        0        0      313 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/types/quipu_fa2/tezos_parameters/token_to_tez_payment.py
--rw-r--r--   0        0        0      479 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/types/quipu_fa2/tezos_parameters/transfer.py
--rw-r--r--   0        0        0      199 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/types/quipu_fa2/tezos_parameters/withdraw_profit.py
--rw-r--r--   0        0        0     1405 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_dex/types/quipu_fa2/tezos_storage.py
--rw-r--r--   0        0        0      267 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/.dockerignore
--rw-r--r--   0        0        0      363 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/.gitignore
--rw-r--r--   0        0        0       35 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_domains/.ruff_cache/.gitignore
--rw-r--r--   0        0        0      202 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_domains/.ruff_cache/0.4.6/1289096812726405569
--rw-r--r--   0        0        0      368 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_domains/.ruff_cache/0.4.6/209858414813208832
--rw-r--r--   0        0        0      361 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_domains/.ruff_cache/0.4.6/7015232390909576803
--rw-r--r--   0        0        0       43 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_domains/.ruff_cache/CACHEDIR.TAG
--rw-r--r--   0        0        0      936 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/Makefile
--rw-r--r--   0        0        0      919 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/README.md
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/abi/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/configs/.keep
--rw-r--r--   0        0        0      523 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/configs/dipdup.compose.yaml
--rw-r--r--   0        0        0       73 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/configs/dipdup.sqlite.yaml
--rw-r--r--   0        0        0      548 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/configs/dipdup.swarm.yaml
--rw-r--r--   0        0        0      568 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/configs/replay.yaml
--rw-r--r--   0        0        0      431 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/deploy/.env.default
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/deploy/.keep
--rw-r--r--   0        0        0      218 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/deploy/Dockerfile
--rw-r--r--   0        0        0      363 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/deploy/compose.sqlite.yaml
--rw-r--r--   0        0        0     2675 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/deploy/compose.swarm.yaml
--rw-r--r--   0        0        0     1261 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/deploy/compose.yaml
--rw-r--r--   0        0        0      242 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/deploy/sqlite.env.default
--rw-r--r--   0        0        0      456 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/deploy/swarm.env.default
--rw-r--r--   0        0        0      893 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/dipdup.yaml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/graphql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/handlers/.keep
--rw-r--r--   0        0        0     1938 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/handlers/on_update_expiry_map.py
--rw-r--r--   0        0        0     3286 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/handlers/on_update_records.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/hasura/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/hooks/.keep
--rw-r--r--   0        0        0      959 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/hooks/check_expiration.py
--rw-r--r--   0        0        0      378 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/hooks/on_index_rollback.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/hooks/on_reindex.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/hooks/on_restart.py
--rw-r--r--   0        0        0      145 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/hooks/on_synchronized.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/models/.keep
--rw-r--r--   0        0        0      972 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/models/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/py.typed
--rw-r--r--   0        0        0     1499 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/pyproject.toml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/sql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/sql/on_index_rollback/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.221086 dipdup-7.5.7/src/demo_domains/sql/on_reindex/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_domains/sql/on_restart/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_domains/sql/on_synchronized/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_domains/types/.keep
--rw-r--r--   0        0        0      199 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_domains/types/name_registry/tezos_big_maps/store_expiry_map_key.py
--rw-r--r--   0        0        0      203 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_domains/types/name_registry/tezos_big_maps/store_expiry_map_value.py
--rw-r--r--   0        0        0      194 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_domains/types/name_registry/tezos_big_maps/store_records_key.py
--rw-r--r--   0        0        0      427 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_domains/types/name_registry/tezos_big_maps/store_records_value.py
--rw-r--r--   0        0        0      269 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/.dockerignore
--rw-r--r--   0        0        0      365 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/.gitignore
--rw-r--r--   0        0        0       35 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_etherlink/.ruff_cache/.gitignore
--rw-r--r--   0        0        0      145 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_etherlink/.ruff_cache/0.4.6/10683567633256137694
--rw-r--r--   0        0        0      156 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_etherlink/.ruff_cache/0.4.6/11885873784288089140
--rw-r--r--   0        0        0      188 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_etherlink/.ruff_cache/0.4.6/13068053185694110200
--rw-r--r--   0        0        0      140 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_etherlink/.ruff_cache/0.4.6/14024513152605979096
--rw-r--r--   0        0        0      149 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_etherlink/.ruff_cache/0.4.6/14870787188785001377
--rw-r--r--   0        0        0      308 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_etherlink/.ruff_cache/0.4.6/1784665511473031261
--rw-r--r--   0        0        0      138 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_etherlink/.ruff_cache/0.4.6/4831370666459392320
--rw-r--r--   0        0        0      205 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_etherlink/.ruff_cache/0.4.6/8343994076423201062
--rw-r--r--   0        0        0       43 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_etherlink/.ruff_cache/CACHEDIR.TAG
--rw-r--r--   0        0        0      938 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/Makefile
--rw-r--r--   0        0        0      921 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/README.md
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/abi/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/configs/.keep
--rw-r--r--   0        0        0      523 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/configs/dipdup.compose.yaml
--rw-r--r--   0        0        0       75 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/configs/dipdup.sqlite.yaml
--rw-r--r--   0        0        0      552 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/configs/dipdup.swarm.yaml
--rw-r--r--   0        0        0      572 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/configs/replay.yaml
--rw-r--r--   0        0        0      442 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/deploy/.env.default
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/deploy/.keep
--rw-r--r--   0        0        0      222 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/deploy/Dockerfile
--rw-r--r--   0        0        0      367 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/deploy/compose.sqlite.yaml
--rw-r--r--   0        0        0     2679 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/deploy/compose.swarm.yaml
--rw-r--r--   0        0        0     1263 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/deploy/compose.yaml
--rw-r--r--   0        0        0      255 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/deploy/sqlite.env.default
--rw-r--r--   0        0        0      471 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/deploy/swarm.env.default
--rw-r--r--   0        0        0     1343 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/dipdup.yaml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/graphql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/handlers/.keep
--rw-r--r--   0        0        0      874 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/handlers/on_deposit.py
--rw-r--r--   0        0        0      583 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/handlers/on_withdraw.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/hasura/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/hooks/.keep
--rw-r--r--   0        0        0      378 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/hooks/on_index_rollback.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/hooks/on_reindex.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/hooks/on_restart.py
--rw-r--r--   0        0        0      145 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/hooks/on_synchronized.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/models/.keep
--rw-r--r--   0        0        0     1241 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/models/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/py.typed
--rw-r--r--   0        0        0     1501 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/pyproject.toml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/sql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/sql/on_index_rollback/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/sql/on_reindex/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/sql/on_restart/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/sql/on_synchronized/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/types/.keep
--rw-r--r--   0        0        0      894 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/types/rollup/tezos_parameters/default.py
--rw-r--r--   0        0        0      189 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/types/rollup/tezos_storage.py
--rw-r--r--   0        0        0      398 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/types/ticket_helper/tezos_parameters/default.py
--rw-r--r--   0        0        0      744 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/types/ticket_helper/tezos_storage.py
--rw-r--r--   0        0        0      185 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/types/ticketer/tezos_parameters/deposit.py
--rw-r--r--   0        0        0      512 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/types/ticketer/tezos_parameters/withdraw.py
--rw-r--r--   0        0        0      712 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_etherlink/types/ticketer/tezos_storage.py
--rw-r--r--   0        0        0      266 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/.dockerignore
--rw-r--r--   0        0        0      362 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/.gitignore
--rw-r--r--   0        0        0       35 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_events/.ruff_cache/.gitignore
--rw-r--r--   0        0        0      250 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_events/.ruff_cache/0.4.6/12982536521510682863
--rw-r--r--   0        0        0      198 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_events/.ruff_cache/0.4.6/1931364631853749832
--rw-r--r--   0        0        0      305 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_events/.ruff_cache/0.4.6/7814564911216302775
--rw-r--r--   0        0        0       43 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_events/.ruff_cache/CACHEDIR.TAG
--rw-r--r--   0        0        0      935 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/Makefile
--rw-r--r--   0        0        0      909 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/README.md
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/abi/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/configs/.keep
--rw-r--r--   0        0        0      523 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/configs/dipdup.compose.yaml
--rw-r--r--   0        0        0       72 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/configs/dipdup.sqlite.yaml
--rw-r--r--   0        0        0      546 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/configs/dipdup.swarm.yaml
--rw-r--r--   0        0        0      557 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/configs/replay.yaml
--rw-r--r--   0        0        0      402 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/deploy/.env.default
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/deploy/.keep
--rw-r--r--   0        0        0      216 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/deploy/Dockerfile
--rw-r--r--   0        0        0      361 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/deploy/compose.sqlite.yaml
--rw-r--r--   0        0        0     2673 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/deploy/compose.swarm.yaml
--rw-r--r--   0        0        0     1260 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/deploy/compose.yaml
--rw-r--r--   0        0        0      212 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/deploy/sqlite.env.default
--rw-r--r--   0        0        0      425 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/deploy/swarm.env.default
--rw-r--r--   0        0        0      534 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/dipdup.yaml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/graphql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/handlers/.keep
--rw-r--r--   0        0        0      311 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/handlers/on_move_event.py
--rw-r--r--   0        0        0      237 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/handlers/on_other_event.py
--rw-r--r--   0        0        0      311 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/handlers/on_roll_event.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/hasura/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/hooks/.keep
--rw-r--r--   0        0        0      378 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/hooks/on_index_rollback.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/hooks/on_reindex.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/hooks/on_restart.py
--rw-r--r--   0        0        0      145 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/hooks/on_synchronized.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/models/.keep
--rw-r--r--   0        0        0     1241 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/models/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/py.typed
--rw-r--r--   0        0        0     1489 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/pyproject.toml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/sql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/sql/on_index_rollback/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/sql/on_reindex/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/sql/on_restart/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/sql/on_synchronized/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/types/.keep
--rw-r--r--   0        0        0      317 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/types/events_contract/tezos_events/move.py
--rw-r--r--   0        0        0      266 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_events/types/events_contract/tezos_events/roll.py
--rw-r--r--   0        0        0      270 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_evm_events/.dockerignore
--rw-r--r--   0        0        0      366 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_evm_events/.gitignore
--rw-r--r--   0        0        0       35 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_evm_events/.ruff_cache/.gitignore
--rw-r--r--   0        0        0      147 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_evm_events/.ruff_cache/0.4.6/13636334052103910630
--rw-r--r--   0        0        0      133 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_evm_events/.ruff_cache/0.4.6/16137286487269764171
--rw-r--r--   0        0        0      309 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_evm_events/.ruff_cache/0.4.6/6340792336577073510
--rw-r--r--   0        0        0       43 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_evm_events/.ruff_cache/CACHEDIR.TAG
--rw-r--r--   0        0        0      939 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_evm_events/Makefile
--rw-r--r--   0        0        0      927 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_evm_events/README.md
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.225086 dipdup-7.5.7/src/demo_evm_events/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/abi/.keep
--rw-r--r--   0        0        0    11460 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/abi/eth_usdt/abi.json
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/configs/.keep
--rw-r--r--   0        0        0      523 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/configs/dipdup.compose.yaml
--rw-r--r--   0        0        0       76 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/configs/dipdup.sqlite.yaml
--rw-r--r--   0        0        0      554 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/configs/dipdup.swarm.yaml
--rw-r--r--   0        0        0      579 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/configs/replay.yaml
--rw-r--r--   0        0        0      644 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/deploy/.env.default
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/deploy/.keep
--rw-r--r--   0        0        0      224 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/deploy/Dockerfile
--rw-r--r--   0        0        0      369 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/deploy/compose.sqlite.yaml
--rw-r--r--   0        0        0     2681 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/deploy/compose.swarm.yaml
--rw-r--r--   0        0        0     1264 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/deploy/compose.yaml
--rw-r--r--   0        0        0      458 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/deploy/sqlite.env.default
--rw-r--r--   0        0        0      675 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/deploy/swarm.env.default
--rw-r--r--   0        0        0      811 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/dipdup.yaml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/graphql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/handlers/.keep
--rw-r--r--   0        0        0     1291 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/handlers/on_transfer.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/hasura/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/hooks/.keep
--rw-r--r--   0        0        0      378 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/hooks/on_index_rollback.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/hooks/on_reindex.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/hooks/on_restart.py
--rw-r--r--   0        0        0      145 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/hooks/on_synchronized.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/models/.keep
--rw-r--r--   0        0        0      469 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/models/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/py.typed
--rw-r--r--   0        0        0     1507 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/pyproject.toml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/sql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/sql/on_index_rollback/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/sql/on_reindex/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/sql/on_restart/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/sql/on_synchronized/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/types/.keep
--rw-r--r--   0        0        0      331 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_events/types/eth_usdt/evm_events/transfer.py
--rw-r--r--   0        0        0      276 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/.dockerignore
--rw-r--r--   0        0        0      372 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/.gitignore
--rw-r--r--   0        0        0       35 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_evm_transactions/.ruff_cache/.gitignore
--rw-r--r--   0        0        0      139 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_evm_transactions/.ruff_cache/0.4.6/10730177481786867571
--rw-r--r--   0        0        0      154 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_evm_transactions/.ruff_cache/0.4.6/17711529834938179041
--rw-r--r--   0        0        0      315 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_evm_transactions/.ruff_cache/0.4.6/18181918862698586528
--rw-r--r--   0        0        0       43 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_evm_transactions/.ruff_cache/CACHEDIR.TAG
--rw-r--r--   0        0        0      945 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/Makefile
--rw-r--r--   0        0        0      935 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/README.md
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/abi/.keep
--rw-r--r--   0        0        0    11460 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/abi/eth_usdt/abi.json
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/configs/.keep
--rw-r--r--   0        0        0      523 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/configs/dipdup.compose.yaml
--rw-r--r--   0        0        0       82 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/configs/dipdup.sqlite.yaml
--rw-r--r--   0        0        0      566 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/configs/dipdup.swarm.yaml
--rw-r--r--   0        0        0      593 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/configs/replay.yaml
--rw-r--r--   0        0        0      644 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/deploy/.env.default
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/deploy/.keep
--rw-r--r--   0        0        0      236 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/deploy/Dockerfile
--rw-r--r--   0        0        0      381 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/deploy/compose.sqlite.yaml
--rw-r--r--   0        0        0     2693 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/deploy/compose.swarm.yaml
--rw-r--r--   0        0        0     1270 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/deploy/compose.yaml
--rw-r--r--   0        0        0      464 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/deploy/sqlite.env.default
--rw-r--r--   0        0        0      687 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/deploy/swarm.env.default
--rw-r--r--   0        0        0      850 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/dipdup.yaml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/graphql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/handlers/.keep
--rw-r--r--   0        0        0     1345 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/handlers/on_transfer.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/hasura/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/hooks/.keep
--rw-r--r--   0        0        0      378 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/hooks/on_index_rollback.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/hooks/on_reindex.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/hooks/on_restart.py
--rw-r--r--   0        0        0      145 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/hooks/on_synchronized.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/models/.keep
--rw-r--r--   0        0        0      469 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/models/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/py.typed
--rw-r--r--   0        0        0     1515 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/pyproject.toml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/sql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/sql/on_index_rollback/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/sql/on_reindex/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/sql/on_restart/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/sql/on_synchronized/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/types/.keep
--rw-r--r--   0        0        0      262 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_evm_transactions/types/eth_usdt/evm_methods/transfer.py
--rw-r--r--   0        0        0      269 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/.dockerignore
--rw-r--r--   0        0        0      365 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/.gitignore
--rw-r--r--   0        0        0       35 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_factories/.ruff_cache/.gitignore
--rw-r--r--   0        0        0      139 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_factories/.ruff_cache/0.4.6/14653597352086107285
--rw-r--r--   0        0        0      308 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_factories/.ruff_cache/0.4.6/17409646336381538258
--rw-r--r--   0        0        0      149 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_factories/.ruff_cache/0.4.6/17920886584411799377
--rw-r--r--   0        0        0      137 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_factories/.ruff_cache/0.4.6/18166390207757415471
--rw-r--r--   0        0        0      200 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_factories/.ruff_cache/0.4.6/9859528036613215474
--rw-r--r--   0        0        0       43 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_factories/.ruff_cache/CACHEDIR.TAG
--rw-r--r--   0        0        0      938 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/Makefile
--rw-r--r--   0        0        0      924 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/README.md
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/abi/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/configs/.keep
--rw-r--r--   0        0        0      523 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/configs/dipdup.compose.yaml
--rw-r--r--   0        0        0       75 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/configs/dipdup.sqlite.yaml
--rw-r--r--   0        0        0      552 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/configs/dipdup.swarm.yaml
--rw-r--r--   0        0        0      575 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/configs/replay.yaml
--rw-r--r--   0        0        0      431 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/deploy/.env.default
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/deploy/.keep
--rw-r--r--   0        0        0      222 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/deploy/Dockerfile
--rw-r--r--   0        0        0      367 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/deploy/compose.sqlite.yaml
--rw-r--r--   0        0        0     2679 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/deploy/compose.swarm.yaml
--rw-r--r--   0        0        0     1263 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/deploy/compose.yaml
--rw-r--r--   0        0        0      244 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/deploy/sqlite.env.default
--rw-r--r--   0        0        0      460 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/deploy/swarm.env.default
--rw-r--r--   0        0        0     1090 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/dipdup.yaml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/graphql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/handlers/.keep
--rw-r--r--   0        0        0     1082 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/handlers/on_factory_origination.py
--rw-r--r--   0        0        0      658 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/handlers/on_transfer.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.229086 dipdup-7.5.7/src/demo_factories/hasura/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_factories/hooks/.keep
--rw-r--r--   0        0        0      378 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_factories/hooks/on_index_rollback.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_factories/hooks/on_reindex.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_factories/hooks/on_restart.py
--rw-r--r--   0        0        0      145 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_factories/hooks/on_synchronized.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_factories/models/.keep
--rw-r--r--   0        0        0      208 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_factories/models/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_factories/py.typed
--rw-r--r--   0        0        0     1504 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_factories/pyproject.toml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_factories/sql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_factories/sql/on_index_rollback/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_factories/sql/on_reindex/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_factories/sql/on_restart/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_factories/sql/on_synchronized/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_factories/types/.keep
--rw-r--r--   0        0        0     1355 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_factories/types/factory/tezos_storage.py
--rw-r--r--   0        0        0      479 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_factories/types/token/tezos_parameters/transfer.py
--rw-r--r--   0        0        0     1128 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_factories/types/token/tezos_storage.py
--rw-r--r--   0        0        0      264 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/.dockerignore
--rw-r--r--   0        0        0      360 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/.gitignore
--rw-r--r--   0        0        0       35 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_head/.ruff_cache/.gitignore
--rw-r--r--   0        0        0      303 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_head/.ruff_cache/0.4.6/12678801074623674009
--rw-r--r--   0        0        0      131 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_head/.ruff_cache/0.4.6/2973433179821984425
--rw-r--r--   0        0        0       43 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_head/.ruff_cache/CACHEDIR.TAG
--rw-r--r--   0        0        0      933 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/Makefile
--rw-r--r--   0        0        0      927 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/README.md
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/abi/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/configs/.keep
--rw-r--r--   0        0        0      523 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/configs/dipdup.compose.yaml
--rw-r--r--   0        0        0       70 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/configs/dipdup.sqlite.yaml
--rw-r--r--   0        0        0      542 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/configs/dipdup.swarm.yaml
--rw-r--r--   0        0        0      573 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/configs/replay.yaml
--rw-r--r--   0        0        0      431 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/deploy/.env.default
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/deploy/.keep
--rw-r--r--   0        0        0      212 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/deploy/Dockerfile
--rw-r--r--   0        0        0      357 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/deploy/compose.sqlite.yaml
--rw-r--r--   0        0        0     2669 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/deploy/compose.swarm.yaml
--rw-r--r--   0        0        0     1258 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/deploy/compose.yaml
--rw-r--r--   0        0        0      239 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/deploy/sqlite.env.default
--rw-r--r--   0        0        0      450 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/deploy/swarm.env.default
--rw-r--r--   0        0        0      240 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/dipdup.yaml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/graphql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/handlers/.keep
--rw-r--r--   0        0        0      237 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/handlers/on_mainnet_head.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/hasura/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/hooks/.keep
--rw-r--r--   0        0        0      378 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/hooks/on_index_rollback.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/hooks/on_reindex.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/hooks/on_restart.py
--rw-r--r--   0        0        0      145 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/hooks/on_synchronized.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/models/.keep
--rw-r--r--   0        0        0     1241 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/models/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/py.typed
--rw-r--r--   0        0        0     1507 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/pyproject.toml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/sql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/sql/on_index_rollback/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/sql/on_reindex/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/sql/on_restart/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/sql/on_synchronized/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_head/types/.keep
--rw-r--r--   0        0        0      275 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/.dockerignore
--rw-r--r--   0        0        0      371 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/.gitignore
--rw-r--r--   0        0        0       35 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_nft_marketplace/.ruff_cache/.gitignore
--rw-r--r--   0        0        0      322 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_nft_marketplace/.ruff_cache/0.4.6/12010236643163427680
--rw-r--r--   0        0        0      148 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_nft_marketplace/.ruff_cache/0.4.6/12048565622104986003
--rw-r--r--   0        0        0      148 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_nft_marketplace/.ruff_cache/0.4.6/14032670602179217047
--rw-r--r--   0        0        0      314 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_nft_marketplace/.ruff_cache/0.4.6/15378771397136242159
--rw-r--r--   0        0        0      303 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_nft_marketplace/.ruff_cache/0.4.6/2337714856597327238
--rw-r--r--   0        0        0      156 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_nft_marketplace/.ruff_cache/0.4.6/9086030281192365289
--rw-r--r--   0        0        0       43 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_nft_marketplace/.ruff_cache/CACHEDIR.TAG
--rw-r--r--   0        0        0      944 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/Makefile
--rw-r--r--   0        0        0      921 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/README.md
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/abi/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/configs/.keep
--rw-r--r--   0        0        0      523 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/configs/dipdup.compose.yaml
--rw-r--r--   0        0        0       81 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/configs/dipdup.sqlite.yaml
--rw-r--r--   0        0        0      564 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/configs/dipdup.swarm.yaml
--rw-r--r--   0        0        0      578 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/configs/replay.yaml
--rw-r--r--   0        0        0      527 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/deploy/.env.default
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/deploy/.keep
--rw-r--r--   0        0        0      234 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/deploy/Dockerfile
--rw-r--r--   0        0        0      379 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/deploy/compose.sqlite.yaml
--rw-r--r--   0        0        0     2691 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/deploy/compose.swarm.yaml
--rw-r--r--   0        0        0     1269 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/deploy/compose.yaml
--rw-r--r--   0        0        0      346 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/deploy/sqlite.env.default
--rw-r--r--   0        0        0      568 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/deploy/swarm.env.default
--rw-r--r--   0        0        0     1199 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/dipdup.yaml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/graphql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/handlers/.keep
--rw-r--r--   0        0        0      605 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/handlers/on_cancel_swap.py
--rw-r--r--   0        0        0     1037 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/handlers/on_collect.py
--rw-r--r--   0        0        0      977 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/handlers/on_mint.py
--rw-r--r--   0        0        0      885 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/handlers/on_swap.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/hasura/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/hooks/.keep
--rw-r--r--   0        0        0      378 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/hooks/on_index_rollback.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/hooks/on_reindex.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/hooks/on_restart.py
--rw-r--r--   0        0        0      145 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/hooks/on_synchronized.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/models/.keep
--rw-r--r--   0        0        0     1306 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/models/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/py.typed
--rw-r--r--   0        0        0     1501 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/pyproject.toml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/sql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/sql/on_index_rollback/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/sql/on_reindex/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/sql/on_restart/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/sql/on_synchronized/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/types/.keep
--rw-r--r--   0        0        0      192 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/types/hen_minter/tezos_parameters/cancel_swap.py
--rw-r--r--   0        0        0      281 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/types/hen_minter/tezos_parameters/collect.py
--rw-r--r--   0        0        0      317 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/types/hen_minter/tezos_parameters/mint_objkt.py
--rw-r--r--   0        0        0      299 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/types/hen_minter/tezos_parameters/swap.py
--rw-r--r--   0        0        0      752 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/types/hen_minter/tezos_storage.py
--rw-r--r--   0        0        0      318 2024-05-30 22:20:27.233086 dipdup-7.5.7/src/demo_nft_marketplace/types/hen_objkts/tezos_parameters/mint.py
--rw-r--r--   0        0        0     1046 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_nft_marketplace/types/hen_objkts/tezos_storage.py
--rw-r--r--   0        0        0      263 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/.dockerignore
--rw-r--r--   0        0        0      359 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/.gitignore
--rw-r--r--   0        0        0       35 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_raw/.ruff_cache/.gitignore
--rw-r--r--   0        0        0      127 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_raw/.ruff_cache/0.4.6/18304408310323723990
--rw-r--r--   0        0        0      302 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_raw/.ruff_cache/0.4.6/3881355825003436427
--rw-r--r--   0        0        0       43 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_raw/.ruff_cache/CACHEDIR.TAG
--rw-r--r--   0        0        0      932 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/Makefile
--rw-r--r--   0        0        0      939 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/README.md
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/abi/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/configs/.keep
--rw-r--r--   0        0        0      523 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/configs/dipdup.compose.yaml
--rw-r--r--   0        0        0       69 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/configs/dipdup.sqlite.yaml
--rw-r--r--   0        0        0      540 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/configs/dipdup.swarm.yaml
--rw-r--r--   0        0        0      584 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/configs/replay.yaml
--rw-r--r--   0        0        0      431 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/deploy/.env.default
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/deploy/.keep
--rw-r--r--   0        0        0      210 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/deploy/Dockerfile
--rw-r--r--   0        0        0      355 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/deploy/compose.sqlite.yaml
--rw-r--r--   0        0        0     2667 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/deploy/compose.swarm.yaml
--rw-r--r--   0        0        0     1257 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/deploy/compose.yaml
--rw-r--r--   0        0        0      238 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/deploy/sqlite.env.default
--rw-r--r--   0        0        0      448 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/deploy/swarm.env.default
--rw-r--r--   0        0        0      411 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/dipdup.yaml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/graphql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/handlers/.keep
--rw-r--r--   0        0        0      350 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/handlers/on_operation.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/hasura/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/hooks/.keep
--rw-r--r--   0        0        0      378 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/hooks/on_index_rollback.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/hooks/on_reindex.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/hooks/on_restart.py
--rw-r--r--   0        0        0      145 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/hooks/on_synchronized.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/models/.keep
--rw-r--r--   0        0        0      245 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/models/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/py.typed
--rw-r--r--   0        0        0     1519 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/pyproject.toml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/sql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/sql/on_index_rollback/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/sql/on_reindex/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/sql/on_restart/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/sql/on_synchronized/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_raw/types/.keep
--rw-r--r--   0        0        0      265 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/.dockerignore
--rw-r--r--   0        0        0      361 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/.gitignore
--rw-r--r--   0        0        0       35 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_token/.ruff_cache/.gitignore
--rw-r--r--   0        0        0      244 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_token/.ruff_cache/0.4.6/11771725527368314331
--rw-r--r--   0        0        0      133 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_token/.ruff_cache/0.4.6/16726784808962748799
--rw-r--r--   0        0        0      195 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_token/.ruff_cache/0.4.6/6128800063644318726
--rw-r--r--   0        0        0      304 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_token/.ruff_cache/0.4.6/8399627469422152450
--rw-r--r--   0        0        0       43 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_token/.ruff_cache/CACHEDIR.TAG
--rw-r--r--   0        0        0      934 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/Makefile
--rw-r--r--   0        0        0      913 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/README.md
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/abi/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/configs/.keep
--rw-r--r--   0        0        0      523 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/configs/dipdup.compose.yaml
--rw-r--r--   0        0        0       71 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/configs/dipdup.sqlite.yaml
--rw-r--r--   0        0        0      544 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/configs/dipdup.swarm.yaml
--rw-r--r--   0        0        0      560 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/configs/replay.yaml
--rw-r--r--   0        0        0      402 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/deploy/.env.default
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/deploy/.keep
--rw-r--r--   0        0        0      214 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/deploy/Dockerfile
--rw-r--r--   0        0        0      359 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/deploy/compose.sqlite.yaml
--rw-r--r--   0        0        0     2671 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/deploy/compose.swarm.yaml
--rw-r--r--   0        0        0     1259 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/deploy/compose.yaml
--rw-r--r--   0        0        0      211 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/deploy/sqlite.env.default
--rw-r--r--   0        0        0      423 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/deploy/swarm.env.default
--rw-r--r--   0        0        0      730 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/dipdup.yaml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/graphql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/handlers/.keep
--rw-r--r--   0        0        0      436 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/handlers/on_balance_update.py
--rw-r--r--   0        0        0      630 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/handlers/on_mint.py
--rw-r--r--   0        0        0      928 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/handlers/on_transfer.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/hasura/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/hooks/.keep
--rw-r--r--   0        0        0      378 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/hooks/on_index_rollback.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/hooks/on_reindex.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/hooks/on_restart.py
--rw-r--r--   0        0        0      145 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/hooks/on_synchronized.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/models/.keep
--rw-r--r--   0        0        0      370 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/models/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/py.typed
--rw-r--r--   0        0        0     1493 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/pyproject.toml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/sql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/sql/on_index_rollback/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/sql/on_reindex/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/sql/on_restart/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/sql/on_synchronized/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/types/.keep
--rw-r--r--   0        0        0      263 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/types/tzbtc/tezos_parameters/mint.py
--rw-r--r--   0        0        0      340 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/types/tzbtc/tezos_parameters/transfer.py
--rw-r--r--   0        0        0      373 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token/types/tzbtc/tezos_storage.py
--rw-r--r--   0        0        0      274 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/.dockerignore
--rw-r--r--   0        0        0      370 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/.gitignore
--rw-r--r--   0        0        0       35 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_token_balances/.ruff_cache/.gitignore
--rw-r--r--   0        0        0      143 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_token_balances/.ruff_cache/0.4.6/11294916845361203596
--rw-r--r--   0        0        0      313 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_token_balances/.ruff_cache/0.4.6/16467683142043327099
--rw-r--r--   0        0        0       43 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_token_balances/.ruff_cache/CACHEDIR.TAG
--rw-r--r--   0        0        0      943 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/Makefile
--rw-r--r--   0        0        0      911 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/README.md
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/abi/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/configs/.keep
--rw-r--r--   0        0        0      523 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/configs/dipdup.compose.yaml
--rw-r--r--   0        0        0       80 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/configs/dipdup.sqlite.yaml
--rw-r--r--   0        0        0      562 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/configs/dipdup.swarm.yaml
--rw-r--r--   0        0        0      567 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/configs/replay.yaml
--rw-r--r--   0        0        0      402 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/deploy/.env.default
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/deploy/.keep
--rw-r--r--   0        0        0      232 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/deploy/Dockerfile
--rw-r--r--   0        0        0      377 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/deploy/compose.sqlite.yaml
--rw-r--r--   0        0        0     2689 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/deploy/compose.swarm.yaml
--rw-r--r--   0        0        0     1268 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/deploy/compose.yaml
--rw-r--r--   0        0        0      220 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/deploy/sqlite.env.default
--rw-r--r--   0        0        0      441 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/deploy/swarm.env.default
--rw-r--r--   0        0        0      407 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/dipdup.yaml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/graphql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/handlers/.keep
--rw-r--r--   0        0        0      472 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/handlers/on_balance_update.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/hasura/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.237086 dipdup-7.5.7/src/demo_token_balances/hooks/.keep
--rw-r--r--   0        0        0      378 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_balances/hooks/on_index_rollback.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_balances/hooks/on_reindex.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_balances/hooks/on_restart.py
--rw-r--r--   0        0        0      145 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_balances/hooks/on_synchronized.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_balances/models/.keep
--rw-r--r--   0        0        0      198 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_balances/models/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_balances/py.typed
--rw-r--r--   0        0        0     1491 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_balances/pyproject.toml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_balances/sql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_balances/sql/on_index_rollback/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_balances/sql/on_reindex/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_balances/sql/on_restart/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_balances/sql/on_synchronized/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_balances/types/.keep
--rw-r--r--   0        0        0      275 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/.dockerignore
--rw-r--r--   0        0        0      371 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/.gitignore
--rw-r--r--   0        0        0       35 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_token_transfers/.ruff_cache/.gitignore
--rw-r--r--   0        0        0      207 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_token_transfers/.ruff_cache/0.4.6/3605925384916486065
--rw-r--r--   0        0        0      314 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_token_transfers/.ruff_cache/0.4.6/5077617199139803837
--rw-r--r--   0        0        0       43 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_token_transfers/.ruff_cache/CACHEDIR.TAG
--rw-r--r--   0        0        0      944 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/Makefile
--rw-r--r--   0        0        0      913 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/README.md
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/abi/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/configs/.keep
--rw-r--r--   0        0        0      523 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/configs/dipdup.compose.yaml
--rw-r--r--   0        0        0       81 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/configs/dipdup.sqlite.yaml
--rw-r--r--   0        0        0      564 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/configs/dipdup.swarm.yaml
--rw-r--r--   0        0        0      570 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/configs/replay.yaml
--rw-r--r--   0        0        0      402 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/deploy/.env.default
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/deploy/.keep
--rw-r--r--   0        0        0      234 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/deploy/Dockerfile
--rw-r--r--   0        0        0      379 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/deploy/compose.sqlite.yaml
--rw-r--r--   0        0        0     2691 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/deploy/compose.swarm.yaml
--rw-r--r--   0        0        0     1269 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/deploy/compose.yaml
--rw-r--r--   0        0        0      221 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/deploy/sqlite.env.default
--rw-r--r--   0        0        0      443 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/deploy/swarm.env.default
--rw-r--r--   0        0        0      409 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/dipdup.yaml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/graphql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/handlers/.keep
--rw-r--r--   0        0        0      545 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/handlers/on_balance_update.py
--rw-r--r--   0        0        0      836 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/handlers/on_token_transfer.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/hasura/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/hooks/.keep
--rw-r--r--   0        0        0      378 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/hooks/on_index_rollback.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/hooks/on_reindex.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/hooks/on_restart.py
--rw-r--r--   0        0        0      145 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/hooks/on_synchronized.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/models/.keep
--rw-r--r--   0        0        0      370 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/models/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/py.typed
--rw-r--r--   0        0        0     1493 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/pyproject.toml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/sql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/sql/on_index_rollback/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/sql/on_reindex/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/sql/on_restart/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/sql/on_synchronized/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_token_transfers/types/.keep
--rw-r--r--   0        0        0      267 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/.dockerignore
--rw-r--r--   0        0        0      363 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/.gitignore
--rw-r--r--   0        0        0       35 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_uniswap/.ruff_cache/.gitignore
--rw-r--r--   0        0        0      325 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_uniswap/.ruff_cache/0.4.6/10578814500589456155
--rw-r--r--   0        0        0      306 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_uniswap/.ruff_cache/0.4.6/11867978224273138244
--rw-r--r--   0        0        0      335 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_uniswap/.ruff_cache/0.4.6/15035839586954891769
--rw-r--r--   0        0        0      147 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_uniswap/.ruff_cache/0.4.6/17210973101880480403
--rw-r--r--   0        0        0      333 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_uniswap/.ruff_cache/0.4.6/2059631100374128175
--rw-r--r--   0        0        0      396 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_uniswap/.ruff_cache/0.4.6/3636983781439945036
--rw-r--r--   0        0        0      139 2024-05-30 22:21:06.249345 dipdup-7.5.7/src/demo_uniswap/.ruff_cache/0.4.6/5352656847451927027
--rw-r--r--   0        0        0       43 2024-05-30 22:21:06.213345 dipdup-7.5.7/src/demo_uniswap/.ruff_cache/CACHEDIR.TAG
--rw-r--r--   0        0        0      936 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/Makefile
--rw-r--r--   0        0        0      946 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/README.md
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/abi/.keep
--rw-r--r--   0        0        0     3684 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/abi/erc20/ERC20.json
--rw-r--r--   0        0        0      268 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/abi/erc20/ERC20NameBytes.json
--rw-r--r--   0        0        0      270 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/abi/erc20/ERC20SymbolBytes.json
--rw-r--r--   0        0        0     4418 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/abi/factory/abi.json
--rw-r--r--   0        0        0    19609 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/abi/pool/abi.json
--rw-r--r--   0        0        0    24313 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/abi/position_manager/abi.json
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/configs/.keep
--rw-r--r--   0        0        0      523 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/configs/dipdup.compose.yaml
--rw-r--r--   0        0        0       73 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/configs/dipdup.sqlite.yaml
--rw-r--r--   0        0        0      548 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/configs/dipdup.swarm.yaml
--rw-r--r--   0        0        0      615 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/configs/replay.yaml
--rw-r--r--   0        0        0      644 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/deploy/.env.default
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/deploy/.keep
--rw-r--r--   0        0        0      218 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/deploy/Dockerfile
--rw-r--r--   0        0        0      363 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/deploy/compose.sqlite.yaml
--rw-r--r--   0        0        0     2695 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/deploy/compose.swarm.yaml
--rw-r--r--   0        0        0     1281 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/deploy/compose.yaml
--rw-r--r--   0        0        0      455 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/deploy/sqlite.env.default
--rw-r--r--   0        0        0      669 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/deploy/swarm.env.default
--rw-r--r--   0        0        0     2039 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/dipdup.yaml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/graphql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/handlers/.keep
--rw-r--r--   0        0        0     2668 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/handlers/factory/pool_created.py
--rw-r--r--   0        0        0      531 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/handlers/pool/burn.py
--rw-r--r--   0        0        0      291 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/handlers/pool/flash.py
--rw-r--r--   0        0        0      871 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/handlers/pool/initialize.py
--rw-r--r--   0        0        0     1329 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/handlers/pool/mint.py
--rw-r--r--   0        0        0     6569 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/handlers/pool/swap.py
--rw-r--r--   0        0        0     1249 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/handlers/position_manager/collect.py
--rw-r--r--   0        0        0     1383 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/handlers/position_manager/decrease_liquidity.py
--rw-r--r--   0        0        0     1471 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/handlers/position_manager/increase_liquidity.py
--rw-r--r--   0        0        0     1367 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/handlers/position_manager/transfer.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/hasura/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/hooks/.keep
--rw-r--r--   0        0        0      378 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/hooks/on_index_rollback.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/hooks/on_reindex.py
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/hooks/on_restart.py
--rw-r--r--   0        0        0      145 2024-05-30 22:20:27.241086 dipdup-7.5.7/src/demo_uniswap/hooks/on_synchronized.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/models/.keep
--rw-r--r--   0        0        0    19956 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/models/__init__.py
--rw-r--r--   0        0        0      373 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/models/abi.py
--rw-r--r--   0        0        0     4207 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/models/pool.py
--rw-r--r--   0        0        0     2831 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/models/position.py
--rw-r--r--   0        0        0     1452 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/models/repo.py
--rw-r--r--   0        0        0      577 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/models/tick.py
--rw-r--r--   0        0        0     7140 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/models/token.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/py.typed
--rw-r--r--   0        0        0     1526 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/pyproject.toml
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/sql/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/sql/on_index_rollback/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/sql/on_reindex/.keep
--rw-r--r--   0        0        0      225 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/sql/on_reindex/00_prepare_db.sql
--rw-r--r--   0        0        0      792 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/sql/on_reindex/20_create_ca_quotes_1m.sql
--rw-r--r--   0        0        0      788 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/sql/on_reindex/21_create_ca_quotes_1h.sql
--rw-r--r--   0        0        0      787 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/sql/on_reindex/22_create_ca_quotes_1d.sql
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/sql/on_restart/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/sql/on_synchronized/.keep
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/types/.keep
--rw-r--r--   0        0        0      321 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/types/factory/evm_events/pool_created.py
--rw-r--r--   0        0        0      330 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/types/pool/evm_events/burn.py
--rw-r--r--   0        0        0      339 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/types/pool/evm_events/collect.py
--rw-r--r--   0        0        0      328 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/types/pool/evm_events/flash.py
--rw-r--r--   0        0        0      275 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/types/pool/evm_events/initialize.py
--rw-r--r--   0        0        0      346 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/types/pool/evm_events/mint.py
--rw-r--r--   0        0        0      351 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/types/pool/evm_events/swap.py
--rw-r--r--   0        0        0      303 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/types/position_manager/evm_events/collect.py
--rw-r--r--   0        0        0      323 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/types/position_manager/evm_events/decrease_liquidity.py
--rw-r--r--   0        0        0      323 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/types/position_manager/evm_events/increase_liquidity.py
--rw-r--r--   0        0        0      333 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/demo_uniswap/types/position_manager/evm_events/transfer.py
--rw-r--r--   0        0        0      180 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/__init__.py
--rw-r--r--   0        0        0      105 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/__main__.py
--rw-r--r--   0        0        0     1989 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/api.py
--rw-r--r--   0        0        0    25974 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/cli.py
--rw-r--r--   0        0        0     7935 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/codegen/__init__.py
--rw-r--r--   0        0        0     9467 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/codegen/evm_subsquid.py
--rw-r--r--   0        0        0    19380 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/codegen/tezos_tzkt.py
--rw-r--r--   0        0        0    45557 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/config/__init__.py
--rw-r--r--   0        0        0      709 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/config/abi_etherscan.py
--rw-r--r--   0        0        0      802 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/config/coinbase.py
--rw-r--r--   0        0        0     1555 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/config/evm.py
--rw-r--r--   0        0        0     1354 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/config/evm_node.py
--rw-r--r--   0        0        0     1889 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/config/evm_subsquid.py
--rw-r--r--   0        0        0     2933 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/config/evm_subsquid_events.py
--rw-r--r--   0        0        0     1054 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/config/evm_subsquid_traces.py
--rw-r--r--   0        0        0     3590 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/config/evm_subsquid_transactions.py
--rw-r--r--   0        0        0      558 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/config/http.py
--rw-r--r--   0        0        0      631 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/config/ipfs.py
--rw-r--r--   0        0        0     2121 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/config/tezos.py
--rw-r--r--   0        0        0     2455 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/config/tezos_tzkt.py
--rw-r--r--   0        0        0     3993 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/config/tezos_tzkt_big_maps.py
--rw-r--r--   0        0        0     3362 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/config/tezos_tzkt_events.py
--rw-r--r--   0        0        0     1689 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/config/tezos_tzkt_head.py
--rw-r--r--   0        0        0    15312 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/config/tezos_tzkt_operations.py
--rw-r--r--   0        0        0     2871 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/config/tezos_tzkt_token_balances.py
--rw-r--r--   0        0        0     3293 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/config/tezos_tzkt_token_transfers.py
--rw-r--r--   0        0        0      857 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/config/tzip_metadata.py
--rw-r--r--   0        0        0    30520 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/context.py
--rw-r--r--   0        0        0    15587 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/database.py
--rw-r--r--   0        0        0     5524 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/datasources/__init__.py
--rw-r--r--   0        0        0     1680 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/datasources/abi_etherscan.py
--rw-r--r--   0        0        0     2251 2024-05-30 22:20:27.245086 dipdup-7.5.7/src/dipdup/datasources/coinbase.py
--rw-r--r--   0        0        0    16173 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/datasources/evm_node.py
--rw-r--r--   0        0        0     8233 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/datasources/evm_subsquid.py
--rw-r--r--   0        0        0      399 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/datasources/http.py
--rw-r--r--   0        0        0      524 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/datasources/ipfs.py
--rw-r--r--   0        0        0    48706 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/datasources/tezos_tzkt.py
--rw-r--r--   0        0        0     1545 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/datasources/tzip_metadata.py
--rw-r--r--   0        0        0    35194 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/dipdup.py
--rw-r--r--   0        0        0     3175 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/env.py
--rw-r--r--   0        0        0     8666 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/exceptions.py
--rw-r--r--   0        0        0     4447 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/fetcher.py
--rw-r--r--   0        0        0     6780 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/fields.py
--rw-r--r--   0        0        0    26459 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/hasura.py
--rw-r--r--   0        0        0    10837 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/http.py
--rw-r--r--   0        0        0    10321 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/index.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/__init__.py
--rw-r--r--   0        0        0     2827 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/evm_node.py
--rw-r--r--   0        0        0     6314 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/evm_subsquid.py
--rw-r--r--   0        0        0     3664 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/evm_subsquid_events/fetcher.py
--rw-r--r--   0        0        0     4793 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/evm_subsquid_events/index.py
--rw-r--r--   0        0        0     3889 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/evm_subsquid_events/matcher.py
--rw-r--r--   0        0        0      266 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/evm_subsquid_traces/fetcher.py
--rw-r--r--   0        0        0      560 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/evm_subsquid_traces/index.py
--rw-r--r--   0        0        0        4 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/evm_subsquid_traces/matcher.py
--rw-r--r--   0        0        0     3444 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/evm_subsquid_transactions/fetcher.py
--rw-r--r--   0        0        0     4114 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/evm_subsquid_transactions/index.py
--rw-r--r--   0        0        0     3967 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/evm_subsquid_transactions/matcher.py
--rw-r--r--   0        0        0      497 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_big_maps/__init__.py
--rw-r--r--   0        0        0     3160 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_big_maps/fetcher.py
--rw-r--r--   0        0        0     5166 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_big_maps/index.py
--rw-r--r--   0        0        0     2659 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_big_maps/matcher.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_events/__init__.py
--rw-r--r--   0        0        0     1363 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_events/fetcher.py
--rw-r--r--   0        0        0     3446 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_events/index.py
--rw-r--r--   0        0        0     3781 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_events/matcher.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_head/__init__.py
--rw-r--r--   0        0        0     2679 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_head/index.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_operations/__init__.py
--rw-r--r--   0        0        0    23285 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_operations/fetcher.py
--rw-r--r--   0        0        0    13887 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_operations/index.py
--rw-r--r--   0        0        0    10443 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_operations/matcher.py
--rw-r--r--   0        0        0     7554 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_operations/parser.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_token_balances/__init__.py
--rw-r--r--   0        0        0     2753 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_token_balances/index.py
--rw-r--r--   0        0        0     1545 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_token_balances/matcher.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_token_transfers/__init__.py
--rw-r--r--   0        0        0     1576 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_token_transfers/fetcher.py
--rw-r--r--   0        0        0     3209 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_token_transfers/index.py
--rw-r--r--   0        0        0     1817 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_token_transfers/matcher.py
--rwxr-xr-x   0        0        0     9239 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/install.py
--rw-r--r--   0        0        0    22316 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/models/__init__.py
--rw-r--r--   0        0        0     1240 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/models/coinbase.py
--rw-r--r--   0        0        0     6463 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/models/evm_node.py
--rw-r--r--   0        0        0     8462 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/models/evm_subsquid.py
--rw-r--r--   0        0        0    24947 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/models/tezos_tzkt.py
--rw-r--r--   0        0        0      463 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/models/tzip_metadata.py
--rw-r--r--   0        0        0     7237 2024-05-30 22:20:27.249086 dipdup-7.5.7/src/dipdup/package.py
--rw-r--r--   0        0        0     7491 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/performance.py
--rw-r--r--   0        0        0    10232 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/project.py
--rw-r--r--   0        0        0      277 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/base/.dockerignore.j2
--rw-r--r--   0        0        0      372 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/base/.gitignore.j2
--rw-r--r--   0        0        0      945 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/base/Makefile.j2
--rw-r--r--   0        0        0     1061 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/base/README.md.j2
--rw-r--r--   0        0        0      524 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/base/configs/dipdup.compose.yaml.j2
--rw-r--r--   0        0        0       82 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/base/configs/dipdup.sqlite.yaml.j2
--rw-r--r--   0        0        0      567 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/base/configs/dipdup.swarm.yaml.j2
--rw-r--r--   0        0        0      291 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/base/deploy/Dockerfile.j2
--rw-r--r--   0        0        0      382 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/base/deploy/compose.sqlite.yaml.j2
--rw-r--r--   0        0        0     2744 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/base/deploy/compose.swarm.yaml.j2
--rw-r--r--   0        0        0     1294 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/base/deploy/compose.yaml.j2
--rw-r--r--   0        0        0     2849 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/base/pyproject.toml.j2
--rw-r--r--   0        0        0     1087 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_auction/dipdup.yaml.j2
--rw-r--r--   0        0        0      935 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_auction/handlers/on_bid.py.j2
--rw-r--r--   0        0        0     1641 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_auction/handlers/on_create_auction.py.j2
--rw-r--r--   0        0        0      734 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_auction/handlers/on_withdraw.py.j2
--rw-r--r--   0        0        0     1447 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_auction/models/__init__.py.j2
--rw-r--r--   0        0        0      116 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_auction/replay.yaml
--rw-r--r--   0        0        0      734 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_big_maps/dipdup.yaml.j2
--rw-r--r--   0        0        0      865 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_big_maps/handlers/on_update_expiry_map.py.j2
--rw-r--r--   0        0        0     1709 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_big_maps/handlers/on_update_records.py.j2
--rw-r--r--   0        0        0      669 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_big_maps/models/__init__.py.j2
--rw-r--r--   0        0        0      118 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_big_maps/replay.yaml
--rw-r--r--   0        0        0       49 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_blank/dipdup.yaml.j2
--rw-r--r--   0        0        0      116 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_blank/replay.yaml
--rw-r--r--   0        0        0      657 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dao/dipdup.yaml.j2
--rw-r--r--   0        0        0      431 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dao/handlers/on_origination.py.j2
--rw-r--r--   0        0        0      540 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dao/handlers/on_propose.py.j2
--rw-r--r--   0        0        0      784 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dao/models/__init__.py.j2
--rw-r--r--   0        0        0      109 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dao/replay.yaml
--rw-r--r--   0        0        0     4859 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dex/dipdup.yaml.j2
--rw-r--r--   0        0        0     1885 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa12_divest_liquidity.py.j2
--rw-r--r--   0        0        0     1793 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa12_invest_liquidity.py.j2
--rw-r--r--   0        0        0      602 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa12_origination.py.j2
--rw-r--r--   0        0        0     1666 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa12_tez_to_token.py.j2
--rw-r--r--   0        0        0     1732 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa12_token_to_tez.py.j2
--rw-r--r--   0        0        0     1056 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa12_transfer.py.j2
--rw-r--r--   0        0        0      993 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa12_withdraw_profit.py.j2
--rw-r--r--   0        0        0     1911 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa2_divest_liquidity.py.j2
--rw-r--r--   0        0        0     1819 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa2_invest_liquidity.py.j2
--rw-r--r--   0        0        0      596 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa2_origination.py.j2
--rw-r--r--   0        0        0     1660 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa2_tez_to_token.py.j2
--rw-r--r--   0        0        0     1698 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa2_token_to_tez.py.j2
--rw-r--r--   0        0        0     1177 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa2_transfer.py.j2
--rw-r--r--   0        0        0      989 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa2_withdraw_profit.py.j2
--rw-r--r--   0        0        0      918 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dex/models/__init__.py.j2
--rw-r--r--   0        0        0      120 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_dex/replay.yaml
--rw-r--r--   0        0        0      903 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_domains/dipdup.yaml.j2
--rw-r--r--   0        0        0     1967 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_domains/handlers/on_update_expiry_map.py.j2
--rw-r--r--   0        0        0     3314 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_domains/handlers/on_update_records.py.j2
--rw-r--r--   0        0        0      968 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_domains/hooks/check_expiration.py.j2
--rw-r--r--   0        0        0      972 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_domains/models/__init__.py.j2
--rw-r--r--   0        0        0      125 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_domains/replay.yaml
--rw-r--r--   0        0        0     1343 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_etherlink/dipdup.yaml.j2
--rw-r--r--   0        0        0      129 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_etherlink/replay.yaml
--rw-r--r--   0        0        0      545 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_events/dipdup.yaml.j2
--rw-r--r--   0        0        0      114 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_events/replay.yaml
--rw-r--r--   0        0        0      818 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_evm_events/dipdup.yaml.j2
--rw-r--r--   0        0        0     1305 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_evm_events/handlers/on_transfer.py.j2
--rw-r--r--   0        0        0      470 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_evm_events/models/__init__.py.j2
--rw-r--r--   0        0        0      136 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_evm_events/replay.yaml
--rw-r--r--   0        0        0      851 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_evm_transactions/dipdup.yaml.j2
--rw-r--r--   0        0        0     1346 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_evm_transactions/handlers/on_transfer.py.j2
--rw-r--r--   0        0        0      470 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_evm_transactions/models/__init__.py.j2
--rw-r--r--   0        0        0      150 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_evm_transactions/replay.yaml
--rw-r--r--   0        0        0     1098 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_factories/dipdup.yaml.j2
--rw-r--r--   0        0        0     1082 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_factories/handlers/on_factory_origination.py.j2
--rw-r--r--   0        0        0      681 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_factories/handlers/on_transfer.py.j2
--rw-r--r--   0        0        0      214 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_factories/models/__init__.py.j2
--rw-r--r--   0        0        0      132 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_factories/replay.yaml
--rw-r--r--   0        0        0      253 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_head/dipdup.yaml.j2
--rw-r--r--   0        0        0      130 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_head/replay.yaml
--rw-r--r--   0        0        0     1201 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_nft_marketplace/dipdup.yaml.j2
--rw-r--r--   0        0        0      603 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_nft_marketplace/handlers/on_cancel_swap.py.j2
--rw-r--r--   0        0        0     1035 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_nft_marketplace/handlers/on_collect.py.j2
--rw-r--r--   0        0        0      973 2024-05-30 22:20:27.253086 dipdup-7.5.7/src/dipdup/projects/demo_nft_marketplace/handlers/on_mint.py.j2
--rw-r--r--   0        0        0      883 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_nft_marketplace/handlers/on_swap.py.j2
--rw-r--r--   0        0        0     1309 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_nft_marketplace/models/__init__.py.j2
--rw-r--r--   0        0        0      135 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_nft_marketplace/replay.yaml
--rw-r--r--   0        0        0      425 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_raw/dipdup.yaml.j2
--rw-r--r--   0        0        0      364 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_raw/handlers/on_operation.py.j2
--rw-r--r--   0        0        0      247 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_raw/models/__init__.py.j2
--rw-r--r--   0        0        0      141 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_raw/replay.yaml
--rw-r--r--   0        0        0      742 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_token/dipdup.yaml.j2
--rw-r--r--   0        0        0      448 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_token/handlers/on_balance_update.py.j2
--rw-r--r--   0        0        0      664 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_token/handlers/on_mint.py.j2
--rw-r--r--   0        0        0      962 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_token/handlers/on_transfer.py.j2
--rw-r--r--   0        0        0      372 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_token/models/__init__.py.j2
--rw-r--r--   0        0        0      117 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_token/replay.yaml
--rw-r--r--   0        0        0      410 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_token_balances/dipdup.yaml.j2
--rw-r--r--   0        0        0      473 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_token_balances/handlers/on_balance_update.py.j2
--rw-r--r--   0        0        0      200 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_token_balances/models/__init__.py.j2
--rw-r--r--   0        0        0      124 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_token_balances/replay.yaml
--rw-r--r--   0        0        0      411 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_token_transfers/dipdup.yaml.j2
--rw-r--r--   0        0        0      545 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_token_transfers/handlers/on_balance_update.py.j2
--rw-r--r--   0        0        0      836 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_token_transfers/handlers/on_token_transfer.py.j2
--rw-r--r--   0        0        0      372 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_token_transfers/models/__init__.py.j2
--rw-r--r--   0        0        0      127 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_token_transfers/replay.yaml
--rw-r--r--   0        0        0     3685 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/abi/erc20/ERC20.json.j2
--rw-r--r--   0        0        0      269 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/abi/erc20/ERC20NameBytes.json.j2
--rw-r--r--   0        0        0      271 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/abi/erc20/ERC20SymbolBytes.json.j2
--rw-r--r--   0        0        0     2049 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/dipdup.yaml.j2
--rw-r--r--   0        0        0     2711 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/handlers/factory/pool_created.py.j2
--rw-r--r--   0        0        0      567 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/handlers/pool/burn.py.j2
--rw-r--r--   0        0        0      309 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/handlers/pool/flash.py.j2
--rw-r--r--   0        0        0      898 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/handlers/pool/initialize.py.j2
--rw-r--r--   0        0        0     1375 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/handlers/pool/mint.py.j2
--rw-r--r--   0        0        0     6641 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/handlers/pool/swap.py.j2
--rw-r--r--   0        0        0     1286 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/handlers/position_manager/collect.py.j2
--rw-r--r--   0        0        0     1420 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/handlers/position_manager/decrease_liquidity.py.j2
--rw-r--r--   0        0        0     1508 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/handlers/position_manager/increase_liquidity.py.j2
--rw-r--r--   0        0        0     1405 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/handlers/position_manager/transfer.py.j2
--rw-r--r--   0        0        0    19957 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/models/__init__.py.j2
--rw-r--r--   0        0        0      373 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/models/abi.py.j2
--rw-r--r--   0        0        0     4269 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/models/pool.py.j2
--rw-r--r--   0        0        0     2849 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/models/position.py.j2
--rw-r--r--   0        0        0     1461 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/models/repo.py.j2
--rw-r--r--   0        0        0      586 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/models/tick.py.j2
--rw-r--r--   0        0        0     7167 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/models/token.py.j2
--rw-r--r--   0        0        0      250 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/replay.yaml
--rw-r--r--   0        0        0      226 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/sql/on_reindex/00_prepare_db.sql.j2
--rw-r--r--   0        0        0      793 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/sql/on_reindex/20_create_ca_quotes_1m.sql.j2
--rw-r--r--   0        0        0      789 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/sql/on_reindex/21_create_ca_quotes_1h.sql.j2
--rw-r--r--   0        0        0      788 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/projects/demo_uniswap/sql/on_reindex/22_create_ca_quotes_1d.sql.j2
--rw-r--r--   0        0        0     4126 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/prometheus.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/py.typed
--rw-r--r--   0        0        0     1774 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/pysignalr.py
--rw-r--r--   0        0        0     2147 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/report.py
--rw-r--r--   0        0        0     4938 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/scheduler.py
--rw-r--r--   0        0        0     4598 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/sentry.py
--rw-r--r--   0        0        0      272 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/sql/dipdup_approve.sql
--rw-r--r--   0        0        0      199 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/sql/dipdup_head_status.sql
--rw-r--r--   0        0        0     1904 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/sql/dipdup_wipe.sql
--rw-r--r--   0        0        0     2077 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/subscriptions.py
--rw-r--r--   0        0        0     2227 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/sys.py
--rw-r--r--   0        0        0      227 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/templates/callback.py.j2
--rw-r--r--   0        0        0     1241 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/templates/models.py
--rw-r--r--   0        0        0      276 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/templates/replay.yaml.j2
--rw-r--r--   0        0        0     6532 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/test.py
--rw-r--r--   0        0        0     3017 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/transactions.py
--rw-r--r--   0        0        0     7610 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/utils.py
--rw-r--r--   0        0        0     5500 2024-05-30 22:20:27.257086 dipdup-7.5.7/src/dipdup/yaml.py
--rw-r--r--   0        0        0      864 2024-05-30 22:20:27.257086 dipdup-7.5.7/tests/__init__.py
--rw-r--r--   0        0        0      496 2024-05-30 22:20:27.257086 dipdup-7.5.7/tests/configs/asdf.yml
--rw-r--r--   0        0        0     1222 2024-05-30 22:20:27.257086 dipdup-7.5.7/tests/configs/demo_auction.yml
--rw-r--r--   0        0        0      780 2024-05-30 22:20:27.257086 dipdup-7.5.7/tests/configs/demo_big_maps.yml
--rw-r--r--   0        0        0      747 2024-05-30 22:20:27.257086 dipdup-7.5.7/tests/configs/demo_dao.yml
--rw-r--r--   0        0        0     5012 2024-05-30 22:20:27.257086 dipdup-7.5.7/tests/configs/demo_dex.yml
--rw-r--r--   0        0        0      943 2024-05-30 22:20:27.257086 dipdup-7.5.7/tests/configs/demo_domains.yml
--rw-r--r--   0        0        0     1392 2024-05-30 22:20:27.257086 dipdup-7.5.7/tests/configs/demo_etherlink.yaml
--rw-r--r--   0        0        0      583 2024-05-30 22:20:27.257086 dipdup-7.5.7/tests/configs/demo_events.yml
--rw-r--r--   0        0        0      824 2024-05-30 22:20:27.257086 dipdup-7.5.7/tests/configs/demo_evm_events.yml
--rw-r--r--   0        0        0      824 2024-05-30 22:20:27.257086 dipdup-7.5.7/tests/configs/demo_evm_events_node.yml
--rw-r--r--   0        0        0      877 2024-05-30 22:20:27.257086 dipdup-7.5.7/tests/configs/demo_evm_transactions.yml
--rw-r--r--   0        0        0      877 2024-05-30 22:20:27.257086 dipdup-7.5.7/tests/configs/demo_evm_transactions_node.yml
--rw-r--r--   0        0        0     1144 2024-05-30 22:20:27.257086 dipdup-7.5.7/tests/configs/demo_factories.yml
--rw-r--r--   0        0        0     1316 2024-05-30 22:20:27.257086 dipdup-7.5.7/tests/configs/demo_nft_marketplace.yml
--rw-r--r--   0        0        0      590 2024-05-30 22:20:27.257086 dipdup-7.5.7/tests/configs/demo_raw.yml
--rw-r--r--   0        0        0      711 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/configs/demo_token.yml
--rw-r--r--   0        0        0      456 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/configs/demo_token_balances.yml
--rw-r--r--   0        0        0      527 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/configs/demo_token_transfers.yml
--rw-r--r--   0        0        0      527 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/configs/demo_token_transfers_2.yml
--rw-r--r--   0        0        0      527 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/configs/demo_token_transfers_3.yml
--rw-r--r--   0        0        0      814 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/configs/demo_token_transfers_4.yml
--rw-r--r--   0        0        0     1252 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/configs/dipdup.yml
--rw-r--r--   0        0        0      521 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/configs/hen_subjkt.yml
--rw-r--r--   0        0        0      496 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/configs/hjkl.yml
--rw-r--r--   0        0        0      546 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/configs/kolibri_ovens.yml
--rw-r--r--   0        0        0      684 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/configs/operation_filters.yml
--rw-r--r--   0        0        0      496 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/configs/qwer.yml
--rw-r--r--   0        0        0      496 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/configs/rewq.yml
--rw-r--r--   0        0        0       98 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/configs/test_postgres.yaml
--rw-r--r--   0        0        0      151 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/configs/test_postgres_immune.yaml
--rw-r--r--   0        0        0       44 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/configs/test_sqlite.yaml
--rw-r--r--   0        0        0      128 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/configs/test_sqlite_immune.yaml
--rw-r--r--   0        0        0      534 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/configs/yupana.yml
--rw-r--r--   0        0        0      496 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/configs/zxcv.yml
--rw-r--r--   0        0        0     1330 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/profile_abi_decoding.py
--rw-r--r--   0        0        0    29145 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/replays/0535b2dcc93076e6026fa48cc501adaed47b7b060e6483d8312f40c184d7287d
--rw-r--r--   0        0        0      305 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/replays/0b7d26b8f2813d12a80b9e96cc6f0bb186bf9ac5c5b0c0b3bb2cc8d750126843
--rw-r--r--   0        0        0      959 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/replays/0eaaba2830dbdd3a80286fbc367084bce6e55c678e21da178a7eb16beef6c997
--rw-r--r--   0        0        0    25834 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/replays/1228b36594bb93d619170ad49373f1ceec52d10faafdd727b37f3cdeffd663db
--rw-r--r--   0        0        0    13886 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/replays/13afdf001ce3d6a0219c0f7f6d372d9b645770e5f4304576f7f7a37b45af96fc
--rw-r--r--   0        0        0      403 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/replays/1430e37dce64ecb83499da8feaa3c0906e4fdf5d0a3c3570174645e97ba54bc4
--rw-r--r--   0        0        0      295 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/replays/185f6628ac43f6ca728c5b79b7b81a3c3671efce7f14030a06a27e90cf641dea
--rw-r--r--   0        0        0        2 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/replays/1c717490846300e1639e96a0c1438b6dd2abd6de013c5edec49042fa364c06e6
--rw-r--r--   0        0        0     1871 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/replays/27373c23411bf37b605c8d0ead9a0e6c6c1f1718ce7863b095b759811e44e155
--rw-r--r--   0        0        0     1824 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/replays/2a45ec6372b45e46199a6af24272cb93586777a0522cd1203b3eeef213ce4583
--rw-r--r--   0        0        0    54602 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/replays/383899084f79460e96fd311bb64e4925738c486b39d6281539456c5fcac41620
--rw-r--r--   0        0        0   234676 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/replays/388fe9107380b6dd1e9ce3a87c23abd56ad39dfb6cb8a5a27b959e5b0434633b
--rw-r--r--   0        0        0      642 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/replays/39b8664d1bca5d374ff905c8a3a396b53d19ee469dc37545a8ca6b080bd0e9e0
--rw-r--r--   0        0        0     1200 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/replays/3a2bd8b6b72bf18152d2550c106789fa9b8abc98ea9d759a6597b7ebfbab0fc2
--rw-r--r--   0        0        0    34389 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/replays/3f5927db41422038d8e2cc203ef56a769c66b25835cdee42b17bc61e600be550
--rw-r--r--   0        0        0      804 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/replays/43cb0ab415d8b8b3f7addc3e82ea27d93b2c66ff55c117e1e0c7c64a0fcfc3f2
--rw-r--r--   0        0        0   109726 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/replays/4a57776d93475adfd9c49b6c3295a7cedfc23b73733a1fb5f0c985ee039dc5dc
--rw-r--r--   0        0        0     1160 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/replays/4aa7f9b0657be0c44baf2caed8c7cb08d02097a4095cf6417f78cba3a25e8423
--rw-r--r--   0        0        0       67 2024-05-30 22:20:27.261086 dipdup-7.5.7/tests/replays/4fbdb4667971fab446a5ac5937a7c8cc6ef5813ff00af24b6fd1b1a0427bedbb
--rw-r--r--   0        0        0   192680 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/5483a0e11009e0f186bf70c214e2597d267a75a1e19152a9e7ed1ec257ce88ca
--rw-r--r--   0        0        0    40432 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/587613799ebfae42b1884016d1a44a452d68e70e3ed80641d90b8e7657ba8ee5
--rw-r--r--   0        0        0       32 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/5b004196490632859ec1b019d640f6bbb93fc86a433c8969e10f36f51ac2c78d
--rw-r--r--   0        0        0    40439 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/5b99bc4beb6a9a33f7d2f118426458e4c788e0ab6d9e51949d3ccbf8b4003fc1
--rw-r--r--   0        0        0    33335 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/607ecfd3653eda82aac502ac370c6ad7144d30c1e3c525ed520d44f9edf5b7e9
--rw-r--r--   0        0        0       67 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/60f48c13c47a1347786a6dcf6f741874e7b30b587d148faa67d15067bb3871de
--rw-r--r--   0        0        0        2 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/694f9dfac7db616fa52c4d35bca1036b6521d285ed1873028303b83822b5980b
--rw-r--r--   0        0        0      132 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/6d0c5443d41a15551acb41adc10d36d4895f5786d6922a878b5c5414610e0ebc
--rw-r--r--   0        0        0      754 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/6d76a3c3f427ff534c551de1793cb1d1dfbd22ccad97f5917a9f9b201a3f9804
--rw-r--r--   0        0        0     1781 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/6fa41b68da742cc7cf8a0d68baef77ce8b2e9abf765767318d7ff4cf453ded4c
--rw-r--r--   0        0        0      451 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/739d17c86095aac3da3508a16dc1c9ae9459ea86eeb09f62aaefc32de2997918
--rw-r--r--   0        0        0        2 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/759b79ec12b1305d9fa8e1a5218e62bb3d3ad913580e19914d30d8aa09920ae4
--rw-r--r--   0        0        0    50588 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/7b6cf9b8c69712bf26ed09059352ec740606969bf20eab0dedda870273f4fde9
--rw-r--r--   0        0        0      807 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/803e05a8d0bb9e7cfb49530271d43ea62111b6419e7cded2d221f7e0e0c92ece
--rw-r--r--   0        0        0   203748 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/8060a1f95213d470ee947a12242ef76cb7fb0c05bbaecc385eb6ec4a20d694c4
--rw-r--r--   0        0        0      395 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/8335acc6585656ec3a4301cd8b089401f2dc2c7d758b381c96c730e610b67f7b
--rw-r--r--   0        0        0     1151 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/93516225810a23a6799f2f9a1dee055ca79a66ee2b8d0f32be820c9c385e936b
--rw-r--r--   0        0        0      877 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/9e6e907842da2cd494c558ea5ecc211fd12e56bfc547450978fb7dfe03853e58
--rw-r--r--   0        0        0    22801 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/a3ce91a1b0d505cc221f0e201781466ba1e2d6dc7b624b9bc75a03ce3dbb0f92
--rw-r--r--   0        0        0      767 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/aa8fe6037996b296bf9a3011e45cd9ecb92fb728592a843f91b03b2848cb1fb1
--rw-r--r--   0        0        0     1931 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/acaa57345850f3b76471a7b3a8fb76b7f83e824f1520a2e0ee8ec93cdd6cb1c3
--rw-r--r--   0        0        0     1882 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/acc952ba1905717315212f952ed689d7b8f683165b31c0a7a25199aed9fda27f
--rw-r--r--   0        0        0       67 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/af37212b31e932f269c42c7f34ad8f3849bd8aed244652c41b9327c508985ce5
--rw-r--r--   0        0        0     1200 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/b3af887f7ad8172af75b94a09bedfb9ae1e14f8819a36d6ce9f709721068263b
--rw-r--r--   0        0        0    34407 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/b89b0ea704071e273d3c74a4dbb7b4f6c6fd9ea1848c69b452dce4f04872d3b5
--rw-r--r--   0        0        0     2271 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/bec4433b4206f00c2310a7961cff7f539434b9161b45673793aa5a3b50234313
--rw-r--r--   0        0        0      403 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/bed2329e63d559db2fb81c69606e715d1f90aaacab6ae45b33516e7828841a3c
--rw-r--r--   0        0        0    89684 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/c1c3eef91f7149d7aa2da072f71598f3ad5e29250cfa441bb6d4411acd70d657
--rw-r--r--   0        0        0    25834 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/cc5d3d4a58d5cb6bc7270d38c797b7740b79f913590ef0164abd50e58fba9405
--rw-r--r--   0        0        0     1157 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/d0a594d14bcb3fbf916092ec6707dfd3c9f48f53f0a1ad40a32023e7a87f8ef5
--rw-r--r--   0        0        0     6669 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/d62748a927a09395579b5790c8f871cc8653081cf4475abc93173989f950b92b
--rw-r--r--   0        0        0    27896 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/d94397f6ecec8ce25f87177fe410f6498d7d30a04360506c0cd300d291c167e7
--rw-r--r--   0        0        0      132 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/db797e6bf4c1b9c3237af5dec694fb1b6d21418a5a2f7947eb7f54d4e9201baf
--rw-r--r--   0        0        0    20467 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/dca9cf4f9f27623f10975d369444899458ab9ea85c22af2da6ce6ce8c09c2b58
--rw-r--r--   0        0        0      767 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/dd5d267c6e8e943a637ede23d708587123b9184560358d294be7fbed0d4b587a
--rw-r--r--   0        0        0   209761 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/e10e6552f0dce5124e0d72b74c508541a8098c407c9a3b0d2e10a7408b4d7cfe
--rw-r--r--   0        0        0    17502 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/e4a563a0b19379a44e9d2dc398131e9fd30d6039ff4ffacf1252db0bf8b433aa
--rw-r--r--   0        0        0       67 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/e82ba90c8570b92c0b1fc360b853aca3f1d7de457aacb9f6f19fa3e43879a8b3
--rw-r--r--   0        0        0      132 2024-05-30 22:20:27.265086 dipdup-7.5.7/tests/replays/e9fa56a94eb559c550dfbca4b27ef350a0b4a787afbe60205482a38223dcea04
--rw-r--r--   0        0        0   713738 2024-05-30 22:20:27.269086 dipdup-7.5.7/tests/replays/eb8b6b33cb2e165d1a3a73c09938d3083671a82ad73d4c0cff1fb2a5e5715f76
--rw-r--r--   0        0        0    27505 2024-05-30 22:20:27.269086 dipdup-7.5.7/tests/replays/eb8e2c3ce2fe7792d2c8e81c61d37821275b64021343103b0c955042ae802189
--rw-r--r--   0        0        0    17245 2024-05-30 22:20:27.269086 dipdup-7.5.7/tests/replays/f3d608f99e6b92e28a064bb9c10c3c605c9c817383c1eebcc68f663d1d23d650
--rw-r--r--   0        0        0   211527 2024-05-30 22:20:27.269086 dipdup-7.5.7/tests/replays/f7d244938de3e3d153e4ef8172cab0f1e896b801904a54ac034d3d14352ee64a
--rw-r--r--   0        0        0    27847 2024-05-30 22:20:27.269086 dipdup-7.5.7/tests/replays/f9fa1571c3d850f4a19c286205291893d184a9d124390d0358034a8b8366556d
--rw-r--r--   0        0        0   118246 2024-05-30 22:20:27.269086 dipdup-7.5.7/tests/replays/fe80425d17f2467fccc527a99b5a11da144f63f9a3cab83989be0f8fed737264
--rw-r--r--   0        0        0      996 2024-05-30 22:20:27.269086 dipdup-7.5.7/tests/replays/ff51b3535acc2972090ecd5db3af8f827464c9d92f1aa661630976e5b4ed4cbe
--rw-r--r--   0        0        0     4599 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/responses/asdf.json
--rw-r--r--   0        0        0     6704 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/responses/ftzfun.json
--rw-r--r--   0        0        0     3445 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/responses/hen_subjkt.json
--rw-r--r--   0        0        0     5210 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/responses/hjkl.json
--rw-r--r--   0        0        0     2097 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/responses/kolibri_ovens.json
--rw-r--r--   0        0        0    11186 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/responses/ooQuCAKBHkmWy2VciDAV9c6CFTywuMLupLzVoKDwS1xvR4EdRng.json
--rw-r--r--   0        0        0     1811 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/responses/origination_amount.json
--rw-r--r--   0        0        0     4256 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/responses/qwer.json
--rw-r--r--   0        0        0     5307 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/responses/rewq.json
--rw-r--r--   0        0        0    38178 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/responses/yupana.json
--rw-r--r--   0        0        0     5909 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/responses/zxcv.json
--rw-r--r--   0        0        0     1077 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/schemas/asdf/storage.json
--rw-r--r--   0        0        0     2116 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/schemas/hen_subjkt/storage.json
--rw-r--r--   0        0        0     1638 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/schemas/hjkl/storage.json
--rw-r--r--   0        0        0      800 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/schemas/kolibri_ovens/storage.json
--rw-r--r--   0        0        0     1005 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/schemas/qwer/storage.json
--rw-r--r--   0        0        0     2212 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/schemas/rewq/storage.json
--rw-r--r--   0        0        0    12561 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/schemas/yupana/storage.json
--rw-r--r--   0        0        0     2660 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/schemas/zxcv/storage.json
--rw-r--r--   0        0        0     3767 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_config/test_callbacks.py
--rw-r--r--   0        0        0     5583 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_config/test_config.py
--rw-r--r--   0        0        0     4138 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_config/test_custom_config.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_datasources/__init__.py
--rw-r--r--   0        0        0      814 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_datasources/test_ipfs.py
--rw-r--r--   0        0        0      795 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_datasources/test_metadata.py
--rw-r--r--   0        0        0     8320 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_datasources/test_tzkt.py
--rw-r--r--   0        0        0     1215 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_datasources/test_tzkt_blocks.py
--rw-r--r--   0        0        0     1971 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_datasources/test_tzkt_buffer.py
--rw-r--r--   0        0        0     1425 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_datasources/test_tzkt_quotes.py
--rw-r--r--   0        0        0     9022 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_demos.py
--rw-r--r--   0        0        0     2872 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_dipdup.py
--rw-r--r--   0        0        0     3108 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_hasura.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_http.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_index/__init__.py
--rw-r--r--   0        0        0     7461 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_index/test_tzkt_operations.py
--rw-r--r--   0        0        0     5409 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_introspection.py
--rw-r--r--   0        0        0    11401 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_models.py
--rw-r--r--   0        0        0    13543 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_rollback.py
--rw-r--r--   0        0        0     6692 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_schema.py
--rw-r--r--   0        0        0     3620 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/test_utils.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/__init__.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/asdf/__init__.py
--rw-r--r--   0        0        0      455 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/asdf/storage.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/bazaar/__init__.py
--rw-r--r--   0        0        0      539 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/bazaar/storage.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/ftzfun/__init__.py
--rw-r--r--   0        0        0      881 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/ftzfun/storage.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/hen_subjkt/__init__.py
--rw-r--r--   0        0        0      558 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/hen_subjkt/storage.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/hjkl/__init__.py
--rw-r--r--   0        0        0      564 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/hjkl/storage.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/kolibri_ovens/__init__.py
--rw-r--r--   0        0        0      200 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/kolibri_ovens/set_delegate.py
--rw-r--r--   0        0        0      392 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/kolibri_ovens/storage.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/listofmaps/__init__.py
--rw-r--r--   0        0        0      104 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/listofmaps/storage.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/qwer/__init__.py
--rw-r--r--   0        0        0      452 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/qwer/storage.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/rewq/__init__.py
--rw-r--r--   0        0        0      770 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/rewq/storage.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/tezotop/__init__.py
--rw-r--r--   0        0        0      660 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/tezotop/storage.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/yupana/__init__.py
--rw-r--r--   0        0        0     2635 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/yupana/storage.py
--rw-r--r--   0        0        0        0 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/zxcv/__init__.py
--rw-r--r--   0        0        0      981 2024-05-30 22:20:27.273086 dipdup-7.5.7/tests/types/zxcv/storage.py
--rw-r--r--   0        0        0     4732 1970-01-01 00:00:00.000000 dipdup-7.5.7/PKG-INFO
+-rw-r--r--   0        0        0     1067 2024-05-06 16:41:21.600766 dipdup-8.0.0a1/LICENSE
+-rw-r--r--   0        0        0     2562 2024-05-06 16:41:21.600766 dipdup-8.0.0a1/README.md
+-rw-r--r--   0        0        0     5025 2024-05-06 16:49:22.042062 dipdup-8.0.0a1/pyproject.toml
+-rw-r--r--   0        0        0      265 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/.dockerignore
+-rw-r--r--   0        0        0      361 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/.gitignore
+-rw-r--r--   0        0        0       35 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_blank/.ruff_cache/.gitignore
+-rw-r--r--   0        0        0      304 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_blank/.ruff_cache/0.4.3/7458884783087565696
+-rw-r--r--   0        0        0       43 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_blank/.ruff_cache/CACHEDIR.TAG
+-rw-r--r--   0        0        0      934 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/Makefile
+-rw-r--r--   0        0        0      915 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/README.md
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/abi/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/configs/.keep
+-rw-r--r--   0        0        0      523 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/configs/dipdup.compose.yaml
+-rw-r--r--   0        0        0       71 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/configs/dipdup.sqlite.yaml
+-rw-r--r--   0        0        0      544 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/configs/dipdup.swarm.yaml
+-rw-r--r--   0        0        0      559 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/configs/replay.yaml
+-rw-r--r--   0        0        0      402 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/deploy/.env.default
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/deploy/.keep
+-rw-r--r--   0        0        0      214 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/deploy/Dockerfile
+-rw-r--r--   0        0        0      359 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/deploy/compose.sqlite.yaml
+-rw-r--r--   0        0        0     2671 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/deploy/compose.swarm.yaml
+-rw-r--r--   0        0        0     1259 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/deploy/compose.yaml
+-rw-r--r--   0        0        0      211 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/deploy/sqlite.env.default
+-rw-r--r--   0        0        0      423 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/deploy/swarm.env.default
+-rw-r--r--   0        0        0       37 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/dipdup.yaml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/graphql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/handlers/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/hasura/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/hooks/.keep
+-rw-r--r--   0        0        0      378 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/hooks/on_index_rollback.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/hooks/on_reindex.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/hooks/on_restart.py
+-rw-r--r--   0        0        0      145 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/hooks/on_synchronized.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/models/.keep
+-rw-r--r--   0        0        0     1241 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/models/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/py.typed
+-rw-r--r--   0        0        0     1494 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/pyproject.toml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/sql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/sql/on_index_rollback/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/sql/on_reindex/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/sql/on_restart/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/sql/on_synchronized/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_blank/types/.keep
+-rw-r--r--   0        0        0      270 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_evm_events/.dockerignore
+-rw-r--r--   0        0        0      366 2024-05-06 16:41:21.616766 dipdup-8.0.0a1/src/demo_evm_events/.gitignore
+-rw-r--r--   0        0        0       35 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_evm_events/.ruff_cache/.gitignore
+-rw-r--r--   0        0        0      309 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_evm_events/.ruff_cache/0.4.3/8860806339027549023
+-rw-r--r--   0        0        0      133 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_evm_events/.ruff_cache/0.4.3/9161987054779895070
+-rw-r--r--   0        0        0      147 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_evm_events/.ruff_cache/0.4.3/9391793766016953357
+-rw-r--r--   0        0        0       43 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_evm_events/.ruff_cache/CACHEDIR.TAG
+-rw-r--r--   0        0        0      939 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/Makefile
+-rw-r--r--   0        0        0      930 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/README.md
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/abi/.keep
+-rw-r--r--   0        0        0    11460 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/abi/eth_usdt/abi.json
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/configs/.keep
+-rw-r--r--   0        0        0      523 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/configs/dipdup.compose.yaml
+-rw-r--r--   0        0        0       76 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/configs/dipdup.sqlite.yaml
+-rw-r--r--   0        0        0      554 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/configs/dipdup.swarm.yaml
+-rw-r--r--   0        0        0      579 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/configs/replay.yaml
+-rw-r--r--   0        0        0      644 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/deploy/.env.default
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/deploy/.keep
+-rw-r--r--   0        0        0      224 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/deploy/Dockerfile
+-rw-r--r--   0        0        0      369 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/deploy/compose.sqlite.yaml
+-rw-r--r--   0        0        0     2681 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/deploy/compose.swarm.yaml
+-rw-r--r--   0        0        0     1264 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/deploy/compose.yaml
+-rw-r--r--   0        0        0      458 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/deploy/sqlite.env.default
+-rw-r--r--   0        0        0      675 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/deploy/swarm.env.default
+-rw-r--r--   0        0        0      827 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/dipdup.yaml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/graphql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/handlers/.keep
+-rw-r--r--   0        0        0     1286 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/handlers/on_transfer.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/hasura/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/hooks/.keep
+-rw-r--r--   0        0        0      378 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/hooks/on_index_rollback.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/hooks/on_reindex.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/hooks/on_restart.py
+-rw-r--r--   0        0        0      145 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/hooks/on_synchronized.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/models/.keep
+-rw-r--r--   0        0        0      469 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/models/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/py.typed
+-rw-r--r--   0        0        0     1509 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/pyproject.toml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/sql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/sql/on_index_rollback/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/sql/on_reindex/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/sql/on_restart/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/sql/on_synchronized/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/types/.keep
+-rw-r--r--   0        0        0      323 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_events/types/eth_usdt/evm_events/transfer.py
+-rw-r--r--   0        0        0      276 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/.dockerignore
+-rw-r--r--   0        0        0      372 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/.gitignore
+-rw-r--r--   0        0        0       35 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_evm_transactions/.ruff_cache/.gitignore
+-rw-r--r--   0        0        0      139 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_evm_transactions/.ruff_cache/0.4.3/10423168124916732550
+-rw-r--r--   0        0        0      315 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_evm_transactions/.ruff_cache/0.4.3/14334534642061198666
+-rw-r--r--   0        0        0      159 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_evm_transactions/.ruff_cache/0.4.3/2856164939688226645
+-rw-r--r--   0        0        0       43 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_evm_transactions/.ruff_cache/CACHEDIR.TAG
+-rw-r--r--   0        0        0      945 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/Makefile
+-rw-r--r--   0        0        0      938 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/README.md
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/abi/.keep
+-rw-r--r--   0        0        0    11460 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/abi/eth_usdt/abi.json
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/configs/.keep
+-rw-r--r--   0        0        0      523 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/configs/dipdup.compose.yaml
+-rw-r--r--   0        0        0       82 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/configs/dipdup.sqlite.yaml
+-rw-r--r--   0        0        0      566 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/configs/dipdup.swarm.yaml
+-rw-r--r--   0        0        0      593 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/configs/replay.yaml
+-rw-r--r--   0        0        0      644 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/deploy/.env.default
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/deploy/.keep
+-rw-r--r--   0        0        0      236 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/deploy/Dockerfile
+-rw-r--r--   0        0        0      381 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/deploy/compose.sqlite.yaml
+-rw-r--r--   0        0        0     2693 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/deploy/compose.swarm.yaml
+-rw-r--r--   0        0        0     1270 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/deploy/compose.yaml
+-rw-r--r--   0        0        0      464 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/deploy/sqlite.env.default
+-rw-r--r--   0        0        0      687 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/deploy/swarm.env.default
+-rw-r--r--   0        0        0      866 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/dipdup.yaml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/graphql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/handlers/.keep
+-rw-r--r--   0        0        0     1341 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/handlers/on_transfer.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/hasura/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/hooks/.keep
+-rw-r--r--   0        0        0      378 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/hooks/on_index_rollback.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/hooks/on_reindex.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/hooks/on_restart.py
+-rw-r--r--   0        0        0      145 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/hooks/on_synchronized.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/models/.keep
+-rw-r--r--   0        0        0      469 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/models/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/py.typed
+-rw-r--r--   0        0        0     1517 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/pyproject.toml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/sql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/sql/on_index_rollback/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/sql/on_reindex/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/sql/on_restart/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/sql/on_synchronized/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/types/.keep
+-rw-r--r--   0        0        0      252 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_transactions/types/eth_usdt/evm_transactions/transfer.py
+-rw-r--r--   0        0        0      271 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_uniswap/.dockerignore
+-rw-r--r--   0        0        0      367 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_uniswap/.gitignore
+-rw-r--r--   0        0        0       35 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_evm_uniswap/.ruff_cache/.gitignore
+-rw-r--r--   0        0        0      310 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_evm_uniswap/.ruff_cache/0.4.3/11602067459202152054
+-rw-r--r--   0        0        0      329 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_evm_uniswap/.ruff_cache/0.4.3/13987272415079215471
+-rw-r--r--   0        0        0      143 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_evm_uniswap/.ruff_cache/0.4.3/14299902902424710960
+-rw-r--r--   0        0        0      151 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_evm_uniswap/.ruff_cache/0.4.3/14857693123772290028
+-rw-r--r--   0        0        0      339 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_evm_uniswap/.ruff_cache/0.4.3/3466246245111307653
+-rw-r--r--   0        0        0      400 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_evm_uniswap/.ruff_cache/0.4.3/4651924748073477142
+-rw-r--r--   0        0        0      337 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_evm_uniswap/.ruff_cache/0.4.3/6549441799034856475
+-rw-r--r--   0        0        0       43 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_evm_uniswap/.ruff_cache/CACHEDIR.TAG
+-rw-r--r--   0        0        0      940 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_uniswap/Makefile
+-rw-r--r--   0        0        0      953 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_uniswap/README.md
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_uniswap/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_uniswap/abi/.keep
+-rw-r--r--   0        0        0     3684 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_uniswap/abi/erc20/ERC20.json
+-rw-r--r--   0        0        0      268 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_uniswap/abi/erc20/ERC20NameBytes.json
+-rw-r--r--   0        0        0      270 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_uniswap/abi/erc20/ERC20SymbolBytes.json
+-rw-r--r--   0        0        0     4418 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_uniswap/abi/factory/abi.json
+-rw-r--r--   0        0        0    19609 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_uniswap/abi/pool/abi.json
+-rw-r--r--   0        0        0    24313 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_uniswap/abi/position_manager/abi.json
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.620766 dipdup-8.0.0a1/src/demo_evm_uniswap/configs/.keep
+-rw-r--r--   0        0        0      523 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/configs/dipdup.compose.yaml
+-rw-r--r--   0        0        0       77 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/configs/dipdup.sqlite.yaml
+-rw-r--r--   0        0        0      556 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/configs/dipdup.swarm.yaml
+-rw-r--r--   0        0        0      623 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/configs/replay.yaml
+-rw-r--r--   0        0        0      644 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/deploy/.env.default
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/deploy/.keep
+-rw-r--r--   0        0        0      226 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/deploy/Dockerfile
+-rw-r--r--   0        0        0      371 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/deploy/compose.sqlite.yaml
+-rw-r--r--   0        0        0     2703 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/deploy/compose.swarm.yaml
+-rw-r--r--   0        0        0     1285 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/deploy/compose.yaml
+-rw-r--r--   0        0        0      459 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/deploy/sqlite.env.default
+-rw-r--r--   0        0        0      677 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/deploy/swarm.env.default
+-rw-r--r--   0        0        0     2059 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/dipdup.yaml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/graphql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/handlers/.keep
+-rw-r--r--   0        0        0     2679 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/handlers/factory/pool_created.py
+-rw-r--r--   0        0        0      542 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/handlers/pool/burn.py
+-rw-r--r--   0        0        0      294 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/handlers/pool/flash.py
+-rw-r--r--   0        0        0      878 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/handlers/pool/initialize.py
+-rw-r--r--   0        0        0     1344 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/handlers/pool/mint.py
+-rw-r--r--   0        0        0     6596 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/handlers/pool/swap.py
+-rw-r--r--   0        0        0     1260 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/handlers/position_manager/collect.py
+-rw-r--r--   0        0        0     1394 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/handlers/position_manager/decrease_liquidity.py
+-rw-r--r--   0        0        0     1482 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/handlers/position_manager/increase_liquidity.py
+-rw-r--r--   0        0        0     1378 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/handlers/position_manager/transfer.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/hasura/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/hooks/.keep
+-rw-r--r--   0        0        0      378 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/hooks/on_index_rollback.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/hooks/on_reindex.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/hooks/on_restart.py
+-rw-r--r--   0        0        0      145 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/hooks/on_synchronized.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/models/.keep
+-rw-r--r--   0        0        0    19960 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/models/__init__.py
+-rw-r--r--   0        0        0      373 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/models/abi.py
+-rw-r--r--   0        0        0     4260 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/models/pool.py
+-rw-r--r--   0        0        0     2839 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/models/position.py
+-rw-r--r--   0        0        0     1456 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/models/repo.py
+-rw-r--r--   0        0        0      581 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/models/tick.py
+-rw-r--r--   0        0        0     7152 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/models/token.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/py.typed
+-rw-r--r--   0        0        0     1532 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/pyproject.toml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/sql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/sql/on_index_rollback/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/sql/on_reindex/.keep
+-rw-r--r--   0        0        0      225 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/sql/on_reindex/00_prepare_db.sql
+-rw-r--r--   0        0        0      792 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/sql/on_reindex/20_create_ca_quotes_1m.sql
+-rw-r--r--   0        0        0      788 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/sql/on_reindex/21_create_ca_quotes_1h.sql
+-rw-r--r--   0        0        0      787 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/sql/on_reindex/22_create_ca_quotes_1d.sql
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/sql/on_restart/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/sql/on_synchronized/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/types/.keep
+-rw-r--r--   0        0        0      310 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/types/factory/evm_events/pool_created.py
+-rw-r--r--   0        0        0      326 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/types/pool/evm_events/burn.py
+-rw-r--r--   0        0        0      332 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/types/pool/evm_events/collect.py
+-rw-r--r--   0        0        0      323 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/types/pool/evm_events/flash.py
+-rw-r--r--   0        0        0      265 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/types/pool/evm_events/initialize.py
+-rw-r--r--   0        0        0      342 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/types/pool/evm_events/mint.py
+-rw-r--r--   0        0        0      347 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/types/pool/evm_events/swap.py
+-rw-r--r--   0        0        0      296 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/types/position_manager/evm_events/collect.py
+-rw-r--r--   0        0        0      306 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/types/position_manager/evm_events/decrease_liquidity.py
+-rw-r--r--   0        0        0      306 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/types/position_manager/evm_events/increase_liquidity.py
+-rw-r--r--   0        0        0      325 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_evm_uniswap/types/position_manager/evm_events/transfer.py
+-rw-r--r--   0        0        0      273 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/.dockerignore
+-rw-r--r--   0        0        0      369 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/.gitignore
+-rw-r--r--   0        0        0       35 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_auction/.ruff_cache/.gitignore
+-rw-r--r--   0        0        0      312 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_auction/.ruff_cache/0.4.3/1581765555314869202
+-rw-r--r--   0        0        0      273 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_auction/.ruff_cache/0.4.3/16247802108505747561
+-rw-r--r--   0        0        0      152 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_auction/.ruff_cache/0.4.3/18212407888146132188
+-rw-r--r--   0        0        0      251 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_auction/.ruff_cache/0.4.3/791484405554922686
+-rw-r--r--   0        0        0       43 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_auction/.ruff_cache/CACHEDIR.TAG
+-rw-r--r--   0        0        0      942 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/Makefile
+-rw-r--r--   0        0        0      919 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/README.md
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/abi/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/configs/.keep
+-rw-r--r--   0        0        0      523 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/configs/dipdup.compose.yaml
+-rw-r--r--   0        0        0       79 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/configs/dipdup.sqlite.yaml
+-rw-r--r--   0        0        0      560 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/configs/dipdup.swarm.yaml
+-rw-r--r--   0        0        0      571 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/configs/replay.yaml
+-rw-r--r--   0        0        0      431 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/deploy/.env.default
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/deploy/.keep
+-rw-r--r--   0        0        0      230 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/deploy/Dockerfile
+-rw-r--r--   0        0        0      375 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/deploy/compose.sqlite.yaml
+-rw-r--r--   0        0        0     2687 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/deploy/compose.swarm.yaml
+-rw-r--r--   0        0        0     1267 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/deploy/compose.yaml
+-rw-r--r--   0        0        0      248 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/deploy/sqlite.env.default
+-rw-r--r--   0        0        0      468 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/deploy/swarm.env.default
+-rw-r--r--   0        0        0     1087 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/dipdup.yaml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/graphql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/handlers/.keep
+-rw-r--r--   0        0        0      924 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/handlers/on_bid.py
+-rw-r--r--   0        0        0     1634 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/handlers/on_create_auction.py
+-rw-r--r--   0        0        0      723 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/handlers/on_withdraw.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/hasura/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/hooks/.keep
+-rw-r--r--   0        0        0      378 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/hooks/on_index_rollback.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/hooks/on_reindex.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/hooks/on_restart.py
+-rw-r--r--   0        0        0      145 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/hooks/on_synchronized.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/models/.keep
+-rw-r--r--   0        0        0     1445 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/models/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/py.typed
+-rw-r--r--   0        0        0     1498 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/pyproject.toml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.624766 dipdup-8.0.0a1/src/demo_tezos_auction/sql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_auction/sql/on_index_rollback/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_auction/sql/on_reindex/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_auction/sql/on_restart/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_auction/sql/on_synchronized/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_auction/types/.keep
+-rw-r--r--   0        0        0      150 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_auction/types/tzcolors_auction/tezos_parameters/bid.py
+-rw-r--r--   0        0        0      360 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_auction/types/tzcolors_auction/tezos_parameters/create_auction.py
+-rw-r--r--   0        0        0      155 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_auction/types/tzcolors_auction/tezos_parameters/withdraw.py
+-rw-r--r--   0        0        0      549 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_auction/types/tzcolors_auction/tezos_storage.py
+-rw-r--r--   0        0        0      274 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/.dockerignore
+-rw-r--r--   0        0        0      370 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/.gitignore
+-rw-r--r--   0        0        0       35 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_big_maps/.ruff_cache/.gitignore
+-rw-r--r--   0        0        0      209 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_big_maps/.ruff_cache/0.4.3/10066915361535739159
+-rw-r--r--   0        0        0      313 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_big_maps/.ruff_cache/0.4.3/14449213820809892926
+-rw-r--r--   0        0        0      368 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_big_maps/.ruff_cache/0.4.3/6445708972851478045
+-rw-r--r--   0        0        0       43 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_big_maps/.ruff_cache/CACHEDIR.TAG
+-rw-r--r--   0        0        0      943 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/Makefile
+-rw-r--r--   0        0        0      920 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/README.md
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/abi/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/configs/.keep
+-rw-r--r--   0        0        0      523 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/configs/dipdup.compose.yaml
+-rw-r--r--   0        0        0       80 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/configs/dipdup.sqlite.yaml
+-rw-r--r--   0        0        0      562 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/configs/dipdup.swarm.yaml
+-rw-r--r--   0        0        0      573 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/configs/replay.yaml
+-rw-r--r--   0        0        0      431 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/deploy/.env.default
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/deploy/.keep
+-rw-r--r--   0        0        0      232 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/deploy/Dockerfile
+-rw-r--r--   0        0        0      377 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/deploy/compose.sqlite.yaml
+-rw-r--r--   0        0        0     2689 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/deploy/compose.swarm.yaml
+-rw-r--r--   0        0        0     1268 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/deploy/compose.yaml
+-rw-r--r--   0        0        0      249 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/deploy/sqlite.env.default
+-rw-r--r--   0        0        0      470 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/deploy/swarm.env.default
+-rw-r--r--   0        0        0      735 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/dipdup.yaml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/graphql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/handlers/.keep
+-rw-r--r--   0        0        0      853 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/handlers/on_update_expiry_map.py
+-rw-r--r--   0        0        0     1701 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/handlers/on_update_records.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/hasura/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/hooks/.keep
+-rw-r--r--   0        0        0      378 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/hooks/on_index_rollback.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/hooks/on_reindex.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/hooks/on_restart.py
+-rw-r--r--   0        0        0      145 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/hooks/on_synchronized.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/models/.keep
+-rw-r--r--   0        0        0      667 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/models/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/py.typed
+-rw-r--r--   0        0        0     1499 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/pyproject.toml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/sql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/sql/on_index_rollback/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/sql/on_reindex/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/sql/on_restart/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/sql/on_synchronized/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/types/.keep
+-rw-r--r--   0        0        0      155 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/types/name_registry/tezos_big_maps/store_expiry_map_key.py
+-rw-r--r--   0        0        0      157 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/types/name_registry/tezos_big_maps/store_expiry_map_value.py
+-rw-r--r--   0        0        0      153 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/types/name_registry/tezos_big_maps/store_records_key.py
+-rw-r--r--   0        0        0      422 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_big_maps/types/name_registry/tezos_big_maps/store_records_value.py
+-rw-r--r--   0        0        0      269 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/.dockerignore
+-rw-r--r--   0        0        0      365 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/.gitignore
+-rw-r--r--   0        0        0       35 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_dao/.ruff_cache/.gitignore
+-rw-r--r--   0        0        0      151 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_dao/.ruff_cache/0.4.3/10973831898660537587
+-rw-r--r--   0        0        0      140 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_dao/.ruff_cache/0.4.3/11782409822220307222
+-rw-r--r--   0        0        0      308 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_dao/.ruff_cache/0.4.3/14513816908233912065
+-rw-r--r--   0        0        0      191 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_dao/.ruff_cache/0.4.3/5262914534415971841
+-rw-r--r--   0        0        0       43 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_dao/.ruff_cache/CACHEDIR.TAG
+-rw-r--r--   0        0        0      938 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/Makefile
+-rw-r--r--   0        0        0      916 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/README.md
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/abi/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/configs/.keep
+-rw-r--r--   0        0        0      523 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/configs/dipdup.compose.yaml
+-rw-r--r--   0        0        0       75 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/configs/dipdup.sqlite.yaml
+-rw-r--r--   0        0        0      552 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/configs/dipdup.swarm.yaml
+-rw-r--r--   0        0        0      564 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/configs/replay.yaml
+-rw-r--r--   0        0        0      431 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/deploy/.env.default
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/deploy/.keep
+-rw-r--r--   0        0        0      222 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/deploy/Dockerfile
+-rw-r--r--   0        0        0      367 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/deploy/compose.sqlite.yaml
+-rw-r--r--   0        0        0     2679 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/deploy/compose.swarm.yaml
+-rw-r--r--   0        0        0     1263 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/deploy/compose.yaml
+-rw-r--r--   0        0        0      244 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/deploy/sqlite.env.default
+-rw-r--r--   0        0        0      460 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/deploy/swarm.env.default
+-rw-r--r--   0        0        0      653 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/dipdup.yaml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/graphql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/handlers/.keep
+-rw-r--r--   0        0        0      417 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/handlers/on_origination.py
+-rw-r--r--   0        0        0      521 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/handlers/on_propose.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/hasura/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/hooks/.keep
+-rw-r--r--   0        0        0      378 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/hooks/on_index_rollback.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/hooks/on_reindex.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/hooks/on_restart.py
+-rw-r--r--   0        0        0      145 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/hooks/on_synchronized.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/models/.keep
+-rw-r--r--   0        0        0      782 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/models/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/py.typed
+-rw-r--r--   0        0        0     1495 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/pyproject.toml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/sql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/sql/on_index_rollback/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/sql/on_reindex/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/sql/on_restart/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/sql/on_synchronized/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/types/.keep
+-rw-r--r--   0        0        0      346 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/types/registry/tezos_parameters/propose.py
+-rw-r--r--   0        0        0     2572 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dao/types/registry/tezos_storage.py
+-rw-r--r--   0        0        0      269 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dex/.dockerignore
+-rw-r--r--   0        0        0      365 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dex/.gitignore
+-rw-r--r--   0        0        0       35 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_dex/.ruff_cache/.gitignore
+-rw-r--r--   0        0        0      141 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_dex/.ruff_cache/0.4.3/11099518876581013779
+-rw-r--r--   0        0        0      153 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_dex/.ruff_cache/0.4.3/11294502438604056792
+-rw-r--r--   0        0        0      308 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_dex/.ruff_cache/0.4.3/13077154456408787927
+-rw-r--r--   0        0        0     1004 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_dex/.ruff_cache/0.4.3/14035347461067337851
+-rw-r--r--   0        0        0      154 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_dex/.ruff_cache/0.4.3/16296517581839558674
+-rw-r--r--   0        0        0      142 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_dex/.ruff_cache/0.4.3/16946593341495954117
+-rw-r--r--   0        0        0      470 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_dex/.ruff_cache/0.4.3/17809830723368671469
+-rw-r--r--   0        0        0      141 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_dex/.ruff_cache/0.4.3/2210924300452135717
+-rw-r--r--   0        0        0      142 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_dex/.ruff_cache/0.4.3/2444851010617375990
+-rw-r--r--   0        0        0      471 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_dex/.ruff_cache/0.4.3/3586645887032485472
+-rw-r--r--   0        0        0       43 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_dex/.ruff_cache/CACHEDIR.TAG
+-rw-r--r--   0        0        0      938 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dex/Makefile
+-rw-r--r--   0        0        0      927 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dex/README.md
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dex/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dex/abi/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dex/configs/.keep
+-rw-r--r--   0        0        0      523 2024-05-06 16:41:21.628766 dipdup-8.0.0a1/src/demo_tezos_dex/configs/dipdup.compose.yaml
+-rw-r--r--   0        0        0       75 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/configs/dipdup.sqlite.yaml
+-rw-r--r--   0        0        0      552 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/configs/dipdup.swarm.yaml
+-rw-r--r--   0        0        0      575 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/configs/replay.yaml
+-rw-r--r--   0        0        0      402 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/deploy/.env.default
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/deploy/.keep
+-rw-r--r--   0        0        0      222 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/deploy/Dockerfile
+-rw-r--r--   0        0        0      367 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/deploy/compose.sqlite.yaml
+-rw-r--r--   0        0        0     2679 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/deploy/compose.swarm.yaml
+-rw-r--r--   0        0        0     1263 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/deploy/compose.yaml
+-rw-r--r--   0        0        0      215 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/deploy/sqlite.env.default
+-rw-r--r--   0        0        0      431 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/deploy/swarm.env.default
+-rw-r--r--   0        0        0     4859 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/dipdup.yaml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/graphql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/handlers/.keep
+-rw-r--r--   0        0        0     1854 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa12_divest_liquidity.py
+-rw-r--r--   0        0        0     1765 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa12_invest_liquidity.py
+-rw-r--r--   0        0        0      588 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa12_origination.py
+-rw-r--r--   0        0        0     1638 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa12_tez_to_token.py
+-rw-r--r--   0        0        0     1701 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa12_token_to_tez.py
+-rw-r--r--   0        0        0     1037 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa12_transfer.py
+-rw-r--r--   0        0        0      943 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa12_withdraw_profit.py
+-rw-r--r--   0        0        0     1876 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa2_divest_liquidity.py
+-rw-r--r--   0        0        0     1787 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa2_invest_liquidity.py
+-rw-r--r--   0        0        0      582 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa2_origination.py
+-rw-r--r--   0        0        0     1628 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa2_tez_to_token.py
+-rw-r--r--   0        0        0     1667 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa2_token_to_tez.py
+-rw-r--r--   0        0        0     1154 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa2_transfer.py
+-rw-r--r--   0        0        0      939 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa2_withdraw_profit.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/hasura/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/hooks/.keep
+-rw-r--r--   0        0        0      378 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/hooks/on_index_rollback.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/hooks/on_reindex.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/hooks/on_restart.py
+-rw-r--r--   0        0        0      145 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/hooks/on_synchronized.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/models/.keep
+-rw-r--r--   0        0        0      916 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/models/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/py.typed
+-rw-r--r--   0        0        0     1506 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/pyproject.toml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/sql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/sql/on_index_rollback/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/sql/on_reindex/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/sql/on_restart/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/sql/on_synchronized/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/types/.keep
+-rw-r--r--   0        0        0      325 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/types/fa12_token/tezos_parameters/transfer.py
+-rw-r--r--   0        0        0      720 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/types/fa12_token/tezos_storage.py
+-rw-r--r--   0        0        0      533 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/types/fa2_token/tezos_parameters/transfer.py
+-rw-r--r--   0        0        0     1090 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/types/fa2_token/tezos_storage.py
+-rw-r--r--   0        0        0      289 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/types/quipu_fa12/tezos_parameters/divest_liquidity.py
+-rw-r--r--   0        0        0      162 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/types/quipu_fa12/tezos_parameters/invest_liquidity.py
+-rw-r--r--   0        0        0      273 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/types/quipu_fa12/tezos_parameters/tez_to_token_payment.py
+-rw-r--r--   0        0        0      289 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/types/quipu_fa12/tezos_parameters/token_to_tez_payment.py
+-rw-r--r--   0        0        0      325 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/types/quipu_fa12/tezos_parameters/transfer.py
+-rw-r--r--   0        0        0      161 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/types/quipu_fa12/tezos_parameters/withdraw_profit.py
+-rw-r--r--   0        0        0     1446 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/types/quipu_fa12/tezos_storage.py
+-rw-r--r--   0        0        0      289 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/types/quipu_fa2/tezos_parameters/divest_liquidity.py
+-rw-r--r--   0        0        0      162 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/types/quipu_fa2/tezos_parameters/invest_liquidity.py
+-rw-r--r--   0        0        0      273 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/types/quipu_fa2/tezos_parameters/tez_to_token_payment.py
+-rw-r--r--   0        0        0      289 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/types/quipu_fa2/tezos_parameters/token_to_tez_payment.py
+-rw-r--r--   0        0        0      533 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/types/quipu_fa2/tezos_parameters/transfer.py
+-rw-r--r--   0        0        0      161 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/types/quipu_fa2/tezos_parameters/withdraw_profit.py
+-rw-r--r--   0        0        0     1458 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_dex/types/quipu_fa2/tezos_storage.py
+-rw-r--r--   0        0        0      273 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/.dockerignore
+-rw-r--r--   0        0        0      369 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/.gitignore
+-rw-r--r--   0        0        0       35 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_domains/.ruff_cache/.gitignore
+-rw-r--r--   0        0        0      208 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_domains/.ruff_cache/0.4.3/7363227042974458940
+-rw-r--r--   0        0        0      374 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_domains/.ruff_cache/0.4.3/9555919289849422971
+-rw-r--r--   0        0        0      367 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_domains/.ruff_cache/0.4.3/9737789287334098014
+-rw-r--r--   0        0        0       43 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_domains/.ruff_cache/CACHEDIR.TAG
+-rw-r--r--   0        0        0      942 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/Makefile
+-rw-r--r--   0        0        0      928 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/README.md
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/abi/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/configs/.keep
+-rw-r--r--   0        0        0      523 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/configs/dipdup.compose.yaml
+-rw-r--r--   0        0        0       79 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/configs/dipdup.sqlite.yaml
+-rw-r--r--   0        0        0      560 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/configs/dipdup.swarm.yaml
+-rw-r--r--   0        0        0      580 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/configs/replay.yaml
+-rw-r--r--   0        0        0      431 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/deploy/.env.default
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/deploy/.keep
+-rw-r--r--   0        0        0      230 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/deploy/Dockerfile
+-rw-r--r--   0        0        0      375 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/deploy/compose.sqlite.yaml
+-rw-r--r--   0        0        0     2687 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/deploy/compose.swarm.yaml
+-rw-r--r--   0        0        0     1267 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/deploy/compose.yaml
+-rw-r--r--   0        0        0      248 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/deploy/sqlite.env.default
+-rw-r--r--   0        0        0      468 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/deploy/swarm.env.default
+-rw-r--r--   0        0        0      903 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/dipdup.yaml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/graphql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/handlers/.keep
+-rw-r--r--   0        0        0     1920 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/handlers/on_update_expiry_map.py
+-rw-r--r--   0        0        0     3280 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/handlers/on_update_records.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/hasura/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/hooks/.keep
+-rw-r--r--   0        0        0      975 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/hooks/check_expiration.py
+-rw-r--r--   0        0        0      378 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/hooks/on_index_rollback.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/hooks/on_reindex.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/hooks/on_restart.py
+-rw-r--r--   0        0        0      145 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/hooks/on_synchronized.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/models/.keep
+-rw-r--r--   0        0        0      972 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/models/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/py.typed
+-rw-r--r--   0        0        0     1507 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/pyproject.toml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/sql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/sql/on_index_rollback/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/sql/on_reindex/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/sql/on_restart/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/sql/on_synchronized/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/types/.keep
+-rw-r--r--   0        0        0      155 2024-05-06 16:41:21.632766 dipdup-8.0.0a1/src/demo_tezos_domains/types/name_registry/tezos_big_maps/store_expiry_map_key.py
+-rw-r--r--   0        0        0      157 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_domains/types/name_registry/tezos_big_maps/store_expiry_map_value.py
+-rw-r--r--   0        0        0      153 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_domains/types/name_registry/tezos_big_maps/store_records_key.py
+-rw-r--r--   0        0        0      422 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_domains/types/name_registry/tezos_big_maps/store_records_value.py
+-rw-r--r--   0        0        0      275 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/.dockerignore
+-rw-r--r--   0        0        0      371 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/.gitignore
+-rw-r--r--   0        0        0       35 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_etherlink/.ruff_cache/.gitignore
+-rw-r--r--   0        0        0      211 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_etherlink/.ruff_cache/0.4.3/14361919572049819204
+-rw-r--r--   0        0        0      144 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_etherlink/.ruff_cache/0.4.3/16775238721333733628
+-rw-r--r--   0        0        0      151 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_etherlink/.ruff_cache/0.4.3/17582342770926753886
+-rw-r--r--   0        0        0      162 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_etherlink/.ruff_cache/0.4.3/3251235857487434377
+-rw-r--r--   0        0        0      314 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_etherlink/.ruff_cache/0.4.3/4453277644764148483
+-rw-r--r--   0        0        0      155 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_etherlink/.ruff_cache/0.4.3/8144515047258742777
+-rw-r--r--   0        0        0      194 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_etherlink/.ruff_cache/0.4.3/8944970581780848165
+-rw-r--r--   0        0        0      146 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_etherlink/.ruff_cache/0.4.3/9188957887755351463
+-rw-r--r--   0        0        0       43 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_etherlink/.ruff_cache/CACHEDIR.TAG
+-rw-r--r--   0        0        0      944 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/Makefile
+-rw-r--r--   0        0        0      930 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/README.md
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/abi/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/configs/.keep
+-rw-r--r--   0        0        0      523 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/configs/dipdup.compose.yaml
+-rw-r--r--   0        0        0       81 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/configs/dipdup.sqlite.yaml
+-rw-r--r--   0        0        0      564 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/configs/dipdup.swarm.yaml
+-rw-r--r--   0        0        0      584 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/configs/replay.yaml
+-rw-r--r--   0        0        0      442 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/deploy/.env.default
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/deploy/.keep
+-rw-r--r--   0        0        0      234 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/deploy/Dockerfile
+-rw-r--r--   0        0        0      379 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/deploy/compose.sqlite.yaml
+-rw-r--r--   0        0        0     2691 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/deploy/compose.swarm.yaml
+-rw-r--r--   0        0        0     1269 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/deploy/compose.yaml
+-rw-r--r--   0        0        0      261 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/deploy/sqlite.env.default
+-rw-r--r--   0        0        0      483 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/deploy/swarm.env.default
+-rw-r--r--   0        0        0     1353 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/dipdup.yaml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/graphql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/handlers/.keep
+-rw-r--r--   0        0        0      959 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/handlers/on_deposit.py
+-rw-r--r--   0        0        0      636 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/handlers/on_withdraw.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/hasura/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/hooks/.keep
+-rw-r--r--   0        0        0      378 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/hooks/on_index_rollback.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/hooks/on_reindex.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/hooks/on_restart.py
+-rw-r--r--   0        0        0      145 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/hooks/on_synchronized.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/models/.keep
+-rw-r--r--   0        0        0     1241 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/models/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/py.typed
+-rw-r--r--   0        0        0     1509 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/pyproject.toml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/sql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/sql/on_index_rollback/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/sql/on_reindex/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/sql/on_restart/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/sql/on_synchronized/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/types/.keep
+-rw-r--r--   0        0        0     1038 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/types/rollup/tezos_parameters/default.py
+-rw-r--r--   0        0        0      153 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/types/rollup/tezos_storage.py
+-rw-r--r--   0        0        0      404 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/types/ticket_helper/tezos_parameters/default.py
+-rw-r--r--   0        0        0      783 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/types/ticket_helper/tezos_storage.py
+-rw-r--r--   0        0        0      154 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/types/ticketer/tezos_parameters/deposit.py
+-rw-r--r--   0        0        0      530 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/types/ticketer/tezos_parameters/withdraw.py
+-rw-r--r--   0        0        0      751 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_etherlink/types/ticketer/tezos_storage.py
+-rw-r--r--   0        0        0      272 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/.dockerignore
+-rw-r--r--   0        0        0      368 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/.gitignore
+-rw-r--r--   0        0        0       35 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_events/.ruff_cache/.gitignore
+-rw-r--r--   0        0        0      311 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_events/.ruff_cache/0.4.3/11325409648288212438
+-rw-r--r--   0        0        0      256 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_events/.ruff_cache/0.4.3/11390283371106105399
+-rw-r--r--   0        0        0      204 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_events/.ruff_cache/0.4.3/2551068100518760141
+-rw-r--r--   0        0        0       43 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_events/.ruff_cache/CACHEDIR.TAG
+-rw-r--r--   0        0        0      941 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/Makefile
+-rw-r--r--   0        0        0      918 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/README.md
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/abi/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/configs/.keep
+-rw-r--r--   0        0        0      523 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/configs/dipdup.compose.yaml
+-rw-r--r--   0        0        0       78 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/configs/dipdup.sqlite.yaml
+-rw-r--r--   0        0        0      558 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/configs/dipdup.swarm.yaml
+-rw-r--r--   0        0        0      569 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/configs/replay.yaml
+-rw-r--r--   0        0        0      402 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/deploy/.env.default
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/deploy/.keep
+-rw-r--r--   0        0        0      228 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/deploy/Dockerfile
+-rw-r--r--   0        0        0      373 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/deploy/compose.sqlite.yaml
+-rw-r--r--   0        0        0     2685 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/deploy/compose.swarm.yaml
+-rw-r--r--   0        0        0     1266 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/deploy/compose.yaml
+-rw-r--r--   0        0        0      218 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/deploy/sqlite.env.default
+-rw-r--r--   0        0        0      437 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/deploy/swarm.env.default
+-rw-r--r--   0        0        0      544 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/dipdup.yaml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/graphql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/handlers/.keep
+-rw-r--r--   0        0        0      320 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/handlers/on_move_event.py
+-rw-r--r--   0        0        0      240 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/handlers/on_other_event.py
+-rw-r--r--   0        0        0      320 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/handlers/on_roll_event.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/hasura/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/hooks/.keep
+-rw-r--r--   0        0        0      378 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/hooks/on_index_rollback.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/hooks/on_reindex.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/hooks/on_restart.py
+-rw-r--r--   0        0        0      145 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/hooks/on_synchronized.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/models/.keep
+-rw-r--r--   0        0        0     1241 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/models/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/py.typed
+-rw-r--r--   0        0        0     1497 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/pyproject.toml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/sql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/sql/on_index_rollback/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/sql/on_reindex/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/sql/on_restart/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/sql/on_synchronized/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/types/.keep
+-rw-r--r--   0        0        0      306 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/types/events_contract/tezos_events/move.py
+-rw-r--r--   0        0        0      255 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_events/types/events_contract/tezos_events/roll.py
+-rw-r--r--   0        0        0      275 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_factories/.dockerignore
+-rw-r--r--   0        0        0      371 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_factories/.gitignore
+-rw-r--r--   0        0        0       35 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_factories/.ruff_cache/.gitignore
+-rw-r--r--   0        0        0      145 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_factories/.ruff_cache/0.4.3/13804393407624004279
+-rw-r--r--   0        0        0      143 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_factories/.ruff_cache/0.4.3/14492936145770554530
+-rw-r--r--   0        0        0      206 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_factories/.ruff_cache/0.4.3/16944360719752285284
+-rw-r--r--   0        0        0      155 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_factories/.ruff_cache/0.4.3/17976803095327677262
+-rw-r--r--   0        0        0      314 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_factories/.ruff_cache/0.4.3/5767552591528574066
+-rw-r--r--   0        0        0       43 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_factories/.ruff_cache/CACHEDIR.TAG
+-rw-r--r--   0        0        0      944 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_factories/Makefile
+-rw-r--r--   0        0        0      933 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_factories/README.md
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_factories/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_factories/abi/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_factories/configs/.keep
+-rw-r--r--   0        0        0      523 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_factories/configs/dipdup.compose.yaml
+-rw-r--r--   0        0        0       81 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_factories/configs/dipdup.sqlite.yaml
+-rw-r--r--   0        0        0      564 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_factories/configs/dipdup.swarm.yaml
+-rw-r--r--   0        0        0      587 2024-05-06 16:41:21.636766 dipdup-8.0.0a1/src/demo_tezos_factories/configs/replay.yaml
+-rw-r--r--   0        0        0      431 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/deploy/.env.default
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/deploy/.keep
+-rw-r--r--   0        0        0      234 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/deploy/Dockerfile
+-rw-r--r--   0        0        0      379 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/deploy/compose.sqlite.yaml
+-rw-r--r--   0        0        0     2691 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/deploy/compose.swarm.yaml
+-rw-r--r--   0        0        0     1269 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/deploy/compose.yaml
+-rw-r--r--   0        0        0      250 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/deploy/sqlite.env.default
+-rw-r--r--   0        0        0      472 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/deploy/swarm.env.default
+-rw-r--r--   0        0        0     1104 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/dipdup.yaml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/graphql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/handlers/.keep
+-rw-r--r--   0        0        0     1080 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/handlers/on_factory_origination.py
+-rw-r--r--   0        0        0      669 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/handlers/on_transfer.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/hasura/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/hooks/.keep
+-rw-r--r--   0        0        0      378 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/hooks/on_index_rollback.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/hooks/on_reindex.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/hooks/on_restart.py
+-rw-r--r--   0        0        0      145 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/hooks/on_synchronized.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/models/.keep
+-rw-r--r--   0        0        0      208 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/models/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/py.typed
+-rw-r--r--   0        0        0     1512 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/pyproject.toml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/sql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/sql/on_index_rollback/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/sql/on_reindex/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/sql/on_restart/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/sql/on_synchronized/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/types/.keep
+-rw-r--r--   0        0        0     1420 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/types/factory/tezos_storage.py
+-rw-r--r--   0        0        0      533 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/types/token/tezos_parameters/transfer.py
+-rw-r--r--   0        0        0     1173 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_factories/types/token/tezos_storage.py
+-rw-r--r--   0        0        0      270 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/.dockerignore
+-rw-r--r--   0        0        0      366 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/.gitignore
+-rw-r--r--   0        0        0       35 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_head/.ruff_cache/.gitignore
+-rw-r--r--   0        0        0      137 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_head/.ruff_cache/0.4.3/11676593018986204769
+-rw-r--r--   0        0        0      309 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_head/.ruff_cache/0.4.3/15102362554345955364
+-rw-r--r--   0        0        0       43 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_head/.ruff_cache/CACHEDIR.TAG
+-rw-r--r--   0        0        0      939 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/Makefile
+-rw-r--r--   0        0        0      936 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/README.md
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/abi/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/configs/.keep
+-rw-r--r--   0        0        0      523 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/configs/dipdup.compose.yaml
+-rw-r--r--   0        0        0       76 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/configs/dipdup.sqlite.yaml
+-rw-r--r--   0        0        0      554 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/configs/dipdup.swarm.yaml
+-rw-r--r--   0        0        0      585 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/configs/replay.yaml
+-rw-r--r--   0        0        0      431 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/deploy/.env.default
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/deploy/.keep
+-rw-r--r--   0        0        0      224 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/deploy/Dockerfile
+-rw-r--r--   0        0        0      369 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/deploy/compose.sqlite.yaml
+-rw-r--r--   0        0        0     2681 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/deploy/compose.swarm.yaml
+-rw-r--r--   0        0        0     1264 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/deploy/compose.yaml
+-rw-r--r--   0        0        0      245 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/deploy/sqlite.env.default
+-rw-r--r--   0        0        0      462 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/deploy/swarm.env.default
+-rw-r--r--   0        0        0      250 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/dipdup.yaml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/graphql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/handlers/.keep
+-rw-r--r--   0        0        0      240 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/handlers/on_mainnet_head.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/hasura/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/hooks/.keep
+-rw-r--r--   0        0        0      378 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/hooks/on_index_rollback.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/hooks/on_reindex.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/hooks/on_restart.py
+-rw-r--r--   0        0        0      145 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/hooks/on_synchronized.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/models/.keep
+-rw-r--r--   0        0        0     1241 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/models/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/py.typed
+-rw-r--r--   0        0        0     1515 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/pyproject.toml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/sql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/sql/on_index_rollback/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/sql/on_reindex/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/sql/on_restart/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/sql/on_synchronized/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_head/types/.keep
+-rw-r--r--   0        0        0      281 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/.dockerignore
+-rw-r--r--   0        0        0      377 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/.gitignore
+-rw-r--r--   0        0        0       35 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/.ruff_cache/.gitignore
+-rw-r--r--   0        0        0      328 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/.ruff_cache/0.4.3/10308005156419698599
+-rw-r--r--   0        0        0      154 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/.ruff_cache/0.4.3/10900046015408355250
+-rw-r--r--   0        0        0      162 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/.ruff_cache/0.4.3/12304189155453818371
+-rw-r--r--   0        0        0      309 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/.ruff_cache/0.4.3/16229680813839303132
+-rw-r--r--   0        0        0      154 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/.ruff_cache/0.4.3/5633345603186183391
+-rw-r--r--   0        0        0      320 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/.ruff_cache/0.4.3/6504371159825113924
+-rw-r--r--   0        0        0       43 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/.ruff_cache/CACHEDIR.TAG
+-rw-r--r--   0        0        0      950 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/Makefile
+-rw-r--r--   0        0        0      930 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/README.md
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/abi/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/configs/.keep
+-rw-r--r--   0        0        0      523 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/configs/dipdup.compose.yaml
+-rw-r--r--   0        0        0       87 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/configs/dipdup.sqlite.yaml
+-rw-r--r--   0        0        0      576 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/configs/dipdup.swarm.yaml
+-rw-r--r--   0        0        0      590 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/configs/replay.yaml
+-rw-r--r--   0        0        0      527 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/deploy/.env.default
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/deploy/.keep
+-rw-r--r--   0        0        0      246 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/deploy/Dockerfile
+-rw-r--r--   0        0        0      391 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/deploy/compose.sqlite.yaml
+-rw-r--r--   0        0        0     2703 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/deploy/compose.swarm.yaml
+-rw-r--r--   0        0        0     1275 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/deploy/compose.yaml
+-rw-r--r--   0        0        0      352 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/deploy/sqlite.env.default
+-rw-r--r--   0        0        0      580 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/deploy/swarm.env.default
+-rw-r--r--   0        0        0     1209 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/dipdup.yaml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/graphql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/handlers/.keep
+-rw-r--r--   0        0        0      616 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/handlers/on_cancel_swap.py
+-rw-r--r--   0        0        0     1052 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/handlers/on_collect.py
+-rw-r--r--   0        0        0     1005 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/handlers/on_mint.py
+-rw-r--r--   0        0        0      900 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/handlers/on_swap.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/hasura/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/hooks/.keep
+-rw-r--r--   0        0        0      378 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/hooks/on_index_rollback.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/hooks/on_reindex.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/hooks/on_restart.py
+-rw-r--r--   0        0        0      145 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/hooks/on_synchronized.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/models/.keep
+-rw-r--r--   0        0        0     1306 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/models/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/py.typed
+-rw-r--r--   0        0        0     1509 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/pyproject.toml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/sql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.640766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/sql/on_index_rollback/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/sql/on_reindex/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/sql/on_restart/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/sql/on_synchronized/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/types/.keep
+-rw-r--r--   0        0        0      157 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/types/hen_minter/tezos_parameters/cancel_swap.py
+-rw-r--r--   0        0        0      267 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/types/hen_minter/tezos_parameters/collect.py
+-rw-r--r--   0        0        0      300 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/types/hen_minter/tezos_parameters/mint_objkt.py
+-rw-r--r--   0        0        0      288 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/types/hen_minter/tezos_parameters/swap.py
+-rw-r--r--   0        0        0      758 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/types/hen_minter/tezos_storage.py
+-rw-r--r--   0        0        0      307 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/types/hen_objkts/tezos_parameters/mint.py
+-rw-r--r--   0        0        0     1091 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/types/hen_objkts/tezos_storage.py
+-rw-r--r--   0        0        0      269 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/.dockerignore
+-rw-r--r--   0        0        0      365 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/.gitignore
+-rw-r--r--   0        0        0       35 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_raw/.ruff_cache/.gitignore
+-rw-r--r--   0        0        0      308 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_raw/.ruff_cache/0.4.3/1274307697484945795
+-rw-r--r--   0        0        0      133 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_raw/.ruff_cache/0.4.3/2254649350499136473
+-rw-r--r--   0        0        0       43 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_raw/.ruff_cache/CACHEDIR.TAG
+-rw-r--r--   0        0        0      938 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/Makefile
+-rw-r--r--   0        0        0      948 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/README.md
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/abi/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/configs/.keep
+-rw-r--r--   0        0        0      523 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/configs/dipdup.compose.yaml
+-rw-r--r--   0        0        0       75 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/configs/dipdup.sqlite.yaml
+-rw-r--r--   0        0        0      552 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/configs/dipdup.swarm.yaml
+-rw-r--r--   0        0        0      596 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/configs/replay.yaml
+-rw-r--r--   0        0        0      431 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/deploy/.env.default
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/deploy/.keep
+-rw-r--r--   0        0        0      222 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/deploy/Dockerfile
+-rw-r--r--   0        0        0      367 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/deploy/compose.sqlite.yaml
+-rw-r--r--   0        0        0     2679 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/deploy/compose.swarm.yaml
+-rw-r--r--   0        0        0     1263 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/deploy/compose.yaml
+-rw-r--r--   0        0        0      244 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/deploy/sqlite.env.default
+-rw-r--r--   0        0        0      460 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/deploy/swarm.env.default
+-rw-r--r--   0        0        0      421 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/dipdup.yaml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/graphql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/handlers/.keep
+-rw-r--r--   0        0        0      353 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/handlers/on_operation.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/hasura/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/hooks/.keep
+-rw-r--r--   0        0        0      378 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/hooks/on_index_rollback.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/hooks/on_reindex.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/hooks/on_restart.py
+-rw-r--r--   0        0        0      145 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/hooks/on_synchronized.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/models/.keep
+-rw-r--r--   0        0        0      242 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/models/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/py.typed
+-rw-r--r--   0        0        0     1527 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/pyproject.toml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/sql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/sql/on_index_rollback/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/sql/on_reindex/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/sql/on_restart/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/sql/on_synchronized/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_raw/types/.keep
+-rw-r--r--   0        0        0      271 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/.dockerignore
+-rw-r--r--   0        0        0      367 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/.gitignore
+-rw-r--r--   0        0        0       35 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_token/.ruff_cache/.gitignore
+-rw-r--r--   0        0        0      139 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_token/.ruff_cache/0.4.3/16113411399124020357
+-rw-r--r--   0        0        0      310 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_token/.ruff_cache/0.4.3/17269123424613725696
+-rw-r--r--   0        0        0      201 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_token/.ruff_cache/0.4.3/2008799447224770089
+-rw-r--r--   0        0        0      250 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_token/.ruff_cache/0.4.3/3379391049973467325
+-rw-r--r--   0        0        0       43 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_token/.ruff_cache/CACHEDIR.TAG
+-rw-r--r--   0        0        0      940 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/Makefile
+-rw-r--r--   0        0        0      922 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/README.md
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/abi/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/configs/.keep
+-rw-r--r--   0        0        0      523 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/configs/dipdup.compose.yaml
+-rw-r--r--   0        0        0       77 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/configs/dipdup.sqlite.yaml
+-rw-r--r--   0        0        0      556 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/configs/dipdup.swarm.yaml
+-rw-r--r--   0        0        0      572 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/configs/replay.yaml
+-rw-r--r--   0        0        0      402 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/deploy/.env.default
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/deploy/.keep
+-rw-r--r--   0        0        0      226 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/deploy/Dockerfile
+-rw-r--r--   0        0        0      371 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/deploy/compose.sqlite.yaml
+-rw-r--r--   0        0        0     2683 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/deploy/compose.swarm.yaml
+-rw-r--r--   0        0        0     1265 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/deploy/compose.yaml
+-rw-r--r--   0        0        0      217 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/deploy/sqlite.env.default
+-rw-r--r--   0        0        0      435 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/deploy/swarm.env.default
+-rw-r--r--   0        0        0      740 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/dipdup.yaml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/graphql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/handlers/.keep
+-rw-r--r--   0        0        0      442 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/handlers/on_balance_update.py
+-rw-r--r--   0        0        0      645 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/handlers/on_mint.py
+-rw-r--r--   0        0        0      943 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/handlers/on_transfer.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/hasura/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/hooks/.keep
+-rw-r--r--   0        0        0      378 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/hooks/on_index_rollback.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/hooks/on_reindex.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/hooks/on_restart.py
+-rw-r--r--   0        0        0      145 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/hooks/on_synchronized.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/models/.keep
+-rw-r--r--   0        0        0      370 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/models/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/py.typed
+-rw-r--r--   0        0        0     1501 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/pyproject.toml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/sql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/sql/on_index_rollback/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/sql/on_reindex/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/sql/on_restart/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/sql/on_synchronized/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/types/.keep
+-rw-r--r--   0        0        0      252 2024-05-06 16:41:21.644766 dipdup-8.0.0a1/src/demo_tezos_token/types/tzbtc/tezos_parameters/mint.py
+-rw-r--r--   0        0        0      325 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token/types/tzbtc/tezos_parameters/transfer.py
+-rw-r--r--   0        0        0      353 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token/types/tzbtc/tezos_storage.py
+-rw-r--r--   0        0        0      280 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/.dockerignore
+-rw-r--r--   0        0        0      376 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/.gitignore
+-rw-r--r--   0        0        0       35 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_token_balances/.ruff_cache/.gitignore
+-rw-r--r--   0        0        0      319 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_token_balances/.ruff_cache/0.4.3/11310803749457900869
+-rw-r--r--   0        0        0      149 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_token_balances/.ruff_cache/0.4.3/12833243666624827340
+-rw-r--r--   0        0        0       43 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_token_balances/.ruff_cache/CACHEDIR.TAG
+-rw-r--r--   0        0        0      949 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/Makefile
+-rw-r--r--   0        0        0      920 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/README.md
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/abi/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/configs/.keep
+-rw-r--r--   0        0        0      523 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/configs/dipdup.compose.yaml
+-rw-r--r--   0        0        0       86 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/configs/dipdup.sqlite.yaml
+-rw-r--r--   0        0        0      574 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/configs/dipdup.swarm.yaml
+-rw-r--r--   0        0        0      579 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/configs/replay.yaml
+-rw-r--r--   0        0        0      402 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/deploy/.env.default
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/deploy/.keep
+-rw-r--r--   0        0        0      244 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/deploy/Dockerfile
+-rw-r--r--   0        0        0      389 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/deploy/compose.sqlite.yaml
+-rw-r--r--   0        0        0     2701 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/deploy/compose.swarm.yaml
+-rw-r--r--   0        0        0     1274 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/deploy/compose.yaml
+-rw-r--r--   0        0        0      226 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/deploy/sqlite.env.default
+-rw-r--r--   0        0        0      453 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/deploy/swarm.env.default
+-rw-r--r--   0        0        0      417 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/dipdup.yaml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/graphql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/handlers/.keep
+-rw-r--r--   0        0        0      475 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/handlers/on_balance_update.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/hasura/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/hooks/.keep
+-rw-r--r--   0        0        0      378 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/hooks/on_index_rollback.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/hooks/on_reindex.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/hooks/on_restart.py
+-rw-r--r--   0        0        0      145 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/hooks/on_synchronized.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/models/.keep
+-rw-r--r--   0        0        0      198 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/models/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/py.typed
+-rw-r--r--   0        0        0     1499 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/pyproject.toml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/sql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/sql/on_index_rollback/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/sql/on_reindex/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/sql/on_restart/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/sql/on_synchronized/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_balances/types/.keep
+-rw-r--r--   0        0        0      281 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/.dockerignore
+-rw-r--r--   0        0        0      377 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/.gitignore
+-rw-r--r--   0        0        0       35 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_token_transfers/.ruff_cache/.gitignore
+-rw-r--r--   0        0        0      320 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_token_transfers/.ruff_cache/0.4.3/12280012634670505097
+-rw-r--r--   0        0        0      213 2024-05-06 16:42:15.233242 dipdup-8.0.0a1/src/demo_tezos_token_transfers/.ruff_cache/0.4.3/2822693667168370652
+-rw-r--r--   0        0        0       43 2024-05-06 16:42:15.197241 dipdup-8.0.0a1/src/demo_tezos_token_transfers/.ruff_cache/CACHEDIR.TAG
+-rw-r--r--   0        0        0      950 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/Makefile
+-rw-r--r--   0        0        0      922 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/README.md
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/abi/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/configs/.keep
+-rw-r--r--   0        0        0      523 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/configs/dipdup.compose.yaml
+-rw-r--r--   0        0        0       87 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/configs/dipdup.sqlite.yaml
+-rw-r--r--   0        0        0      576 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/configs/dipdup.swarm.yaml
+-rw-r--r--   0        0        0      582 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/configs/replay.yaml
+-rw-r--r--   0        0        0      402 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/deploy/.env.default
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/deploy/.keep
+-rw-r--r--   0        0        0      246 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/deploy/Dockerfile
+-rw-r--r--   0        0        0      391 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/deploy/compose.sqlite.yaml
+-rw-r--r--   0        0        0     2703 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/deploy/compose.swarm.yaml
+-rw-r--r--   0        0        0     1275 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/deploy/compose.yaml
+-rw-r--r--   0        0        0      227 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/deploy/sqlite.env.default
+-rw-r--r--   0        0        0      455 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/deploy/swarm.env.default
+-rw-r--r--   0        0        0      419 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/dipdup.yaml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/graphql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/handlers/.keep
+-rw-r--r--   0        0        0      551 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/handlers/on_balance_update.py
+-rw-r--r--   0        0        0      839 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/handlers/on_token_transfer.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/hasura/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/hooks/.keep
+-rw-r--r--   0        0        0      378 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/hooks/on_index_rollback.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/hooks/on_reindex.py
+-rw-r--r--   0        0        0      135 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/hooks/on_restart.py
+-rw-r--r--   0        0        0      145 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/hooks/on_synchronized.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/models/.keep
+-rw-r--r--   0        0        0      370 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/models/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/py.typed
+-rw-r--r--   0        0        0     1501 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/pyproject.toml
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/sql/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/sql/on_index_rollback/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/sql/on_reindex/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/sql/on_restart/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/sql/on_synchronized/.keep
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/demo_tezos_token_transfers/types/.keep
+-rw-r--r--   0        0        0      180 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/dipdup/__init__.py
+-rw-r--r--   0        0        0      105 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/dipdup/__main__.py
+-rw-r--r--   0        0        0     1997 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/dipdup/api.py
+-rw-r--r--   0        0        0    27620 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/dipdup/cli.py
+-rw-r--r--   0        0        0     8093 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/dipdup/codegen/__init__.py
+-rw-r--r--   0        0        0     8997 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/dipdup/codegen/evm.py
+-rw-r--r--   0        0        0    19112 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/dipdup/codegen/tezos.py
+-rw-r--r--   0        0        0    45818 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/dipdup/config/__init__.py
+-rw-r--r--   0        0        0      681 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/dipdup/config/abi_etherscan.py
+-rw-r--r--   0        0        0      768 2024-05-06 16:41:21.648766 dipdup-8.0.0a1/src/dipdup/config/coinbase.py
+-rw-r--r--   0        0        0     2311 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/config/evm.py
+-rw-r--r--   0        0        0     2529 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/config/evm_events.py
+-rw-r--r--   0        0        0     1375 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/config/evm_node.py
+-rw-r--r--   0        0        0     1067 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/config/evm_subsquid.py
+-rw-r--r--   0        0        0     3066 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/config/evm_transactions.py
+-rw-r--r--   0        0        0      527 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/config/http.py
+-rw-r--r--   0        0        0      600 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/config/ipfs.py
+-rw-r--r--   0        0        0     2973 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/config/tezos.py
+-rw-r--r--   0        0        0     3984 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/config/tezos_big_maps.py
+-rw-r--r--   0        0        0     3323 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/config/tezos_events.py
+-rw-r--r--   0        0        0     1630 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/config/tezos_head.py
+-rw-r--r--   0        0        0    15360 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/config/tezos_operations.py
+-rw-r--r--   0        0        0     2820 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/config/tezos_token_balances.py
+-rw-r--r--   0        0        0     3195 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/config/tezos_token_transfers.py
+-rw-r--r--   0        0        0     1908 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/config/tezos_tzkt.py
+-rw-r--r--   0        0        0      826 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/config/tzip_metadata.py
+-rw-r--r--   0        0        0    28859 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/context.py
+-rw-r--r--   0        0        0    15587 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/database.py
+-rw-r--r--   0        0        0     5793 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/datasources/__init__.py
+-rw-r--r--   0        0        0     1751 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/datasources/abi_etherscan.py
+-rw-r--r--   0        0        0     2299 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/datasources/coinbase.py
+-rw-r--r--   0        0        0    15970 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/datasources/evm_node.py
+-rw-r--r--   0        0        0     8407 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/datasources/evm_subsquid.py
+-rw-r--r--   0        0        0      399 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/datasources/http.py
+-rw-r--r--   0        0        0      524 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/datasources/ipfs.py
+-rw-r--r--   0        0        0    49149 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/datasources/tezos_tzkt.py
+-rw-r--r--   0        0        0     1545 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/datasources/tzip_metadata.py
+-rw-r--r--   0        0        0    33940 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/dipdup.py
+-rw-r--r--   0        0        0     3861 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/env.py
+-rw-r--r--   0        0        0     8763 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/exceptions.py
+-rw-r--r--   0        0        0     4664 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/fetcher.py
+-rw-r--r--   0        0        0     6780 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/fields.py
+-rw-r--r--   0        0        0    26459 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/hasura.py
+-rw-r--r--   0        0        0    10860 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/http.py
+-rw-r--r--   0        0        0    10217 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/index.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/__init__.py
+-rw-r--r--   0        0        0     5646 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/evm.py
+-rw-r--r--   0        0        0     3689 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/evm_events/fetcher.py
+-rw-r--r--   0        0        0     4832 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/evm_events/index.py
+-rw-r--r--   0        0        0     3584 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/evm_events/matcher.py
+-rw-r--r--   0        0        0     2579 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/evm_node.py
+-rw-r--r--   0        0        0      293 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/evm_subsquid.py
+-rw-r--r--   0        0        0     3276 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/evm_transactions/fetcher.py
+-rw-r--r--   0        0        0     3772 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/evm_transactions/index.py
+-rw-r--r--   0        0        0     3857 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/evm_transactions/matcher.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_big_maps/__init__.py
+-rw-r--r--   0        0        0     3188 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_big_maps/fetcher.py
+-rw-r--r--   0        0        0     5029 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_big_maps/index.py
+-rw-r--r--   0        0        0     2647 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_big_maps/matcher.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_events/__init__.py
+-rw-r--r--   0        0        0     1251 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_events/fetcher.py
+-rw-r--r--   0        0        0     3406 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_events/index.py
+-rw-r--r--   0        0        0     3802 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_events/matcher.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_head/__init__.py
+-rw-r--r--   0        0        0     2685 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_head/index.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_operations/__init__.py
+-rw-r--r--   0        0        0    23660 2024-05-06 16:41:21.652766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_operations/fetcher.py
+-rw-r--r--   0        0        0    13739 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_operations/index.py
+-rw-r--r--   0        0        0    10529 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_operations/matcher.py
+-rw-r--r--   0        0        0     7108 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_operations/parser.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_token_balances/__init__.py
+-rw-r--r--   0        0        0     2730 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_token_balances/index.py
+-rw-r--r--   0        0        0     1543 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_token_balances/matcher.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_token_transfers/__init__.py
+-rw-r--r--   0        0        0     1593 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_token_transfers/fetcher.py
+-rw-r--r--   0        0        0     3177 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_token_transfers/index.py
+-rw-r--r--   0        0        0     1815 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_token_transfers/matcher.py
+-rw-r--r--   0        0        0      698 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/indexes/tezos_tzkt.py
+-rwxr-xr-x   0        0        0     9332 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/install.py
+-rw-r--r--   0        0        0     2705 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/migrations/__init__.py
+-rw-r--r--   0        0        0     8931 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/migrations/three_zero.py
+-rw-r--r--   0        0        0    22253 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/models/__init__.py
+-rw-r--r--   0        0        0     1320 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/models/coinbase.py
+-rw-r--r--   0        0        0     7189 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/models/evm.py
+-rw-r--r--   0        0        0     3086 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/models/evm_node.py
+-rw-r--r--   0        0        0     3824 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/models/evm_subsquid.py
+-rw-r--r--   0        0        0      205 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/models/subsquid.py
+-rw-r--r--   0        0        0    20861 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/models/tezos.py
+-rw-r--r--   0        0        0     4348 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/models/tezos_tzkt.py
+-rw-r--r--   0        0        0      407 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/models/tzip_metadata.py
+-rw-r--r--   0        0        0     7281 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/package.py
+-rw-r--r--   0        0        0     6265 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/performance.py
+-rw-r--r--   0        0        0    10594 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/project.py
+-rw-r--r--   0        0        0      277 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/base/.dockerignore.j2
+-rw-r--r--   0        0        0      372 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/base/.gitignore.j2
+-rw-r--r--   0        0        0      945 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/base/Makefile.j2
+-rw-r--r--   0        0        0     1064 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/base/README.md.j2
+-rw-r--r--   0        0        0      524 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/base/configs/dipdup.compose.yaml.j2
+-rw-r--r--   0        0        0       82 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/base/configs/dipdup.sqlite.yaml.j2
+-rw-r--r--   0        0        0      567 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/base/configs/dipdup.swarm.yaml.j2
+-rw-r--r--   0        0        0      291 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/base/deploy/Dockerfile.j2
+-rw-r--r--   0        0        0      382 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/base/deploy/compose.sqlite.yaml.j2
+-rw-r--r--   0        0        0     2744 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/base/deploy/compose.swarm.yaml.j2
+-rw-r--r--   0        0        0     1294 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/base/deploy/compose.yaml.j2
+-rw-r--r--   0        0        0     2822 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/base/pyproject.toml.j2
+-rw-r--r--   0        0        0       49 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_blank/dipdup.yaml.j2
+-rw-r--r--   0        0        0      116 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_blank/replay.yaml
+-rw-r--r--   0        0        0      834 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_events/dipdup.yaml.j2
+-rw-r--r--   0        0        0     1300 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_events/handlers/on_transfer.py.j2
+-rw-r--r--   0        0        0      470 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_events/models/__init__.py.j2
+-rw-r--r--   0        0        0      136 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_events/replay.yaml
+-rw-r--r--   0        0        0      867 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_transactions/dipdup.yaml.j2
+-rw-r--r--   0        0        0     1342 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_transactions/handlers/on_transfer.py.j2
+-rw-r--r--   0        0        0      470 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_transactions/models/__init__.py.j2
+-rw-r--r--   0        0        0      150 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_transactions/replay.yaml
+-rw-r--r--   0        0        0     3685 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/abi/erc20/ERC20.json.j2
+-rw-r--r--   0        0        0      269 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/abi/erc20/ERC20NameBytes.json.j2
+-rw-r--r--   0        0        0      271 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/abi/erc20/ERC20SymbolBytes.json.j2
+-rw-r--r--   0        0        0     2065 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/dipdup.yaml.j2
+-rw-r--r--   0        0        0     2706 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/handlers/factory/pool_created.py.j2
+-rw-r--r--   0        0        0      562 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/handlers/pool/burn.py.j2
+-rw-r--r--   0        0        0      304 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/handlers/pool/flash.py.j2
+-rw-r--r--   0        0        0      893 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/handlers/pool/initialize.py.j2
+-rw-r--r--   0        0        0     1370 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/handlers/pool/mint.py.j2
+-rw-r--r--   0        0        0     6636 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/handlers/pool/swap.py.j2
+-rw-r--r--   0        0        0     1281 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/handlers/position_manager/collect.py.j2
+-rw-r--r--   0        0        0     1415 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/handlers/position_manager/decrease_liquidity.py.j2
+-rw-r--r--   0        0        0     1503 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/handlers/position_manager/increase_liquidity.py.j2
+-rw-r--r--   0        0        0     1400 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/handlers/position_manager/transfer.py.j2
+-rw-r--r--   0        0        0    19961 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/models/__init__.py.j2
+-rw-r--r--   0        0        0      373 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/models/abi.py.j2
+-rw-r--r--   0        0        0     4294 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/models/pool.py.j2
+-rw-r--r--   0        0        0     2849 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/models/position.py.j2
+-rw-r--r--   0        0        0     1461 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/models/repo.py.j2
+-rw-r--r--   0        0        0      586 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/models/tick.py.j2
+-rw-r--r--   0        0        0     7167 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/models/token.py.j2
+-rw-r--r--   0        0        0      258 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/replay.yaml
+-rw-r--r--   0        0        0      226 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/sql/on_reindex/00_prepare_db.sql.j2
+-rw-r--r--   0        0        0      793 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/sql/on_reindex/20_create_ca_quotes_1m.sql.j2
+-rw-r--r--   0        0        0      789 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/sql/on_reindex/21_create_ca_quotes_1h.sql.j2
+-rw-r--r--   0        0        0      788 2024-05-06 16:41:21.656766 dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/sql/on_reindex/22_create_ca_quotes_1d.sql.j2
+-rw-r--r--   0        0        0     1091 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_auction/dipdup.yaml.j2
+-rw-r--r--   0        0        0      928 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_auction/handlers/on_bid.py.j2
+-rw-r--r--   0        0        0     1638 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_auction/handlers/on_create_auction.py.j2
+-rw-r--r--   0        0        0      727 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_auction/handlers/on_withdraw.py.j2
+-rw-r--r--   0        0        0     1447 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_auction/models/__init__.py.j2
+-rw-r--r--   0        0        0      128 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_auction/replay.yaml
+-rw-r--r--   0        0        0      738 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_big_maps/dipdup.yaml.j2
+-rw-r--r--   0        0        0      854 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_big_maps/handlers/on_update_expiry_map.py.j2
+-rw-r--r--   0        0        0     1702 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_big_maps/handlers/on_update_records.py.j2
+-rw-r--r--   0        0        0      669 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_big_maps/models/__init__.py.j2
+-rw-r--r--   0        0        0      130 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_big_maps/replay.yaml
+-rw-r--r--   0        0        0      661 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dao/dipdup.yaml.j2
+-rw-r--r--   0        0        0      428 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dao/handlers/on_origination.py.j2
+-rw-r--r--   0        0        0      537 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dao/handlers/on_propose.py.j2
+-rw-r--r--   0        0        0      784 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dao/models/__init__.py.j2
+-rw-r--r--   0        0        0      121 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dao/replay.yaml
+-rw-r--r--   0        0        0     4867 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/dipdup.yaml.j2
+-rw-r--r--   0        0        0     1880 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa12_divest_liquidity.py.j2
+-rw-r--r--   0        0        0     1791 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa12_invest_liquidity.py.j2
+-rw-r--r--   0        0        0      599 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa12_origination.py.j2
+-rw-r--r--   0        0        0     1664 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa12_tez_to_token.py.j2
+-rw-r--r--   0        0        0     1727 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa12_token_to_tez.py.j2
+-rw-r--r--   0        0        0     1053 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa12_transfer.py.j2
+-rw-r--r--   0        0        0      987 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa12_withdraw_profit.py.j2
+-rw-r--r--   0        0        0     1902 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa2_divest_liquidity.py.j2
+-rw-r--r--   0        0        0     1813 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa2_invest_liquidity.py.j2
+-rw-r--r--   0        0        0      593 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa2_origination.py.j2
+-rw-r--r--   0        0        0     1654 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa2_tez_to_token.py.j2
+-rw-r--r--   0        0        0     1693 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa2_token_to_tez.py.j2
+-rw-r--r--   0        0        0     1170 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa2_transfer.py.j2
+-rw-r--r--   0        0        0      983 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa2_withdraw_profit.py.j2
+-rw-r--r--   0        0        0      918 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/models/__init__.py.j2
+-rw-r--r--   0        0        0      132 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/replay.yaml
+-rw-r--r--   0        0        0      907 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_domains/dipdup.yaml.j2
+-rw-r--r--   0        0        0     1993 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_domains/handlers/on_update_expiry_map.py.j2
+-rw-r--r--   0        0        0     3376 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_domains/handlers/on_update_records.py.j2
+-rw-r--r--   0        0        0      978 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_domains/hooks/check_expiration.py.j2
+-rw-r--r--   0        0        0      972 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_domains/models/__init__.py.j2
+-rw-r--r--   0        0        0      137 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_domains/replay.yaml
+-rw-r--r--   0        0        0     1353 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_etherlink/dipdup.yaml.j2
+-rw-r--r--   0        0        0      141 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_etherlink/replay.yaml
+-rw-r--r--   0        0        0      549 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_events/dipdup.yaml.j2
+-rw-r--r--   0        0        0      126 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_events/replay.yaml
+-rw-r--r--   0        0        0     1106 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_factories/dipdup.yaml.j2
+-rw-r--r--   0        0        0     1080 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_factories/handlers/on_factory_origination.py.j2
+-rw-r--r--   0        0        0      674 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_factories/handlers/on_transfer.py.j2
+-rw-r--r--   0        0        0      214 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_factories/models/__init__.py.j2
+-rw-r--r--   0        0        0      144 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_factories/replay.yaml
+-rw-r--r--   0        0        0      257 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_head/dipdup.yaml.j2
+-rw-r--r--   0        0        0      142 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_head/replay.yaml
+-rw-r--r--   0        0        0     1205 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_nft_marketplace/dipdup.yaml.j2
+-rw-r--r--   0        0        0      596 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_nft_marketplace/handlers/on_cancel_swap.py.j2
+-rw-r--r--   0        0        0     1032 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_nft_marketplace/handlers/on_collect.py.j2
+-rw-r--r--   0        0        0      971 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_nft_marketplace/handlers/on_mint.py.j2
+-rw-r--r--   0        0        0      880 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_nft_marketplace/handlers/on_swap.py.j2
+-rw-r--r--   0        0        0     1309 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_nft_marketplace/models/__init__.py.j2
+-rw-r--r--   0        0        0      147 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_nft_marketplace/replay.yaml
+-rw-r--r--   0        0        0      429 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_raw/dipdup.yaml.j2
+-rw-r--r--   0        0        0      361 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_raw/handlers/on_operation.py.j2
+-rw-r--r--   0        0        0      244 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_raw/models/__init__.py.j2
+-rw-r--r--   0        0        0      153 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_raw/replay.yaml
+-rw-r--r--   0        0        0      746 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_token/dipdup.yaml.j2
+-rw-r--r--   0        0        0      448 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_token/handlers/on_balance_update.py.j2
+-rw-r--r--   0        0        0      661 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_token/handlers/on_mint.py.j2
+-rw-r--r--   0        0        0      959 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_token/handlers/on_transfer.py.j2
+-rw-r--r--   0        0        0      372 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_token/models/__init__.py.j2
+-rw-r--r--   0        0        0      129 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_token/replay.yaml
+-rw-r--r--   0        0        0      414 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_token_balances/dipdup.yaml.j2
+-rw-r--r--   0        0        0      470 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_token_balances/handlers/on_balance_update.py.j2
+-rw-r--r--   0        0        0      200 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_token_balances/models/__init__.py.j2
+-rw-r--r--   0        0        0      136 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_token_balances/replay.yaml
+-rw-r--r--   0        0        0      415 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_token_transfers/dipdup.yaml.j2
+-rw-r--r--   0        0        0      545 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_token_transfers/handlers/on_balance_update.py.j2
+-rw-r--r--   0        0        0      833 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_token_transfers/handlers/on_token_transfer.py.j2
+-rw-r--r--   0        0        0      372 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_token_transfers/models/__init__.py.j2
+-rw-r--r--   0        0        0      139 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_token_transfers/replay.yaml
+-rw-r--r--   0        0        0     4126 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/prometheus.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/py.typed
+-rw-r--r--   0        0        0     1774 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/pysignalr.py
+-rw-r--r--   0        0        0     2147 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/report.py
+-rw-r--r--   0        0        0     4944 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/scheduler.py
+-rw-r--r--   0        0        0     4598 2024-05-06 16:41:21.660766 dipdup-8.0.0a1/src/dipdup/sentry.py
+-rw-r--r--   0        0        0      272 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/src/dipdup/sql/dipdup_approve.sql
+-rw-r--r--   0        0        0      199 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/src/dipdup/sql/dipdup_head_status.sql
+-rw-r--r--   0        0        0     1904 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/src/dipdup/sql/dipdup_wipe.sql
+-rw-r--r--   0        0        0     2077 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/src/dipdup/subscriptions.py
+-rw-r--r--   0        0        0     2227 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/src/dipdup/sys.py
+-rw-r--r--   0        0        0      227 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/src/dipdup/templates/callback.py.j2
+-rw-r--r--   0        0        0     1241 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/src/dipdup/templates/models.py
+-rw-r--r--   0        0        0      276 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/src/dipdup/templates/replay.yaml.j2
+-rw-r--r--   0        0        0     6533 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/src/dipdup/test.py
+-rw-r--r--   0        0        0     3017 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/src/dipdup/transactions.py
+-rw-r--r--   0        0        0     7627 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/src/dipdup/utils.py
+-rw-r--r--   0        0        0     4990 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/src/dipdup/yaml.py
+-rw-r--r--   0        0        0      889 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/__init__.py
+-rw-r--r--   0        0        0      500 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/asdf.yml
+-rw-r--r--   0        0        0      840 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/demo_evm_events.yml
+-rw-r--r--   0        0        0      805 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/demo_evm_events_node.yml
+-rw-r--r--   0        0        0      893 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/demo_evm_transactions.yml
+-rw-r--r--   0        0        0      858 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/demo_evm_transactions_node.yml
+-rw-r--r--   0        0        0     1232 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/demo_tezos_auction.yml
+-rw-r--r--   0        0        0      790 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/demo_tezos_big_maps.yml
+-rw-r--r--   0        0        0      757 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/demo_tezos_dao.yml
+-rw-r--r--   0        0        0     5026 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/demo_tezos_dex.yml
+-rw-r--r--   0        0        0      953 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/demo_tezos_domains.yml
+-rw-r--r--   0        0        0     1402 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/demo_tezos_etherlink.yaml
+-rw-r--r--   0        0        0      593 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/demo_tezos_events.yml
+-rw-r--r--   0        0        0     1158 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/demo_tezos_factories.yml
+-rw-r--r--   0        0        0     1326 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/demo_tezos_nft_marketplace.yml
+-rw-r--r--   0        0        0      604 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/demo_tezos_raw.yml
+-rw-r--r--   0        0        0      721 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/demo_tezos_token.yml
+-rw-r--r--   0        0        0      466 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/demo_tezos_token_balances.yml
+-rw-r--r--   0        0        0      537 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/demo_tezos_token_transfers.yml
+-rw-r--r--   0        0        0      537 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/demo_tezos_token_transfers_2.yml
+-rw-r--r--   0        0        0      537 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/demo_tezos_token_transfers_3.yml
+-rw-r--r--   0        0        0      824 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/demo_tezos_token_transfers_4.yml
+-rw-r--r--   0        0        0     1262 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/dipdup.yml
+-rw-r--r--   0        0        0      525 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/hen_subjkt.yml
+-rw-r--r--   0        0        0      500 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/hjkl.yml
+-rw-r--r--   0        0        0      550 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/kolibri_ovens.yml
+-rw-r--r--   0        0        0      694 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/operation_filters.yml
+-rw-r--r--   0        0        0      500 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/qwer.yml
+-rw-r--r--   0        0        0      500 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/rewq.yml
+-rw-r--r--   0        0        0       98 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/test_postgres.yaml
+-rw-r--r--   0        0        0      151 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/test_postgres_immune.yaml
+-rw-r--r--   0        0        0       44 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/test_sqlite.yaml
+-rw-r--r--   0        0        0      128 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/test_sqlite_immune.yaml
+-rw-r--r--   0        0        0      538 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/yupana.yml
+-rw-r--r--   0        0        0      500 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/configs/zxcv.yml
+-rw-r--r--   0        0        0    29145 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/replays/0535b2dcc93076e6026fa48cc501adaed47b7b060e6483d8312f40c184d7287d
+-rw-r--r--   0        0        0      305 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/replays/0b7d26b8f2813d12a80b9e96cc6f0bb186bf9ac5c5b0c0b3bb2cc8d750126843
+-rw-r--r--   0        0        0      959 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/replays/0eaaba2830dbdd3a80286fbc367084bce6e55c678e21da178a7eb16beef6c997
+-rw-r--r--   0        0        0    25834 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/replays/1228b36594bb93d619170ad49373f1ceec52d10faafdd727b37f3cdeffd663db
+-rw-r--r--   0        0        0    13886 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/replays/13afdf001ce3d6a0219c0f7f6d372d9b645770e5f4304576f7f7a37b45af96fc
+-rw-r--r--   0        0        0      403 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/replays/1430e37dce64ecb83499da8feaa3c0906e4fdf5d0a3c3570174645e97ba54bc4
+-rw-r--r--   0        0        0      295 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/replays/185f6628ac43f6ca728c5b79b7b81a3c3671efce7f14030a06a27e90cf641dea
+-rw-r--r--   0        0        0        2 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/replays/1c717490846300e1639e96a0c1438b6dd2abd6de013c5edec49042fa364c06e6
+-rw-r--r--   0        0        0     1871 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/replays/27373c23411bf37b605c8d0ead9a0e6c6c1f1718ce7863b095b759811e44e155
+-rw-r--r--   0        0        0     1824 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/replays/2a45ec6372b45e46199a6af24272cb93586777a0522cd1203b3eeef213ce4583
+-rw-r--r--   0        0        0    54602 2024-05-06 16:41:21.664766 dipdup-8.0.0a1/tests/replays/383899084f79460e96fd311bb64e4925738c486b39d6281539456c5fcac41620
+-rw-r--r--   0        0        0   234676 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/388fe9107380b6dd1e9ce3a87c23abd56ad39dfb6cb8a5a27b959e5b0434633b
+-rw-r--r--   0        0        0      642 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/39b8664d1bca5d374ff905c8a3a396b53d19ee469dc37545a8ca6b080bd0e9e0
+-rw-r--r--   0        0        0     1200 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/3a2bd8b6b72bf18152d2550c106789fa9b8abc98ea9d759a6597b7ebfbab0fc2
+-rw-r--r--   0        0        0    34389 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/3f5927db41422038d8e2cc203ef56a769c66b25835cdee42b17bc61e600be550
+-rw-r--r--   0        0        0      804 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/43cb0ab415d8b8b3f7addc3e82ea27d93b2c66ff55c117e1e0c7c64a0fcfc3f2
+-rw-r--r--   0        0        0   109726 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/4a57776d93475adfd9c49b6c3295a7cedfc23b73733a1fb5f0c985ee039dc5dc
+-rw-r--r--   0        0        0     1160 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/4aa7f9b0657be0c44baf2caed8c7cb08d02097a4095cf6417f78cba3a25e8423
+-rw-r--r--   0        0        0       67 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/4fbdb4667971fab446a5ac5937a7c8cc6ef5813ff00af24b6fd1b1a0427bedbb
+-rw-r--r--   0        0        0   192680 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/5483a0e11009e0f186bf70c214e2597d267a75a1e19152a9e7ed1ec257ce88ca
+-rw-r--r--   0        0        0    40432 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/587613799ebfae42b1884016d1a44a452d68e70e3ed80641d90b8e7657ba8ee5
+-rw-r--r--   0        0        0       32 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/5b004196490632859ec1b019d640f6bbb93fc86a433c8969e10f36f51ac2c78d
+-rw-r--r--   0        0        0    40439 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/5b99bc4beb6a9a33f7d2f118426458e4c788e0ab6d9e51949d3ccbf8b4003fc1
+-rw-r--r--   0        0        0    33335 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/607ecfd3653eda82aac502ac370c6ad7144d30c1e3c525ed520d44f9edf5b7e9
+-rw-r--r--   0        0        0       67 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/60f48c13c47a1347786a6dcf6f741874e7b30b587d148faa67d15067bb3871de
+-rw-r--r--   0        0        0        2 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/694f9dfac7db616fa52c4d35bca1036b6521d285ed1873028303b83822b5980b
+-rw-r--r--   0        0        0      132 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/6d0c5443d41a15551acb41adc10d36d4895f5786d6922a878b5c5414610e0ebc
+-rw-r--r--   0        0        0      754 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/6d76a3c3f427ff534c551de1793cb1d1dfbd22ccad97f5917a9f9b201a3f9804
+-rw-r--r--   0        0        0     1781 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/6fa41b68da742cc7cf8a0d68baef77ce8b2e9abf765767318d7ff4cf453ded4c
+-rw-r--r--   0        0        0      451 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/739d17c86095aac3da3508a16dc1c9ae9459ea86eeb09f62aaefc32de2997918
+-rw-r--r--   0        0        0        2 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/759b79ec12b1305d9fa8e1a5218e62bb3d3ad913580e19914d30d8aa09920ae4
+-rw-r--r--   0        0        0    50588 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/7b6cf9b8c69712bf26ed09059352ec740606969bf20eab0dedda870273f4fde9
+-rw-r--r--   0        0        0      807 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/803e05a8d0bb9e7cfb49530271d43ea62111b6419e7cded2d221f7e0e0c92ece
+-rw-r--r--   0        0        0   203748 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/8060a1f95213d470ee947a12242ef76cb7fb0c05bbaecc385eb6ec4a20d694c4
+-rw-r--r--   0        0        0      395 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/8335acc6585656ec3a4301cd8b089401f2dc2c7d758b381c96c730e610b67f7b
+-rw-r--r--   0        0        0     1151 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/93516225810a23a6799f2f9a1dee055ca79a66ee2b8d0f32be820c9c385e936b
+-rw-r--r--   0        0        0      877 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/9e6e907842da2cd494c558ea5ecc211fd12e56bfc547450978fb7dfe03853e58
+-rw-r--r--   0        0        0    22801 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/a3ce91a1b0d505cc221f0e201781466ba1e2d6dc7b624b9bc75a03ce3dbb0f92
+-rw-r--r--   0        0        0      767 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/aa8fe6037996b296bf9a3011e45cd9ecb92fb728592a843f91b03b2848cb1fb1
+-rw-r--r--   0        0        0     1931 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/acaa57345850f3b76471a7b3a8fb76b7f83e824f1520a2e0ee8ec93cdd6cb1c3
+-rw-r--r--   0        0        0     1882 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/acc952ba1905717315212f952ed689d7b8f683165b31c0a7a25199aed9fda27f
+-rw-r--r--   0        0        0       67 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/af37212b31e932f269c42c7f34ad8f3849bd8aed244652c41b9327c508985ce5
+-rw-r--r--   0        0        0     1200 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/b3af887f7ad8172af75b94a09bedfb9ae1e14f8819a36d6ce9f709721068263b
+-rw-r--r--   0        0        0    34407 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/b89b0ea704071e273d3c74a4dbb7b4f6c6fd9ea1848c69b452dce4f04872d3b5
+-rw-r--r--   0        0        0     2271 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/bec4433b4206f00c2310a7961cff7f539434b9161b45673793aa5a3b50234313
+-rw-r--r--   0        0        0      403 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/bed2329e63d559db2fb81c69606e715d1f90aaacab6ae45b33516e7828841a3c
+-rw-r--r--   0        0        0    89684 2024-05-06 16:41:21.668766 dipdup-8.0.0a1/tests/replays/c1c3eef91f7149d7aa2da072f71598f3ad5e29250cfa441bb6d4411acd70d657
+-rw-r--r--   0        0        0    25834 2024-05-06 16:41:21.672766 dipdup-8.0.0a1/tests/replays/cc5d3d4a58d5cb6bc7270d38c797b7740b79f913590ef0164abd50e58fba9405
+-rw-r--r--   0        0        0     1157 2024-05-06 16:41:21.672766 dipdup-8.0.0a1/tests/replays/d0a594d14bcb3fbf916092ec6707dfd3c9f48f53f0a1ad40a32023e7a87f8ef5
+-rw-r--r--   0        0        0     6669 2024-05-06 16:41:21.672766 dipdup-8.0.0a1/tests/replays/d62748a927a09395579b5790c8f871cc8653081cf4475abc93173989f950b92b
+-rw-r--r--   0        0        0    27896 2024-05-06 16:41:21.672766 dipdup-8.0.0a1/tests/replays/d94397f6ecec8ce25f87177fe410f6498d7d30a04360506c0cd300d291c167e7
+-rw-r--r--   0        0        0      132 2024-05-06 16:41:21.672766 dipdup-8.0.0a1/tests/replays/db797e6bf4c1b9c3237af5dec694fb1b6d21418a5a2f7947eb7f54d4e9201baf
+-rw-r--r--   0        0        0    20467 2024-05-06 16:41:21.672766 dipdup-8.0.0a1/tests/replays/dca9cf4f9f27623f10975d369444899458ab9ea85c22af2da6ce6ce8c09c2b58
+-rw-r--r--   0        0        0      767 2024-05-06 16:41:21.672766 dipdup-8.0.0a1/tests/replays/dd5d267c6e8e943a637ede23d708587123b9184560358d294be7fbed0d4b587a
+-rw-r--r--   0        0        0   209761 2024-05-06 16:41:21.672766 dipdup-8.0.0a1/tests/replays/e10e6552f0dce5124e0d72b74c508541a8098c407c9a3b0d2e10a7408b4d7cfe
+-rw-r--r--   0        0        0    17502 2024-05-06 16:41:21.672766 dipdup-8.0.0a1/tests/replays/e4a563a0b19379a44e9d2dc398131e9fd30d6039ff4ffacf1252db0bf8b433aa
+-rw-r--r--   0        0        0       67 2024-05-06 16:41:21.672766 dipdup-8.0.0a1/tests/replays/e82ba90c8570b92c0b1fc360b853aca3f1d7de457aacb9f6f19fa3e43879a8b3
+-rw-r--r--   0        0        0      132 2024-05-06 16:41:21.672766 dipdup-8.0.0a1/tests/replays/e9fa56a94eb559c550dfbca4b27ef350a0b4a787afbe60205482a38223dcea04
+-rw-r--r--   0        0        0   713738 2024-05-06 16:41:21.672766 dipdup-8.0.0a1/tests/replays/eb8b6b33cb2e165d1a3a73c09938d3083671a82ad73d4c0cff1fb2a5e5715f76
+-rw-r--r--   0        0        0    27505 2024-05-06 16:41:21.672766 dipdup-8.0.0a1/tests/replays/eb8e2c3ce2fe7792d2c8e81c61d37821275b64021343103b0c955042ae802189
+-rw-r--r--   0        0        0    17245 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/replays/f3d608f99e6b92e28a064bb9c10c3c605c9c817383c1eebcc68f663d1d23d650
+-rw-r--r--   0        0        0   211527 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/replays/f7d244938de3e3d153e4ef8172cab0f1e896b801904a54ac034d3d14352ee64a
+-rw-r--r--   0        0        0    27847 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/replays/f9fa1571c3d850f4a19c286205291893d184a9d124390d0358034a8b8366556d
+-rw-r--r--   0        0        0   118246 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/replays/fe80425d17f2467fccc527a99b5a11da144f63f9a3cab83989be0f8fed737264
+-rw-r--r--   0        0        0      996 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/replays/ff51b3535acc2972090ecd5db3af8f827464c9d92f1aa661630976e5b4ed4cbe
+-rw-r--r--   0        0        0     4599 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/responses/asdf.json
+-rw-r--r--   0        0        0     6704 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/responses/ftzfun.json
+-rw-r--r--   0        0        0     3445 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/responses/hen_subjkt.json
+-rw-r--r--   0        0        0     5210 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/responses/hjkl.json
+-rw-r--r--   0        0        0     2097 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/responses/kolibri_ovens.json
+-rw-r--r--   0        0        0      783 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/responses/node_transaction.json
+-rw-r--r--   0        0        0    11186 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/responses/ooQuCAKBHkmWy2VciDAV9c6CFTywuMLupLzVoKDwS1xvR4EdRng.json
+-rw-r--r--   0        0        0     1811 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/responses/origination_amount.json
+-rw-r--r--   0        0        0     4256 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/responses/qwer.json
+-rw-r--r--   0        0        0     5307 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/responses/rewq.json
+-rw-r--r--   0        0        0      958 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/responses/subsquid_transaction.json
+-rw-r--r--   0        0        0    38178 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/responses/yupana.json
+-rw-r--r--   0        0        0     5909 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/responses/zxcv.json
+-rw-r--r--   0        0        0     1077 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/schemas/asdf/storage.json
+-rw-r--r--   0        0        0     2116 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/schemas/hen_subjkt/storage.json
+-rw-r--r--   0        0        0     1638 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/schemas/hjkl/storage.json
+-rw-r--r--   0        0        0      800 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/schemas/kolibri_ovens/storage.json
+-rw-r--r--   0        0        0     1005 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/schemas/qwer/storage.json
+-rw-r--r--   0        0        0     2212 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/schemas/rewq/storage.json
+-rw-r--r--   0        0        0    12561 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/schemas/yupana/storage.json
+-rw-r--r--   0        0        0     2660 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/schemas/zxcv/storage.json
+-rw-r--r--   0        0        0     3763 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_config/test_callbacks.py
+-rw-r--r--   0        0        0     5422 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_config/test_config.py
+-rw-r--r--   0        0        0     4224 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_config/test_custom_config.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_datasources/__init__.py
+-rw-r--r--   0        0        0      814 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_datasources/test_ipfs.py
+-rw-r--r--   0        0        0      795 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_datasources/test_metadata.py
+-rw-r--r--   0        0        0     8337 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_datasources/test_tzkt.py
+-rw-r--r--   0        0        0     1215 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_datasources/test_tzkt_blocks.py
+-rw-r--r--   0        0        0     2091 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_datasources/test_tzkt_buffer.py
+-rw-r--r--   0        0        0     1423 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_datasources/test_tzkt_quotes.py
+-rw-r--r--   0        0        0     9756 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_demos.py
+-rw-r--r--   0        0        0     2873 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_dipdup.py
+-rw-r--r--   0        0        0     3126 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_hasura.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_http.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_index/__init__.py
+-rw-r--r--   0        0        0     7632 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_index/test_tzkt_operations.py
+-rw-r--r--   0        0        0     5431 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_introspection.py
+-rw-r--r--   0        0        0    11358 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_models.py
+-rw-r--r--   0        0        0    13586 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_rollback.py
+-rw-r--r--   0        0        0     6732 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_schema.py
+-rw-r--r--   0        0        0     3602 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/test_utils.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/types/__init__.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/types/asdf/__init__.py
+-rw-r--r--   0        0        0      514 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/types/asdf/storage.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/types/bazaar/__init__.py
+-rw-r--r--   0        0        0      597 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/types/bazaar/storage.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/types/ftzfun/__init__.py
+-rw-r--r--   0        0        0      881 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/types/ftzfun/storage.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/types/hen_subjkt/__init__.py
+-rw-r--r--   0        0        0      561 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/types/hen_subjkt/storage.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/types/hjkl/__init__.py
+-rw-r--r--   0        0        0      622 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/types/hjkl/storage.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/types/kolibri_ovens/__init__.py
+-rw-r--r--   0        0        0      231 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/types/kolibri_ovens/set_delegate.py
+-rw-r--r--   0        0        0      396 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/types/kolibri_ovens/storage.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/types/listofmaps/__init__.py
+-rw-r--r--   0        0        0      129 2024-05-06 16:41:21.676766 dipdup-8.0.0a1/tests/types/listofmaps/storage.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.680766 dipdup-8.0.0a1/tests/types/qwer/__init__.py
+-rw-r--r--   0        0        0      511 2024-05-06 16:41:21.680766 dipdup-8.0.0a1/tests/types/qwer/storage.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.680766 dipdup-8.0.0a1/tests/types/rewq/__init__.py
+-rw-r--r--   0        0        0      770 2024-05-06 16:41:21.680766 dipdup-8.0.0a1/tests/types/rewq/storage.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.680766 dipdup-8.0.0a1/tests/types/tezotop/__init__.py
+-rw-r--r--   0        0        0      663 2024-05-06 16:41:21.680766 dipdup-8.0.0a1/tests/types/tezotop/storage.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.680766 dipdup-8.0.0a1/tests/types/yupana/__init__.py
+-rw-r--r--   0        0        0     2624 2024-05-06 16:41:21.680766 dipdup-8.0.0a1/tests/types/yupana/storage.py
+-rw-r--r--   0        0        0        0 2024-05-06 16:41:21.680766 dipdup-8.0.0a1/tests/types/zxcv/__init__.py
+-rw-r--r--   0        0        0      979 2024-05-06 16:41:21.680766 dipdup-8.0.0a1/tests/types/zxcv/storage.py
+-rw-r--r--   0        0        0     4638 1970-01-01 00:00:00.000000 dipdup-8.0.0a1/PKG-INFO
```

### Comparing `dipdup-7.5.7/LICENSE` & `dipdup-8.0.0a1/LICENSE`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/README.md` & `dipdup-8.0.0a1/README.md`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 [![Twitter](https://badgen.net/badge/icon/dipdup_io?icon=twitter&label=)](https://twitter.com/dipdup_io)
+[![Monthly downloads](https://static.pepy.tech/badge/dipdup/month)](https://pepy.tech/project/dipdup)
 [![GitHub stars](https://img.shields.io/github/stars/dipdup-io/dipdup?color=2c2c2c&style=plain)](https://github.com/dipdup-io/dipdup)
-[![PyPI monthly downloads](https://img.shields.io/pypi/dm/dipdup?color=2c2c2c)](https://pypi.org/project/dipdup/)
-[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/dipdup?color=2c2c2c)](https://www.python.org)
+[![Python Version](https://img.shields.io/pypi/pyversions/dipdup?color=2c2c2c)](https://www.python.org)
 [![License: MIT](https://img.shields.io/github/license/dipdup-io/dipdup?color=2c2c2c)](https://github.com/dipdup-io/dipdup/blob/next/LICENSE)
 <br>
 [![Latest stable release](https://img.shields.io/github/v/release/dipdup-io/dipdup?label=stable%20release&color=2c2c2c)](https://github.com/dipdup-io/dipdup/releases)
 [![Latest pre-release](https://img.shields.io/github/v/release/dipdup-io/dipdup?include_prereleases&label=latest%20release&color=2c2c2c)](https://github.com/dipdup-io/dipdup/releases)
 [![GitHub issues](https://img.shields.io/github/issues/dipdup-io/dipdup?color=2c2c2c)](https://github.com/dipdup-io/dipdup/issues)
 [![GitHub pull requests](https://img.shields.io/github/issues-pr/dipdup-io/dipdup?color=2c2c2c)](https://github.com/dipdup-io/dipdup/pulls)
```

### Comparing `dipdup-7.5.7/pyproject.toml` & `dipdup-8.0.0a1/pyproject.toml`

 * *Files 3% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 [project]
 name = "dipdup"
 description = "Modular framework for creating selective indexers and featureful backends for dapps"
-version = "7.5.7"
+version = "8.0.0a1"
 authors = [
     { name = "Lev Gorodetskii", email = "dipdup@drsr.io" },
     { name = "Vladimir Bobrikov", email = "vladimir_bobrikov@pm.me" },
     { name = "Michael Zaikin", email = "mz@baking-bad.org" },
 ]
 maintainers = [
     { name = "Lev Gorodetskii", email = "dipdup@drsr.io" },
     { name = "Vladimir Bobrikov", email = "vladimir_bobrikov@pm.me" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 keywords = [
     "api",
     "backend",
     "blockchain",
     "crypto",
     "cryptocurrencies",
     "dapp",
@@ -37,79 +37,78 @@
 classifiers = [
     "Development Status :: 5 - Production/Stable",
     "Environment :: Console",
     "Intended Audience :: Developers",
     "License :: OSI Approved :: MIT License",
     "Operating System :: OS Independent",
     "Programming Language :: Python :: 3",
-    "Programming Language :: Python :: 3.11",
+    "Programming Language :: Python :: 3.12",
     "Programming Language :: Python :: Implementation :: CPython",
     "Topic :: Software Development :: Libraries :: Application Frameworks",
     "Typing :: Typed",
 ]
 dependencies = [
-    "asyncpg~=0.29.0",
     "datamodel-code-generator~=0.25.0",
-    "pydantic~=1.10.11",
-    "tortoise-orm==0.19.3",
-    "aiohttp~=3.8",
+    "pyarrow~=16.0",
+    "pydantic~=2.2",
+    "sentry-sdk~=2.0",
+    "tortoise-orm==0.20.1",
+    "web3~=6.18",
+    "aiohttp~=3.9",
     "aiolimiter~=1.0",
     "anyio>=4.1.0",
     "APScheduler~=3.8",
     "async-lru~=2.0",
     "asyncclick~=8.0",
+    "asyncpg~=0.29",
     "eth-abi>=5.0.1,<6",
-    "lru-dict~=1.3.0",
     "orjson~=3.9",
     "prometheus-client~=0.17",
-    "pyarrow>=14.0.1,<15",
     "pycryptodome~=3.17",
     "pyhumps~=3.0",
     "pysignalr~=1.0",
     "python-dotenv~=1.0",
     "ruamel.yaml~=0.17",
-    "sentry-sdk~=1.29",
-    "setuptools>=68.1.2",
     "sqlparse~=0.4",
     "strict-rfc3339~=0.7",
-    "survey~=4.4",
+    "survey~=5.3",
     "tabulate~=0.9",
-    "web3~=6.2",
 ]
 
 [project.license]
 text = "MIT"
 
 [project.urls]
 Homepage = "https://dipdup.io/"
 Documentation = "https://dipdup.io/docs"
 Repository = "https://github.com/dipdup-io/dipdup"
 
 [project.scripts]
 dipdup = "dipdup.cli:cli"
 
+[tool.pdm.resolution.overrides]
+lru-dict = "1.3.0"
+
 [tool.pdm.dev-dependencies]
 dev = [
     "black",
     "docker",
     "mypy",
-    "pprofile",
     "pytest~=7.4",
     "pytest-aiohttp",
     "pytest-asyncio",
     "pytest-cov",
     "pytest-xdist",
     "ruff",
     "types-pytz",
     "types-tabulate",
 ]
 docs = [
-    "git+https://github.com/dipdup-io/dc_schema.git@pydantic-dc",
     "Sphinx",
-    "sphinx-click==5.2.2",
+    "sphinx-click",
     "sphinx-markdown-builder",
     "watchdog",
 ]
 
 [tool.pdm.scripts.help]
 cmd = "make"
 help = "Show this help (default)"
@@ -178,27 +177,28 @@
 packages = [
     "src/dipdup",
 ]
 
 [tool.black]
 line-length = 120
 target-version = [
-    "py311",
+    "py312",
 ]
 skip-string-normalization = true
 
 [tool.ruff]
 line-length = 120
-target-version = "py311"
+target-version = "py312"
 
 [tool.ruff.lint]
 ignore = [
     "E402",
     "E501",
     "TCH001",
+    "UP040",
 ]
 extend-select = [
     "B",
     "C4",
     "FA",
     "G",
     "I",
@@ -217,15 +217,15 @@
 [tool.ruff.lint.isort]
 force-single-line = true
 known-first-party = [
     "dipdup",
 ]
 
 [tool.mypy]
-python_version = "3.11"
+python_version = "3.12"
 plugins = [
     "pydantic.mypy",
 ]
 strict = true
 
 [tool.pytest.ini_options]
 asyncio_mode = "auto"
```

### Comparing `dipdup-7.5.7/src/demo_auction/Makefile` & `dipdup-8.0.0a1/src/demo_tezos_auction/Makefile`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 .PHONY: $(MAKECMDGOALS)
 MAKEFLAGS += --no-print-directory
 ##
 ##   DipDup developer tools
 ##
-PACKAGE=demo_auction
+PACKAGE=demo_tezos_auction
 TAG=latest
 COMPOSE=deploy/compose.yaml
 
 help:           ## Show this help (default)
 	@grep -Fh "##" $(MAKEFILE_LIST) | grep -Fv grep -F | sed -e 's/\\$$//' | sed -e 's/##//'
 
 all:            ## Run an entire CI pipeline
```

### Comparing `dipdup-7.5.7/src/demo_auction/README.md` & `dipdup-8.0.0a1/src/demo_blank/README.md`

 * *Files 6% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# demo_auction
+# demo_blank
 
-NFT marketplace (TzColors)
+Empty config for a fresh start
 
 ## Installation
 
 This project is based on [DipDup](https://dipdup.io), a framework for building featureful dapps.
 
-You need a Linux/macOS system with Python 3.11 installed. To install DipDup with pipx for the current user:
+You need a Linux/macOS system with Python 3.12 installed. To install DipDup with pipx or use our installer:
 
 ```shell
-curl -Lsf https://dipdup.io/install.py | python3
+curl -Lsf https://dipdup.io/install.py | python3.12
 ```
 
 See the [Installation](https://dipdup.io/docs/installation) page for all options.
 
 ## Usage
 
 Run the indexer in memory:
```

### Comparing `dipdup-7.5.7/src/demo_auction/configs/dipdup.compose.yaml` & `dipdup-8.0.0a1/src/demo_blank/configs/dipdup.compose.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_auction/configs/dipdup.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_auction/configs/dipdup.swarm.yaml`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 database:
   kind: postgres
-  host: ${POSTGRES_HOST:-demo_auction_db}
+  host: ${POSTGRES_HOST:-demo_tezos_auction_db}
   port: 5432
   user: ${POSTGRES_USER:-dipdup}
   password: ${POSTGRES_PASSWORD}
   database: ${POSTGRES_DB:-dipdup}
 
 hasura:
-  url: http://${HASURA_HOST:-demo_auction_hasura}:8080
+  url: http://${HASURA_HOST:-demo_tezos_auction_hasura}:8080
   admin_secret: ${HASURA_SECRET}
   allow_aggregations: ${HASURA_ALLOW_AGGREGATIONS:-false}
   select_limit: ${HASURA_SELECT_LIMIT:-100}
   camel_case: ${HASURA_CAMEL_CASE:-true}
 
 sentry:
   dsn: ${SENTRY_DSN:-''}
```

### Comparing `dipdup-7.5.7/src/demo_auction/configs/replay.yaml` & `dipdup-8.0.0a1/src/demo_tezos_dao/configs/replay.yaml`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 # To refresh existing project run `dipdup init --base --force` after modifying this file.
 # To generate a new project from this replay run `dipdup new --replay <path_to_file>`.
 #
-spec_version: 2.0
+spec_version: 3.0
 replay:
-  dipdup_version: 7
-  template: demo_auction
-  package: demo_auction
+  dipdup_version: 8
+  template: demo_tezos_dao
+  package: demo_tezos_dao
   version: 0.0.1
-  description: NFT marketplace (TzColors)
+  description: DAO registry (Homebase DAO)
   license: MIT
   name: John Doe
   email: john_doe@example.com
   postgres_image: postgres:15
   postgres_data_path: /var/lib/postgresql/data
   hasura_image: hasura/graphql-engine:latest
   line_length: 120
```

### Comparing `dipdup-7.5.7/src/demo_auction/deploy/compose.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_auction/deploy/compose.swarm.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 version: "3.8"
-name: demo_auction
+name: demo_tezos_auction
 
 services:
   dipdup:
-    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-7}
+    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-8}
     depends_on:
       - db
       - hasura
     command: ["-c", "dipdup.yaml", "-c", "configs/dipdup.swarm.yaml", "run"]
     env_file: .env
     networks:
       - internal
@@ -51,15 +51,15 @@
     logging: *logging
 
   hasura:
     image: hasura/graphql-engine:latest
     depends_on:
       - db
     environment:
-      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_auction_db:5432/dipdup
+      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_tezos_auction_db:5432/dipdup
       - HASURA_GRAPHQL_ADMIN_SECRET=${HASURA_SECRET}
       - HASURA_GRAPHQL_ENABLE_CONSOLE=true
       - HASURA_GRAPHQL_DEV_MODE=false
       - HASURA_GRAPHQL_LOG_LEVEL=warn
       - HASURA_GRAPHQL_ENABLE_TELEMETRY=false
       - HASURA_GRAPHQL_UNAUTHORIZED_ROLE=user
       - HASURA_GRAPHQL_STRINGIFY_NUMERIC_TYPES=true
```

### Comparing `dipdup-7.5.7/src/demo_auction/deploy/compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_token_transfers/deploy/compose.yaml`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 version: "3.8"
-name: demo_auction
+name: demo_tezos_token_transfers
 
 services:
   dipdup:
     build:
       context: ..
       dockerfile: deploy/Dockerfile
     restart: always
```

### Comparing `dipdup-7.5.7/src/demo_auction/dipdup.yaml` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_auction/dipdup.yaml.j2`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-spec_version: 2.0
-package: demo_auction
+spec_version: 3.0
+package: {{ project.package }}
 
 contracts:
   tzcolors_minter:
     kind: tezos
     address: KT1FyaDqiMQWg7Exo7VUiXAgZbd2kCzo3d4s
     typename: tzcolors_minter
   tzcolors_auction:
@@ -14,16 +14,17 @@
 datasources:
   tzkt:
     kind: tezos.tzkt
     url: ${TZKT_URL:-https://api.tzkt.io}
 
 templates:
   auction:
-    kind: tezos.tzkt.operations
-    datasource: <datasource>
+    kind: tezos.operations
+    datasources:
+      - <datasource>
     contracts:
       - <auction>
     handlers:
       - callback: on_create_auction
         pattern:
           - type: transaction
             destination: <auction>
@@ -41,8 +42,8 @@
 
 indexes:
   tzcolors:
     template: auction
     values:
       datasource: tzkt
       minter: tzcolors_minter
-      auction: tzcolors_auction
+      auction: tzcolors_auction
```

### Comparing `dipdup-7.5.7/src/demo_auction/handlers/on_bid.py` & `dipdup-8.0.0a1/src/demo_tezos_auction/handlers/on_bid.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,22 +1,22 @@
-import demo_auction.models as models
-from demo_auction.types.tzcolors_auction.tezos_parameters.bid import BidParameter
-from demo_auction.types.tzcolors_auction.tezos_storage import TzcolorsAuctionStorage
+import demo_tezos_auction.models as models
+from demo_tezos_auction.types.tzcolors_auction.tezos_parameters.bid import BidParameter
+from demo_tezos_auction.types.tzcolors_auction.tezos_storage import TzcolorsAuctionStorage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_bid(
     ctx: HandlerContext,
-    bid: TzktTransaction[BidParameter, TzcolorsAuctionStorage],
+    bid: TezosTransaction[BidParameter, TzcolorsAuctionStorage],
 ) -> None:
     assert bid.data.amount is not None
 
     auction = await models.Auction.filter(
-        id=bid.parameter.__root__,
+        id=bid.parameter.root,
     ).get()
 
     bidder, _ = await models.User.get_or_create(address=bid.data.sender_address)
     await models.Bid(
         auction=auction,
         bidder=bidder,
         bid_amount=bid.data.amount,
```

### Comparing `dipdup-7.5.7/src/demo_auction/handlers/on_create_auction.py` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_auction/handlers/on_create_auction.py.j2`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-import demo_auction.models as models
-from demo_auction.types.tzcolors_auction.tezos_parameters.create_auction import CreateAuctionParameter
-from demo_auction.types.tzcolors_auction.tezos_storage import TzcolorsAuctionStorage
+import {{project.package}}.models as models
+from {{project.package}}.types.tzcolors_auction.tezos_parameters.create_auction import CreateAuctionParameter
+from {{project.package}}.types.tzcolors_auction.tezos_storage import TzcolorsAuctionStorage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_create_auction(
     ctx: HandlerContext,
-    create_auction: TzktTransaction[CreateAuctionParameter, TzcolorsAuctionStorage],
+    create_auction: TezosTransaction[CreateAuctionParameter, TzcolorsAuctionStorage],
 ) -> None:
     holder, _ = await models.User.get_or_create(address=create_auction.data.sender_address)
 
     token, _ = await models.Token.get_or_create(
         id=create_auction.parameter.token_id,
         address=create_auction.parameter.token_address,
         defaults={
@@ -38,8 +38,8 @@
     bid = models.Bid(
         auction=auction,
         bidder=holder,
         bid_amount=create_auction.parameter.bid_amount,
         level=create_auction.data.level,
         timestamp=create_auction.data.timestamp,
     )
-    await bid.save()
+    await bid.save()
```

### Comparing `dipdup-7.5.7/src/demo_auction/handlers/on_withdraw.py` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_auction/handlers/on_withdraw.py.j2`

 * *Files 11% similar despite different names*

```diff
@@ -1,22 +1,22 @@
-import demo_auction.models as models
-from demo_auction.types.tzcolors_auction.tezos_parameters.withdraw import WithdrawParameter
-from demo_auction.types.tzcolors_auction.tezos_storage import TzcolorsAuctionStorage
+import {{project.package}}.models as models
+from {{project.package}}.types.tzcolors_auction.tezos_parameters.withdraw import WithdrawParameter
+from {{project.package}}.types.tzcolors_auction.tezos_storage import TzcolorsAuctionStorage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_withdraw(
     ctx: HandlerContext,
-    withdraw: TzktTransaction[WithdrawParameter, TzcolorsAuctionStorage],
+    withdraw: TezosTransaction[WithdrawParameter, TzcolorsAuctionStorage],
 ) -> None:
     auction = await models.Auction.filter(
-        id=withdraw.parameter.__root__,
+        id=withdraw.parameter.root,
     ).get()
 
     token = await auction.token
 
     token.holder = await auction.bidder
     await token.save()
 
     auction.status = models.AuctionStatus.FINISHED
-    await auction.save()
+    await auction.save()
```

### Comparing `dipdup-7.5.7/src/demo_auction/models/__init__.py` & `dipdup-8.0.0a1/src/demo_tezos_auction/models/__init__.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_auction/pyproject.toml` & `dipdup-8.0.0a1/src/demo_tezos_etherlink/pyproject.toml`

 * *Files 6% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Generated by DipDup 7.5.7
+# generated by DipDup 8.0.0a1
 [project]
-name = "demo_auction"
+name = "demo_tezos_etherlink"
 version = "0.0.1"
-description = "NFT marketplace (TzColors)"
+description = "Etherlink smart rollup transactions"
 license = { text = "MIT" }
 authors = [
     { name = "John Doe", email = "john_doe@example.com" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 dependencies = [
-    "dipdup>=7,<8",
+    "dipdup>=8,<9",
 ]
 
 [tool.pdm.dev-dependencies]
 dev = [
     "black",
     "ruff",
     "mypy",
@@ -30,27 +30,27 @@
 mypy = {cmd = "make mypy", help = "Lint with mypy"}
 image = {cmd = "make image", help = "Build Docker image"}
 up = {cmd = "make up", help = "Run Compose stack"}
 down = {cmd = "make down", help = "Stop Compose stack"}
 
 [tool.black]
 line-length = 120
-target-version = ['py311']
+target-version = ['py312']
 skip-string-normalization = true
 
 [tool.ruff]
 line-length = 120
-target-version = 'py311'
+target-version = 'py312'
 
 [tool.ruff.lint]
 extend-select = ["B", "C4", "FA", "G", "I", "PTH", "Q", "RET", "RUF", "TCH", "UP"]
 flake8-quotes = { inline-quotes = "single", multiline-quotes = "double" }
 isort = { force-single-line = true}
 
 [tool.mypy]
-python_version = "3.11"
+python_version = "3.12"
 plugins = ["pydantic.mypy"]
 strict = false
 
 [build-system]
 requires = ["pdm-backend"]
 build-backend = "pdm.backend"
```

### Comparing `dipdup-7.5.7/src/demo_big_maps/Makefile` & `dipdup-8.0.0a1/src/demo_tezos_big_maps/Makefile`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 .PHONY: $(MAKECMDGOALS)
 MAKEFLAGS += --no-print-directory
 ##
 ##   DipDup developer tools
 ##
-PACKAGE=demo_big_maps
+PACKAGE=demo_tezos_big_maps
 TAG=latest
 COMPOSE=deploy/compose.yaml
 
 help:           ## Show this help (default)
 	@grep -Fh "##" $(MAKEFILE_LIST) | grep -Fv grep -F | sed -e 's/\\$$//' | sed -e 's/##//'
 
 all:            ## Run an entire CI pipeline
```

### Comparing `dipdup-7.5.7/src/demo_big_maps/README.md` & `dipdup-8.0.0a1/src/demo_tezos_dao/README.md`

 * *Files 10% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# demo_big_maps
+# demo_tezos_dao
 
-Indexing specific big maps
+DAO registry (Homebase DAO)
 
 ## Installation
 
 This project is based on [DipDup](https://dipdup.io), a framework for building featureful dapps.
 
-You need a Linux/macOS system with Python 3.11 installed. To install DipDup with pipx for the current user:
+You need a Linux/macOS system with Python 3.12 installed. To install DipDup with pipx or use our installer:
 
 ```shell
-curl -Lsf https://dipdup.io/install.py | python3
+curl -Lsf https://dipdup.io/install.py | python3.12
 ```
 
 See the [Installation](https://dipdup.io/docs/installation) page for all options.
 
 ## Usage
 
 Run the indexer in memory:
```

### Comparing `dipdup-7.5.7/src/demo_big_maps/configs/dipdup.compose.yaml` & `dipdup-8.0.0a1/src/demo_evm_events/configs/dipdup.compose.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_big_maps/configs/dipdup.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_big_maps/configs/dipdup.swarm.yaml`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 database:
   kind: postgres
-  host: ${POSTGRES_HOST:-demo_big_maps_db}
+  host: ${POSTGRES_HOST:-demo_tezos_big_maps_db}
   port: 5432
   user: ${POSTGRES_USER:-dipdup}
   password: ${POSTGRES_PASSWORD}
   database: ${POSTGRES_DB:-dipdup}
 
 hasura:
-  url: http://${HASURA_HOST:-demo_big_maps_hasura}:8080
+  url: http://${HASURA_HOST:-demo_tezos_big_maps_hasura}:8080
   admin_secret: ${HASURA_SECRET}
   allow_aggregations: ${HASURA_ALLOW_AGGREGATIONS:-false}
   select_limit: ${HASURA_SELECT_LIMIT:-100}
   camel_case: ${HASURA_CAMEL_CASE:-true}
 
 sentry:
   dsn: ${SENTRY_DSN:-''}
```

### Comparing `dipdup-7.5.7/src/demo_big_maps/configs/replay.yaml` & `dipdup-8.0.0a1/src/demo_tezos_raw/configs/replay.yaml`

 * *Files 18% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 # To refresh existing project run `dipdup init --base --force` after modifying this file.
 # To generate a new project from this replay run `dipdup new --replay <path_to_file>`.
 #
-spec_version: 2.0
+spec_version: 3.0
 replay:
-  dipdup_version: 7
-  template: demo_big_maps
-  package: demo_big_maps
+  dipdup_version: 8
+  template: demo_tezos_raw
+  package: demo_tezos_raw
   version: 0.0.1
-  description: Indexing specific big maps
+  description: Process raw operations without filtering and typed payloads
   license: MIT
   name: John Doe
   email: john_doe@example.com
   postgres_image: postgres:15
   postgres_data_path: /var/lib/postgresql/data
   hasura_image: hasura/graphql-engine:latest
   line_length: 120
```

### Comparing `dipdup-7.5.7/src/demo_big_maps/deploy/compose.swarm.yaml` & `dipdup-8.0.0a1/src/demo_evm_events/deploy/compose.swarm.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 version: "3.8"
-name: demo_big_maps
+name: demo_evm_events
 
 services:
   dipdup:
-    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-7}
+    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-8}
     depends_on:
       - db
       - hasura
     command: ["-c", "dipdup.yaml", "-c", "configs/dipdup.swarm.yaml", "run"]
     env_file: .env
     networks:
       - internal
@@ -51,15 +51,15 @@
     logging: *logging
 
   hasura:
     image: hasura/graphql-engine:latest
     depends_on:
       - db
     environment:
-      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_big_maps_db:5432/dipdup
+      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_evm_events_db:5432/dipdup
       - HASURA_GRAPHQL_ADMIN_SECRET=${HASURA_SECRET}
       - HASURA_GRAPHQL_ENABLE_CONSOLE=true
       - HASURA_GRAPHQL_DEV_MODE=false
       - HASURA_GRAPHQL_LOG_LEVEL=warn
       - HASURA_GRAPHQL_ENABLE_TELEMETRY=false
       - HASURA_GRAPHQL_UNAUTHORIZED_ROLE=user
       - HASURA_GRAPHQL_STRINGIFY_NUMERIC_TYPES=true
```

### Comparing `dipdup-7.5.7/src/demo_big_maps/deploy/compose.yaml` & `dipdup-8.0.0a1/src/demo_evm_events/deploy/compose.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 version: "3.8"
-name: demo_big_maps
+name: demo_evm_events
 
 services:
   dipdup:
     build:
       context: ..
       dockerfile: deploy/Dockerfile
     restart: always
```

### Comparing `dipdup-7.5.7/src/demo_big_maps/dipdup.yaml` & `dipdup-8.0.0a1/src/demo_tezos_big_maps/dipdup.yaml`

 * *Files 14% similar despite different names*

```diff
@@ -1,25 +1,26 @@
-spec_version: 2.0
-package: demo_big_maps
+spec_version: 3.0
+package: demo_tezos_big_maps
 
 contracts:
   mainnet_name_registry:
     kind: tezos
     address: KT1GBZmSxmnKJXGMdMLbugPfLyUPmuLSMwKS
     typename: name_registry
 
 datasources:
   tzkt_mainnet:
     kind: tezos.tzkt
     url: ${TZKT_URL:-https://api.tzkt.io}
 
 templates:
   big_maps:
-    kind: tezos.tzkt.big_maps
-    datasource: <datasource>
+    kind: tezos.big_maps
+    datasources:
+      - <datasource>
     skip_history: once
     handlers:
       - callback: on_update_records
         contract: <name_registry>
         path: store.records
       - callback: on_update_expiry_map
         contract: <name_registry>
```

### Comparing `dipdup-7.5.7/src/demo_big_maps/handlers/on_update_expiry_map.py` & `dipdup-8.0.0a1/src/demo_tezos_big_maps/handlers/on_update_expiry_map.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,22 +1,22 @@
-import demo_big_maps.models as models
-from demo_big_maps.types.name_registry.tezos_big_maps.store_expiry_map_key import StoreExpiryMapKey
-from demo_big_maps.types.name_registry.tezos_big_maps.store_expiry_map_value import StoreExpiryMapValue
+import demo_tezos_big_maps.models as models
+from demo_tezos_big_maps.types.name_registry.tezos_big_maps.store_expiry_map_key import StoreExpiryMapKey
+from demo_tezos_big_maps.types.name_registry.tezos_big_maps.store_expiry_map_value import StoreExpiryMapValue
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktBigMapDiff
+from dipdup.models.tezos import TezosBigMapDiff
 
 
 async def on_update_expiry_map(
     ctx: HandlerContext,
-    store_expiry_map: TzktBigMapDiff[StoreExpiryMapKey, StoreExpiryMapValue],
+    store_expiry_map: TezosBigMapDiff[StoreExpiryMapKey, StoreExpiryMapValue],
 ) -> None:
     if not store_expiry_map.action.has_value:
         return
     assert store_expiry_map.key
     assert store_expiry_map.value
 
-    timestamp = store_expiry_map.value.__root__
-    record_name = bytes.fromhex(store_expiry_map.key.__root__).decode()
+    timestamp = store_expiry_map.value.root
+    record_name = bytes.fromhex(store_expiry_map.key.root).decode()
     await models.Expiry.update_or_create(
         id=record_name,
         defaults={'timestamp': timestamp},
     )
```

### Comparing `dipdup-7.5.7/src/demo_big_maps/handlers/on_update_records.py` & `dipdup-8.0.0a1/src/demo_tezos_big_maps/handlers/on_update_records.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,24 +1,24 @@
-import demo_big_maps.models as models
-from demo_big_maps.types.name_registry.tezos_big_maps.store_records_key import StoreRecordsKey
-from demo_big_maps.types.name_registry.tezos_big_maps.store_records_value import StoreRecordsValue
+import demo_tezos_big_maps.models as models
+from demo_tezos_big_maps.types.name_registry.tezos_big_maps.store_records_key import StoreRecordsKey
+from demo_tezos_big_maps.types.name_registry.tezos_big_maps.store_records_value import StoreRecordsValue
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktBigMapDiff
+from dipdup.models.tezos import TezosBigMapDiff
 
 
 async def on_update_records(
     ctx: HandlerContext,
-    store_records: TzktBigMapDiff[StoreRecordsKey, StoreRecordsValue],
+    store_records: TezosBigMapDiff[StoreRecordsKey, StoreRecordsValue],
 ) -> None:
     if not store_records.action.has_value:
         return
     assert store_records.key
     assert store_records.value
 
-    record_name = bytes.fromhex(store_records.key.__root__).decode()
+    record_name = bytes.fromhex(store_records.key.root).decode()
     record_path = record_name.split('.')
     ctx.logger.info('Processing `%s`', record_name)
 
     level = store_records.value.level
     if len(record_path) != int(level):
         ctx.logger.warning('`%s`: expected %s chunks, got %s', record_name, level, len(record_path))
         return
```

### Comparing `dipdup-7.5.7/src/demo_big_maps/models/__init__.py` & `dipdup-8.0.0a1/src/demo_tezos_big_maps/models/__init__.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_big_maps/pyproject.toml` & `dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/pyproject.toml`

 * *Files 7% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Generated by DipDup 7.5.7
+# generated by DipDup 8.0.0a1
 [project]
-name = "demo_big_maps"
+name = "demo_tezos_nft_marketplace"
 version = "0.0.1"
-description = "Indexing specific big maps"
+description = "NFT marketplace (hic at nunc)"
 license = { text = "MIT" }
 authors = [
     { name = "John Doe", email = "john_doe@example.com" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 dependencies = [
-    "dipdup>=7,<8",
+    "dipdup>=8,<9",
 ]
 
 [tool.pdm.dev-dependencies]
 dev = [
     "black",
     "ruff",
     "mypy",
@@ -30,27 +30,27 @@
 mypy = {cmd = "make mypy", help = "Lint with mypy"}
 image = {cmd = "make image", help = "Build Docker image"}
 up = {cmd = "make up", help = "Run Compose stack"}
 down = {cmd = "make down", help = "Stop Compose stack"}
 
 [tool.black]
 line-length = 120
-target-version = ['py311']
+target-version = ['py312']
 skip-string-normalization = true
 
 [tool.ruff]
 line-length = 120
-target-version = 'py311'
+target-version = 'py312'
 
 [tool.ruff.lint]
 extend-select = ["B", "C4", "FA", "G", "I", "PTH", "Q", "RET", "RUF", "TCH", "UP"]
 flake8-quotes = { inline-quotes = "single", multiline-quotes = "double" }
 isort = { force-single-line = true}
 
 [tool.mypy]
-python_version = "3.11"
+python_version = "3.12"
 plugins = ["pydantic.mypy"]
 strict = false
 
 [build-system]
 requires = ["pdm-backend"]
 build-backend = "pdm.backend"
```

### Comparing `dipdup-7.5.7/src/demo_blank/Makefile` & `dipdup-8.0.0a1/src/demo_blank/Makefile`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_blank/README.md` & `dipdup-8.0.0a1/src/demo_tezos_big_maps/README.md`

 * *Files 11% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# demo_blank
+# demo_tezos_big_maps
 
-Empty config for a fresh start
+Indexing specific big maps
 
 ## Installation
 
 This project is based on [DipDup](https://dipdup.io), a framework for building featureful dapps.
 
-You need a Linux/macOS system with Python 3.11 installed. To install DipDup with pipx for the current user:
+You need a Linux/macOS system with Python 3.12 installed. To install DipDup with pipx or use our installer:
 
 ```shell
-curl -Lsf https://dipdup.io/install.py | python3
+curl -Lsf https://dipdup.io/install.py | python3.12
 ```
 
 See the [Installation](https://dipdup.io/docs/installation) page for all options.
 
 ## Usage
 
 Run the indexer in memory:
```

### Comparing `dipdup-7.5.7/src/demo_blank/configs/dipdup.compose.yaml` & `dipdup-8.0.0a1/src/demo_evm_transactions/configs/dipdup.compose.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_blank/configs/dipdup.swarm.yaml` & `dipdup-8.0.0a1/src/demo_blank/configs/dipdup.swarm.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_blank/configs/replay.yaml` & `dipdup-8.0.0a1/src/demo_tezos_auction/configs/replay.yaml`

 * *Files 11% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 # To refresh existing project run `dipdup init --base --force` after modifying this file.
 # To generate a new project from this replay run `dipdup new --replay <path_to_file>`.
 #
-spec_version: 2.0
+spec_version: 3.0
 replay:
-  dipdup_version: 7
-  template: demo_blank
-  package: demo_blank
+  dipdup_version: 8
+  template: demo_tezos_auction
+  package: demo_tezos_auction
   version: 0.0.1
-  description: Empty config for a fresh start
+  description: NFT marketplace (TzColors)
   license: MIT
   name: John Doe
   email: john_doe@example.com
   postgres_image: postgres:15
   postgres_data_path: /var/lib/postgresql/data
   hasura_image: hasura/graphql-engine:latest
   line_length: 120
```

### Comparing `dipdup-7.5.7/src/demo_blank/deploy/compose.swarm.yaml` & `dipdup-8.0.0a1/src/demo_blank/deploy/compose.swarm.yaml`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 version: "3.8"
 name: demo_blank
 
 services:
   dipdup:
-    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-7}
+    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-8}
     depends_on:
       - db
       - hasura
     command: ["-c", "dipdup.yaml", "-c", "configs/dipdup.swarm.yaml", "run"]
     env_file: .env
     networks:
       - internal
```

### Comparing `dipdup-7.5.7/src/demo_blank/deploy/compose.yaml` & `dipdup-8.0.0a1/src/demo_blank/deploy/compose.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_blank/models/__init__.py` & `dipdup-8.0.0a1/src/demo_blank/models/__init__.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_blank/pyproject.toml` & `dipdup-8.0.0a1/src/demo_tezos_events/pyproject.toml`

 * *Files 7% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Generated by DipDup 7.5.7
+# generated by DipDup 8.0.0a1
 [project]
-name = "demo_blank"
+name = "demo_tezos_events"
 version = "0.0.1"
-description = "Empty config for a fresh start"
+description = "Processing contract events"
 license = { text = "MIT" }
 authors = [
     { name = "John Doe", email = "john_doe@example.com" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 dependencies = [
-    "dipdup>=7,<8",
+    "dipdup>=8,<9",
 ]
 
 [tool.pdm.dev-dependencies]
 dev = [
     "black",
     "ruff",
     "mypy",
@@ -30,27 +30,27 @@
 mypy = {cmd = "make mypy", help = "Lint with mypy"}
 image = {cmd = "make image", help = "Build Docker image"}
 up = {cmd = "make up", help = "Run Compose stack"}
 down = {cmd = "make down", help = "Stop Compose stack"}
 
 [tool.black]
 line-length = 120
-target-version = ['py311']
+target-version = ['py312']
 skip-string-normalization = true
 
 [tool.ruff]
 line-length = 120
-target-version = 'py311'
+target-version = 'py312'
 
 [tool.ruff.lint]
 extend-select = ["B", "C4", "FA", "G", "I", "PTH", "Q", "RET", "RUF", "TCH", "UP"]
 flake8-quotes = { inline-quotes = "single", multiline-quotes = "double" }
 isort = { force-single-line = true}
 
 [tool.mypy]
-python_version = "3.11"
+python_version = "3.12"
 plugins = ["pydantic.mypy"]
 strict = false
 
 [build-system]
 requires = ["pdm-backend"]
 build-backend = "pdm.backend"
```

### Comparing `dipdup-7.5.7/src/demo_dao/Makefile` & `dipdup-8.0.0a1/src/demo_tezos_dao/Makefile`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 .PHONY: $(MAKECMDGOALS)
 MAKEFLAGS += --no-print-directory
 ##
 ##   DipDup developer tools
 ##
-PACKAGE=demo_dao
+PACKAGE=demo_tezos_dao
 TAG=latest
 COMPOSE=deploy/compose.yaml
 
 help:           ## Show this help (default)
 	@grep -Fh "##" $(MAKEFILE_LIST) | grep -Fv grep -F | sed -e 's/\\$$//' | sed -e 's/##//'
 
 all:            ## Run an entire CI pipeline
```

### Comparing `dipdup-7.5.7/src/demo_dao/README.md` & `dipdup-8.0.0a1/src/demo_tezos_domains/README.md`

 * *Files 10% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# demo_dao
+# demo_tezos_domains
 
-DAO registry (Homebase DAO)
+Domain name service (Tezos Domains)
 
 ## Installation
 
 This project is based on [DipDup](https://dipdup.io), a framework for building featureful dapps.
 
-You need a Linux/macOS system with Python 3.11 installed. To install DipDup with pipx for the current user:
+You need a Linux/macOS system with Python 3.12 installed. To install DipDup with pipx or use our installer:
 
 ```shell
-curl -Lsf https://dipdup.io/install.py | python3
+curl -Lsf https://dipdup.io/install.py | python3.12
 ```
 
 See the [Installation](https://dipdup.io/docs/installation) page for all options.
 
 ## Usage
 
 Run the indexer in memory:
```

### Comparing `dipdup-7.5.7/src/demo_dao/configs/dipdup.compose.yaml` & `dipdup-8.0.0a1/src/demo_evm_uniswap/configs/dipdup.compose.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_dao/configs/dipdup.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_dao/configs/dipdup.swarm.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 database:
   kind: postgres
-  host: ${POSTGRES_HOST:-demo_dao_db}
+  host: ${POSTGRES_HOST:-demo_tezos_dao_db}
   port: 5432
   user: ${POSTGRES_USER:-dipdup}
   password: ${POSTGRES_PASSWORD}
   database: ${POSTGRES_DB:-dipdup}
 
 hasura:
-  url: http://${HASURA_HOST:-demo_dao_hasura}:8080
+  url: http://${HASURA_HOST:-demo_tezos_dao_hasura}:8080
   admin_secret: ${HASURA_SECRET}
   allow_aggregations: ${HASURA_ALLOW_AGGREGATIONS:-false}
   select_limit: ${HASURA_SELECT_LIMIT:-100}
   camel_case: ${HASURA_CAMEL_CASE:-true}
 
 sentry:
   dsn: ${SENTRY_DSN:-''}
```

### Comparing `dipdup-7.5.7/src/demo_dao/configs/replay.yaml` & `dipdup-8.0.0a1/src/demo_tezos_domains/configs/replay.yaml`

 * *Files 22% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 # To refresh existing project run `dipdup init --base --force` after modifying this file.
 # To generate a new project from this replay run `dipdup new --replay <path_to_file>`.
 #
-spec_version: 2.0
+spec_version: 3.0
 replay:
-  dipdup_version: 7
-  template: demo_dao
-  package: demo_dao
+  dipdup_version: 8
+  template: demo_tezos_domains
+  package: demo_tezos_domains
   version: 0.0.1
-  description: DAO registry (Homebase DAO)
+  description: Domain name service (Tezos Domains)
   license: MIT
   name: John Doe
   email: john_doe@example.com
   postgres_image: postgres:15
   postgres_data_path: /var/lib/postgresql/data
   hasura_image: hasura/graphql-engine:latest
   line_length: 120
```

### Comparing `dipdup-7.5.7/src/demo_dao/deploy/compose.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_dao/deploy/compose.swarm.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 version: "3.8"
-name: demo_dao
+name: demo_tezos_dao
 
 services:
   dipdup:
-    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-7}
+    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-8}
     depends_on:
       - db
       - hasura
     command: ["-c", "dipdup.yaml", "-c", "configs/dipdup.swarm.yaml", "run"]
     env_file: .env
     networks:
       - internal
@@ -51,15 +51,15 @@
     logging: *logging
 
   hasura:
     image: hasura/graphql-engine:latest
     depends_on:
       - db
     environment:
-      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_dao_db:5432/dipdup
+      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_tezos_dao_db:5432/dipdup
       - HASURA_GRAPHQL_ADMIN_SECRET=${HASURA_SECRET}
       - HASURA_GRAPHQL_ENABLE_CONSOLE=true
       - HASURA_GRAPHQL_DEV_MODE=false
       - HASURA_GRAPHQL_LOG_LEVEL=warn
       - HASURA_GRAPHQL_ENABLE_TELEMETRY=false
       - HASURA_GRAPHQL_UNAUTHORIZED_ROLE=user
       - HASURA_GRAPHQL_STRINGIFY_NUMERIC_TYPES=true
```

### Comparing `dipdup-7.5.7/src/demo_dao/deploy/compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_token/deploy/compose.yaml`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 version: "3.8"
-name: demo_dao
+name: demo_tezos_token
 
 services:
   dipdup:
     build:
       context: ..
       dockerfile: deploy/Dockerfile
     restart: always
```

### Comparing `dipdup-7.5.7/src/demo_dao/dipdup.yaml` & `dipdup-8.0.0a1/src/demo_tezos_dao/dipdup.yaml`

 * *Files 5% similar despite different names*

```diff
@@ -1,25 +1,26 @@
-spec_version: 2.0
-package: demo_dao
+spec_version: 3.0
+package: demo_tezos_dao
 
 contracts:
   registry:
     kind: tezos
     code_hash: KT19CF3KKrvdW77ttFomCuin2k4uAVkryYqh
     typename: registry
 
 datasources:
   tzkt:
     kind: tezos.tzkt
     url: ${TZKT_URL:-https://api.tzkt.io}
 
 indexes:
   registry_dao:
-    kind: tezos.tzkt.operations
-    datasource: tzkt
+    kind: tezos.operations
+    datasources:
+      - tzkt
     types:
       - transaction
       - origination
     handlers:
       - callback: on_origination
         pattern:
           - type: origination
```

### Comparing `dipdup-7.5.7/src/demo_dao/models/__init__.py` & `dipdup-8.0.0a1/src/demo_tezos_dao/models/__init__.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_dao/pyproject.toml` & `dipdup-8.0.0a1/src/demo_tezos_dex/pyproject.toml`

 * *Files 6% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Generated by DipDup 7.5.7
+# generated by DipDup 8.0.0a1
 [project]
-name = "demo_dao"
+name = "demo_tezos_dex"
 version = "0.0.1"
-description = "DAO registry (Homebase DAO)"
+description = "DEX balances and liquidity (Quipuswap)"
 license = { text = "MIT" }
 authors = [
     { name = "John Doe", email = "john_doe@example.com" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 dependencies = [
-    "dipdup>=7,<8",
+    "dipdup>=8,<9",
 ]
 
 [tool.pdm.dev-dependencies]
 dev = [
     "black",
     "ruff",
     "mypy",
@@ -30,27 +30,27 @@
 mypy = {cmd = "make mypy", help = "Lint with mypy"}
 image = {cmd = "make image", help = "Build Docker image"}
 up = {cmd = "make up", help = "Run Compose stack"}
 down = {cmd = "make down", help = "Stop Compose stack"}
 
 [tool.black]
 line-length = 120
-target-version = ['py311']
+target-version = ['py312']
 skip-string-normalization = true
 
 [tool.ruff]
 line-length = 120
-target-version = 'py311'
+target-version = 'py312'
 
 [tool.ruff.lint]
 extend-select = ["B", "C4", "FA", "G", "I", "PTH", "Q", "RET", "RUF", "TCH", "UP"]
 flake8-quotes = { inline-quotes = "single", multiline-quotes = "double" }
 isort = { force-single-line = true}
 
 [tool.mypy]
-python_version = "3.11"
+python_version = "3.12"
 plugins = ["pydantic.mypy"]
 strict = false
 
 [build-system]
 requires = ["pdm-backend"]
 build-backend = "pdm.backend"
```

### Comparing `dipdup-7.5.7/src/demo_dex/Makefile` & `dipdup-8.0.0a1/src/demo_tezos_dex/Makefile`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 .PHONY: $(MAKECMDGOALS)
 MAKEFLAGS += --no-print-directory
 ##
 ##   DipDup developer tools
 ##
-PACKAGE=demo_dex
+PACKAGE=demo_tezos_dex
 TAG=latest
 COMPOSE=deploy/compose.yaml
 
 help:           ## Show this help (default)
 	@grep -Fh "##" $(MAKEFILE_LIST) | grep -Fv grep -F | sed -e 's/\\$$//' | sed -e 's/##//'
 
 all:            ## Run an entire CI pipeline
```

### Comparing `dipdup-7.5.7/src/demo_dex/README.md` & `dipdup-8.0.0a1/src/demo_tezos_token/README.md`

 * *Files 6% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# demo_dex
+# demo_tezos_token
 
-DEX balances and liquidity (Quipuswap)
+FA1.2 token contract operations
 
 ## Installation
 
 This project is based on [DipDup](https://dipdup.io), a framework for building featureful dapps.
 
-You need a Linux/macOS system with Python 3.11 installed. To install DipDup with pipx for the current user:
+You need a Linux/macOS system with Python 3.12 installed. To install DipDup with pipx or use our installer:
 
 ```shell
-curl -Lsf https://dipdup.io/install.py | python3
+curl -Lsf https://dipdup.io/install.py | python3.12
 ```
 
 See the [Installation](https://dipdup.io/docs/installation) page for all options.
 
 ## Usage
 
 Run the indexer in memory:
```

### Comparing `dipdup-7.5.7/src/demo_dex/configs/dipdup.compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_auction/configs/dipdup.compose.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_dex/configs/dipdup.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_dex/configs/dipdup.swarm.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 database:
   kind: postgres
-  host: ${POSTGRES_HOST:-demo_dex_db}
+  host: ${POSTGRES_HOST:-demo_tezos_dex_db}
   port: 5432
   user: ${POSTGRES_USER:-dipdup}
   password: ${POSTGRES_PASSWORD}
   database: ${POSTGRES_DB:-dipdup}
 
 hasura:
-  url: http://${HASURA_HOST:-demo_dex_hasura}:8080
+  url: http://${HASURA_HOST:-demo_tezos_dex_hasura}:8080
   admin_secret: ${HASURA_SECRET}
   allow_aggregations: ${HASURA_ALLOW_AGGREGATIONS:-false}
   select_limit: ${HASURA_SELECT_LIMIT:-100}
   camel_case: ${HASURA_CAMEL_CASE:-true}
 
 sentry:
   dsn: ${SENTRY_DSN:-''}
```

### Comparing `dipdup-7.5.7/src/demo_dex/configs/replay.yaml` & `dipdup-8.0.0a1/src/demo_tezos_dex/configs/replay.yaml`

 * *Files 25% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # To refresh existing project run `dipdup init --base --force` after modifying this file.
 # To generate a new project from this replay run `dipdup new --replay <path_to_file>`.
 #
-spec_version: 2.0
+spec_version: 3.0
 replay:
-  dipdup_version: 7
-  template: demo_dex
-  package: demo_dex
+  dipdup_version: 8
+  template: demo_tezos_dex
+  package: demo_tezos_dex
   version: 0.0.1
   description: DEX balances and liquidity (Quipuswap)
   license: MIT
   name: John Doe
   email: john_doe@example.com
   postgres_image: postgres:15
   postgres_data_path: /var/lib/postgresql/data
```

### Comparing `dipdup-7.5.7/src/demo_dex/deploy/compose.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_domains/deploy/compose.swarm.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 version: "3.8"
-name: demo_dex
+name: demo_tezos_domains
 
 services:
   dipdup:
-    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-7}
+    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-8}
     depends_on:
       - db
       - hasura
     command: ["-c", "dipdup.yaml", "-c", "configs/dipdup.swarm.yaml", "run"]
     env_file: .env
     networks:
       - internal
@@ -51,15 +51,15 @@
     logging: *logging
 
   hasura:
     image: hasura/graphql-engine:latest
     depends_on:
       - db
     environment:
-      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_dex_db:5432/dipdup
+      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_tezos_domains_db:5432/dipdup
       - HASURA_GRAPHQL_ADMIN_SECRET=${HASURA_SECRET}
       - HASURA_GRAPHQL_ENABLE_CONSOLE=true
       - HASURA_GRAPHQL_DEV_MODE=false
       - HASURA_GRAPHQL_LOG_LEVEL=warn
       - HASURA_GRAPHQL_ENABLE_TELEMETRY=false
       - HASURA_GRAPHQL_UNAUTHORIZED_ROLE=user
       - HASURA_GRAPHQL_STRINGIFY_NUMERIC_TYPES=true
```

### Comparing `dipdup-7.5.7/src/demo_dex/deploy/compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_dex/deploy/compose.yaml`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 version: "3.8"
-name: demo_dex
+name: demo_tezos_dex
 
 services:
   dipdup:
     build:
       context: ..
       dockerfile: deploy/Dockerfile
     restart: always
```

### Comparing `dipdup-7.5.7/src/demo_dex/dipdup.yaml` & `dipdup-8.0.0a1/tests/configs/demo_tezos_dex.yml`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-spec_version: 2.0
-package: demo_dex
+spec_version: 3.0
+package: demo_tezos_dex
 
 contracts:
   kusd_dex_mainnet:
     kind: tezos
     address: KT1K4EwTpbvYN9agJdjpyJm4ZZdhpUNKB3F6
     typename: quipu_fa12
   kusd_token_mainnet:
@@ -19,19 +19,22 @@
     address: KT1AFA2mwNUMNd4SsujE1YYp29vd8BZejyKW
     typename: fa2_token
 
 datasources:
   tzkt_mainnet:
     kind: tezos.tzkt
     url: https://api.tzkt.io
+    http:
+      replay_path: ${DIPDUP_REPLAY_PATH:-}
 
 templates:
   quipuswap_fa12:
-    kind: tezos.tzkt.operations
-    datasource: tzkt_mainnet
+    kind: tezos.operations
+    datasources:
+      - tzkt_mainnet
     contracts:
       - <dex_contract>
     types:
       - transaction
       - origination
     handlers:
       - callback: on_fa12_origination
@@ -85,16 +88,17 @@
             destination: <dex_contract>
             entrypoint: withdrawProfit
           - type: transaction
             source: <dex_contract>
             optional: True
 
   quipuswap_fa2:
-    kind: tezos.tzkt.operations
-    datasource: tzkt_mainnet
+    kind: tezos.operations
+    datasources:
+      - tzkt_mainnet
     contracts:
       - <dex_contract>
     types:
       - transaction
       - origination
     handlers:
       - callback: on_fa2_origination
@@ -155,15 +159,21 @@
   kusd_mainnet:
     template: quipuswap_fa12
     values:
       dex_contract: kusd_dex_mainnet
       token_contract: kusd_token_mainnet
       symbol: kUSD
       decimals: 18
+    first_level: 3032136
+    last_level: 3032136
 
   hdao_mainnet:
     template: quipuswap_fa2
     values:
       dex_contract: hdao_dex_mainnet
       token_contract: hdao_token_mainnet
       symbol: hDAO
-      decimals: 6
+      decimals: 6
+    first_level: 1443017
+    last_level: 1443370
+
+logging: WARN
```

### Comparing `dipdup-7.5.7/src/demo_dex/handlers/on_fa12_divest_liquidity.py` & `dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa2_divest_liquidity.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,36 +1,36 @@
 from decimal import Decimal
 
-import demo_dex.models as models
-from demo_dex.types.fa12_token.tezos_parameters.transfer import TransferParameter
-from demo_dex.types.fa12_token.tezos_storage import Fa12TokenStorage
-from demo_dex.types.quipu_fa12.tezos_parameters.divest_liquidity import DivestLiquidityParameter
-from demo_dex.types.quipu_fa12.tezos_storage import QuipuFa12Storage
+import demo_tezos_dex.models as models
+from demo_tezos_dex.types.fa2_token.tezos_parameters.transfer import TransferParameter
+from demo_tezos_dex.types.fa2_token.tezos_storage import Fa2TokenStorage
+from demo_tezos_dex.types.quipu_fa2.tezos_parameters.divest_liquidity import DivestLiquidityParameter
+from demo_tezos_dex.types.quipu_fa2.tezos_storage import QuipuFa2Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktOperationData
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosOperationData
+from dipdup.models.tezos import TezosTransaction
 
 
-async def on_fa12_divest_liquidity(
+async def on_fa2_divest_liquidity(
     ctx: HandlerContext,
-    divest_liquidity: TzktTransaction[DivestLiquidityParameter, QuipuFa12Storage],
-    transfer: TzktTransaction[TransferParameter, Fa12TokenStorage],
-    transaction_1: TzktOperationData,
+    divest_liquidity: TezosTransaction[DivestLiquidityParameter, QuipuFa2Storage],
+    transfer: TezosTransaction[TransferParameter, Fa2TokenStorage],
+    transaction_1: TezosOperationData,
 ) -> None:
     storage = divest_liquidity.storage
 
     decimals = int(ctx.template_values['decimals'])
     symbol = ctx.template_values['symbol']
     trader = divest_liquidity.data.sender_address
 
     position, _ = await models.Position.get_or_create(trader=trader, symbol=symbol)
 
     assert transaction_1.amount is not None
     tez_qty = Decimal(transaction_1.amount) / (10**6)
-    token_qty = Decimal(transfer.parameter.value) / (10**decimals)
+    token_qty = sum(Decimal(tx.amount) for tx in transfer.parameter.root[0].txs) / (10**decimals)
     shares_qty = int(divest_liquidity.parameter.shares)
 
     tez_pool = Decimal(storage.storage.tez_pool) / (10**6)
     token_pool = Decimal(storage.storage.token_pool) / (10**decimals)
 
     # NOTE: Empty pools mean exchange is not initialized yet
     if not tez_pool and not token_pool:
```

### Comparing `dipdup-7.5.7/src/demo_dex/handlers/on_fa12_invest_liquidity.py` & `dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa12_invest_liquidity.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 from decimal import Decimal
 
-import demo_dex.models as models
-from demo_dex.types.fa12_token.tezos_parameters.transfer import TransferParameter
-from demo_dex.types.fa12_token.tezos_storage import Fa12TokenStorage
-from demo_dex.types.quipu_fa12.tezos_parameters.invest_liquidity import InvestLiquidityParameter
-from demo_dex.types.quipu_fa12.tezos_storage import QuipuFa12Storage
+import demo_tezos_dex.models as models
+from demo_tezos_dex.types.fa12_token.tezos_parameters.transfer import TransferParameter
+from demo_tezos_dex.types.fa12_token.tezos_storage import Fa12TokenStorage
+from demo_tezos_dex.types.quipu_fa12.tezos_parameters.invest_liquidity import InvestLiquidityParameter
+from demo_tezos_dex.types.quipu_fa12.tezos_storage import QuipuFa12Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_fa12_invest_liquidity(
     ctx: HandlerContext,
-    invest_liquidity: TzktTransaction[InvestLiquidityParameter, QuipuFa12Storage],
-    transfer: TzktTransaction[TransferParameter, Fa12TokenStorage],
+    invest_liquidity: TezosTransaction[InvestLiquidityParameter, QuipuFa12Storage],
+    transfer: TezosTransaction[TransferParameter, Fa12TokenStorage],
 ) -> None:
     storage = invest_liquidity.storage
 
     decimals = int(ctx.template_values['decimals'])
     symbol = ctx.template_values['symbol']
     trader = invest_liquidity.data.sender_address
```

### Comparing `dipdup-7.5.7/src/demo_dex/handlers/on_fa12_origination.py` & `dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa12_origination.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-import demo_dex.models as models
-from demo_dex.types.quipu_fa12.tezos_storage import QuipuFa12Storage
+import demo_tezos_dex.models as models
+from demo_tezos_dex.types.quipu_fa12.tezos_storage import QuipuFa12Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktOrigination
+from dipdup.models.tezos import TezosOrigination
 
 
 async def on_fa12_origination(
     ctx: HandlerContext,
-    quipu_fa12_origination: TzktOrigination[QuipuFa12Storage],
+    quipu_fa12_origination: TezosOrigination[QuipuFa12Storage],
 ) -> None:
     symbol = ctx.template_values['symbol']
 
     for address, value in quipu_fa12_origination.storage.storage.ledger.items():
         shares_qty = value.balance
         await models.Position(trader=address, symbol=symbol, shares_qty=shares_qty).save()
```

### Comparing `dipdup-7.5.7/src/demo_dex/handlers/on_fa12_tez_to_token.py` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa12_tez_to_token.py.j2`

 * *Files 12% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 from decimal import Decimal
 
-import demo_dex.models as models
-from demo_dex.types.fa12_token.tezos_parameters.transfer import TransferParameter
-from demo_dex.types.fa12_token.tezos_storage import Fa12TokenStorage
-from demo_dex.types.quipu_fa12.tezos_parameters.tez_to_token_payment import TezToTokenPaymentParameter
-from demo_dex.types.quipu_fa12.tezos_storage import QuipuFa12Storage
+import {{project.package}}.models as models
+from {{project.package}}.types.fa12_token.tezos_parameters.transfer import TransferParameter
+from {{project.package}}.types.fa12_token.tezos_storage import Fa12TokenStorage
+from {{project.package}}.types.quipu_fa12.tezos_parameters.tez_to_token_payment import TezToTokenPaymentParameter
+from {{project.package}}.types.quipu_fa12.tezos_storage import QuipuFa12Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_fa12_tez_to_token(
     ctx: HandlerContext,
-    tez_to_token_payment: TzktTransaction[TezToTokenPaymentParameter, QuipuFa12Storage],
-    transfer: TzktTransaction[TransferParameter, Fa12TokenStorage],
+    tez_to_token_payment: TezosTransaction[TezToTokenPaymentParameter, QuipuFa12Storage],
+    transfer: TezosTransaction[TransferParameter, Fa12TokenStorage],
 ) -> None:
     decimals = int(ctx.template_values['decimals'])
     symbol = ctx.template_values['symbol']
     trader = tez_to_token_payment.data.sender_address
 
     min_token_quantity = Decimal(tez_to_token_payment.parameter.min_out) / (10**decimals)
     token_quantity = Decimal(transfer.parameter.value) / (10**decimals)
@@ -30,8 +30,8 @@
         side=models.TradeSide.BUY,
         quantity=token_quantity,
         price=token_quantity / tez_quantity,
         slippage=(1 - (min_token_quantity / token_quantity)).quantize(Decimal('0.000001')),
         level=transfer.data.level,
         timestamp=transfer.data.timestamp,
     )
-    await trade.save()
+    await trade.save()
```

### Comparing `dipdup-7.5.7/src/demo_dex/handlers/on_fa12_token_to_tez.py` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa12_token_to_tez.py.j2`

 * *Files 10% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 from decimal import Decimal
 
-import demo_dex.models as models
-from demo_dex.types.fa12_token.tezos_parameters.transfer import TransferParameter
-from demo_dex.types.fa12_token.tezos_storage import Fa12TokenStorage
-from demo_dex.types.quipu_fa12.tezos_parameters.token_to_tez_payment import TokenToTezPaymentParameter
-from demo_dex.types.quipu_fa12.tezos_storage import QuipuFa12Storage
+import {{project.package}}.models as models
+from {{project.package}}.types.fa12_token.tezos_parameters.transfer import TransferParameter
+from {{project.package}}.types.fa12_token.tezos_storage import Fa12TokenStorage
+from {{project.package}}.types.quipu_fa12.tezos_parameters.token_to_tez_payment import TokenToTezPaymentParameter
+from {{project.package}}.types.quipu_fa12.tezos_storage import QuipuFa12Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktOperationData
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosOperationData
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_fa12_token_to_tez(
     ctx: HandlerContext,
-    token_to_tez_payment: TzktTransaction[TokenToTezPaymentParameter, QuipuFa12Storage],
-    transfer: TzktTransaction[TransferParameter, Fa12TokenStorage],
-    transaction_0: TzktOperationData,
+    token_to_tez_payment: TezosTransaction[TokenToTezPaymentParameter, QuipuFa12Storage],
+    transfer: TezosTransaction[TransferParameter, Fa12TokenStorage],
+    transaction_0: TezosOperationData,
 ) -> None:
     decimals = int(ctx.template_values['decimals'])
     symbol = ctx.template_values['symbol']
     trader = token_to_tez_payment.data.sender_address
 
     min_tez_quantity = Decimal(token_to_tez_payment.parameter.min_out) / (10**6)
     token_quantity = Decimal(token_to_tez_payment.parameter.amount) / (10**decimals)
@@ -32,8 +32,8 @@
         side=models.TradeSide.SELL,
         quantity=token_quantity,
         price=token_quantity / tez_quantity,
         slippage=(1 - (min_tez_quantity / tez_quantity)).quantize(Decimal('0.000001')),
         level=transfer.data.level,
         timestamp=transfer.data.timestamp,
     )
-    await trade.save()
+    await trade.save()
```

### Comparing `dipdup-7.5.7/src/demo_dex/handlers/on_fa12_transfer.py` & `dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa12_transfer.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-import demo_dex.models as models
-from demo_dex.types.quipu_fa12.tezos_parameters.transfer import TransferParameter
-from demo_dex.types.quipu_fa12.tezos_storage import QuipuFa12Storage
+import demo_tezos_dex.models as models
+from demo_tezos_dex.types.quipu_fa12.tezos_parameters.transfer import TransferParameter
+from demo_tezos_dex.types.quipu_fa12.tezos_storage import QuipuFa12Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_fa12_transfer(
     ctx: HandlerContext,
-    transfer: TzktTransaction[TransferParameter, QuipuFa12Storage],
+    transfer: TezosTransaction[TransferParameter, QuipuFa12Storage],
 ) -> None:
     symbol = ctx.template_values['symbol']
     from_address = transfer.parameter.from_
     to_address = transfer.parameter.to
     value = int(transfer.parameter.value)
 
     from_position, _ = await models.Position.get_or_create(trader=from_address, symbol=symbol)
```

### Comparing `dipdup-7.5.7/src/demo_dex/handlers/on_fa12_withdraw_profit.py` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa2_withdraw_profit.py.j2`

 * *Files 13% similar despite different names*

```diff
@@ -1,24 +1,26 @@
 from decimal import Decimal
+from typing import Optional
 
-import demo_dex.models as models
-from demo_dex.types.quipu_fa12.tezos_parameters.withdraw_profit import WithdrawProfitParameter
-from demo_dex.types.quipu_fa12.tezos_storage import QuipuFa12Storage
+import {{project.package}}.models as models
+from {{project.package}}.types.quipu_fa2.tezos_parameters.withdraw_profit import WithdrawProfitParameter
+from {{project.package}}.types.quipu_fa2.tezos_storage import QuipuFa2Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktOperationData
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosOperationData
+from dipdup.models.tezos import TezosTransaction
 
 
-async def on_fa12_withdraw_profit(
+async def on_fa2_withdraw_profit(
     ctx: HandlerContext,
-    withdraw_profit: TzktTransaction[WithdrawProfitParameter, QuipuFa12Storage],
-    transaction_0: TzktOperationData | None = None,
+    withdraw_profit: TezosTransaction[WithdrawProfitParameter, QuipuFa2Storage],
+    transaction_0: TezosOperationData | None = None,
 ) -> None:
     symbol = ctx.template_values['symbol']
     trader = withdraw_profit.data.sender_address
 
     position, _ = await models.Position.get_or_create(trader=trader, symbol=symbol)
+
     if transaction_0:
         assert transaction_0.amount is not None
         position.realized_pl += Decimal(transaction_0.amount) / (10**6)
 
-        await position.save()
+        await position.save()
```

### Comparing `dipdup-7.5.7/src/demo_dex/handlers/on_fa2_divest_liquidity.py` & `dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa12_divest_liquidity.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,36 +1,36 @@
 from decimal import Decimal
 
-import demo_dex.models as models
-from demo_dex.types.fa2_token.tezos_parameters.transfer import TransferParameter
-from demo_dex.types.fa2_token.tezos_storage import Fa2TokenStorage
-from demo_dex.types.quipu_fa2.tezos_parameters.divest_liquidity import DivestLiquidityParameter
-from demo_dex.types.quipu_fa2.tezos_storage import QuipuFa2Storage
+import demo_tezos_dex.models as models
+from demo_tezos_dex.types.fa12_token.tezos_parameters.transfer import TransferParameter
+from demo_tezos_dex.types.fa12_token.tezos_storage import Fa12TokenStorage
+from demo_tezos_dex.types.quipu_fa12.tezos_parameters.divest_liquidity import DivestLiquidityParameter
+from demo_tezos_dex.types.quipu_fa12.tezos_storage import QuipuFa12Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktOperationData
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosOperationData
+from dipdup.models.tezos import TezosTransaction
 
 
-async def on_fa2_divest_liquidity(
+async def on_fa12_divest_liquidity(
     ctx: HandlerContext,
-    divest_liquidity: TzktTransaction[DivestLiquidityParameter, QuipuFa2Storage],
-    transfer: TzktTransaction[TransferParameter, Fa2TokenStorage],
-    transaction_1: TzktOperationData,
+    divest_liquidity: TezosTransaction[DivestLiquidityParameter, QuipuFa12Storage],
+    transfer: TezosTransaction[TransferParameter, Fa12TokenStorage],
+    transaction_1: TezosOperationData,
 ) -> None:
     storage = divest_liquidity.storage
 
     decimals = int(ctx.template_values['decimals'])
     symbol = ctx.template_values['symbol']
     trader = divest_liquidity.data.sender_address
 
     position, _ = await models.Position.get_or_create(trader=trader, symbol=symbol)
 
     assert transaction_1.amount is not None
     tez_qty = Decimal(transaction_1.amount) / (10**6)
-    token_qty = sum(Decimal(tx.amount) for tx in transfer.parameter.__root__[0].txs) / (10**decimals)
+    token_qty = Decimal(transfer.parameter.value) / (10**decimals)
     shares_qty = int(divest_liquidity.parameter.shares)
 
     tez_pool = Decimal(storage.storage.tez_pool) / (10**6)
     token_pool = Decimal(storage.storage.token_pool) / (10**decimals)
 
     # NOTE: Empty pools mean exchange is not initialized yet
     if not tez_pool and not token_pool:
```

### Comparing `dipdup-7.5.7/src/demo_dex/handlers/on_fa2_invest_liquidity.py` & `dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa2_invest_liquidity.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,36 +1,36 @@
 from decimal import Decimal
 
-import demo_dex.models as models
-from demo_dex.types.fa2_token.tezos_parameters.transfer import TransferParameter
-from demo_dex.types.fa2_token.tezos_storage import Fa2TokenStorage
-from demo_dex.types.quipu_fa2.tezos_parameters.invest_liquidity import InvestLiquidityParameter
-from demo_dex.types.quipu_fa2.tezos_storage import QuipuFa2Storage
+import demo_tezos_dex.models as models
+from demo_tezos_dex.types.fa2_token.tezos_parameters.transfer import TransferParameter
+from demo_tezos_dex.types.fa2_token.tezos_storage import Fa2TokenStorage
+from demo_tezos_dex.types.quipu_fa2.tezos_parameters.invest_liquidity import InvestLiquidityParameter
+from demo_tezos_dex.types.quipu_fa2.tezos_storage import QuipuFa2Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_fa2_invest_liquidity(
     ctx: HandlerContext,
-    invest_liquidity: TzktTransaction[InvestLiquidityParameter, QuipuFa2Storage],
-    transfer: TzktTransaction[TransferParameter, Fa2TokenStorage],
+    invest_liquidity: TezosTransaction[InvestLiquidityParameter, QuipuFa2Storage],
+    transfer: TezosTransaction[TransferParameter, Fa2TokenStorage],
 ) -> None:
     storage = invest_liquidity.storage
 
     decimals = int(ctx.template_values['decimals'])
     symbol = ctx.template_values['symbol']
     trader = invest_liquidity.data.sender_address
 
     assert trader is not None
 
     position, _ = await models.Position.get_or_create(trader=trader, symbol=symbol)
 
     assert invest_liquidity.data.amount is not None
     tez_qty = Decimal(invest_liquidity.data.amount) / (10**6)
-    token_qty = sum(Decimal(tx.amount) for tx in transfer.parameter.__root__[0].txs) / (10**decimals)
+    token_qty = sum(Decimal(tx.amount) for tx in transfer.parameter.root[0].txs) / (10**decimals)
     new_shares_qty = int(storage.storage.ledger[trader].balance) + int(storage.storage.ledger[trader].frozen_balance)
 
     price = (Decimal(storage.storage.tez_pool) / (10**6)) / (Decimal(storage.storage.token_pool) / (10**decimals))
     value = tez_qty + price * token_qty
     share_px = value / (new_shares_qty - position.shares_qty)
     assert share_px > 0, invest_liquidity.data.hash
```

### Comparing `dipdup-7.5.7/src/demo_dex/handlers/on_fa2_origination.py` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa2_origination.py.j2`

 * *Files 20% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-import demo_dex.models as models
-from demo_dex.types.quipu_fa2.tezos_storage import QuipuFa2Storage
+import {{project.package}}.models as models
+from {{project.package}}.types.quipu_fa2.tezos_storage import QuipuFa2Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktOrigination
+from dipdup.models.tezos import TezosOrigination
 
 
 async def on_fa2_origination(
     ctx: HandlerContext,
-    quipu_fa2_origination: TzktOrigination[QuipuFa2Storage],
+    quipu_fa2_origination: TezosOrigination[QuipuFa2Storage],
 ) -> None:
     symbol = ctx.template_values['symbol']
 
     for address, value in quipu_fa2_origination.storage.storage.ledger.items():
         shares_qty = value.balance
-        await models.Position(trader=address, symbol=symbol, shares_qty=shares_qty).save()
+        await models.Position(trader=address, symbol=symbol, shares_qty=shares_qty).save()
```

### Comparing `dipdup-7.5.7/src/demo_dex/handlers/on_fa2_tez_to_token.py` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa2_tez_to_token.py.j2`

 * *Files 24% similar despite different names*

```diff
@@ -1,37 +1,37 @@
 from decimal import Decimal
 
-import demo_dex.models as models
-from demo_dex.types.fa2_token.tezos_parameters.transfer import TransferParameter
-from demo_dex.types.fa2_token.tezos_storage import Fa2TokenStorage
-from demo_dex.types.quipu_fa2.tezos_parameters.tez_to_token_payment import TezToTokenPaymentParameter
-from demo_dex.types.quipu_fa2.tezos_storage import QuipuFa2Storage
+import {{project.package}}.models as models
+from {{project.package}}.types.fa2_token.tezos_parameters.transfer import TransferParameter
+from {{project.package}}.types.fa2_token.tezos_storage import Fa2TokenStorage
+from {{project.package}}.types.quipu_fa2.tezos_parameters.tez_to_token_payment import TezToTokenPaymentParameter
+from {{project.package}}.types.quipu_fa2.tezos_storage import QuipuFa2Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_fa2_tez_to_token(
     ctx: HandlerContext,
-    tez_to_token_payment: TzktTransaction[TezToTokenPaymentParameter, QuipuFa2Storage],
-    transfer: TzktTransaction[TransferParameter, Fa2TokenStorage],
+    tez_to_token_payment: TezosTransaction[TezToTokenPaymentParameter, QuipuFa2Storage],
+    transfer: TezosTransaction[TransferParameter, Fa2TokenStorage],
 ) -> None:
     decimals = int(ctx.template_values['decimals'])
     symbol = ctx.template_values['symbol']
     trader = tez_to_token_payment.data.sender_address
 
     min_token_quantity = Decimal(tez_to_token_payment.parameter.min_out) / (10**decimals)
     assert tez_to_token_payment.data.amount is not None
-    token_quantity = sum(Decimal(tx.amount) for tx in transfer.parameter.__root__[0].txs) / (10**decimals)
+    token_quantity = sum(Decimal(tx.amount) for tx in transfer.parameter.root[0].txs) / (10**decimals)
     tez_quantity = Decimal(tez_to_token_payment.data.amount) / (10**6)
     assert min_token_quantity <= token_quantity, tez_to_token_payment.data.hash
 
     trade = models.Trade(
         symbol=symbol,
         trader=trader,
         side=models.TradeSide.BUY,
         quantity=token_quantity,
         price=token_quantity / tez_quantity,
         slippage=1 - (min_token_quantity / token_quantity),
         level=transfer.data.level,
         timestamp=transfer.data.timestamp,
     )
-    await trade.save()
+    await trade.save()
```

### Comparing `dipdup-7.5.7/src/demo_dex/handlers/on_fa2_token_to_tez.py` & `dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa12_token_to_tez.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,39 +1,39 @@
 from decimal import Decimal
 
-import demo_dex.models as models
-from demo_dex.types.fa2_token.tezos_parameters.transfer import TransferParameter
-from demo_dex.types.fa2_token.tezos_storage import Fa2TokenStorage
-from demo_dex.types.quipu_fa2.tezos_parameters.token_to_tez_payment import TokenToTezPaymentParameter
-from demo_dex.types.quipu_fa2.tezos_storage import QuipuFa2Storage
+import demo_tezos_dex.models as models
+from demo_tezos_dex.types.fa12_token.tezos_parameters.transfer import TransferParameter
+from demo_tezos_dex.types.fa12_token.tezos_storage import Fa12TokenStorage
+from demo_tezos_dex.types.quipu_fa12.tezos_parameters.token_to_tez_payment import TokenToTezPaymentParameter
+from demo_tezos_dex.types.quipu_fa12.tezos_storage import QuipuFa12Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktOperationData
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosOperationData
+from dipdup.models.tezos import TezosTransaction
 
 
-async def on_fa2_token_to_tez(
+async def on_fa12_token_to_tez(
     ctx: HandlerContext,
-    token_to_tez_payment: TzktTransaction[TokenToTezPaymentParameter, QuipuFa2Storage],
-    transfer: TzktTransaction[TransferParameter, Fa2TokenStorage],
-    transaction_0: TzktOperationData,
+    token_to_tez_payment: TezosTransaction[TokenToTezPaymentParameter, QuipuFa12Storage],
+    transfer: TezosTransaction[TransferParameter, Fa12TokenStorage],
+    transaction_0: TezosOperationData,
 ) -> None:
     decimals = int(ctx.template_values['decimals'])
     symbol = ctx.template_values['symbol']
     trader = token_to_tez_payment.data.sender_address
 
-    min_tez_quantity = Decimal(token_to_tez_payment.parameter.min_out) / (10**decimals)
+    min_tez_quantity = Decimal(token_to_tez_payment.parameter.min_out) / (10**6)
     token_quantity = Decimal(token_to_tez_payment.parameter.amount) / (10**decimals)
     assert transaction_0.amount is not None
     tez_quantity = Decimal(transaction_0.amount) / (10**6)
     assert min_tez_quantity <= tez_quantity, token_to_tez_payment.data.hash
 
     trade = models.Trade(
         symbol=symbol,
         trader=trader,
         side=models.TradeSide.SELL,
         quantity=token_quantity,
         price=token_quantity / tez_quantity,
-        slippage=1 - (min_tez_quantity / tez_quantity),
+        slippage=(1 - (min_tez_quantity / tez_quantity)).quantize(Decimal('0.000001')),
         level=transfer.data.level,
         timestamp=transfer.data.timestamp,
     )
     await trade.save()
```

### Comparing `dipdup-7.5.7/src/demo_dex/handlers/on_fa2_transfer.py` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa2_transfer.py.j2`

 * *Files 12% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-import demo_dex.models as models
-from demo_dex.types.quipu_fa2.tezos_parameters.transfer import TransferParameter
-from demo_dex.types.quipu_fa2.tezos_storage import QuipuFa2Storage
+import {{project.package}}.models as models
+from {{project.package}}.types.quipu_fa2.tezos_parameters.transfer import TransferParameter
+from {{project.package}}.types.quipu_fa2.tezos_storage import QuipuFa2Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_fa2_transfer(
     ctx: HandlerContext,
-    transfer: TzktTransaction[TransferParameter, QuipuFa2Storage],
+    transfer: TezosTransaction[TransferParameter, QuipuFa2Storage],
 ) -> None:
-    transfer_parameter = transfer.parameter.__root__[0]
+    transfer_parameter = transfer.parameter.root[0]
 
     symbol = ctx.template_values['symbol']
     from_address = transfer_parameter.from_
     from_position, _ = await models.Position.get_or_create(trader=from_address, symbol=symbol)
 
     for transfer_tx in transfer_parameter.txs:
         to_address = transfer_tx.to_
@@ -23,8 +23,8 @@
         assert from_position.shares_qty >= 0, transfer.data.hash
 
         to_position, _ = await models.Position.get_or_create(trader=to_address, symbol=symbol)
         to_position.shares_qty += value
         assert to_position.shares_qty >= 0, transfer.data.hash
         await to_position.save()
 
-    await from_position.save()
+    await from_position.save()
```

### Comparing `dipdup-7.5.7/src/demo_dex/handlers/on_fa2_withdraw_profit.py` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa12_transfer.py.j2`

 * *Files 22% similar despite different names*

```diff
@@ -1,25 +1,25 @@
-from decimal import Decimal
-
-import demo_dex.models as models
-from demo_dex.types.quipu_fa2.tezos_parameters.withdraw_profit import WithdrawProfitParameter
-from demo_dex.types.quipu_fa2.tezos_storage import QuipuFa2Storage
+import {{project.package}}.models as models
+from {{project.package}}.types.quipu_fa12.tezos_parameters.transfer import TransferParameter
+from {{project.package}}.types.quipu_fa12.tezos_storage import QuipuFa12Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktOperationData
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
-async def on_fa2_withdraw_profit(
+async def on_fa12_transfer(
     ctx: HandlerContext,
-    withdraw_profit: TzktTransaction[WithdrawProfitParameter, QuipuFa2Storage],
-    transaction_0: TzktOperationData | None = None,
+    transfer: TezosTransaction[TransferParameter, QuipuFa12Storage],
 ) -> None:
     symbol = ctx.template_values['symbol']
-    trader = withdraw_profit.data.sender_address
-
-    position, _ = await models.Position.get_or_create(trader=trader, symbol=symbol)
-
-    if transaction_0:
-        assert transaction_0.amount is not None
-        position.realized_pl += Decimal(transaction_0.amount) / (10**6)
-
-        await position.save()
+    from_address = transfer.parameter.from_
+    to_address = transfer.parameter.to
+    value = int(transfer.parameter.value)
+
+    from_position, _ = await models.Position.get_or_create(trader=from_address, symbol=symbol)
+    from_position.shares_qty -= value
+    assert from_position.shares_qty >= 0, transfer.data.hash
+    await from_position.save()
+
+    to_position, _ = await models.Position.get_or_create(trader=to_address, symbol=symbol)
+    to_position.shares_qty += value
+    assert to_position.shares_qty >= 0, transfer.data.hash
+    await to_position.save()
```

### Comparing `dipdup-7.5.7/src/demo_dex/models/__init__.py` & `dipdup-8.0.0a1/src/demo_tezos_dex/models/__init__.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_dex/pyproject.toml` & `dipdup-8.0.0a1/src/demo_evm_events/pyproject.toml`

 * *Files 8% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Generated by DipDup 7.5.7
+# generated by DipDup 8.0.0a1
 [project]
-name = "demo_dex"
+name = "demo_evm_events"
 version = "0.0.1"
-description = "DEX balances and liquidity (Quipuswap)"
+description = "ERC-20 token transfers (from event logs)"
 license = { text = "MIT" }
 authors = [
     { name = "John Doe", email = "john_doe@example.com" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 dependencies = [
-    "dipdup>=7,<8",
+    "dipdup>=8,<9",
 ]
 
 [tool.pdm.dev-dependencies]
 dev = [
     "black",
     "ruff",
     "mypy",
@@ -30,27 +30,27 @@
 mypy = {cmd = "make mypy", help = "Lint with mypy"}
 image = {cmd = "make image", help = "Build Docker image"}
 up = {cmd = "make up", help = "Run Compose stack"}
 down = {cmd = "make down", help = "Stop Compose stack"}
 
 [tool.black]
 line-length = 120
-target-version = ['py311']
+target-version = ['py312']
 skip-string-normalization = true
 
 [tool.ruff]
 line-length = 120
-target-version = 'py311'
+target-version = 'py312'
 
 [tool.ruff.lint]
 extend-select = ["B", "C4", "FA", "G", "I", "PTH", "Q", "RET", "RUF", "TCH", "UP"]
 flake8-quotes = { inline-quotes = "single", multiline-quotes = "double" }
 isort = { force-single-line = true}
 
 [tool.mypy]
-python_version = "3.11"
+python_version = "3.12"
 plugins = ["pydantic.mypy"]
 strict = false
 
 [build-system]
 requires = ["pdm-backend"]
 build-backend = "pdm.backend"
```

### Comparing `dipdup-7.5.7/src/demo_dex/types/quipu_fa12/tezos_storage.py` & `dipdup-8.0.0a1/src/demo_tezos_dex/types/quipu_fa12/tezos_storage.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,50 +1,49 @@
-# generated by datamodel-codegen:
-#   filename:  tezos_storage.json
+# generated by DipDup 8.0.0a1
 
 from __future__ import annotations
 
 from pydantic import BaseModel
-from pydantic import Extra
+from pydantic import ConfigDict
 
 
 class Ledger(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
+    model_config = ConfigDict(
+        extra='forbid',
+    )
     allowances: dict[str, str]
     balance: str
     frozen_balance: str
 
 
 class UserRewards(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
+    model_config = ConfigDict(
+        extra='forbid',
+    )
     reward: str
     reward_paid: str
 
 
 class Voters(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
-    candidate: str | None
+    model_config = ConfigDict(
+        extra='forbid',
+    )
+    candidate: str | None = None
     last_veto: str
     veto: str
     vote: str
 
 
 class Storage(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
+    model_config = ConfigDict(
+        extra='forbid',
+    )
     baker_validator: str
-    current_candidate: str | None
-    current_delegated: str | None
+    current_candidate: str | None = None
+    current_delegated: str | None = None
     last_update_time: str
     last_veto: str
     ledger: dict[str, Ledger]
     period_finish: str
     reward: str
     reward_paid: str
     reward_per_sec: str
@@ -59,14 +58,14 @@
     veto: str
     vetos: dict[str, str]
     voters: dict[str, Voters]
     votes: dict[str, str]
 
 
 class QuipuFa12Storage(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
+    model_config = ConfigDict(
+        extra='forbid',
+    )
     dex_lambdas: dict[str, str]
     metadata: dict[str, str]
     storage: Storage
     token_lambdas: dict[str, str]
```

### Comparing `dipdup-7.5.7/src/demo_dex/types/quipu_fa2/tezos_storage.py` & `dipdup-8.0.0a1/src/demo_tezos_dex/types/quipu_fa2/tezos_storage.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,50 +1,49 @@
-# generated by datamodel-codegen:
-#   filename:  tezos_storage.json
+# generated by DipDup 8.0.0a1
 
 from __future__ import annotations
 
 from pydantic import BaseModel
-from pydantic import Extra
+from pydantic import ConfigDict
 
 
 class Ledger(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
+    model_config = ConfigDict(
+        extra='forbid',
+    )
     allowances: list[str]
     balance: str
     frozen_balance: str
 
 
 class UserRewards(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
+    model_config = ConfigDict(
+        extra='forbid',
+    )
     reward: str
     reward_paid: str
 
 
 class Voters(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
-    candidate: str | None
+    model_config = ConfigDict(
+        extra='forbid',
+    )
+    candidate: str | None = None
     last_veto: str
     veto: str
     vote: str
 
 
 class Storage(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
+    model_config = ConfigDict(
+        extra='forbid',
+    )
     baker_validator: str
-    current_candidate: str | None
-    current_delegated: str | None
+    current_candidate: str | None = None
+    current_delegated: str | None = None
     last_update_time: str
     last_veto: str
     ledger: dict[str, Ledger]
     period_finish: str
     reward: str
     reward_paid: str
     reward_per_sec: str
@@ -60,14 +59,14 @@
     veto: str
     vetos: dict[str, str]
     voters: dict[str, Voters]
     votes: dict[str, str]
 
 
 class QuipuFa2Storage(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
+    model_config = ConfigDict(
+        extra='forbid',
+    )
     dex_lambdas: dict[str, str]
     metadata: dict[str, str]
     storage: Storage
     token_lambdas: dict[str, str]
```

### Comparing `dipdup-7.5.7/src/demo_domains/Makefile` & `dipdup-8.0.0a1/src/demo_tezos_domains/Makefile`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 .PHONY: $(MAKECMDGOALS)
 MAKEFLAGS += --no-print-directory
 ##
 ##   DipDup developer tools
 ##
-PACKAGE=demo_domains
+PACKAGE=demo_tezos_domains
 TAG=latest
 COMPOSE=deploy/compose.yaml
 
 help:           ## Show this help (default)
 	@grep -Fh "##" $(MAKEFILE_LIST) | grep -Fv grep -F | sed -e 's/\\$$//' | sed -e 's/##//'
 
 all:            ## Run an entire CI pipeline
```

### Comparing `dipdup-7.5.7/src/demo_domains/README.md` & `dipdup-8.0.0a1/src/demo_tezos_raw/README.md`

 * *Files 7% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# demo_domains
+# demo_tezos_raw
 
-Domain name service (Tezos Domains)
+Process raw operations without filtering and typed payloads
 
 ## Installation
 
 This project is based on [DipDup](https://dipdup.io), a framework for building featureful dapps.
 
-You need a Linux/macOS system with Python 3.11 installed. To install DipDup with pipx for the current user:
+You need a Linux/macOS system with Python 3.12 installed. To install DipDup with pipx or use our installer:
 
 ```shell
-curl -Lsf https://dipdup.io/install.py | python3
+curl -Lsf https://dipdup.io/install.py | python3.12
 ```
 
 See the [Installation](https://dipdup.io/docs/installation) page for all options.
 
 ## Usage
 
 Run the indexer in memory:
```

### Comparing `dipdup-7.5.7/src/demo_domains/configs/dipdup.compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_big_maps/configs/dipdup.compose.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_domains/configs/dipdup.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_domains/configs/dipdup.swarm.yaml`

 * *Files 14% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 database:
   kind: postgres
-  host: ${POSTGRES_HOST:-demo_domains_db}
+  host: ${POSTGRES_HOST:-demo_tezos_domains_db}
   port: 5432
   user: ${POSTGRES_USER:-dipdup}
   password: ${POSTGRES_PASSWORD}
   database: ${POSTGRES_DB:-dipdup}
 
 hasura:
-  url: http://${HASURA_HOST:-demo_domains_hasura}:8080
+  url: http://${HASURA_HOST:-demo_tezos_domains_hasura}:8080
   admin_secret: ${HASURA_SECRET}
   allow_aggregations: ${HASURA_ALLOW_AGGREGATIONS:-false}
   select_limit: ${HASURA_SELECT_LIMIT:-100}
   camel_case: ${HASURA_CAMEL_CASE:-true}
 
 sentry:
   dsn: ${SENTRY_DSN:-''}
```

### Comparing `dipdup-7.5.7/src/demo_domains/configs/replay.yaml` & `dipdup-8.0.0a1/src/demo_evm_events/configs/replay.yaml`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 # To refresh existing project run `dipdup init --base --force` after modifying this file.
 # To generate a new project from this replay run `dipdup new --replay <path_to_file>`.
 #
-spec_version: 2.0
+spec_version: 3.0
 replay:
-  dipdup_version: 7
-  template: demo_domains
-  package: demo_domains
+  dipdup_version: 8
+  template: demo_evm_events
+  package: demo_evm_events
   version: 0.0.1
-  description: Domain name service (Tezos Domains)
+  description: ERC-20 token transfers (from event logs)
   license: MIT
   name: John Doe
   email: john_doe@example.com
   postgres_image: postgres:15
   postgres_data_path: /var/lib/postgresql/data
   hasura_image: hasura/graphql-engine:latest
   line_length: 120
```

### Comparing `dipdup-7.5.7/src/demo_domains/deploy/compose.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_etherlink/deploy/compose.swarm.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 version: "3.8"
-name: demo_domains
+name: demo_tezos_etherlink
 
 services:
   dipdup:
-    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-7}
+    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-8}
     depends_on:
       - db
       - hasura
     command: ["-c", "dipdup.yaml", "-c", "configs/dipdup.swarm.yaml", "run"]
     env_file: .env
     networks:
       - internal
@@ -51,15 +51,15 @@
     logging: *logging
 
   hasura:
     image: hasura/graphql-engine:latest
     depends_on:
       - db
     environment:
-      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_domains_db:5432/dipdup
+      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_tezos_etherlink_db:5432/dipdup
       - HASURA_GRAPHQL_ADMIN_SECRET=${HASURA_SECRET}
       - HASURA_GRAPHQL_ENABLE_CONSOLE=true
       - HASURA_GRAPHQL_DEV_MODE=false
       - HASURA_GRAPHQL_LOG_LEVEL=warn
       - HASURA_GRAPHQL_ENABLE_TELEMETRY=false
       - HASURA_GRAPHQL_UNAUTHORIZED_ROLE=user
       - HASURA_GRAPHQL_STRINGIFY_NUMERIC_TYPES=true
```

### Comparing `dipdup-7.5.7/src/demo_domains/deploy/compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_domains/deploy/compose.yaml`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 version: "3.8"
-name: demo_domains
+name: demo_tezos_domains
 
 services:
   dipdup:
     build:
       context: ..
       dockerfile: deploy/Dockerfile
     restart: always
```

### Comparing `dipdup-7.5.7/src/demo_domains/dipdup.yaml` & `dipdup-8.0.0a1/src/demo_tezos_domains/dipdup.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -1,25 +1,26 @@
-spec_version: 2.0
-package: demo_domains
+spec_version: 3.0
+package: demo_tezos_domains
 
 contracts:
   mainnet_name_registry:
     kind: tezos
     address: KT1GBZmSxmnKJXGMdMLbugPfLyUPmuLSMwKS
     typename: name_registry
 
 datasources:
   mainnet:
     kind: tezos.tzkt
     url: ${TZKT_URL:-https://api.tzkt.io}
 
 templates:
   tezos_domains_big_map:
-    kind: tezos.tzkt.big_maps
-    datasource: <datasource>
+    kind: tezos.big_maps
+    datasources:
+      - <datasource>
     handlers:
       - callback: on_update_records
         contract: <name_registry>
         path: store.records
       - callback: on_update_expiry_map
         contract: <name_registry>
         path: store.expiry_map
```

### Comparing `dipdup-7.5.7/src/demo_domains/handlers/on_update_expiry_map.py` & `dipdup-8.0.0a1/src/demo_tezos_domains/handlers/on_update_expiry_map.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,31 +1,30 @@
 from datetime import datetime
 from typing import Any
 from typing import cast
 
 import strict_rfc3339  # type: ignore[import-untyped]
-from demo_domains import models as models
-from demo_domains.types.name_registry.tezos_big_maps.store_expiry_map_key import StoreExpiryMapKey
-from demo_domains.types.name_registry.tezos_big_maps.store_expiry_map_value import StoreExpiryMapValue
+from demo_tezos_domains import models as models
+from demo_tezos_domains.types.name_registry.tezos_big_maps.store_expiry_map_key import StoreExpiryMapKey
+from demo_tezos_domains.types.name_registry.tezos_big_maps.store_expiry_map_value import StoreExpiryMapValue
 from dipdup.context import HandlerContext
-from dipdup.datasources.tezos_tzkt import TzktDatasource
-from dipdup.models.tezos_tzkt import TzktBigMapDiff
+from dipdup.models.tezos import TezosBigMapDiff
 
 
 async def on_update_expiry_map(
     ctx: HandlerContext,
-    store_expiry_map: TzktBigMapDiff[StoreExpiryMapKey, StoreExpiryMapValue],
+    store_expiry_map: TezosBigMapDiff[StoreExpiryMapKey, StoreExpiryMapValue],
 ) -> None:
     if not store_expiry_map.action.has_value:
         return
     assert store_expiry_map.key
     assert store_expiry_map.value
 
-    expires_at = datetime.utcfromtimestamp(strict_rfc3339.rfc3339_to_timestamp(store_expiry_map.value.__root__))
-    record_name = bytes.fromhex(store_expiry_map.key.__root__).decode()
+    expires_at = datetime.utcfromtimestamp(strict_rfc3339.rfc3339_to_timestamp(store_expiry_map.value.root))
+    record_name = bytes.fromhex(store_expiry_map.key.root).decode()
     await models.Expiry.update_or_create(
         id=record_name,
         defaults={'expires_at': expires_at},
     )
 
     domain = await models.Domain.get_or_none(id=record_name).prefetch_related('records')
     if domain is None:
@@ -41,11 +40,11 @@
     for record in domain.records:
         record.expired = False
         await record.save()
         if record.address is not None:
             metadata = {} if record.metadata is None else cast(dict[str, Any], record.metadata)
             metadata.update(name=record.id)
             await ctx.update_contract_metadata(
-                network=cast(TzktDatasource, ctx.datasource).name,
+                network=ctx.handler_config.parent.datasources[0].name,  # type: ignore[union-attr]
                 address=record.address,
                 metadata=metadata,
             )
```

### Comparing `dipdup-7.5.7/src/demo_domains/handlers/on_update_records.py` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_domains/handlers/on_update_records.py.j2`

 * *Files 6% similar despite different names*

```diff
@@ -1,38 +1,39 @@
 from contextlib import suppress
 from typing import cast
 
 import orjson
-from demo_domains import models as models
-from demo_domains.types.name_registry.tezos_big_maps.store_records_key import StoreRecordsKey
-from demo_domains.types.name_registry.tezos_big_maps.store_records_value import StoreRecordsValue
 from dipdup.context import HandlerContext
-from dipdup.datasources.tezos_tzkt import TzktDatasource
-from dipdup.models.tezos_tzkt import TzktBigMapDiff
+from dipdup.datasources.tezos_tzkt import TezosTzktDatasource
+from dipdup.models.tezos import TezosBigMapDiff
+
+from {{ project.package }} import models as models
+from {{ project.package }}.types.name_registry.tezos_big_maps.store_records_key import StoreRecordsKey
+from {{ project.package }}.types.name_registry.tezos_big_maps.store_records_value import StoreRecordsValue
 
 
 def decode_domain_data(data: dict[str, str]) -> dict[str, str]:
     res = {}
     if isinstance(data, dict):
         for k, v in data.items():
             with suppress(ValueError, orjson.JSONDecodeError):
                 res[k] = orjson.loads(bytes.fromhex(v).decode())
     return res
 
 
 async def on_update_records(
     ctx: HandlerContext,
-    store_records: TzktBigMapDiff[StoreRecordsKey, StoreRecordsValue],
+    store_records: TezosBigMapDiff[StoreRecordsKey, StoreRecordsValue],
 ) -> None:
     if not store_records.action.has_value:
         return
     assert store_records.key
     assert store_records.value
 
-    record_name = bytes.fromhex(store_records.key.__root__).decode()
+    record_name = bytes.fromhex(store_records.key.root).decode()
     record_path = record_name.split('.')
     domain_data = decode_domain_data(store_records.value.data)
     ctx.logger.info('Processing `%s`', record_name)
 
     if len(record_path) != int(store_records.value.level):
         ctx.logger.warning(
             'Invalid record `%s`: expected %s chunks, got %s',
@@ -51,15 +52,15 @@
         )
         return
 
     if store_records.value.level == '2':
         token_id = store_records.value.tzip12_token_id
         if token_id:
             await ctx.update_token_metadata(
-                network=cast(TzktDatasource, ctx.datasource).name,
+                network=ctx.handler_config.parent.datasources[0].name,  # type: ignore[union-attr]
                 address=store_records.data.contract_address,
                 token_id=token_id,
                 metadata={
                     'name': record_name,
                     'symbol': 'TD',
                     'decimals': '0',
                     'isBooleanAmount': True,
@@ -88,11 +89,11 @@
             'expired': False,
             'metadata': domain_data,
         },
     )
 
     if store_records.value.address is not None:
         await ctx.update_contract_metadata(
-            network=cast(TzktDatasource, ctx.datasource).name,
+            network=ctx.handler_config.parent.datasources[0].name,  # type: ignore[union-attr]
             address=store_records.value.address,
             metadata={**domain_data, 'name': record_name},
         )
```

### Comparing `dipdup-7.5.7/src/demo_domains/hooks/check_expiration.py` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_domains/hooks/check_expiration.py.j2`

 * *Files 9% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from datetime import datetime
 from typing import cast
 
-from demo_domains.models import Record
+from {{ project.package }}.models import Record
 from dipdup.context import HookContext
-from dipdup.datasources.tezos_tzkt import TzktDatasource
+from dipdup.datasources.tezos_tzkt import TezosTzktDatasource
 
 
 async def check_expiration(
     ctx: HookContext,
 ) -> None:
-    ds = cast(TzktDatasource, next(iter(ctx.datasources.values())))
+    ds = cast(TezosTzktDatasource, next(iter(ctx.datasources.values())))
     expiring_records = (
         await Record.filter(expired=False, domain__expires_at__lt=datetime.utcnow()).all().prefetch_related('domain')
     )
 
     for record in expiring_records:
         ctx.logger.info('Record %s expired at %s', record.id, record.domain.expires_at)
         record.expired = True
```

### Comparing `dipdup-7.5.7/src/demo_domains/models/__init__.py` & `dipdup-8.0.0a1/src/demo_tezos_domains/models/__init__.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_domains/pyproject.toml` & `dipdup-8.0.0a1/src/demo_tezos_domains/pyproject.toml`

 * *Files 6% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Generated by DipDup 7.5.7
+# generated by DipDup 8.0.0a1
 [project]
-name = "demo_domains"
+name = "demo_tezos_domains"
 version = "0.0.1"
 description = "Domain name service (Tezos Domains)"
 license = { text = "MIT" }
 authors = [
     { name = "John Doe", email = "john_doe@example.com" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 dependencies = [
-    "dipdup>=7,<8",
+    "dipdup>=8,<9",
 ]
 
 [tool.pdm.dev-dependencies]
 dev = [
     "black",
     "ruff",
     "mypy",
@@ -30,27 +30,27 @@
 mypy = {cmd = "make mypy", help = "Lint with mypy"}
 image = {cmd = "make image", help = "Build Docker image"}
 up = {cmd = "make up", help = "Run Compose stack"}
 down = {cmd = "make down", help = "Stop Compose stack"}
 
 [tool.black]
 line-length = 120
-target-version = ['py311']
+target-version = ['py312']
 skip-string-normalization = true
 
 [tool.ruff]
 line-length = 120
-target-version = 'py311'
+target-version = 'py312'
 
 [tool.ruff.lint]
 extend-select = ["B", "C4", "FA", "G", "I", "PTH", "Q", "RET", "RUF", "TCH", "UP"]
 flake8-quotes = { inline-quotes = "single", multiline-quotes = "double" }
 isort = { force-single-line = true}
 
 [tool.mypy]
-python_version = "3.11"
+python_version = "3.12"
 plugins = ["pydantic.mypy"]
 strict = false
 
 [build-system]
 requires = ["pdm-backend"]
 build-backend = "pdm.backend"
```

### Comparing `dipdup-7.5.7/src/demo_etherlink/Makefile` & `dipdup-8.0.0a1/src/demo_evm_uniswap/Makefile`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 .PHONY: $(MAKECMDGOALS)
 MAKEFLAGS += --no-print-directory
 ##
 ##   DipDup developer tools
 ##
-PACKAGE=demo_etherlink
+PACKAGE=demo_evm_uniswap
 TAG=latest
 COMPOSE=deploy/compose.yaml
 
 help:           ## Show this help (default)
 	@grep -Fh "##" $(MAKEFILE_LIST) | grep -Fv grep -F | sed -e 's/\\$$//' | sed -e 's/##//'
 
 all:            ## Run an entire CI pipeline
```

### Comparing `dipdup-7.5.7/src/demo_etherlink/README.md` & `dipdup-8.0.0a1/src/demo_tezos_etherlink/README.md`

 * *Files 6% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# demo_etherlink
+# demo_tezos_etherlink
 
 Etherlink smart rollup transactions
 
 ## Installation
 
 This project is based on [DipDup](https://dipdup.io), a framework for building featureful dapps.
 
-You need a Linux/macOS system with Python 3.11 installed. To install DipDup with pipx for the current user:
+You need a Linux/macOS system with Python 3.12 installed. To install DipDup with pipx or use our installer:
 
 ```shell
-curl -Lsf https://dipdup.io/install.py | python3
+curl -Lsf https://dipdup.io/install.py | python3.12
 ```
 
 See the [Installation](https://dipdup.io/docs/installation) page for all options.
 
 ## Usage
 
 Run the indexer in memory:
```

### Comparing `dipdup-7.5.7/src/demo_etherlink/configs/dipdup.compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_dao/configs/dipdup.compose.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_etherlink/configs/dipdup.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_etherlink/configs/dipdup.swarm.yaml`

 * *Files 16% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 database:
   kind: postgres
-  host: ${POSTGRES_HOST:-demo_etherlink_db}
+  host: ${POSTGRES_HOST:-demo_tezos_etherlink_db}
   port: 5432
   user: ${POSTGRES_USER:-dipdup}
   password: ${POSTGRES_PASSWORD}
   database: ${POSTGRES_DB:-dipdup}
 
 hasura:
-  url: http://${HASURA_HOST:-demo_etherlink_hasura}:8080
+  url: http://${HASURA_HOST:-demo_tezos_etherlink_hasura}:8080
   admin_secret: ${HASURA_SECRET}
   allow_aggregations: ${HASURA_ALLOW_AGGREGATIONS:-false}
   select_limit: ${HASURA_SELECT_LIMIT:-100}
   camel_case: ${HASURA_CAMEL_CASE:-true}
 
 sentry:
   dsn: ${SENTRY_DSN:-''}
```

### Comparing `dipdup-7.5.7/src/demo_etherlink/configs/replay.yaml` & `dipdup-8.0.0a1/src/demo_tezos_etherlink/configs/replay.yaml`

 * *Files 6% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # To refresh existing project run `dipdup init --base --force` after modifying this file.
 # To generate a new project from this replay run `dipdup new --replay <path_to_file>`.
 #
-spec_version: 2.0
+spec_version: 3.0
 replay:
-  dipdup_version: 7
-  template: demo_etherlink
-  package: demo_etherlink
+  dipdup_version: 8
+  template: demo_tezos_etherlink
+  package: demo_tezos_etherlink
   version: 0.0.1
   description: Etherlink smart rollup transactions
   license: MIT
   name: John Doe
   email: john_doe@example.com
   postgres_image: postgres:15
   postgres_data_path: /var/lib/postgresql/data
```

### Comparing `dipdup-7.5.7/src/demo_etherlink/deploy/compose.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/deploy/compose.swarm.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 version: "3.8"
-name: demo_etherlink
+name: demo_tezos_nft_marketplace
 
 services:
   dipdup:
-    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-7}
+    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-8}
     depends_on:
       - db
       - hasura
     command: ["-c", "dipdup.yaml", "-c", "configs/dipdup.swarm.yaml", "run"]
     env_file: .env
     networks:
       - internal
@@ -51,15 +51,15 @@
     logging: *logging
 
   hasura:
     image: hasura/graphql-engine:latest
     depends_on:
       - db
     environment:
-      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_etherlink_db:5432/dipdup
+      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_tezos_nft_marketplace_db:5432/dipdup
       - HASURA_GRAPHQL_ADMIN_SECRET=${HASURA_SECRET}
       - HASURA_GRAPHQL_ENABLE_CONSOLE=true
       - HASURA_GRAPHQL_DEV_MODE=false
       - HASURA_GRAPHQL_LOG_LEVEL=warn
       - HASURA_GRAPHQL_ENABLE_TELEMETRY=false
       - HASURA_GRAPHQL_UNAUTHORIZED_ROLE=user
       - HASURA_GRAPHQL_STRINGIFY_NUMERIC_TYPES=true
```

### Comparing `dipdup-7.5.7/src/demo_etherlink/deploy/compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_head/deploy/compose.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 version: "3.8"
-name: demo_etherlink
+name: demo_tezos_head
 
 services:
   dipdup:
     build:
       context: ..
       dockerfile: deploy/Dockerfile
     restart: always
```

### Comparing `dipdup-7.5.7/src/demo_etherlink/dipdup.yaml` & `dipdup-8.0.0a1/src/demo_tezos_etherlink/dipdup.yaml`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-spec_version: 2.0
-package: demo_etherlink
+spec_version: 3.0
+package: demo_tezos_etherlink
 
 datasources:
   tzkt:
     kind: tezos.tzkt
     url: ${TZKT_URL:-https://api.nairobinet.tzkt.io}
 
 contracts:
@@ -18,16 +18,17 @@
   rollup:
     kind: tezos
     address: sr1QgYF6ARMSLcWyAX4wFDrWFaZTyy4twbqe
     typename: rollup
 
 indexes:
   rollup_operations:
-    kind: tezos.tzkt.operations
-    datasource: tzkt
+    kind: tezos.operations
+    datasources:
+      - tzkt
     contracts:
       - ticketer
       - ticket_helper
       - rollup
     types:
       - transaction
       - sr_execute
```

### Comparing `dipdup-7.5.7/src/demo_etherlink/handlers/on_withdraw.py` & `dipdup-8.0.0a1/src/demo_tezos_etherlink/handlers/on_withdraw.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,15 +1,16 @@
-from demo_etherlink.types.ticketer.tezos_parameters.withdraw import WithdrawParameter
-from demo_etherlink.types.ticketer.tezos_storage import TicketerStorage
+from demo_tezos_etherlink import models as models
+from demo_tezos_etherlink.types.ticketer.tezos_parameters.withdraw import WithdrawParameter
+from demo_tezos_etherlink.types.ticketer.tezos_storage import TicketerStorage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktOperationData
-from dipdup.models.tezos_tzkt import TzktSmartRollupExecute
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosOperationData
+from dipdup.models.tezos import TezosSmartRollupExecute
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_withdraw(
     ctx: HandlerContext,
-    sr_execute_0: TzktSmartRollupExecute,
-    withdraw: TzktTransaction[WithdrawParameter, TicketerStorage],
-    transaction_2: TzktOperationData,
+    sr_execute_0: TezosSmartRollupExecute,
+    withdraw: TezosTransaction[WithdrawParameter, TicketerStorage],
+    transaction_2: TezosOperationData,
 ) -> None:
     ...
```

### Comparing `dipdup-7.5.7/src/demo_etherlink/models/__init__.py` & `dipdup-8.0.0a1/src/demo_tezos_etherlink/models/__init__.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_etherlink/pyproject.toml` & `dipdup-8.0.0a1/src/demo_evm_transactions/pyproject.toml`

 * *Files 5% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Generated by DipDup 7.5.7
+# generated by DipDup 8.0.0a1
 [project]
-name = "demo_etherlink"
+name = "demo_evm_transactions"
 version = "0.0.1"
-description = "Etherlink smart rollup transactions"
+description = "ERC-20 token transfers (from transactions)"
 license = { text = "MIT" }
 authors = [
     { name = "John Doe", email = "john_doe@example.com" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 dependencies = [
-    "dipdup>=7,<8",
+    "dipdup>=8,<9",
 ]
 
 [tool.pdm.dev-dependencies]
 dev = [
     "black",
     "ruff",
     "mypy",
@@ -30,27 +30,27 @@
 mypy = {cmd = "make mypy", help = "Lint with mypy"}
 image = {cmd = "make image", help = "Build Docker image"}
 up = {cmd = "make up", help = "Run Compose stack"}
 down = {cmd = "make down", help = "Stop Compose stack"}
 
 [tool.black]
 line-length = 120
-target-version = ['py311']
+target-version = ['py312']
 skip-string-normalization = true
 
 [tool.ruff]
 line-length = 120
-target-version = 'py311'
+target-version = 'py312'
 
 [tool.ruff.lint]
 extend-select = ["B", "C4", "FA", "G", "I", "PTH", "Q", "RET", "RUF", "TCH", "UP"]
 flake8-quotes = { inline-quotes = "single", multiline-quotes = "double" }
 isort = { force-single-line = true}
 
 [tool.mypy]
-python_version = "3.11"
+python_version = "3.12"
 plugins = ["pydantic.mypy"]
 strict = false
 
 [build-system]
 requires = ["pdm-backend"]
 build-backend = "pdm.backend"
```

### Comparing `dipdup-7.5.7/src/demo_etherlink/types/rollup/tezos_parameters/default.py` & `dipdup-8.0.0a1/src/demo_tezos_etherlink/types/rollup/tezos_parameters/default.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,57 +1,57 @@
-# generated by datamodel-codegen:
-#   filename:  default.json
+# generated by DipDup 8.0.0a1
 
 from __future__ import annotations
 
 from pydantic import BaseModel
-from pydantic import Extra
+from pydantic import ConfigDict
+from pydantic import RootModel
 
 
 class Data(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
+    model_config = ConfigDict(
+        extra='forbid',
+    )
     nat: str
-    bytes: str | None
+    bytes: str | None = None
 
 
 class Ticket(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
+    model_config = ConfigDict(
+        extra='forbid',
+    )
     address: str
     data: Data
     amount: str
 
 
 class LL(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
+    model_config = ConfigDict(
+        extra='forbid',
+    )
     bytes: str
     ticket: Ticket
 
 
 class DefaultParameter1(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
+    model_config = ConfigDict(
+        extra='forbid',
+    )
     LL: LL
 
 
 class DefaultParameter2(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
+    model_config = ConfigDict(
+        extra='forbid',
+    )
     LR: str
 
 
 class DefaultParameter3(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
+    model_config = ConfigDict(
+        extra='forbid',
+    )
     R: str
 
 
-class DefaultParameter(BaseModel):
-    __root__: DefaultParameter1 | DefaultParameter2 | DefaultParameter3
+class DefaultParameter(RootModel[DefaultParameter1 | DefaultParameter2 | DefaultParameter3]):
+    root: DefaultParameter1 | DefaultParameter2 | DefaultParameter3
```

### Comparing `dipdup-7.5.7/src/demo_events/Makefile` & `dipdup-8.0.0a1/src/demo_evm_events/Makefile`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 .PHONY: $(MAKECMDGOALS)
 MAKEFLAGS += --no-print-directory
 ##
 ##   DipDup developer tools
 ##
-PACKAGE=demo_events
+PACKAGE=demo_evm_events
 TAG=latest
 COMPOSE=deploy/compose.yaml
 
 help:           ## Show this help (default)
 	@grep -Fh "##" $(MAKEFILE_LIST) | grep -Fv grep -F | sed -e 's/\\$$//' | sed -e 's/##//'
 
 all:            ## Run an entire CI pipeline
```

### Comparing `dipdup-7.5.7/src/demo_events/README.md` & `dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/README.md`

 * *Files 13% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# demo_events
+# demo_tezos_nft_marketplace
 
-Processing contract events
+NFT marketplace (hic at nunc)
 
 ## Installation
 
 This project is based on [DipDup](https://dipdup.io), a framework for building featureful dapps.
 
-You need a Linux/macOS system with Python 3.11 installed. To install DipDup with pipx for the current user:
+You need a Linux/macOS system with Python 3.12 installed. To install DipDup with pipx or use our installer:
 
 ```shell
-curl -Lsf https://dipdup.io/install.py | python3
+curl -Lsf https://dipdup.io/install.py | python3.12
 ```
 
 See the [Installation](https://dipdup.io/docs/installation) page for all options.
 
 ## Usage
 
 Run the indexer in memory:
```

### Comparing `dipdup-7.5.7/src/demo_events/configs/dipdup.compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_dex/configs/dipdup.compose.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_events/configs/dipdup.swarm.yaml` & `dipdup-8.0.0a1/src/demo_evm_transactions/configs/dipdup.swarm.yaml`

 * *Files 15% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 database:
   kind: postgres
-  host: ${POSTGRES_HOST:-demo_events_db}
+  host: ${POSTGRES_HOST:-demo_evm_transactions_db}
   port: 5432
   user: ${POSTGRES_USER:-dipdup}
   password: ${POSTGRES_PASSWORD}
   database: ${POSTGRES_DB:-dipdup}
 
 hasura:
-  url: http://${HASURA_HOST:-demo_events_hasura}:8080
+  url: http://${HASURA_HOST:-demo_evm_transactions_hasura}:8080
   admin_secret: ${HASURA_SECRET}
   allow_aggregations: ${HASURA_ALLOW_AGGREGATIONS:-false}
   select_limit: ${HASURA_SELECT_LIMIT:-100}
   camel_case: ${HASURA_CAMEL_CASE:-true}
 
 sentry:
   dsn: ${SENTRY_DSN:-''}
```

### Comparing `dipdup-7.5.7/src/demo_events/deploy/compose.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_head/deploy/compose.swarm.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 version: "3.8"
-name: demo_events
+name: demo_tezos_head
 
 services:
   dipdup:
-    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-7}
+    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-8}
     depends_on:
       - db
       - hasura
     command: ["-c", "dipdup.yaml", "-c", "configs/dipdup.swarm.yaml", "run"]
     env_file: .env
     networks:
       - internal
@@ -51,15 +51,15 @@
     logging: *logging
 
   hasura:
     image: hasura/graphql-engine:latest
     depends_on:
       - db
     environment:
-      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_events_db:5432/dipdup
+      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_tezos_head_db:5432/dipdup
       - HASURA_GRAPHQL_ADMIN_SECRET=${HASURA_SECRET}
       - HASURA_GRAPHQL_ENABLE_CONSOLE=true
       - HASURA_GRAPHQL_DEV_MODE=false
       - HASURA_GRAPHQL_LOG_LEVEL=warn
       - HASURA_GRAPHQL_ENABLE_TELEMETRY=false
       - HASURA_GRAPHQL_UNAUTHORIZED_ROLE=user
       - HASURA_GRAPHQL_STRINGIFY_NUMERIC_TYPES=true
```

### Comparing `dipdup-7.5.7/src/demo_events/deploy/compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_token_balances/deploy/compose.yaml`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 version: "3.8"
-name: demo_events
+name: demo_tezos_token_balances
 
 services:
   dipdup:
     build:
       context: ..
       dockerfile: deploy/Dockerfile
     restart: always
```

### Comparing `dipdup-7.5.7/src/demo_events/dipdup.yaml` & `dipdup-8.0.0a1/src/demo_tezos_events/dipdup.yaml`

 * *Files 10% similar despite different names*

```diff
@@ -1,24 +1,25 @@
-spec_version: 2.0
-package: demo_events
+spec_version: 3.0
+package: demo_tezos_events
 
 datasources:
   tzkt:
     kind: tezos.tzkt
     url: https://api.ghostnet.tzkt.io
 
 contracts:
   events_contract:
     kind: tezos
     address: KT1Up6AMehze2VTdt3w85xaZPtrEWn1AeyR3
 
 indexes:
   events:
-    kind: tezos.tzkt.events
-    datasource: tzkt
+    kind: tezos.events
+    datasources:
+      - tzkt
     handlers:
       - callback: on_move_event
         contract: events_contract
         tag: move
       - callback: on_roll_event
         contract: events_contract
         tag: roll
```

### Comparing `dipdup-7.5.7/src/demo_events/models/__init__.py` & `dipdup-8.0.0a1/src/demo_tezos_events/models/__init__.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_events/pyproject.toml` & `dipdup-8.0.0a1/src/demo_blank/pyproject.toml`

 * *Files 7% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Generated by DipDup 7.5.7
+# generated by DipDup 8.0.0a1
 [project]
-name = "demo_events"
+name = "demo_blank"
 version = "0.0.1"
-description = "Processing contract events"
+description = "Empty config for a fresh start"
 license = { text = "MIT" }
 authors = [
     { name = "John Doe", email = "john_doe@example.com" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 dependencies = [
-    "dipdup>=7,<8",
+    "dipdup>=8,<9",
 ]
 
 [tool.pdm.dev-dependencies]
 dev = [
     "black",
     "ruff",
     "mypy",
@@ -30,27 +30,27 @@
 mypy = {cmd = "make mypy", help = "Lint with mypy"}
 image = {cmd = "make image", help = "Build Docker image"}
 up = {cmd = "make up", help = "Run Compose stack"}
 down = {cmd = "make down", help = "Stop Compose stack"}
 
 [tool.black]
 line-length = 120
-target-version = ['py311']
+target-version = ['py312']
 skip-string-normalization = true
 
 [tool.ruff]
 line-length = 120
-target-version = 'py311'
+target-version = 'py312'
 
 [tool.ruff.lint]
 extend-select = ["B", "C4", "FA", "G", "I", "PTH", "Q", "RET", "RUF", "TCH", "UP"]
 flake8-quotes = { inline-quotes = "single", multiline-quotes = "double" }
 isort = { force-single-line = true}
 
 [tool.mypy]
-python_version = "3.11"
+python_version = "3.12"
 plugins = ["pydantic.mypy"]
 strict = false
 
 [build-system]
 requires = ["pdm-backend"]
 build-backend = "pdm.backend"
```

### Comparing `dipdup-7.5.7/src/demo_evm_events/Makefile` & `dipdup-8.0.0a1/src/demo_tezos_raw/Makefile`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 .PHONY: $(MAKECMDGOALS)
 MAKEFLAGS += --no-print-directory
 ##
 ##   DipDup developer tools
 ##
-PACKAGE=demo_evm_events
+PACKAGE=demo_tezos_raw
 TAG=latest
 COMPOSE=deploy/compose.yaml
 
 help:           ## Show this help (default)
 	@grep -Fh "##" $(MAKEFILE_LIST) | grep -Fv grep -F | sed -e 's/\\$$//' | sed -e 's/##//'
 
 all:            ## Run an entire CI pipeline
```

### Comparing `dipdup-7.5.7/src/demo_evm_events/README.md` & `dipdup-8.0.0a1/src/demo_tezos_token_balances/README.md`

 * *Files 8% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# demo_evm_events
+# demo_tezos_token_balances
 
-ERC-20 token transfers (from event logs)
+FA1.2 token balances
 
 ## Installation
 
 This project is based on [DipDup](https://dipdup.io), a framework for building featureful dapps.
 
-You need a Linux/macOS system with Python 3.11 installed. To install DipDup with pipx for the current user:
+You need a Linux/macOS system with Python 3.12 installed. To install DipDup with pipx or use our installer:
 
 ```shell
-curl -Lsf https://dipdup.io/install.py | python3
+curl -Lsf https://dipdup.io/install.py | python3.12
 ```
 
 See the [Installation](https://dipdup.io/docs/installation) page for all options.
 
 ## Usage
 
 Run the indexer in memory:
```

### Comparing `dipdup-7.5.7/src/demo_evm_events/abi/eth_usdt/abi.json` & `dipdup-8.0.0a1/src/demo_evm_events/abi/eth_usdt/abi.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_evm_events/configs/dipdup.compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_domains/configs/dipdup.compose.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_evm_events/configs/dipdup.swarm.yaml` & `dipdup-8.0.0a1/src/demo_evm_events/configs/dipdup.swarm.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_evm_events/configs/replay.yaml` & `dipdup-8.0.0a1/src/demo_tezos_events/configs/replay.yaml`

 * *Files 11% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 # To refresh existing project run `dipdup init --base --force` after modifying this file.
 # To generate a new project from this replay run `dipdup new --replay <path_to_file>`.
 #
-spec_version: 2.0
+spec_version: 3.0
 replay:
-  dipdup_version: 7
-  template: demo_evm_events
-  package: demo_evm_events
+  dipdup_version: 8
+  template: demo_tezos_events
+  package: demo_tezos_events
   version: 0.0.1
-  description: ERC-20 token transfers (from event logs)
+  description: Processing contract events
   license: MIT
   name: John Doe
   email: john_doe@example.com
   postgres_image: postgres:15
   postgres_data_path: /var/lib/postgresql/data
   hasura_image: hasura/graphql-engine:latest
   line_length: 120
```

### Comparing `dipdup-7.5.7/src/demo_evm_events/deploy/.env.default` & `dipdup-8.0.0a1/src/demo_evm_events/deploy/.env.default`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_evm_events/deploy/compose.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_dex/deploy/compose.swarm.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 version: "3.8"
-name: demo_evm_events
+name: demo_tezos_dex
 
 services:
   dipdup:
-    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-7}
+    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-8}
     depends_on:
       - db
       - hasura
     command: ["-c", "dipdup.yaml", "-c", "configs/dipdup.swarm.yaml", "run"]
     env_file: .env
     networks:
       - internal
@@ -51,15 +51,15 @@
     logging: *logging
 
   hasura:
     image: hasura/graphql-engine:latest
     depends_on:
       - db
     environment:
-      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_evm_events_db:5432/dipdup
+      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_tezos_dex_db:5432/dipdup
       - HASURA_GRAPHQL_ADMIN_SECRET=${HASURA_SECRET}
       - HASURA_GRAPHQL_ENABLE_CONSOLE=true
       - HASURA_GRAPHQL_DEV_MODE=false
       - HASURA_GRAPHQL_LOG_LEVEL=warn
       - HASURA_GRAPHQL_ENABLE_TELEMETRY=false
       - HASURA_GRAPHQL_UNAUTHORIZED_ROLE=user
       - HASURA_GRAPHQL_STRINGIFY_NUMERIC_TYPES=true
```

### Comparing `dipdup-7.5.7/src/demo_evm_events/deploy/compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_events/deploy/compose.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 version: "3.8"
-name: demo_evm_events
+name: demo_tezos_events
 
 services:
   dipdup:
     build:
       context: ..
       dockerfile: deploy/Dockerfile
     restart: always
```

### Comparing `dipdup-7.5.7/src/demo_evm_events/deploy/swarm.env.default` & `dipdup-8.0.0a1/src/demo_evm_events/deploy/swarm.env.default`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_evm_events/dipdup.yaml` & `dipdup-8.0.0a1/tests/configs/demo_evm_transactions.yml`

 * *Files 14% similar despite different names*

```diff
@@ -1,15 +1,14 @@
-spec_version: 2.0
-package: demo_evm_events
+spec_version: 3.0
+package: demo_evm_transactions
 
 datasources:
   subsquid:
     kind: evm.subsquid
     url: ${SUBSQUID_URL:-https://v2.archive.subsquid.io/network/ethereum-mainnet}
-    node: evm_node
   etherscan:
     kind: abi.etherscan
     url: ${ETHERSCAN_URL:-https://api.etherscan.io/api}
     api_key: ${ETHERSCAN_API_KEY:-''}
   evm_node:
     kind: evm.node
     url: ${NODE_URL:-https://eth-mainnet.g.alchemy.com/v2}/${NODE_API_KEY:-''}
@@ -18,14 +17,19 @@
 contracts:
   eth_usdt:
     kind: evm
     address: 0xdac17f958d2ee523a2206206994597c13d831ec7
     typename: eth_usdt
 
 indexes:
-  eth_usdt_events:
-    kind: evm.subsquid.events
-    datasource: subsquid
+  eth_usdt_transactions:
+    kind: evm.transactions
+    datasources:
+      - subsquid
+      - etherscan
+      - evm_node
     handlers:
       - callback: on_transfer
-        contract: eth_usdt
-        name: Transfer
+        to: eth_usdt
+        method: transfer
+    first_level: 18077421
+    last_level: 18077421
```

### Comparing `dipdup-7.5.7/src/demo_evm_events/handlers/on_transfer.py` & `dipdup-8.0.0a1/src/demo_evm_events/handlers/on_transfer.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from decimal import Decimal
 
 from demo_evm_events import models as models
-from demo_evm_events.types.eth_usdt.evm_events.transfer import Transfer
+from demo_evm_events.types.eth_usdt.evm_events.transfer import TransferPayload
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidEvent
+from dipdup.models.evm import EvmEvent
 from tortoise.exceptions import DoesNotExist
 
 
 async def on_transfer(
     ctx: HandlerContext,
-    event: SubsquidEvent[Transfer],
+    event: EvmEvent[TransferPayload],
 ) -> None:
     amount = Decimal(event.payload.value) / (10**6)
     if not amount:
         return
 
     await on_balance_update(
         address=event.payload.from_,
```

### Comparing `dipdup-7.5.7/src/demo_evm_events/pyproject.toml` & `dipdup-8.0.0a1/src/demo_tezos_head/pyproject.toml`

 * *Files 6% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Generated by DipDup 7.5.7
+# generated by DipDup 8.0.0a1
 [project]
-name = "demo_evm_events"
+name = "demo_tezos_head"
 version = "0.0.1"
-description = "ERC-20 token transfers (from event logs)"
+description = "Processing head block metadata (realtime only)"
 license = { text = "MIT" }
 authors = [
     { name = "John Doe", email = "john_doe@example.com" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 dependencies = [
-    "dipdup>=7,<8",
+    "dipdup>=8,<9",
 ]
 
 [tool.pdm.dev-dependencies]
 dev = [
     "black",
     "ruff",
     "mypy",
@@ -30,27 +30,27 @@
 mypy = {cmd = "make mypy", help = "Lint with mypy"}
 image = {cmd = "make image", help = "Build Docker image"}
 up = {cmd = "make up", help = "Run Compose stack"}
 down = {cmd = "make down", help = "Stop Compose stack"}
 
 [tool.black]
 line-length = 120
-target-version = ['py311']
+target-version = ['py312']
 skip-string-normalization = true
 
 [tool.ruff]
 line-length = 120
-target-version = 'py311'
+target-version = 'py312'
 
 [tool.ruff.lint]
 extend-select = ["B", "C4", "FA", "G", "I", "PTH", "Q", "RET", "RUF", "TCH", "UP"]
 flake8-quotes = { inline-quotes = "single", multiline-quotes = "double" }
 isort = { force-single-line = true}
 
 [tool.mypy]
-python_version = "3.11"
+python_version = "3.12"
 plugins = ["pydantic.mypy"]
 strict = false
 
 [build-system]
 requires = ["pdm-backend"]
 build-backend = "pdm.backend"
```

### Comparing `dipdup-7.5.7/src/demo_evm_transactions/Makefile` & `dipdup-8.0.0a1/src/demo_evm_transactions/Makefile`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_evm_transactions/README.md` & `dipdup-8.0.0a1/src/demo_evm_transactions/README.md`

 * *Files 3% similar despite different names*

```diff
@@ -2,18 +2,18 @@
 
 ERC-20 token transfers (from transactions)
 
 ## Installation
 
 This project is based on [DipDup](https://dipdup.io), a framework for building featureful dapps.
 
-You need a Linux/macOS system with Python 3.11 installed. To install DipDup with pipx for the current user:
+You need a Linux/macOS system with Python 3.12 installed. To install DipDup with pipx or use our installer:
 
 ```shell
-curl -Lsf https://dipdup.io/install.py | python3
+curl -Lsf https://dipdup.io/install.py | python3.12
 ```
 
 See the [Installation](https://dipdup.io/docs/installation) page for all options.
 
 ## Usage
 
 Run the indexer in memory:
```

### Comparing `dipdup-7.5.7/src/demo_evm_transactions/abi/eth_usdt/abi.json` & `dipdup-8.0.0a1/src/demo_evm_transactions/abi/eth_usdt/abi.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_evm_transactions/configs/dipdup.compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_etherlink/configs/dipdup.compose.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_evm_transactions/configs/dipdup.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_token_transfers/configs/dipdup.swarm.yaml`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 database:
   kind: postgres
-  host: ${POSTGRES_HOST:-demo_evm_transactions_db}
+  host: ${POSTGRES_HOST:-demo_tezos_token_transfers_db}
   port: 5432
   user: ${POSTGRES_USER:-dipdup}
   password: ${POSTGRES_PASSWORD}
   database: ${POSTGRES_DB:-dipdup}
 
 hasura:
-  url: http://${HASURA_HOST:-demo_evm_transactions_hasura}:8080
+  url: http://${HASURA_HOST:-demo_tezos_token_transfers_hasura}:8080
   admin_secret: ${HASURA_SECRET}
   allow_aggregations: ${HASURA_ALLOW_AGGREGATIONS:-false}
   select_limit: ${HASURA_SELECT_LIMIT:-100}
   camel_case: ${HASURA_CAMEL_CASE:-true}
 
 sentry:
   dsn: ${SENTRY_DSN:-''}
```

### Comparing `dipdup-7.5.7/src/demo_evm_transactions/configs/replay.yaml` & `dipdup-8.0.0a1/src/demo_evm_transactions/configs/replay.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 # To refresh existing project run `dipdup init --base --force` after modifying this file.
 # To generate a new project from this replay run `dipdup new --replay <path_to_file>`.
 #
-spec_version: 2.0
+spec_version: 3.0
 replay:
-  dipdup_version: 7
+  dipdup_version: 8
   template: demo_evm_transactions
   package: demo_evm_transactions
   version: 0.0.1
   description: ERC-20 token transfers (from transactions)
   license: MIT
   name: John Doe
   email: john_doe@example.com
```

### Comparing `dipdup-7.5.7/src/demo_evm_transactions/deploy/.env.default` & `dipdup-8.0.0a1/src/demo_evm_transactions/deploy/.env.default`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_evm_transactions/deploy/compose.swarm.yaml` & `dipdup-8.0.0a1/src/demo_evm_transactions/deploy/compose.swarm.yaml`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 version: "3.8"
 name: demo_evm_transactions
 
 services:
   dipdup:
-    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-7}
+    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-8}
     depends_on:
       - db
       - hasura
     command: ["-c", "dipdup.yaml", "-c", "configs/dipdup.swarm.yaml", "run"]
     env_file: .env
     networks:
       - internal
```

### Comparing `dipdup-7.5.7/src/demo_evm_transactions/deploy/compose.yaml` & `dipdup-8.0.0a1/src/demo_evm_transactions/deploy/compose.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_evm_transactions/deploy/swarm.env.default` & `dipdup-8.0.0a1/src/demo_evm_transactions/deploy/swarm.env.default`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_evm_transactions/dipdup.yaml` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_events/dipdup.yaml.j2`

 * *Files 8% similar despite different names*

```diff
@@ -1,15 +1,14 @@
-spec_version: 2.0
-package: demo_evm_transactions
+spec_version: 3.0
+package: {{ project.package }}
 
 datasources:
   subsquid:
     kind: evm.subsquid
     url: ${SUBSQUID_URL:-https://v2.archive.subsquid.io/network/ethereum-mainnet}
-    node: evm_node
   etherscan:
     kind: abi.etherscan
     url: ${ETHERSCAN_URL:-https://api.etherscan.io/api}
     api_key: ${ETHERSCAN_API_KEY:-''}
   evm_node:
     kind: evm.node
     url: ${NODE_URL:-https://eth-mainnet.g.alchemy.com/v2}/${NODE_API_KEY:-''}
@@ -18,15 +17,17 @@
 contracts:
   eth_usdt:
     kind: evm
     address: 0xdac17f958d2ee523a2206206994597c13d831ec7
     typename: eth_usdt
 
 indexes:
-  eth_usdt_transactions:
-    kind: evm.subsquid.transactions
-    datasource: subsquid
+  eth_usdt_events:
+    kind: evm.events
+    datasources:
+      - subsquid
+      - etherscan
+      - evm_node
     handlers:
       - callback: on_transfer
-        to: eth_usdt
-        method: transfer
-    first_level: 4634748
+        contract: eth_usdt
+        name: Transfer
```

### Comparing `dipdup-7.5.7/src/demo_evm_transactions/handlers/on_transfer.py` & `dipdup-8.0.0a1/src/demo_evm_transactions/handlers/on_transfer.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from decimal import Decimal
 
 from demo_evm_transactions import models as models
-from demo_evm_transactions.types.eth_usdt.evm_methods.transfer import Transfer
+from demo_evm_transactions.types.eth_usdt.evm_transactions.transfer import TransferInput
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidTransaction
+from dipdup.models.evm import EvmTransaction
 from tortoise.exceptions import DoesNotExist
 
 
 async def on_transfer(
     ctx: HandlerContext,
-    transaction: SubsquidTransaction[Transfer],
+    transaction: EvmTransaction[TransferInput],
 ) -> None:
     amount = Decimal(transaction.input.value) / (10**6)
     if not amount:
         return
 
     await on_balance_update(
         address=transaction.data.from_,
```

### Comparing `dipdup-7.5.7/src/demo_evm_transactions/pyproject.toml` & `dipdup-8.0.0a1/src/demo_tezos_token_balances/pyproject.toml`

 * *Files 10% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Generated by DipDup 7.5.7
+# generated by DipDup 8.0.0a1
 [project]
-name = "demo_evm_transactions"
+name = "demo_tezos_token_balances"
 version = "0.0.1"
-description = "ERC-20 token transfers (from transactions)"
+description = "FA1.2 token balances"
 license = { text = "MIT" }
 authors = [
     { name = "John Doe", email = "john_doe@example.com" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 dependencies = [
-    "dipdup>=7,<8",
+    "dipdup>=8,<9",
 ]
 
 [tool.pdm.dev-dependencies]
 dev = [
     "black",
     "ruff",
     "mypy",
@@ -30,27 +30,27 @@
 mypy = {cmd = "make mypy", help = "Lint with mypy"}
 image = {cmd = "make image", help = "Build Docker image"}
 up = {cmd = "make up", help = "Run Compose stack"}
 down = {cmd = "make down", help = "Stop Compose stack"}
 
 [tool.black]
 line-length = 120
-target-version = ['py311']
+target-version = ['py312']
 skip-string-normalization = true
 
 [tool.ruff]
 line-length = 120
-target-version = 'py311'
+target-version = 'py312'
 
 [tool.ruff.lint]
 extend-select = ["B", "C4", "FA", "G", "I", "PTH", "Q", "RET", "RUF", "TCH", "UP"]
 flake8-quotes = { inline-quotes = "single", multiline-quotes = "double" }
 isort = { force-single-line = true}
 
 [tool.mypy]
-python_version = "3.11"
+python_version = "3.12"
 plugins = ["pydantic.mypy"]
 strict = false
 
 [build-system]
 requires = ["pdm-backend"]
 build-backend = "pdm.backend"
```

### Comparing `dipdup-7.5.7/src/demo_factories/Makefile` & `dipdup-8.0.0a1/src/demo_tezos_factories/Makefile`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 .PHONY: $(MAKECMDGOALS)
 MAKEFLAGS += --no-print-directory
 ##
 ##   DipDup developer tools
 ##
-PACKAGE=demo_factories
+PACKAGE=demo_tezos_factories
 TAG=latest
 COMPOSE=deploy/compose.yaml
 
 help:           ## Show this help (default)
 	@grep -Fh "##" $(MAKEFILE_LIST) | grep -Fv grep -F | sed -e 's/\\$$//' | sed -e 's/##//'
 
 all:            ## Run an entire CI pipeline
```

### Comparing `dipdup-7.5.7/src/demo_factories/README.md` & `dipdup-8.0.0a1/src/demo_tezos_factories/README.md`

 * *Files 15% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# demo_factories
+# demo_tezos_factories
 
 Example of spawning indexes in runtime
 
 ## Installation
 
 This project is based on [DipDup](https://dipdup.io), a framework for building featureful dapps.
 
-You need a Linux/macOS system with Python 3.11 installed. To install DipDup with pipx for the current user:
+You need a Linux/macOS system with Python 3.12 installed. To install DipDup with pipx or use our installer:
 
 ```shell
-curl -Lsf https://dipdup.io/install.py | python3
+curl -Lsf https://dipdup.io/install.py | python3.12
 ```
 
 See the [Installation](https://dipdup.io/docs/installation) page for all options.
 
 ## Usage
 
 Run the indexer in memory:
```

### Comparing `dipdup-7.5.7/src/demo_factories/configs/dipdup.compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_events/configs/dipdup.compose.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_factories/configs/dipdup.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_factories/configs/dipdup.swarm.yaml`

 * *Files 16% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 database:
   kind: postgres
-  host: ${POSTGRES_HOST:-demo_factories_db}
+  host: ${POSTGRES_HOST:-demo_tezos_factories_db}
   port: 5432
   user: ${POSTGRES_USER:-dipdup}
   password: ${POSTGRES_PASSWORD}
   database: ${POSTGRES_DB:-dipdup}
 
 hasura:
-  url: http://${HASURA_HOST:-demo_factories_hasura}:8080
+  url: http://${HASURA_HOST:-demo_tezos_factories_hasura}:8080
   admin_secret: ${HASURA_SECRET}
   allow_aggregations: ${HASURA_ALLOW_AGGREGATIONS:-false}
   select_limit: ${HASURA_SELECT_LIMIT:-100}
   camel_case: ${HASURA_CAMEL_CASE:-true}
 
 sentry:
   dsn: ${SENTRY_DSN:-''}
```

### Comparing `dipdup-7.5.7/src/demo_factories/configs/replay.yaml` & `dipdup-8.0.0a1/src/demo_tezos_token/configs/replay.yaml`

 * *Files 13% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 # To refresh existing project run `dipdup init --base --force` after modifying this file.
 # To generate a new project from this replay run `dipdup new --replay <path_to_file>`.
 #
-spec_version: 2.0
+spec_version: 3.0
 replay:
-  dipdup_version: 7
-  template: demo_factories
-  package: demo_factories
+  dipdup_version: 8
+  template: demo_tezos_token
+  package: demo_tezos_token
   version: 0.0.1
-  description: Example of spawning indexes in runtime
+  description: FA1.2 token contract operations
   license: MIT
   name: John Doe
   email: john_doe@example.com
   postgres_image: postgres:15
   postgres_data_path: /var/lib/postgresql/data
   hasura_image: hasura/graphql-engine:latest
   line_length: 120
```

### Comparing `dipdup-7.5.7/src/demo_factories/deploy/compose.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_raw/deploy/compose.swarm.yaml`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 version: "3.8"
-name: demo_factories
+name: demo_tezos_raw
 
 services:
   dipdup:
-    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-7}
+    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-8}
     depends_on:
       - db
       - hasura
     command: ["-c", "dipdup.yaml", "-c", "configs/dipdup.swarm.yaml", "run"]
     env_file: .env
     networks:
       - internal
@@ -51,15 +51,15 @@
     logging: *logging
 
   hasura:
     image: hasura/graphql-engine:latest
     depends_on:
       - db
     environment:
-      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_factories_db:5432/dipdup
+      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_tezos_raw_db:5432/dipdup
       - HASURA_GRAPHQL_ADMIN_SECRET=${HASURA_SECRET}
       - HASURA_GRAPHQL_ENABLE_CONSOLE=true
       - HASURA_GRAPHQL_DEV_MODE=false
       - HASURA_GRAPHQL_LOG_LEVEL=warn
       - HASURA_GRAPHQL_ENABLE_TELEMETRY=false
       - HASURA_GRAPHQL_UNAUTHORIZED_ROLE=user
       - HASURA_GRAPHQL_STRINGIFY_NUMERIC_TYPES=true
```

### Comparing `dipdup-7.5.7/src/demo_factories/deploy/compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_raw/deploy/compose.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 version: "3.8"
-name: demo_factories
+name: demo_tezos_raw
 
 services:
   dipdup:
     build:
       context: ..
       dockerfile: deploy/Dockerfile
     restart: always
```

### Comparing `dipdup-7.5.7/src/demo_factories/dipdup.yaml` & `dipdup-8.0.0a1/tests/configs/demo_tezos_factories.yml`

 * *Files 16% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-spec_version: 2.0
-package: demo_factories
+spec_version: 3.0
+package: demo_tezos_factories
 
 contracts:
   factory:
     kind: tezos
     address: KT1PvEyN1xCFCgorN92QCfYjw3axS6jawCiJ
     typename: factory
   token:
@@ -11,19 +11,22 @@
     address: KT1UsSfaXyqcjSVPeiD7U1bWgKy3taYN7NWY
     typename: token
 
 datasources:
   tzkt:
     kind: tezos.tzkt
     url: ${TZKT_URL:-https://api.tzkt.io}
+    http:
+      replay_path: ${DIPDUP_REPLAY_PATH:-}
 
 templates:
   dex:
-    kind: tezos.tzkt.operations
-    datasource: tzkt
+    kind: tezos.operations
+    datasources:
+      - tzkt
     types:
       - transaction
     contracts:
       - <dex>
       - <token>
     handlers:
       - callback: on_transfer
@@ -32,23 +35,24 @@
             destination: <token>
             entrypoint: transfer
     first_level: 2393103
     last_level: 2393103
 
 indexes:
   factory:
-    kind: tezos.tzkt.operations
-    datasource: tzkt
+    kind: tezos.operations
+    datasources:
+      - tzkt
     contracts:
       - factory
     types:
       - origination
       - transaction
     handlers:
       - callback: on_factory_origination
         pattern:
           - type: transaction
             entrypoint: launchExchange
           - type: origination
             source: factory
     first_level: 2428590
-    last_level: 2428590
+    last_level: 2428590
```

### Comparing `dipdup-7.5.7/src/demo_factories/handlers/on_factory_origination.py` & `dipdup-8.0.0a1/src/demo_tezos_factories/handlers/on_factory_origination.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from contextlib import suppress
 from typing import cast
 
 from dipdup.context import HandlerContext
 from dipdup.exceptions import ContractAlreadyExistsError
-from dipdup.models.tezos_tzkt import TzktOperationData
+from dipdup.models.tezos import TezosOperationData
 
 
 async def on_factory_origination(
     ctx: HandlerContext,
-    transaction_0: TzktOperationData,
-    origination_1: TzktOperationData,
+    transaction_0: TezosOperationData,
+    origination_1: TezosOperationData,
 ) -> None:
     assert transaction_0.parameter_json
     dex_contract = cast(str, origination_1.originated_contract_address)
     token_contract = cast(str, transaction_0.parameter_json['token']['address'])
 
     await ctx.add_contract(
         kind='tezos',
```

### Comparing `dipdup-7.5.7/src/demo_factories/handlers/on_transfer.py` & `dipdup-8.0.0a1/src/demo_tezos_factories/handlers/on_transfer.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,18 +1,18 @@
-import demo_factories.models as models
-from demo_factories.types.token.tezos_parameters.transfer import TransferParameter
-from demo_factories.types.token.tezos_storage import TokenStorage
+import demo_tezos_factories.models as models
+from demo_tezos_factories.types.token.tezos_parameters.transfer import TransferParameter
+from demo_tezos_factories.types.token.tezos_storage import TokenStorage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_transfer(
     ctx: HandlerContext,
-    transfer: TzktTransaction[TransferParameter, TokenStorage],
+    transfer: TezosTransaction[TransferParameter, TokenStorage],
 ) -> None:
-    for transfer_item in transfer.parameter.__root__:
+    for transfer_item in transfer.parameter.root:
         for tx in transfer_item.txs:
             await models.Transfer.create(
                 from_=transfer_item.from_,
                 to=tx.to_,
                 amount=tx.amount,
             )
```

### Comparing `dipdup-7.5.7/src/demo_factories/pyproject.toml` & `dipdup-8.0.0a1/src/demo_tezos_raw/pyproject.toml`

 * *Files 7% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Generated by DipDup 7.5.7
+# generated by DipDup 8.0.0a1
 [project]
-name = "demo_factories"
+name = "demo_tezos_raw"
 version = "0.0.1"
-description = "Example of spawning indexes in runtime"
+description = "Process raw operations without filtering and typed payloads"
 license = { text = "MIT" }
 authors = [
     { name = "John Doe", email = "john_doe@example.com" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 dependencies = [
-    "dipdup>=7,<8",
+    "dipdup>=8,<9",
 ]
 
 [tool.pdm.dev-dependencies]
 dev = [
     "black",
     "ruff",
     "mypy",
@@ -30,27 +30,27 @@
 mypy = {cmd = "make mypy", help = "Lint with mypy"}
 image = {cmd = "make image", help = "Build Docker image"}
 up = {cmd = "make up", help = "Run Compose stack"}
 down = {cmd = "make down", help = "Stop Compose stack"}
 
 [tool.black]
 line-length = 120
-target-version = ['py311']
+target-version = ['py312']
 skip-string-normalization = true
 
 [tool.ruff]
 line-length = 120
-target-version = 'py311'
+target-version = 'py312'
 
 [tool.ruff.lint]
 extend-select = ["B", "C4", "FA", "G", "I", "PTH", "Q", "RET", "RUF", "TCH", "UP"]
 flake8-quotes = { inline-quotes = "single", multiline-quotes = "double" }
 isort = { force-single-line = true}
 
 [tool.mypy]
-python_version = "3.11"
+python_version = "3.12"
 plugins = ["pydantic.mypy"]
 strict = false
 
 [build-system]
 requires = ["pdm-backend"]
 build-backend = "pdm.backend"
```

### Comparing `dipdup-7.5.7/src/demo_factories/types/factory/tezos_storage.py` & `dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/types/hen_objkts/tezos_storage.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,76 +1,62 @@
-# generated by datamodel-codegen:
-#   filename:  tezos_storage.json
+# generated by DipDup 8.0.0a1
 
 from __future__ import annotations
 
-from pydantic import BaseModel
-from pydantic import Extra
-
-
-class Ledger(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
-    allowances: list[str]
-    balance: str
-    frozen_balance: str
-
+from typing import Any
 
-class TokenList(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
-    address: str
-    nat: str
+from pydantic import BaseModel
+from pydantic import ConfigDict
 
 
 class Key(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
+    model_config = ConfigDict(
+        extra='forbid',
+    )
     address: str
     nat: str
 
 
-class TokenToExchangeItem(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
+class LedgerItem(BaseModel):
+    model_config = ConfigDict(
+        extra='forbid',
+    )
     key: Key
     value: str
 
 
-class UserRewards(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
-    reward: str
-    reward_paid: str
-
-
-class Voters(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
-    candidate: str | None
-    last_veto: str
-    veto: str
-    vote: str
-
-
-class FactoryStorage(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
-    baker_validator: str
-    counter: str
-    dex_lambdas: dict[str, str]
-    ledger: dict[str, Ledger]
+class Key1(BaseModel):
+    model_config = ConfigDict(
+        extra='forbid',
+    )
+    owner: str
+    operator: str
+    token_id: str
+
+
+class Operator(BaseModel):
+    model_config = ConfigDict(
+        extra='forbid',
+    )
+    key: Key1
+    value: dict[str, Any]
+
+
+class TokenMetadata(BaseModel):
+    model_config = ConfigDict(
+        extra='forbid',
+    )
+    token_id: str
+    token_info: dict[str, str]
+
+
+class HenObjktsStorage(BaseModel):
+    model_config = ConfigDict(
+        extra='forbid',
+    )
+    administrator: str
+    all_tokens: str
+    ledger: list[LedgerItem]
     metadata: dict[str, str]
-    token_lambdas: dict[str, str]
-    token_list: dict[str, TokenList]
-    token_to_exchange: list[TokenToExchangeItem]
-    user_rewards: dict[str, UserRewards]
-    vetos: dict[str, str]
-    voters: dict[str, Voters]
-    votes: dict[str, str]
+    operators: list[Operator]
+    paused: bool
+    token_metadata: dict[str, TokenMetadata]
```

### Comparing `dipdup-7.5.7/src/demo_head/Makefile` & `dipdup-8.0.0a1/src/demo_tezos_etherlink/Makefile`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 .PHONY: $(MAKECMDGOALS)
 MAKEFLAGS += --no-print-directory
 ##
 ##   DipDup developer tools
 ##
-PACKAGE=demo_head
+PACKAGE=demo_tezos_etherlink
 TAG=latest
 COMPOSE=deploy/compose.yaml
 
 help:           ## Show this help (default)
 	@grep -Fh "##" $(MAKEFILE_LIST) | grep -Fv grep -F | sed -e 's/\\$$//' | sed -e 's/##//'
 
 all:            ## Run an entire CI pipeline
```

### Comparing `dipdup-7.5.7/src/demo_head/README.md` & `dipdup-8.0.0a1/src/demo_tezos_events/README.md`

 * *Files 8% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# demo_head
+# demo_tezos_events
 
-Processing head block metadata (realtime only)
+Processing contract events
 
 ## Installation
 
 This project is based on [DipDup](https://dipdup.io), a framework for building featureful dapps.
 
-You need a Linux/macOS system with Python 3.11 installed. To install DipDup with pipx for the current user:
+You need a Linux/macOS system with Python 3.12 installed. To install DipDup with pipx or use our installer:
 
 ```shell
-curl -Lsf https://dipdup.io/install.py | python3
+curl -Lsf https://dipdup.io/install.py | python3.12
 ```
 
 See the [Installation](https://dipdup.io/docs/installation) page for all options.
 
 ## Usage
 
 Run the indexer in memory:
```

### Comparing `dipdup-7.5.7/src/demo_head/configs/dipdup.compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_factories/configs/dipdup.compose.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_head/configs/dipdup.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_head/configs/dipdup.swarm.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 database:
   kind: postgres
-  host: ${POSTGRES_HOST:-demo_head_db}
+  host: ${POSTGRES_HOST:-demo_tezos_head_db}
   port: 5432
   user: ${POSTGRES_USER:-dipdup}
   password: ${POSTGRES_PASSWORD}
   database: ${POSTGRES_DB:-dipdup}
 
 hasura:
-  url: http://${HASURA_HOST:-demo_head_hasura}:8080
+  url: http://${HASURA_HOST:-demo_tezos_head_hasura}:8080
   admin_secret: ${HASURA_SECRET}
   allow_aggregations: ${HASURA_ALLOW_AGGREGATIONS:-false}
   select_limit: ${HASURA_SELECT_LIMIT:-100}
   camel_case: ${HASURA_CAMEL_CASE:-true}
 
 sentry:
   dsn: ${SENTRY_DSN:-''}
```

### Comparing `dipdup-7.5.7/src/demo_head/configs/replay.yaml` & `dipdup-8.0.0a1/src/demo_tezos_head/configs/replay.yaml`

 * *Files 5% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # To refresh existing project run `dipdup init --base --force` after modifying this file.
 # To generate a new project from this replay run `dipdup new --replay <path_to_file>`.
 #
-spec_version: 2.0
+spec_version: 3.0
 replay:
-  dipdup_version: 7
-  template: demo_head
-  package: demo_head
+  dipdup_version: 8
+  template: demo_tezos_head
+  package: demo_tezos_head
   version: 0.0.1
   description: Processing head block metadata (realtime only)
   license: MIT
   name: John Doe
   email: john_doe@example.com
   postgres_image: postgres:15
   postgres_data_path: /var/lib/postgresql/data
```

### Comparing `dipdup-7.5.7/src/demo_head/deploy/compose.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_big_maps/deploy/compose.swarm.yaml`

 * *Files 4% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 version: "3.8"
-name: demo_head
+name: demo_tezos_big_maps
 
 services:
   dipdup:
-    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-7}
+    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-8}
     depends_on:
       - db
       - hasura
     command: ["-c", "dipdup.yaml", "-c", "configs/dipdup.swarm.yaml", "run"]
     env_file: .env
     networks:
       - internal
@@ -51,15 +51,15 @@
     logging: *logging
 
   hasura:
     image: hasura/graphql-engine:latest
     depends_on:
       - db
     environment:
-      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_head_db:5432/dipdup
+      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_tezos_big_maps_db:5432/dipdup
       - HASURA_GRAPHQL_ADMIN_SECRET=${HASURA_SECRET}
       - HASURA_GRAPHQL_ENABLE_CONSOLE=true
       - HASURA_GRAPHQL_DEV_MODE=false
       - HASURA_GRAPHQL_LOG_LEVEL=warn
       - HASURA_GRAPHQL_ENABLE_TELEMETRY=false
       - HASURA_GRAPHQL_UNAUTHORIZED_ROLE=user
       - HASURA_GRAPHQL_STRINGIFY_NUMERIC_TYPES=true
```

### Comparing `dipdup-7.5.7/src/demo_head/deploy/compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_auction/deploy/compose.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 version: "3.8"
-name: demo_head
+name: demo_tezos_auction
 
 services:
   dipdup:
     build:
       context: ..
       dockerfile: deploy/Dockerfile
     restart: always
```

### Comparing `dipdup-7.5.7/src/demo_head/models/__init__.py` & `dipdup-8.0.0a1/src/demo_tezos_head/models/__init__.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_head/pyproject.toml` & `dipdup-8.0.0a1/src/demo_tezos_factories/pyproject.toml`

 * *Files 9% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Generated by DipDup 7.5.7
+# generated by DipDup 8.0.0a1
 [project]
-name = "demo_head"
+name = "demo_tezos_factories"
 version = "0.0.1"
-description = "Processing head block metadata (realtime only)"
+description = "Example of spawning indexes in runtime"
 license = { text = "MIT" }
 authors = [
     { name = "John Doe", email = "john_doe@example.com" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 dependencies = [
-    "dipdup>=7,<8",
+    "dipdup>=8,<9",
 ]
 
 [tool.pdm.dev-dependencies]
 dev = [
     "black",
     "ruff",
     "mypy",
@@ -30,27 +30,27 @@
 mypy = {cmd = "make mypy", help = "Lint with mypy"}
 image = {cmd = "make image", help = "Build Docker image"}
 up = {cmd = "make up", help = "Run Compose stack"}
 down = {cmd = "make down", help = "Stop Compose stack"}
 
 [tool.black]
 line-length = 120
-target-version = ['py311']
+target-version = ['py312']
 skip-string-normalization = true
 
 [tool.ruff]
 line-length = 120
-target-version = 'py311'
+target-version = 'py312'
 
 [tool.ruff.lint]
 extend-select = ["B", "C4", "FA", "G", "I", "PTH", "Q", "RET", "RUF", "TCH", "UP"]
 flake8-quotes = { inline-quotes = "single", multiline-quotes = "double" }
 isort = { force-single-line = true}
 
 [tool.mypy]
-python_version = "3.11"
+python_version = "3.12"
 plugins = ["pydantic.mypy"]
 strict = false
 
 [build-system]
 requires = ["pdm-backend"]
 build-backend = "pdm.backend"
```

### Comparing `dipdup-7.5.7/src/demo_nft_marketplace/Makefile` & `dipdup-8.0.0a1/src/demo_tezos_token_balances/Makefile`

 * *Files 4% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 .PHONY: $(MAKECMDGOALS)
 MAKEFLAGS += --no-print-directory
 ##
 ##   DipDup developer tools
 ##
-PACKAGE=demo_nft_marketplace
+PACKAGE=demo_tezos_token_balances
 TAG=latest
 COMPOSE=deploy/compose.yaml
 
 help:           ## Show this help (default)
 	@grep -Fh "##" $(MAKEFILE_LIST) | grep -Fv grep -F | sed -e 's/\\$$//' | sed -e 's/##//'
 
 all:            ## Run an entire CI pipeline
```

### Comparing `dipdup-7.5.7/src/demo_nft_marketplace/README.md` & `dipdup-8.0.0a1/src/demo_tezos_head/README.md`

 * *Files 12% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# demo_nft_marketplace
+# demo_tezos_head
 
-NFT marketplace (hic at nunc)
+Processing head block metadata (realtime only)
 
 ## Installation
 
 This project is based on [DipDup](https://dipdup.io), a framework for building featureful dapps.
 
-You need a Linux/macOS system with Python 3.11 installed. To install DipDup with pipx for the current user:
+You need a Linux/macOS system with Python 3.12 installed. To install DipDup with pipx or use our installer:
 
 ```shell
-curl -Lsf https://dipdup.io/install.py | python3
+curl -Lsf https://dipdup.io/install.py | python3.12
 ```
 
 See the [Installation](https://dipdup.io/docs/installation) page for all options.
 
 ## Usage
 
 Run the indexer in memory:
```

### Comparing `dipdup-7.5.7/src/demo_nft_marketplace/configs/dipdup.compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_head/configs/dipdup.compose.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_nft_marketplace/configs/dipdup.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_events/configs/dipdup.swarm.yaml`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 database:
   kind: postgres
-  host: ${POSTGRES_HOST:-demo_nft_marketplace_db}
+  host: ${POSTGRES_HOST:-demo_tezos_events_db}
   port: 5432
   user: ${POSTGRES_USER:-dipdup}
   password: ${POSTGRES_PASSWORD}
   database: ${POSTGRES_DB:-dipdup}
 
 hasura:
-  url: http://${HASURA_HOST:-demo_nft_marketplace_hasura}:8080
+  url: http://${HASURA_HOST:-demo_tezos_events_hasura}:8080
   admin_secret: ${HASURA_SECRET}
   allow_aggregations: ${HASURA_ALLOW_AGGREGATIONS:-false}
   select_limit: ${HASURA_SELECT_LIMIT:-100}
   camel_case: ${HASURA_CAMEL_CASE:-true}
 
 sentry:
   dsn: ${SENTRY_DSN:-''}
```

### Comparing `dipdup-7.5.7/src/demo_nft_marketplace/configs/replay.yaml` & `dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/configs/replay.yaml`

 * *Files 22% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # To refresh existing project run `dipdup init --base --force` after modifying this file.
 # To generate a new project from this replay run `dipdup new --replay <path_to_file>`.
 #
-spec_version: 2.0
+spec_version: 3.0
 replay:
-  dipdup_version: 7
-  template: demo_nft_marketplace
-  package: demo_nft_marketplace
+  dipdup_version: 8
+  template: demo_tezos_nft_marketplace
+  package: demo_tezos_nft_marketplace
   version: 0.0.1
   description: NFT marketplace (hic at nunc)
   license: MIT
   name: John Doe
   email: john_doe@example.com
   postgres_image: postgres:15
   postgres_data_path: /var/lib/postgresql/data
```

### Comparing `dipdup-7.5.7/src/demo_nft_marketplace/deploy/.env.default` & `dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/deploy/.env.default`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_nft_marketplace/deploy/compose.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_token_balances/deploy/compose.swarm.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 version: "3.8"
-name: demo_nft_marketplace
+name: demo_tezos_token_balances
 
 services:
   dipdup:
-    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-7}
+    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-8}
     depends_on:
       - db
       - hasura
     command: ["-c", "dipdup.yaml", "-c", "configs/dipdup.swarm.yaml", "run"]
     env_file: .env
     networks:
       - internal
@@ -51,15 +51,15 @@
     logging: *logging
 
   hasura:
     image: hasura/graphql-engine:latest
     depends_on:
       - db
     environment:
-      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_nft_marketplace_db:5432/dipdup
+      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_tezos_token_balances_db:5432/dipdup
       - HASURA_GRAPHQL_ADMIN_SECRET=${HASURA_SECRET}
       - HASURA_GRAPHQL_ENABLE_CONSOLE=true
       - HASURA_GRAPHQL_DEV_MODE=false
       - HASURA_GRAPHQL_LOG_LEVEL=warn
       - HASURA_GRAPHQL_ENABLE_TELEMETRY=false
       - HASURA_GRAPHQL_UNAUTHORIZED_ROLE=user
       - HASURA_GRAPHQL_STRINGIFY_NUMERIC_TYPES=true
```

### Comparing `dipdup-7.5.7/src/demo_nft_marketplace/deploy/compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/deploy/compose.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 version: "3.8"
-name: demo_nft_marketplace
+name: demo_tezos_nft_marketplace
 
 services:
   dipdup:
     build:
       context: ..
       dockerfile: deploy/Dockerfile
     restart: always
```

### Comparing `dipdup-7.5.7/src/demo_nft_marketplace/deploy/swarm.env.default` & `dipdup-8.0.0a1/src/demo_evm_uniswap/deploy/.env.default`

 * *Files 24% similar despite different names*

```diff
@@ -1,17 +1,20 @@
 # This env file was generated automatically by DipDup. Do not edit it!
 # Create a copy with .env extension, fill it with your values and run DipDup with `--env-file` option.
 #
-HASURA_ALLOW_AGGREGATIONS=false
+ETHERSCAN_API_KEY=''
+ETHERSCAN_URL=https://api.etherscan.io/api
+HASURA_ALLOW_AGGREGATIONS=true
 HASURA_CAMEL_CASE=true
-HASURA_HOST=demo_nft_marketplace_hasura
+HASURA_HOST=hasura
 HASURA_SECRET=
-HASURA_SELECT_LIMIT=100
-HEN_MINTER=KT1Hkg5qeNhfwpKW4fXvq7HGZB9z2EnmCCA9
-HEN_OBJKTS=KT1RJ6PbjHpwc3M5rw5s2Nbmefwbuwbdxton
+HASURA_SELECT_LIMIT=10000
+NODE_API_KEY=''
+NODE_URL=https://eth-mainnet.g.alchemy.com/v2
+NODE_WS_URL=wss://eth-mainnet.g.alchemy.com/v2
 POSTGRES_DB=dipdup
-POSTGRES_HOST=demo_nft_marketplace_db
+POSTGRES_HOST=db
 POSTGRES_PASSWORD=
 POSTGRES_USER=dipdup
 SENTRY_DSN=''
 SENTRY_ENVIRONMENT=''
-TZKT_URL=https://api.tzkt.io
+SUBSQUID_URL=https://v2.archive.subsquid.io/network/ethereum-mainnet
```

### Comparing `dipdup-7.5.7/src/demo_nft_marketplace/dipdup.yaml` & `dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/dipdup.yaml`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-spec_version: 2.0
-package: demo_nft_marketplace
+spec_version: 3.0
+package: demo_tezos_nft_marketplace
 
 datasources:
   tzkt_mainnet:
     kind: tezos.tzkt
     url: ${TZKT_URL:-https://api.tzkt.io}
 
 contracts:
@@ -14,16 +14,17 @@
   HEN_minter:
     kind: tezos
     address: ${HEN_MINTER:-KT1Hkg5qeNhfwpKW4fXvq7HGZB9z2EnmCCA9}
     typename: hen_minter
 
 indexes:
   hen_mainnet:
-    kind: tezos.tzkt.operations
-    datasource: tzkt_mainnet
+    kind: tezos.operations
+    datasources:
+      - tzkt_mainnet
     contracts:
       - HEN_minter
     handlers:
       - callback: on_mint
         pattern:
           - type: transaction
             destination: HEN_minter
```

### Comparing `dipdup-7.5.7/src/demo_nft_marketplace/handlers/on_cancel_swap.py` & `dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/handlers/on_cancel_swap.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,14 +1,14 @@
-import demo_nft_marketplace.models as models
-from demo_nft_marketplace.types.hen_minter.tezos_parameters.cancel_swap import CancelSwapParameter
-from demo_nft_marketplace.types.hen_minter.tezos_storage import HenMinterStorage
+import demo_tezos_nft_marketplace.models as models
+from demo_tezos_nft_marketplace.types.hen_minter.tezos_parameters.cancel_swap import CancelSwapParameter
+from demo_tezos_nft_marketplace.types.hen_minter.tezos_storage import HenMinterStorage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_cancel_swap(
     ctx: HandlerContext,
-    cancel_swap: TzktTransaction[CancelSwapParameter, HenMinterStorage],
+    cancel_swap: TezosTransaction[CancelSwapParameter, HenMinterStorage],
 ) -> None:
-    swap = await models.Swap.filter(id=int(cancel_swap.parameter.__root__)).get()
+    swap = await models.Swap.filter(id=int(cancel_swap.parameter.root)).get()
     swap.status = models.SwapStatus.CANCELED
     await swap.save()
```

### Comparing `dipdup-7.5.7/src/demo_nft_marketplace/handlers/on_collect.py` & `dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/handlers/on_collect.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-import demo_nft_marketplace.models as models
-from demo_nft_marketplace.types.hen_minter.tezos_parameters.collect import CollectParameter
-from demo_nft_marketplace.types.hen_minter.tezos_storage import HenMinterStorage
+import demo_tezos_nft_marketplace.models as models
+from demo_tezos_nft_marketplace.types.hen_minter.tezos_parameters.collect import CollectParameter
+from demo_tezos_nft_marketplace.types.hen_minter.tezos_storage import HenMinterStorage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_collect(
     ctx: HandlerContext,
-    collect: TzktTransaction[CollectParameter, HenMinterStorage],
+    collect: TezosTransaction[CollectParameter, HenMinterStorage],
 ) -> None:
     swap = await models.Swap.filter(id=collect.parameter.swap_id).get()
     seller = await swap.creator
     buyer, _ = await models.Holder.get_or_create(address=collect.data.sender_address)
 
     trade = models.Trade(
         swap=swap,
```

### Comparing `dipdup-7.5.7/src/demo_nft_marketplace/handlers/on_mint.py` & `dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/handlers/on_mint.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-import demo_nft_marketplace.models as models
-from demo_nft_marketplace.types.hen_minter.tezos_parameters.mint_objkt import MintOBJKTParameter
-from demo_nft_marketplace.types.hen_minter.tezos_storage import HenMinterStorage
-from demo_nft_marketplace.types.hen_objkts.tezos_parameters.mint import MintParameter
-from demo_nft_marketplace.types.hen_objkts.tezos_storage import HenObjktsStorage
+import demo_tezos_nft_marketplace.models as models
+from demo_tezos_nft_marketplace.types.hen_minter.tezos_parameters.mint_objkt import MintOBJKTParameter
+from demo_tezos_nft_marketplace.types.hen_minter.tezos_storage import HenMinterStorage
+from demo_tezos_nft_marketplace.types.hen_objkts.tezos_parameters.mint import MintParameter
+from demo_tezos_nft_marketplace.types.hen_objkts.tezos_storage import HenObjktsStorage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_mint(
     ctx: HandlerContext,
-    mint_objkt: TzktTransaction[MintOBJKTParameter, HenMinterStorage],
-    mint: TzktTransaction[MintParameter, HenObjktsStorage],
+    mint_objkt: TezosTransaction[MintOBJKTParameter, HenMinterStorage],
+    mint: TezosTransaction[MintParameter, HenObjktsStorage],
 ) -> None:
     holder, _ = await models.Holder.get_or_create(address=mint.parameter.address)
     token = models.Token(
         id=mint.parameter.token_id,
         creator=holder,
         supply=mint.parameter.amount,
         level=mint.data.level,
```

### Comparing `dipdup-7.5.7/src/demo_nft_marketplace/handlers/on_swap.py` & `dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/handlers/on_swap.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-import demo_nft_marketplace.models as models
-from demo_nft_marketplace.types.hen_minter.tezos_parameters.swap import SwapParameter
-from demo_nft_marketplace.types.hen_minter.tezos_storage import HenMinterStorage
+import demo_tezos_nft_marketplace.models as models
+from demo_tezos_nft_marketplace.types.hen_minter.tezos_parameters.swap import SwapParameter
+from demo_tezos_nft_marketplace.types.hen_minter.tezos_storage import HenMinterStorage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_swap(
     ctx: HandlerContext,
-    swap: TzktTransaction[SwapParameter, HenMinterStorage],
+    swap: TezosTransaction[SwapParameter, HenMinterStorage],
 ) -> None:
     holder, _ = await models.Holder.get_or_create(address=swap.data.sender_address)
     swap_model = models.Swap(
         id=int(swap.storage.swap_id) - 1,
         creator=holder,
         price=swap.parameter.xtz_per_objkt,
         amount=swap.parameter.objkt_amount,
```

### Comparing `dipdup-7.5.7/src/demo_nft_marketplace/models/__init__.py` & `dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/models/__init__.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_nft_marketplace/pyproject.toml` & `dipdup-8.0.0a1/src/demo_evm_uniswap/pyproject.toml`

 * *Files 10% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Generated by DipDup 7.5.7
+# generated by DipDup 8.0.0a1
 [project]
-name = "demo_nft_marketplace"
+name = "demo_evm_uniswap"
 version = "0.0.1"
-description = "NFT marketplace (hic at nunc)"
+description = "Uniswap V3 pools, positions, etc. (advanced, uses TimescaleDB)"
 license = { text = "MIT" }
 authors = [
     { name = "John Doe", email = "john_doe@example.com" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 dependencies = [
-    "dipdup>=7,<8",
+    "dipdup>=8,<9",
 ]
 
 [tool.pdm.dev-dependencies]
 dev = [
     "black",
     "ruff",
     "mypy",
@@ -30,27 +30,27 @@
 mypy = {cmd = "make mypy", help = "Lint with mypy"}
 image = {cmd = "make image", help = "Build Docker image"}
 up = {cmd = "make up", help = "Run Compose stack"}
 down = {cmd = "make down", help = "Stop Compose stack"}
 
 [tool.black]
 line-length = 120
-target-version = ['py311']
+target-version = ['py312']
 skip-string-normalization = true
 
 [tool.ruff]
 line-length = 120
-target-version = 'py311'
+target-version = 'py312'
 
 [tool.ruff.lint]
 extend-select = ["B", "C4", "FA", "G", "I", "PTH", "Q", "RET", "RUF", "TCH", "UP"]
 flake8-quotes = { inline-quotes = "single", multiline-quotes = "double" }
 isort = { force-single-line = true}
 
 [tool.mypy]
-python_version = "3.11"
+python_version = "3.12"
 plugins = ["pydantic.mypy"]
 strict = false
 
 [build-system]
 requires = ["pdm-backend"]
 build-backend = "pdm.backend"
```

### Comparing `dipdup-7.5.7/src/demo_nft_marketplace/types/hen_minter/tezos_storage.py` & `dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/types/hen_minter/tezos_storage.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,38 +1,37 @@
-# generated by datamodel-codegen:
-#   filename:  tezos_storage.json
+# generated by DipDup 8.0.0a1
 
 from __future__ import annotations
 
 from pydantic import BaseModel
-from pydantic import Extra
+from pydantic import ConfigDict
 
 
 class Royalties(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
+    model_config = ConfigDict(
+        extra='forbid',
+    )
     issuer: str
     royalties: str
 
 
 class Swaps(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
+    model_config = ConfigDict(
+        extra='forbid',
+    )
     issuer: str
     objkt_amount: str
     objkt_id: str
     xtz_per_objkt: str
 
 
 class HenMinterStorage(BaseModel):
-    class Config:
-        extra = Extra.forbid
-
+    model_config = ConfigDict(
+        extra='forbid',
+    )
     curate: str
     genesis: str
     hdao: str
     locked: bool
     manager: str
     metadata: dict[str, str]
     objkt: str
```

### Comparing `dipdup-7.5.7/src/demo_raw/Makefile` & `dipdup-8.0.0a1/src/demo_tezos_head/Makefile`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 .PHONY: $(MAKECMDGOALS)
 MAKEFLAGS += --no-print-directory
 ##
 ##   DipDup developer tools
 ##
-PACKAGE=demo_raw
+PACKAGE=demo_tezos_head
 TAG=latest
 COMPOSE=deploy/compose.yaml
 
 help:           ## Show this help (default)
 	@grep -Fh "##" $(MAKEFILE_LIST) | grep -Fv grep -F | sed -e 's/\\$$//' | sed -e 's/##//'
 
 all:            ## Run an entire CI pipeline
```

### Comparing `dipdup-7.5.7/src/demo_raw/README.md` & `dipdup-8.0.0a1/src/demo_evm_events/README.md`

 * *Files 9% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# demo_raw
+# demo_evm_events
 
-Process raw operations without filtering and typed payloads
+ERC-20 token transfers (from event logs)
 
 ## Installation
 
 This project is based on [DipDup](https://dipdup.io), a framework for building featureful dapps.
 
-You need a Linux/macOS system with Python 3.11 installed. To install DipDup with pipx for the current user:
+You need a Linux/macOS system with Python 3.12 installed. To install DipDup with pipx or use our installer:
 
 ```shell
-curl -Lsf https://dipdup.io/install.py | python3
+curl -Lsf https://dipdup.io/install.py | python3.12
 ```
 
 See the [Installation](https://dipdup.io/docs/installation) page for all options.
 
 ## Usage
 
 Run the indexer in memory:
```

### Comparing `dipdup-7.5.7/src/demo_raw/configs/dipdup.compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/configs/dipdup.compose.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_raw/configs/dipdup.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_raw/configs/dipdup.swarm.yaml`

 * *Files 15% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 database:
   kind: postgres
-  host: ${POSTGRES_HOST:-demo_raw_db}
+  host: ${POSTGRES_HOST:-demo_tezos_raw_db}
   port: 5432
   user: ${POSTGRES_USER:-dipdup}
   password: ${POSTGRES_PASSWORD}
   database: ${POSTGRES_DB:-dipdup}
 
 hasura:
-  url: http://${HASURA_HOST:-demo_raw_hasura}:8080
+  url: http://${HASURA_HOST:-demo_tezos_raw_hasura}:8080
   admin_secret: ${HASURA_SECRET}
   allow_aggregations: ${HASURA_ALLOW_AGGREGATIONS:-false}
   select_limit: ${HASURA_SELECT_LIMIT:-100}
   camel_case: ${HASURA_CAMEL_CASE:-true}
 
 sentry:
   dsn: ${SENTRY_DSN:-''}
```

### Comparing `dipdup-7.5.7/src/demo_raw/configs/replay.yaml` & `dipdup-8.0.0a1/src/demo_tezos_big_maps/configs/replay.yaml`

 * *Files 13% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 # To refresh existing project run `dipdup init --base --force` after modifying this file.
 # To generate a new project from this replay run `dipdup new --replay <path_to_file>`.
 #
-spec_version: 2.0
+spec_version: 3.0
 replay:
-  dipdup_version: 7
-  template: demo_raw
-  package: demo_raw
+  dipdup_version: 8
+  template: demo_tezos_big_maps
+  package: demo_tezos_big_maps
   version: 0.0.1
-  description: Process raw operations without filtering and typed payloads
+  description: Indexing specific big maps
   license: MIT
   name: John Doe
   email: john_doe@example.com
   postgres_image: postgres:15
   postgres_data_path: /var/lib/postgresql/data
   hasura_image: hasura/graphql-engine:latest
   line_length: 120
```

### Comparing `dipdup-7.5.7/src/demo_raw/deploy/compose.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_events/deploy/compose.swarm.yaml`

 * *Files 7% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 version: "3.8"
-name: demo_raw
+name: demo_tezos_events
 
 services:
   dipdup:
-    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-7}
+    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-8}
     depends_on:
       - db
       - hasura
     command: ["-c", "dipdup.yaml", "-c", "configs/dipdup.swarm.yaml", "run"]
     env_file: .env
     networks:
       - internal
@@ -51,15 +51,15 @@
     logging: *logging
 
   hasura:
     image: hasura/graphql-engine:latest
     depends_on:
       - db
     environment:
-      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_raw_db:5432/dipdup
+      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_tezos_events_db:5432/dipdup
       - HASURA_GRAPHQL_ADMIN_SECRET=${HASURA_SECRET}
       - HASURA_GRAPHQL_ENABLE_CONSOLE=true
       - HASURA_GRAPHQL_DEV_MODE=false
       - HASURA_GRAPHQL_LOG_LEVEL=warn
       - HASURA_GRAPHQL_ENABLE_TELEMETRY=false
       - HASURA_GRAPHQL_UNAUTHORIZED_ROLE=user
       - HASURA_GRAPHQL_STRINGIFY_NUMERIC_TYPES=true
```

### Comparing `dipdup-7.5.7/src/demo_raw/deploy/compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_dao/deploy/compose.yaml`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 version: "3.8"
-name: demo_raw
+name: demo_tezos_dao
 
 services:
   dipdup:
     build:
       context: ..
       dockerfile: deploy/Dockerfile
     restart: always
```

### Comparing `dipdup-7.5.7/src/demo_raw/pyproject.toml` & `dipdup-8.0.0a1/src/demo_tezos_auction/pyproject.toml`

 * *Files 19% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Generated by DipDup 7.5.7
+# generated by DipDup 8.0.0a1
 [project]
-name = "demo_raw"
+name = "demo_tezos_auction"
 version = "0.0.1"
-description = "Process raw operations without filtering and typed payloads"
+description = "NFT marketplace (TzColors)"
 license = { text = "MIT" }
 authors = [
     { name = "John Doe", email = "john_doe@example.com" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 dependencies = [
-    "dipdup>=7,<8",
+    "dipdup>=8,<9",
 ]
 
 [tool.pdm.dev-dependencies]
 dev = [
     "black",
     "ruff",
     "mypy",
@@ -30,27 +30,27 @@
 mypy = {cmd = "make mypy", help = "Lint with mypy"}
 image = {cmd = "make image", help = "Build Docker image"}
 up = {cmd = "make up", help = "Run Compose stack"}
 down = {cmd = "make down", help = "Stop Compose stack"}
 
 [tool.black]
 line-length = 120
-target-version = ['py311']
+target-version = ['py312']
 skip-string-normalization = true
 
 [tool.ruff]
 line-length = 120
-target-version = 'py311'
+target-version = 'py312'
 
 [tool.ruff.lint]
 extend-select = ["B", "C4", "FA", "G", "I", "PTH", "Q", "RET", "RUF", "TCH", "UP"]
 flake8-quotes = { inline-quotes = "single", multiline-quotes = "double" }
 isort = { force-single-line = true}
 
 [tool.mypy]
-python_version = "3.11"
+python_version = "3.12"
 plugins = ["pydantic.mypy"]
 strict = false
 
 [build-system]
 requires = ["pdm-backend"]
 build-backend = "pdm.backend"
```

### Comparing `dipdup-7.5.7/src/demo_token/Makefile` & `dipdup-8.0.0a1/src/demo_tezos_token/Makefile`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 .PHONY: $(MAKECMDGOALS)
 MAKEFLAGS += --no-print-directory
 ##
 ##   DipDup developer tools
 ##
-PACKAGE=demo_token
+PACKAGE=demo_tezos_token
 TAG=latest
 COMPOSE=deploy/compose.yaml
 
 help:           ## Show this help (default)
 	@grep -Fh "##" $(MAKEFILE_LIST) | grep -Fv grep -F | sed -e 's/\\$$//' | sed -e 's/##//'
 
 all:            ## Run an entire CI pipeline
```

### Comparing `dipdup-7.5.7/src/demo_token/README.md` & `dipdup-8.0.0a1/src/demo_tezos_auction/README.md`

 * *Files 12% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# demo_token
+# demo_tezos_auction
 
-FA1.2 token contract operations
+NFT marketplace (TzColors)
 
 ## Installation
 
 This project is based on [DipDup](https://dipdup.io), a framework for building featureful dapps.
 
-You need a Linux/macOS system with Python 3.11 installed. To install DipDup with pipx for the current user:
+You need a Linux/macOS system with Python 3.12 installed. To install DipDup with pipx or use our installer:
 
 ```shell
-curl -Lsf https://dipdup.io/install.py | python3
+curl -Lsf https://dipdup.io/install.py | python3.12
 ```
 
 See the [Installation](https://dipdup.io/docs/installation) page for all options.
 
 ## Usage
 
 Run the indexer in memory:
```

### Comparing `dipdup-7.5.7/src/demo_token/configs/dipdup.compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_raw/configs/dipdup.compose.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_token/configs/dipdup.swarm.yaml` & `dipdup-8.0.0a1/src/demo_evm_uniswap/configs/dipdup.swarm.yaml`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 database:
   kind: postgres
-  host: ${POSTGRES_HOST:-demo_token_db}
+  host: ${POSTGRES_HOST:-demo_evm_uniswap_db}
   port: 5432
   user: ${POSTGRES_USER:-dipdup}
   password: ${POSTGRES_PASSWORD}
   database: ${POSTGRES_DB:-dipdup}
 
 hasura:
-  url: http://${HASURA_HOST:-demo_token_hasura}:8080
+  url: http://${HASURA_HOST:-demo_evm_uniswap_hasura}:8080
   admin_secret: ${HASURA_SECRET}
   allow_aggregations: ${HASURA_ALLOW_AGGREGATIONS:-false}
   select_limit: ${HASURA_SELECT_LIMIT:-100}
   camel_case: ${HASURA_CAMEL_CASE:-true}
 
 sentry:
   dsn: ${SENTRY_DSN:-''}
```

### Comparing `dipdup-7.5.7/src/demo_token/configs/replay.yaml` & `dipdup-8.0.0a1/src/demo_evm_uniswap/configs/replay.yaml`

 * *Files 22% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 # To refresh existing project run `dipdup init --base --force` after modifying this file.
 # To generate a new project from this replay run `dipdup new --replay <path_to_file>`.
 #
-spec_version: 2.0
+spec_version: 3.0
 replay:
-  dipdup_version: 7
-  template: demo_token
-  package: demo_token
+  dipdup_version: 8
+  template: demo_evm_uniswap
+  package: demo_evm_uniswap
   version: 0.0.1
-  description: FA1.2 token contract operations
+  description: Uniswap V3 pools, positions, etc. (advanced, uses TimescaleDB)
   license: MIT
   name: John Doe
   email: john_doe@example.com
-  postgres_image: postgres:15
-  postgres_data_path: /var/lib/postgresql/data
+  postgres_image: timescale/timescaledb-ha:pg15
+  postgres_data_path: /home/postgres/pgdata/data
   hasura_image: hasura/graphql-engine:latest
   line_length: 120
   package_manager: pdm
```

### Comparing `dipdup-7.5.7/src/demo_token/deploy/compose.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_token_transfers/deploy/compose.swarm.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 version: "3.8"
-name: demo_token
+name: demo_tezos_token_transfers
 
 services:
   dipdup:
-    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-7}
+    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-8}
     depends_on:
       - db
       - hasura
     command: ["-c", "dipdup.yaml", "-c", "configs/dipdup.swarm.yaml", "run"]
     env_file: .env
     networks:
       - internal
@@ -51,15 +51,15 @@
     logging: *logging
 
   hasura:
     image: hasura/graphql-engine:latest
     depends_on:
       - db
     environment:
-      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_token_db:5432/dipdup
+      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_tezos_token_transfers_db:5432/dipdup
       - HASURA_GRAPHQL_ADMIN_SECRET=${HASURA_SECRET}
       - HASURA_GRAPHQL_ENABLE_CONSOLE=true
       - HASURA_GRAPHQL_DEV_MODE=false
       - HASURA_GRAPHQL_LOG_LEVEL=warn
       - HASURA_GRAPHQL_ENABLE_TELEMETRY=false
       - HASURA_GRAPHQL_UNAUTHORIZED_ROLE=user
       - HASURA_GRAPHQL_STRINGIFY_NUMERIC_TYPES=true
```

### Comparing `dipdup-7.5.7/src/demo_token/deploy/compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_big_maps/deploy/compose.yaml`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 version: "3.8"
-name: demo_token
+name: demo_tezos_big_maps
 
 services:
   dipdup:
     build:
       context: ..
       dockerfile: deploy/Dockerfile
     restart: always
```

### Comparing `dipdup-7.5.7/src/demo_token/dipdup.yaml` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_token/dipdup.yaml.j2`

 * *Files 12% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-spec_version: 2.0
-package: demo_token
+spec_version: 3.0
+package: {{ project.package }}
 
 contracts:
   tzbtc_mainnet:
     kind: tezos
     address: KT1PWx2mnDueood7fEmfbBDKx1D9BAnnXitn
     typename: tzbtc
 
@@ -17,20 +17,21 @@
     template: tzbtc_holders
     values:
       contract: tzbtc_mainnet
       datasource: tzkt_mainnet
 
 templates:
   tzbtc_holders:
-    kind: tezos.tzkt.operations
-    datasource: <datasource>
+    kind: tezos.operations
+    datasources:
+      - <datasource>
     contracts:
       - <contract>
     handlers:
       - callback: on_transfer
         pattern:
           - destination: <contract>
             entrypoint: transfer
       - callback: on_mint
         pattern:
           - destination: <contract>
-            entrypoint: mint
+            entrypoint: mint
```

### Comparing `dipdup-7.5.7/src/demo_token/handlers/on_mint.py` & `dipdup-8.0.0a1/src/demo_tezos_token/handlers/on_mint.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from decimal import Decimal
 
-from demo_token.handlers.on_balance_update import on_balance_update
-from demo_token.types.tzbtc.tezos_parameters.mint import MintParameter
-from demo_token.types.tzbtc.tezos_storage import TzbtcStorage
+from demo_tezos_token.handlers.on_balance_update import on_balance_update
+from demo_tezos_token.types.tzbtc.tezos_parameters.mint import MintParameter
+from demo_tezos_token.types.tzbtc.tezos_storage import TzbtcStorage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_mint(
     ctx: HandlerContext,
-    mint: TzktTransaction[MintParameter, TzbtcStorage],
+    mint: TezosTransaction[MintParameter, TzbtcStorage],
 ) -> None:
     amount = Decimal(mint.parameter.value) / (10**8)
     await on_balance_update(
         address=mint.parameter.to,
         balance_update=amount,
         timestamp=mint.data.timestamp,
     )
```

### Comparing `dipdup-7.5.7/src/demo_token/handlers/on_transfer.py` & `dipdup-8.0.0a1/src/demo_tezos_token/handlers/on_transfer.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from decimal import Decimal
 
-from demo_token.handlers.on_balance_update import on_balance_update
-from demo_token.types.tzbtc.tezos_parameters.transfer import TransferParameter
-from demo_token.types.tzbtc.tezos_storage import TzbtcStorage
+from demo_tezos_token.handlers.on_balance_update import on_balance_update
+from demo_tezos_token.types.tzbtc.tezos_parameters.transfer import TransferParameter
+from demo_tezos_token.types.tzbtc.tezos_storage import TzbtcStorage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_transfer(
     ctx: HandlerContext,
-    transfer: TzktTransaction[TransferParameter, TzbtcStorage],
+    transfer: TezosTransaction[TransferParameter, TzbtcStorage],
 ) -> None:
     if transfer.parameter.from_ == transfer.parameter.to:
         # NOTE: Internal tzBTC transfer
         return
 
     amount = Decimal(transfer.parameter.value) / (10**8)
     await on_balance_update(
```

### Comparing `dipdup-7.5.7/src/demo_token/pyproject.toml` & `dipdup-8.0.0a1/src/demo_tezos_dao/pyproject.toml`

 * *Files 9% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Generated by DipDup 7.5.7
+# generated by DipDup 8.0.0a1
 [project]
-name = "demo_token"
+name = "demo_tezos_dao"
 version = "0.0.1"
-description = "FA1.2 token contract operations"
+description = "DAO registry (Homebase DAO)"
 license = { text = "MIT" }
 authors = [
     { name = "John Doe", email = "john_doe@example.com" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 dependencies = [
-    "dipdup>=7,<8",
+    "dipdup>=8,<9",
 ]
 
 [tool.pdm.dev-dependencies]
 dev = [
     "black",
     "ruff",
     "mypy",
@@ -30,27 +30,27 @@
 mypy = {cmd = "make mypy", help = "Lint with mypy"}
 image = {cmd = "make image", help = "Build Docker image"}
 up = {cmd = "make up", help = "Run Compose stack"}
 down = {cmd = "make down", help = "Stop Compose stack"}
 
 [tool.black]
 line-length = 120
-target-version = ['py311']
+target-version = ['py312']
 skip-string-normalization = true
 
 [tool.ruff]
 line-length = 120
-target-version = 'py311'
+target-version = 'py312'
 
 [tool.ruff.lint]
 extend-select = ["B", "C4", "FA", "G", "I", "PTH", "Q", "RET", "RUF", "TCH", "UP"]
 flake8-quotes = { inline-quotes = "single", multiline-quotes = "double" }
 isort = { force-single-line = true}
 
 [tool.mypy]
-python_version = "3.11"
+python_version = "3.12"
 plugins = ["pydantic.mypy"]
 strict = false
 
 [build-system]
 requires = ["pdm-backend"]
 build-backend = "pdm.backend"
```

### Comparing `dipdup-7.5.7/src/demo_token_balances/Makefile` & `dipdup-8.0.0a1/src/demo_tezos_events/Makefile`

 * *Files 15% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 .PHONY: $(MAKECMDGOALS)
 MAKEFLAGS += --no-print-directory
 ##
 ##   DipDup developer tools
 ##
-PACKAGE=demo_token_balances
+PACKAGE=demo_tezos_events
 TAG=latest
 COMPOSE=deploy/compose.yaml
 
 help:           ## Show this help (default)
 	@grep -Fh "##" $(MAKEFILE_LIST) | grep -Fv grep -F | sed -e 's/\\$$//' | sed -e 's/##//'
 
 all:            ## Run an entire CI pipeline
```

### Comparing `dipdup-7.5.7/src/demo_token_balances/README.md` & `dipdup-8.0.0a1/src/dipdup/projects/base/README.md.j2`

 * *Files 16% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# demo_token_balances
+# {{project.package}}
 
-FA1.2 token balances
+{{project.description}}
 
 ## Installation
 
 This project is based on [DipDup](https://dipdup.io), a framework for building featureful dapps.
 
-You need a Linux/macOS system with Python 3.11 installed. To install DipDup with pipx for the current user:
+You need a Linux/macOS system with Python 3.12 installed. To install DipDup with pipx or use our installer:
 
 ```shell
-curl -Lsf https://dipdup.io/install.py | python3
+curl -Lsf https://dipdup.io/install.py | python3.12
 ```
 
 See the [Installation](https://dipdup.io/docs/installation) page for all options.
 
 ## Usage
 
 Run the indexer in memory:
@@ -37,13 +37,20 @@
 docker-compose up
 ```
 
 ## Development setup
 
 To set up the development environment:
 
+{% if project.package_manager == 'pdm' -%}
 ```shell
 pdm install
 $(pdm venv activate)
 ```
+{%- elif project.package_manager == 'poetry' -%}
+```shell
+poetry install
+poetry shell
+```
+{%- endif %}
 
-Run `make all` to run full CI check or `make help` to see other available commands.
+Run `make all` to run full CI check or `make help` to see other available commands.
```

### Comparing `dipdup-7.5.7/src/demo_token_balances/configs/dipdup.compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_token/configs/dipdup.compose.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_token_balances/configs/dipdup.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_token_balances/configs/dipdup.swarm.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 database:
   kind: postgres
-  host: ${POSTGRES_HOST:-demo_token_balances_db}
+  host: ${POSTGRES_HOST:-demo_tezos_token_balances_db}
   port: 5432
   user: ${POSTGRES_USER:-dipdup}
   password: ${POSTGRES_PASSWORD}
   database: ${POSTGRES_DB:-dipdup}
 
 hasura:
-  url: http://${HASURA_HOST:-demo_token_balances_hasura}:8080
+  url: http://${HASURA_HOST:-demo_tezos_token_balances_hasura}:8080
   admin_secret: ${HASURA_SECRET}
   allow_aggregations: ${HASURA_ALLOW_AGGREGATIONS:-false}
   select_limit: ${HASURA_SELECT_LIMIT:-100}
   camel_case: ${HASURA_CAMEL_CASE:-true}
 
 sentry:
   dsn: ${SENTRY_DSN:-''}
```

### Comparing `dipdup-7.5.7/src/demo_token_balances/configs/replay.yaml` & `dipdup-8.0.0a1/src/demo_tezos_token_balances/configs/replay.yaml`

 * *Files 4% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # To refresh existing project run `dipdup init --base --force` after modifying this file.
 # To generate a new project from this replay run `dipdup new --replay <path_to_file>`.
 #
-spec_version: 2.0
+spec_version: 3.0
 replay:
-  dipdup_version: 7
-  template: demo_token_balances
-  package: demo_token_balances
+  dipdup_version: 8
+  template: demo_tezos_token_balances
+  package: demo_tezos_token_balances
   version: 0.0.1
   description: FA1.2 token balances
   license: MIT
   name: John Doe
   email: john_doe@example.com
   postgres_image: postgres:15
   postgres_data_path: /var/lib/postgresql/data
```

### Comparing `dipdup-7.5.7/src/demo_token_balances/deploy/compose.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_token/deploy/compose.swarm.yaml`

 * *Files 7% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 version: "3.8"
-name: demo_token_balances
+name: demo_tezos_token
 
 services:
   dipdup:
-    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-7}
+    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-8}
     depends_on:
       - db
       - hasura
     command: ["-c", "dipdup.yaml", "-c", "configs/dipdup.swarm.yaml", "run"]
     env_file: .env
     networks:
       - internal
@@ -51,15 +51,15 @@
     logging: *logging
 
   hasura:
     image: hasura/graphql-engine:latest
     depends_on:
       - db
     environment:
-      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_token_balances_db:5432/dipdup
+      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_tezos_token_db:5432/dipdup
       - HASURA_GRAPHQL_ADMIN_SECRET=${HASURA_SECRET}
       - HASURA_GRAPHQL_ENABLE_CONSOLE=true
       - HASURA_GRAPHQL_DEV_MODE=false
       - HASURA_GRAPHQL_LOG_LEVEL=warn
       - HASURA_GRAPHQL_ENABLE_TELEMETRY=false
       - HASURA_GRAPHQL_UNAUTHORIZED_ROLE=user
       - HASURA_GRAPHQL_STRINGIFY_NUMERIC_TYPES=true
```

### Comparing `dipdup-7.5.7/src/demo_token_balances/deploy/compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_etherlink/deploy/compose.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 version: "3.8"
-name: demo_token_balances
+name: demo_tezos_etherlink
 
 services:
   dipdup:
     build:
       context: ..
       dockerfile: deploy/Dockerfile
     restart: always
```

### Comparing `dipdup-7.5.7/src/demo_token_balances/pyproject.toml` & `dipdup-8.0.0a1/src/demo_tezos_big_maps/pyproject.toml`

 * *Files 17% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Generated by DipDup 7.5.7
+# generated by DipDup 8.0.0a1
 [project]
-name = "demo_token_balances"
+name = "demo_tezos_big_maps"
 version = "0.0.1"
-description = "FA1.2 token balances"
+description = "Indexing specific big maps"
 license = { text = "MIT" }
 authors = [
     { name = "John Doe", email = "john_doe@example.com" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 dependencies = [
-    "dipdup>=7,<8",
+    "dipdup>=8,<9",
 ]
 
 [tool.pdm.dev-dependencies]
 dev = [
     "black",
     "ruff",
     "mypy",
@@ -30,27 +30,27 @@
 mypy = {cmd = "make mypy", help = "Lint with mypy"}
 image = {cmd = "make image", help = "Build Docker image"}
 up = {cmd = "make up", help = "Run Compose stack"}
 down = {cmd = "make down", help = "Stop Compose stack"}
 
 [tool.black]
 line-length = 120
-target-version = ['py311']
+target-version = ['py312']
 skip-string-normalization = true
 
 [tool.ruff]
 line-length = 120
-target-version = 'py311'
+target-version = 'py312'
 
 [tool.ruff.lint]
 extend-select = ["B", "C4", "FA", "G", "I", "PTH", "Q", "RET", "RUF", "TCH", "UP"]
 flake8-quotes = { inline-quotes = "single", multiline-quotes = "double" }
 isort = { force-single-line = true}
 
 [tool.mypy]
-python_version = "3.11"
+python_version = "3.12"
 plugins = ["pydantic.mypy"]
 strict = false
 
 [build-system]
 requires = ["pdm-backend"]
 build-backend = "pdm.backend"
```

### Comparing `dipdup-7.5.7/src/demo_token_transfers/Makefile` & `dipdup-8.0.0a1/src/demo_tezos_token_transfers/Makefile`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 .PHONY: $(MAKECMDGOALS)
 MAKEFLAGS += --no-print-directory
 ##
 ##   DipDup developer tools
 ##
-PACKAGE=demo_token_transfers
+PACKAGE=demo_tezos_token_transfers
 TAG=latest
 COMPOSE=deploy/compose.yaml
 
 help:           ## Show this help (default)
 	@grep -Fh "##" $(MAKEFILE_LIST) | grep -Fv grep -F | sed -e 's/\\$$//' | sed -e 's/##//'
 
 all:            ## Run an entire CI pipeline
```

### Comparing `dipdup-7.5.7/src/demo_token_transfers/README.md` & `dipdup-8.0.0a1/src/demo_tezos_token_transfers/README.md`

 * *Files 14% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# demo_token_transfers
+# demo_tezos_token_transfers
 
 FA1.2 token transfers
 
 ## Installation
 
 This project is based on [DipDup](https://dipdup.io), a framework for building featureful dapps.
 
-You need a Linux/macOS system with Python 3.11 installed. To install DipDup with pipx for the current user:
+You need a Linux/macOS system with Python 3.12 installed. To install DipDup with pipx or use our installer:
 
 ```shell
-curl -Lsf https://dipdup.io/install.py | python3
+curl -Lsf https://dipdup.io/install.py | python3.12
 ```
 
 See the [Installation](https://dipdup.io/docs/installation) page for all options.
 
 ## Usage
 
 Run the indexer in memory:
```

### Comparing `dipdup-7.5.7/src/demo_token_transfers/configs/dipdup.compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_token_balances/configs/dipdup.compose.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_token_transfers/configs/dipdup.swarm.yaml` & `dipdup-8.0.0a1/src/demo_tezos_token/configs/dipdup.swarm.yaml`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 database:
   kind: postgres
-  host: ${POSTGRES_HOST:-demo_token_transfers_db}
+  host: ${POSTGRES_HOST:-demo_tezos_token_db}
   port: 5432
   user: ${POSTGRES_USER:-dipdup}
   password: ${POSTGRES_PASSWORD}
   database: ${POSTGRES_DB:-dipdup}
 
 hasura:
-  url: http://${HASURA_HOST:-demo_token_transfers_hasura}:8080
+  url: http://${HASURA_HOST:-demo_tezos_token_hasura}:8080
   admin_secret: ${HASURA_SECRET}
   allow_aggregations: ${HASURA_ALLOW_AGGREGATIONS:-false}
   select_limit: ${HASURA_SELECT_LIMIT:-100}
   camel_case: ${HASURA_CAMEL_CASE:-true}
 
 sentry:
   dsn: ${SENTRY_DSN:-''}
```

### Comparing `dipdup-7.5.7/src/demo_token_transfers/configs/replay.yaml` & `dipdup-8.0.0a1/src/demo_tezos_token_transfers/configs/replay.yaml`

 * *Files 4% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # To refresh existing project run `dipdup init --base --force` after modifying this file.
 # To generate a new project from this replay run `dipdup new --replay <path_to_file>`.
 #
-spec_version: 2.0
+spec_version: 3.0
 replay:
-  dipdup_version: 7
-  template: demo_token_transfers
-  package: demo_token_transfers
+  dipdup_version: 8
+  template: demo_tezos_token_transfers
+  package: demo_tezos_token_transfers
   version: 0.0.1
   description: FA1.2 token transfers
   license: MIT
   name: John Doe
   email: john_doe@example.com
   postgres_image: postgres:15
   postgres_data_path: /var/lib/postgresql/data
```

### Comparing `dipdup-7.5.7/src/demo_token_transfers/deploy/compose.swarm.yaml` & `dipdup-8.0.0a1/src/dipdup/projects/base/deploy/compose.swarm.yaml.j2`

 * *Files 10% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 version: "3.8"
-name: demo_token_transfers
+name: {{ project.package }}
 
 services:
   dipdup:
-    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-7}
+    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-{{ project.dipdup_version }}}
     depends_on:
       - db
       - hasura
     command: ["-c", "dipdup.yaml", "-c", "configs/dipdup.swarm.yaml", "run"]
     env_file: .env
     networks:
       - internal
@@ -25,17 +25,17 @@
       driver: "json-file"
       options:
         max-size: "10m"
         max-file: "10"
         tag: "\{\{.Name\}\}.\{\{.ImageID\}\}"
 
   db:
-    image: postgres:15
+    image: {{ project.postgres_image }}
     volumes:
-      - db:/var/lib/postgresql/data
+      - db:{{ project.postgres_data_path }}
     env_file: .env
     environment:
       - POSTGRES_USER=dipdup
       - POSTGRES_DB=dipdup
       - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
     healthcheck:
       test: ["CMD-SHELL", "pg_isready -U postgres"]
@@ -47,19 +47,19 @@
     deploy:
       mode: replicated
       replicas: 1
       placement: *placement
     logging: *logging
 
   hasura:
-    image: hasura/graphql-engine:latest
+    image: {{ project.hasura_image }}
     depends_on:
       - db
     environment:
-      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_token_transfers_db:5432/dipdup
+      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@{{ project.package }}_db:5432/dipdup
       - HASURA_GRAPHQL_ADMIN_SECRET=${HASURA_SECRET}
       - HASURA_GRAPHQL_ENABLE_CONSOLE=true
       - HASURA_GRAPHQL_DEV_MODE=false
       - HASURA_GRAPHQL_LOG_LEVEL=warn
       - HASURA_GRAPHQL_ENABLE_TELEMETRY=false
       - HASURA_GRAPHQL_UNAUTHORIZED_ROLE=user
       - HASURA_GRAPHQL_STRINGIFY_NUMERIC_TYPES=true
@@ -85,8 +85,8 @@
   db:
 
 networks:
   internal:
   traefik-public:
     external: true
   prometheus-private:
-    external: true
+    external: true
```

### Comparing `dipdup-7.5.7/src/demo_token_transfers/deploy/compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_factories/deploy/compose.yaml`

 * *Files 11% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 version: "3.8"
-name: demo_token_transfers
+name: demo_tezos_factories
 
 services:
   dipdup:
     build:
       context: ..
       dockerfile: deploy/Dockerfile
     restart: always
```

### Comparing `dipdup-7.5.7/src/demo_token_transfers/handlers/on_balance_update.py` & `dipdup-8.0.0a1/src/demo_tezos_token_transfers/handlers/on_balance_update.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from datetime import datetime
 from decimal import Decimal
 from decimal import InvalidOperation
 
-import demo_token_transfers.models as models
+import demo_tezos_token_transfers.models as models
 
 
 async def on_balance_update(address: str, balance_update: Decimal, timestamp: datetime) -> None:
     try:
         holder, _ = await models.Holder.get_or_create(address=address)
         holder.balance += balance_update
         holder.turnover += abs(balance_update)
```

### Comparing `dipdup-7.5.7/src/demo_token_transfers/handlers/on_token_transfer.py` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_token_transfers/handlers/on_token_transfer.py.j2`

 * *Files 5% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 from decimal import Decimal
 from decimal import InvalidOperation
 
-from demo_token_transfers.handlers.on_balance_update import on_balance_update
+from {{project.package}}.handlers.on_balance_update import on_balance_update
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTokenTransferData
+from dipdup.models.tezos import TezosTokenTransferData
 
 
 async def on_token_transfer(
     ctx: HandlerContext,
-    token_transfer: TzktTokenTransferData,
+    token_transfer: TezosTokenTransferData,
 ) -> None:
     from_, to = token_transfer.from_address, token_transfer.to_address
     if not from_ or not to or from_ == to:
         return
     try:
         amount = Decimal(token_transfer.amount or 0) / (10**8)
     except InvalidOperation:
         return
     if not amount:
         return
 
     await on_balance_update(address=from_, balance_update=-amount, timestamp=token_transfer.timestamp)
-    await on_balance_update(address=to, balance_update=amount, timestamp=token_transfer.timestamp)
+    await on_balance_update(address=to, balance_update=amount, timestamp=token_transfer.timestamp)
```

### Comparing `dipdup-7.5.7/src/demo_token_transfers/pyproject.toml` & `dipdup-8.0.0a1/src/demo_tezos_token_transfers/pyproject.toml`

 * *Files 5% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Generated by DipDup 7.5.7
+# generated by DipDup 8.0.0a1
 [project]
-name = "demo_token_transfers"
+name = "demo_tezos_token_transfers"
 version = "0.0.1"
 description = "FA1.2 token transfers"
 license = { text = "MIT" }
 authors = [
     { name = "John Doe", email = "john_doe@example.com" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 dependencies = [
-    "dipdup>=7,<8",
+    "dipdup>=8,<9",
 ]
 
 [tool.pdm.dev-dependencies]
 dev = [
     "black",
     "ruff",
     "mypy",
@@ -30,27 +30,27 @@
 mypy = {cmd = "make mypy", help = "Lint with mypy"}
 image = {cmd = "make image", help = "Build Docker image"}
 up = {cmd = "make up", help = "Run Compose stack"}
 down = {cmd = "make down", help = "Stop Compose stack"}
 
 [tool.black]
 line-length = 120
-target-version = ['py311']
+target-version = ['py312']
 skip-string-normalization = true
 
 [tool.ruff]
 line-length = 120
-target-version = 'py311'
+target-version = 'py312'
 
 [tool.ruff.lint]
 extend-select = ["B", "C4", "FA", "G", "I", "PTH", "Q", "RET", "RUF", "TCH", "UP"]
 flake8-quotes = { inline-quotes = "single", multiline-quotes = "double" }
 isort = { force-single-line = true}
 
 [tool.mypy]
-python_version = "3.11"
+python_version = "3.12"
 plugins = ["pydantic.mypy"]
 strict = false
 
 [build-system]
 requires = ["pdm-backend"]
 build-backend = "pdm.backend"
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/Makefile` & `dipdup-8.0.0a1/src/dipdup/projects/base/Makefile.j2`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 .PHONY: $(MAKECMDGOALS)
 MAKEFLAGS += --no-print-directory
 ##
 ##   DipDup developer tools
 ##
-PACKAGE=demo_uniswap
+PACKAGE={{ project.package }}
 TAG=latest
 COMPOSE=deploy/compose.yaml
 
 help:           ## Show this help (default)
 	@grep -Fh "##" $(MAKEFILE_LIST) | grep -Fv grep -F | sed -e 's/\\$$//' | sed -e 's/##//'
 
 all:            ## Run an entire CI pipeline
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/README.md` & `dipdup-8.0.0a1/src/demo_evm_uniswap/README.md`

 * *Files 4% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# demo_uniswap
+# demo_evm_uniswap
 
 Uniswap V3 pools, positions, etc. (advanced, uses TimescaleDB)
 
 ## Installation
 
 This project is based on [DipDup](https://dipdup.io), a framework for building featureful dapps.
 
-You need a Linux/macOS system with Python 3.11 installed. To install DipDup with pipx for the current user:
+You need a Linux/macOS system with Python 3.12 installed. To install DipDup with pipx or use our installer:
 
 ```shell
-curl -Lsf https://dipdup.io/install.py | python3
+curl -Lsf https://dipdup.io/install.py | python3.12
 ```
 
 See the [Installation](https://dipdup.io/docs/installation) page for all options.
 
 ## Usage
 
 Run the indexer in memory:
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/abi/erc20/ERC20.json` & `dipdup-8.0.0a1/src/demo_evm_uniswap/abi/erc20/ERC20.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_uniswap/abi/factory/abi.json` & `dipdup-8.0.0a1/src/demo_evm_uniswap/abi/factory/abi.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_uniswap/abi/pool/abi.json` & `dipdup-8.0.0a1/src/demo_evm_uniswap/abi/pool/abi.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_uniswap/abi/position_manager/abi.json` & `dipdup-8.0.0a1/src/demo_evm_uniswap/abi/position_manager/abi.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_uniswap/configs/dipdup.compose.yaml` & `dipdup-8.0.0a1/src/demo_tezos_token_transfers/configs/dipdup.compose.yaml`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_uniswap/configs/dipdup.swarm.yaml` & `dipdup-8.0.0a1/src/dipdup/projects/base/configs/dipdup.swarm.yaml.j2`

 * *Files 8% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 database:
   kind: postgres
-  host: ${POSTGRES_HOST:-demo_uniswap_db}
+  host: ${POSTGRES_HOST:-{{ project.package }}_db}
   port: 5432
   user: ${POSTGRES_USER:-dipdup}
   password: ${POSTGRES_PASSWORD}
   database: ${POSTGRES_DB:-dipdup}
 
 hasura:
-  url: http://${HASURA_HOST:-demo_uniswap_hasura}:8080
+  url: http://${HASURA_HOST:-{{ project.package }}_hasura}:8080
   admin_secret: ${HASURA_SECRET}
   allow_aggregations: ${HASURA_ALLOW_AGGREGATIONS:-false}
   select_limit: ${HASURA_SELECT_LIMIT:-100}
   camel_case: ${HASURA_CAMEL_CASE:-true}
 
 sentry:
   dsn: ${SENTRY_DSN:-''}
   environment: ${SENTRY_ENVIRONMENT:-''}
 
 prometheus:
   host: 0.0.0.0
 
 api:
-  host: 0.0.0.0
+  host: 0.0.0.0
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/deploy/.env.default` & `dipdup-8.0.0a1/src/demo_evm_uniswap/deploy/swarm.env.default`

 * *Files 13% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 # This env file was generated automatically by DipDup. Do not edit it!
 # Create a copy with .env extension, fill it with your values and run DipDup with `--env-file` option.
 #
 ETHERSCAN_API_KEY=''
 ETHERSCAN_URL=https://api.etherscan.io/api
-HASURA_ALLOW_AGGREGATIONS=true
+HASURA_ALLOW_AGGREGATIONS=false
 HASURA_CAMEL_CASE=true
-HASURA_HOST=hasura
+HASURA_HOST=demo_evm_uniswap_hasura
 HASURA_SECRET=
-HASURA_SELECT_LIMIT=10000
+HASURA_SELECT_LIMIT=100
 NODE_API_KEY=''
 NODE_URL=https://eth-mainnet.g.alchemy.com/v2
 NODE_WS_URL=wss://eth-mainnet.g.alchemy.com/v2
 POSTGRES_DB=dipdup
-POSTGRES_HOST=db
+POSTGRES_HOST=demo_evm_uniswap_db
 POSTGRES_PASSWORD=
 POSTGRES_USER=dipdup
 SENTRY_DSN=''
 SENTRY_ENVIRONMENT=''
 SUBSQUID_URL=https://v2.archive.subsquid.io/network/ethereum-mainnet
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/deploy/compose.swarm.yaml` & `dipdup-8.0.0a1/src/demo_evm_uniswap/deploy/compose.swarm.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 version: "3.8"
-name: demo_uniswap
+name: demo_evm_uniswap
 
 services:
   dipdup:
-    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-7}
+    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-8}
     depends_on:
       - db
       - hasura
     command: ["-c", "dipdup.yaml", "-c", "configs/dipdup.swarm.yaml", "run"]
     env_file: .env
     networks:
       - internal
@@ -51,15 +51,15 @@
     logging: *logging
 
   hasura:
     image: hasura/graphql-engine:latest
     depends_on:
       - db
     environment:
-      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_uniswap_db:5432/dipdup
+      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_evm_uniswap_db:5432/dipdup
       - HASURA_GRAPHQL_ADMIN_SECRET=${HASURA_SECRET}
       - HASURA_GRAPHQL_ENABLE_CONSOLE=true
       - HASURA_GRAPHQL_DEV_MODE=false
       - HASURA_GRAPHQL_LOG_LEVEL=warn
       - HASURA_GRAPHQL_ENABLE_TELEMETRY=false
       - HASURA_GRAPHQL_UNAUTHORIZED_ROLE=user
       - HASURA_GRAPHQL_STRINGIFY_NUMERIC_TYPES=true
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/deploy/compose.yaml` & `dipdup-8.0.0a1/src/demo_evm_uniswap/deploy/compose.yaml`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 version: "3.8"
-name: demo_uniswap
+name: demo_evm_uniswap
 
 services:
   dipdup:
     build:
       context: ..
       dockerfile: deploy/Dockerfile
     restart: always
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/dipdup.yaml` & `dipdup-8.0.0a1/src/demo_evm_uniswap/dipdup.yaml`

 * *Files 9% similar despite different names*

```diff
@@ -1,15 +1,14 @@
-spec_version: 2.0
-package: demo_uniswap
+spec_version: 3.0
+package: demo_evm_uniswap
 
 datasources:
   subsquid:
     kind: evm.subsquid
     url: ${SUBSQUID_URL:-https://v2.archive.subsquid.io/network/ethereum-mainnet}
-    node: evm_node
   etherscan:
     kind: abi.etherscan
     url: ${ETHERSCAN_URL:-https://api.etherscan.io/api}
     api_key: ${ETHERSCAN_API_KEY:-''}
   evm_node:
     kind: evm.node
     url: ${NODE_URL:-https://eth-mainnet.g.alchemy.com/v2}/${NODE_API_KEY:-''}
@@ -27,16 +26,19 @@
   pool:
     kind: evm
     abi: 0x7668b2ea8490955f68f5c33e77fe150066c94fb9
     typename: pool
 
 templates:
   uniswap_v3_factory:
-    kind: evm.subsquid.events
-    datasource: <datasource>
+    kind: evm.events
+    datasources:
+      - <datasource>
+      - etherscan
+      - evm_node
     first_level: 12369521
     handlers:
       - callback: factory.pool_created
         contract: factory
         name: PoolCreated
       - callback: position_manager.increase_liquidity
         contract: position_manager
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/handlers/factory/pool_created.py` & `dipdup-8.0.0a1/src/demo_evm_uniswap/handlers/factory/pool_created.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 from contextlib import suppress
 from typing import cast
 
-from demo_uniswap import models as models
-from demo_uniswap.models.token import WHITELIST_TOKENS
-from demo_uniswap.models.token import ERC20Token
-from demo_uniswap.types.factory.evm_events.pool_created import PoolCreated
+from demo_evm_uniswap import models as models
+from demo_evm_uniswap.models.token import WHITELIST_TOKENS
+from demo_evm_uniswap.models.token import ERC20Token
+from demo_evm_uniswap.types.factory.evm_events.pool_created import PoolCreatedPayload
 from dipdup.config.evm import EvmContractConfig
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidEvent
+from dipdup.models.evm import EvmEvent
 from tortoise.exceptions import OperationalError
 
 POOL_BLACKLIST = {'0x8fe8d9bb8eeba3ed688069c3d6b556c9ca258248'}
 WETH_ADDRESS = '0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2'
 
 
 async def create_token(ctx: HandlerContext, address: str, pool_id: str) -> None:
@@ -32,15 +32,15 @@
     )
     token.cache()
     await token.save()
 
 
 async def pool_created(
     ctx: HandlerContext,
-    event: SubsquidEvent[PoolCreated],
+    event: EvmEvent[PoolCreatedPayload],
 ) -> None:
     if event.payload.pool in POOL_BLACKLIST:
         ctx.logger.info('Pool %s is blacklisted', event.payload.pool)
         return
 
     factory_address = cast(EvmContractConfig, ctx.config.get_contract('factory')).address
     factory, _ = await models.Factory.get_or_create(id=factory_address)
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/handlers/pool/burn.py` & `dipdup-8.0.0a1/src/demo_evm_uniswap/handlers/pool/burn.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,16 +1,16 @@
-from demo_uniswap import models
-from demo_uniswap.models.pool import PoolUpdateSign
-from demo_uniswap.models.pool import pool_update
-from demo_uniswap.types.pool.evm_events.burn import Burn
+from demo_evm_uniswap import models
+from demo_evm_uniswap.models.pool import PoolUpdateSign
+from demo_evm_uniswap.models.pool import pool_update
+from demo_evm_uniswap.types.pool.evm_events.burn import BurnPayload
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidEvent
+from dipdup.models.evm import EvmEvent
 
 
 async def burn(
     ctx: HandlerContext,
-    event: SubsquidEvent[Burn],
+    event: EvmEvent[BurnPayload],
 ) -> None:
     pool = await models.Pool.cached_get_or_none(event.data.address)
     if not pool:
         return
     await pool_update(ctx, pool, event, PoolUpdateSign.BURN)
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/handlers/pool/initialize.py` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/handlers/pool/initialize.py.j2`

 * *Files 16% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from decimal import Decimal
 
-from demo_uniswap import models
-from demo_uniswap.models.token import token_derive_eth
-from demo_uniswap.types.pool.evm_events.initialize import Initialize
+from {{ project.package }} import models
+from {{ project.package }}.models.token import token_derive_eth
+from {{ project.package }}.types.pool.evm_events.initialize import InitializePayload
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidEvent
+from dipdup.models.evm import EvmEvent
 
 
 async def initialize(
     ctx: HandlerContext,
-    event: SubsquidEvent[Initialize],
+    event: EvmEvent[InitializePayload],
 ) -> None:
     pool = await models.Pool.cached_get_or_none(event.data.address)
     if not pool:
         return
     pool.sqrt_price = Decimal(event.payload.sqrtPriceX96)
     pool.tick = event.payload.tick
     await pool.save()
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/handlers/pool/mint.py` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/handlers/pool/mint.py.j2`

 * *Files 11% similar despite different names*

```diff
@@ -1,22 +1,23 @@
-from demo_uniswap import models
-from demo_uniswap.models.pool import PoolUpdateSign
-from demo_uniswap.models.pool import pool_update
-from demo_uniswap.models.repo import models_repo
-from demo_uniswap.types.pool.evm_events.mint import Mint
-from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidEvent
 from eth_utils.address import to_normalized_address
 
+from {{ project.package }} import models
+from {{ project.package }}.models.pool import PoolUpdateSign
+from {{ project.package }}.models.pool import pool_update
+from {{ project.package }}.models.repo import models_repo
+from {{ project.package }}.types.pool.evm_events.mint import MintPayload
+from dipdup.context import HandlerContext
+from dipdup.models.evm import EvmEvent
+
 BLACKLISTED_POOLS = {'0x8fe8d9bb8eeba3ed688069c3d6b556c9ca258248'}
 
 
 async def mint(
     ctx: HandlerContext,
-    event: SubsquidEvent[Mint],
+    event: EvmEvent[MintPayload],
 ) -> None:
     pool = await models.Pool.cached_get_or_none(event.data.address)
     if not pool or pool.id in BLACKLISTED_POOLS:
         ctx.logger.debug('Pool.mint: skipping pool %s as it is blacklisted', event.data.address)
         return
 
     await pool_update(ctx, pool, event, PoolUpdateSign.MINT)
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/handlers/pool/swap.py` & `dipdup-8.0.0a1/src/demo_evm_uniswap/handlers/pool/swap.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from decimal import Decimal
 
-from demo_uniswap import models as models
-from demo_uniswap.models.repo import USDC_WETH_03_POOL
-from demo_uniswap.models.repo import get_ctx_factory
-from demo_uniswap.models.repo import models_repo
-from demo_uniswap.models.token import WHITELIST_TOKENS
-from demo_uniswap.models.token import convert_token_amount
-from demo_uniswap.models.token import token_derive_eth
-from demo_uniswap.types.pool.evm_events.swap import Swap
+from demo_evm_uniswap import models as models
+from demo_evm_uniswap.models.repo import USDC_WETH_03_POOL
+from demo_evm_uniswap.models.repo import get_ctx_factory
+from demo_evm_uniswap.models.repo import models_repo
+from demo_evm_uniswap.models.token import WHITELIST_TOKENS
+from demo_evm_uniswap.models.token import convert_token_amount
+from demo_evm_uniswap.models.token import token_derive_eth
+from demo_evm_uniswap.types.pool.evm_events.swap import SwapPayload
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidEvent
+from dipdup.models.evm import EvmEvent
 
 POOL_BLACKLIST = {'0x9663f2ca0454accad3e094448ea6f77443880454'}
 Q192 = Decimal(2**192)
 
 
 def get_tracked_amount_usd(
     token0: models.Token, token1: models.Token, amount0: Decimal, amount1: Decimal, eth_usd: Decimal
@@ -44,15 +44,15 @@
     price1 = (num / Q192) * (Decimal(10) ** token0.decimals) / (Decimal(10) ** token1.decimals)
     price0 = Decimal(1) / price1
     return price0, price1
 
 
 async def swap(
     ctx: HandlerContext,
-    event: SubsquidEvent[Swap],
+    event: EvmEvent[SwapPayload],
 ) -> None:
     factory = await get_ctx_factory(ctx)
     pool = await models.Pool.cached_get_or_none(event.data.address)
     if not pool:
         return
     token0 = await models.Token.cached_get(pool.token0_id)
     token1 = await models.Token.cached_get(pool.token1_id)
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/handlers/position_manager/collect.py` & `dipdup-8.0.0a1/src/demo_evm_uniswap/handlers/position_manager/collect.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-from demo_uniswap import models
-from demo_uniswap.models.position import save_position_snapshot
-from demo_uniswap.models.token import convert_token_amount
-from demo_uniswap.types.position_manager.evm_events.collect import Collect
+from demo_evm_uniswap import models
+from demo_evm_uniswap.models.position import save_position_snapshot
+from demo_evm_uniswap.models.token import convert_token_amount
+from demo_evm_uniswap.types.position_manager.evm_events.collect import CollectPayload
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidEvent
+from dipdup.models.evm import EvmEvent
 
 BLACKLISTED_BLOCKS = {14317993}
 
 
 async def collect(
     ctx: HandlerContext,
-    event: SubsquidEvent[Collect],
+    event: EvmEvent[CollectPayload],
 ) -> None:
     if event.data.level in BLACKLISTED_BLOCKS:
         ctx.logger.warning('Blacklisted level %d', event.data.level)
         return
 
     position = await models.Position.get_or_none(id=event.payload.tokenId)
     if position is None:
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/handlers/position_manager/decrease_liquidity.py` & `dipdup-8.0.0a1/src/demo_evm_uniswap/handlers/position_manager/increase_liquidity.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,36 +1,38 @@
-from demo_uniswap import models
-from demo_uniswap.models.position import save_position_snapshot
-from demo_uniswap.models.token import convert_token_amount
-from demo_uniswap.types.position_manager.evm_events.decrease_liquidity import DecreaseLiquidity
+from demo_evm_uniswap import models
+from demo_evm_uniswap.models.position import save_position_snapshot
+from demo_evm_uniswap.models.token import convert_token_amount
+from demo_evm_uniswap.types.position_manager.evm_events.increase_liquidity import IncreaseLiquidityPayload
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidEvent
+from dipdup.models.evm import EvmEvent
 
 BLACKLISTED_BLOCKS = {14317993}
 
 
-async def decrease_liquidity(
+async def increase_liquidity(
     ctx: HandlerContext,
-    event: SubsquidEvent[DecreaseLiquidity],
+    event: EvmEvent[IncreaseLiquidityPayload],
 ) -> None:
     if event.data.level in BLACKLISTED_BLOCKS:
         ctx.logger.warning('Blacklisted level %d', event.data.level)
         return
 
     position = await models.Position.get_or_none(id=event.payload.tokenId)
     if position is None:
         ctx.logger.warning('Skipping position %s (must be blacklisted pool)', event.payload.tokenId)
         return
 
+    # TODO: remove me
+    # await position_validate(ctx, event.data.address, event.payload.tokenId, position)
+
     token0 = await models.Token.cached_get(position.token0_id)
     token1 = await models.Token.cached_get(position.token1_id)
 
     amount0 = convert_token_amount(event.payload.amount0, token0.decimals)
     amount1 = convert_token_amount(event.payload.amount1, token1.decimals)
 
-    position.liquidity -= event.payload.liquidity
-    position.withdrawn_token0 += amount0
-    position.withdrawn_token1 += amount1
+    position.liquidity += event.payload.liquidity
+    position.deposited_token0 += amount0
+    position.deposited_token1 += amount1
 
     await position.save()
-    # position.cache()
     await save_position_snapshot(position, event.data.level, event.data.timestamp)
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/handlers/position_manager/increase_liquidity.py` & `dipdup-8.0.0a1/src/demo_evm_uniswap/handlers/position_manager/decrease_liquidity.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,38 +1,36 @@
-from demo_uniswap import models
-from demo_uniswap.models.position import save_position_snapshot
-from demo_uniswap.models.token import convert_token_amount
-from demo_uniswap.types.position_manager.evm_events.increase_liquidity import IncreaseLiquidity
+from demo_evm_uniswap import models
+from demo_evm_uniswap.models.position import save_position_snapshot
+from demo_evm_uniswap.models.token import convert_token_amount
+from demo_evm_uniswap.types.position_manager.evm_events.decrease_liquidity import DecreaseLiquidityPayload
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidEvent
+from dipdup.models.evm import EvmEvent
 
 BLACKLISTED_BLOCKS = {14317993}
 
 
-async def increase_liquidity(
+async def decrease_liquidity(
     ctx: HandlerContext,
-    event: SubsquidEvent[IncreaseLiquidity],
+    event: EvmEvent[DecreaseLiquidityPayload],
 ) -> None:
     if event.data.level in BLACKLISTED_BLOCKS:
         ctx.logger.warning('Blacklisted level %d', event.data.level)
         return
 
     position = await models.Position.get_or_none(id=event.payload.tokenId)
     if position is None:
         ctx.logger.warning('Skipping position %s (must be blacklisted pool)', event.payload.tokenId)
         return
 
-    # TODO: remove me
-    # await position_validate(ctx, event.data.address, event.payload.tokenId, position)
-
     token0 = await models.Token.cached_get(position.token0_id)
     token1 = await models.Token.cached_get(position.token1_id)
 
     amount0 = convert_token_amount(event.payload.amount0, token0.decimals)
     amount1 = convert_token_amount(event.payload.amount1, token1.decimals)
 
-    position.liquidity += event.payload.liquidity
-    position.deposited_token0 += amount0
-    position.deposited_token1 += amount1
+    position.liquidity -= event.payload.liquidity
+    position.withdrawn_token0 += amount0
+    position.withdrawn_token1 += amount1
 
     await position.save()
+    # position.cache()
     await save_position_snapshot(position, event.data.level, event.data.timestamp)
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/handlers/position_manager/transfer.py` & `dipdup-8.0.0a1/src/demo_evm_uniswap/handlers/position_manager/transfer.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-import demo_uniswap.models as models
-from demo_uniswap.models.position import save_position_snapshot
-from demo_uniswap.models.repo import models_repo
-from demo_uniswap.types.position_manager.evm_events.transfer import Transfer
+import demo_evm_uniswap.models as models
+from demo_evm_uniswap.models.position import save_position_snapshot
+from demo_evm_uniswap.models.repo import models_repo
+from demo_evm_uniswap.types.position_manager.evm_events.transfer import TransferPayload
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidEvent
+from dipdup.models.evm import EvmEvent
 from eth_utils.address import to_normalized_address
 
 
 async def transfer(
     ctx: HandlerContext,
-    event: SubsquidEvent[Transfer],
+    event: EvmEvent[TransferPayload],
 ) -> None:
     if event.payload.from_ == '0x0000000000000000000000000000000000000000':
         idx = f'{event.data.level}.{event.data.transaction_index}.{event.data.log_index}'
         pending_position = models_repo.get_pending_position(idx)
         if pending_position is None:
             ctx.logger.warning('Skipping position %s (must be blacklisted pool)', event.payload.tokenId)
             return
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/models/__init__.py` & `dipdup-8.0.0a1/src/demo_evm_uniswap/models/__init__.py`

 * *Files 0% similar despite different names*

```diff
@@ -169,15 +169,15 @@
     liquidity_provider_count = fields.BigIntField(default=0)  # used to detect new exchanges
     # vars needed for fee computation
     # TODO: require rpc calls
     # fee_growth_outside_0x128 = fields.BigIntField()
     # fee_growth_outside_1x128 = fields.BigIntField()
 
 
-# NOTE: Cached, but with custom logic; see `demo_uniswap.utils.position`
+# NOTE: Cached, but with custom logic; see `demo_evm_uniswap.utils.position`
 class Position(Model):
     id = fields.BigIntField(pk=True)
     # owner of the NFT
     owner = fields.CharField(max_length=42, default=ADDRESS_ZERO)
     # pool position is within
     pool: fields.ForeignKeyRelation[Pool] = fields.ForeignKeyField('models.Pool', related_name='positions')
     # allow indexing by tokens
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/models/pool.py` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/models/pool.py.j2`

 * *Files 7% similar despite different names*

```diff
@@ -1,28 +1,27 @@
+from {{ project.package }} import models
+from {{ project.package }}.models.repo import get_ctx_factory
+from {{ project.package }}.models.repo import models_repo
+from {{ project.package }}.models.tick import tick_get_or_create
+from {{ project.package }}.models.token import convert_token_amount
+from {{ project.package }}.types.pool.evm_events.burn import BurnPayload
+from {{ project.package }}.types.pool.evm_events.mint import MintPayload
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidEvent
-
-from demo_uniswap import models
-from demo_uniswap.models.repo import get_ctx_factory
-from demo_uniswap.models.repo import models_repo
-from demo_uniswap.models.tick import tick_get_or_create
-from demo_uniswap.models.token import convert_token_amount
-from demo_uniswap.types.pool.evm_events.burn import Burn
-from demo_uniswap.types.pool.evm_events.mint import Mint
+from dipdup.models.evm import EvmEvent
 
 
 class PoolUpdateSign:
     MINT = 1
     BURN = -1
 
 
 async def pool_update(
     ctx: HandlerContext,
     pool: models.Pool,
-    event: SubsquidEvent[Burn] | SubsquidEvent[Mint],
+    event: EvmEvent[BurnPayload] | EvmEvent[MintPayload],
     sign: int,
 ) -> None:
     factory = await get_ctx_factory(ctx)
     token0 = await models.Token.cached_get(pool.token0_id)
     token1 = await models.Token.cached_get(pool.token1_id)
 
     amount0 = convert_token_amount(event.payload.amount0, token0.decimals)
@@ -77,19 +76,19 @@
         'amount_usd': amount_usd,
         'tick_lower': event.payload.tickLower,
         'tick_upper': event.payload.tickUpper,
         'log_index': event.data.log_index,
     }
 
     tx: models.Burn | models.Mint
-    if isinstance(event.payload, Mint) and sign == PoolUpdateSign.MINT:
-        if not isinstance(event.payload, Mint):
+    if isinstance(event.payload, MintPayload) and sign == PoolUpdateSign.MINT:
+        if not isinstance(event.payload, MintPayload):
             raise Exception('Invalid event type')
         tx = models.Mint(sender=event.payload.sender, **tx_defaults)
-    elif isinstance(event.payload, Burn) and sign == PoolUpdateSign.BURN:
+    elif isinstance(event.payload, BurnPayload) and sign == PoolUpdateSign.BURN:
         tx = models.Burn(**tx_defaults)
     else:
         raise Exception('Invalid event type')
     await tx.save()
 
     lower_tick = await tick_get_or_create(event.payload.tickLower, pool, event.data.level, event.data.timestamp)
     lower_tick.liquidity_gross = lower_tick.liquidity_gross + sign * event.payload.amount
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/models/position.py` & `dipdup-8.0.0a1/src/demo_evm_uniswap/models/position.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from dipdup.context import HandlerContext
 from eth_utils.address import to_checksum_address
 from eth_utils.address import to_normalized_address
 
-import demo_uniswap.models as models
-from demo_uniswap.models.abi import get_abi
+import demo_evm_uniswap.models as models
+from demo_evm_uniswap.models.abi import get_abi
 
 
 async def position_validate(
     ctx: HandlerContext, contract_address: str, position_id: int, position: models.Position,
 ) -> None:
     web3 = ctx.get_evm_node_datasource('subsquid').web3
     manager = web3.eth.contract(
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/models/repo.py` & `dipdup-8.0.0a1/src/demo_evm_uniswap/models/repo.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 from typing import Any
 from typing import cast
 
 from dipdup.config.evm import EvmContractConfig
 from dipdup.context import HandlerContext
 from lru import LRU
 
-import demo_uniswap.models as models
+import demo_evm_uniswap.models as models
 
 USDC_WETH_03_POOL = '0x8ad599c3a0ff1de082011efddc58f1908eb6e6d8'
 
 
 class ModelsRepo:
     def __init__(self) -> None:
         self._eth_usd: Decimal | None = None
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/models/tick.py` & `dipdup-8.0.0a1/src/demo_evm_uniswap/models/tick.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 from decimal import Decimal
 
-from demo_uniswap import models as models
+from demo_evm_uniswap import models as models
 
 
 async def tick_get_or_create(tick_idx: int, pool: models.Pool, level: int, timestamp: int) -> models.Tick:
     tick, _ = await models.Tick.get_or_create(
         id=f'{pool.id}#{tick_idx}',
         defaults={
             'pool': pool,
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/models/token.py` & `dipdup-8.0.0a1/src/demo_evm_uniswap/models/token.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 from contextlib import suppress
 from decimal import Decimal
 
 from eth_typing import ChecksumAddress
 from eth_utils.address import to_checksum_address
 from web3 import AsyncWeb3
 
-from demo_uniswap import models as models
-from demo_uniswap.models.abi import get_abi
-from demo_uniswap.models.repo import models_repo
+from demo_evm_uniswap import models as models
+from demo_evm_uniswap.models.abi import get_abi
+from demo_evm_uniswap.models.repo import models_repo
 
 MINIMUM_ETH_LOCKED = Decimal('60')
 STABLE_COINS = {
     '0x6b175474e89094c44da98b954eedeac495271d0f',
     '0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48',
     '0xdac17f958d2ee523a2206206994597c13d831ec7',
     '0x0000000000085d4780b73119b644ae5ecd22b376',
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/pyproject.toml` & `dipdup-8.0.0a1/src/demo_tezos_token/pyproject.toml`

 * *Files 19% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Generated by DipDup 7.5.7
+# generated by DipDup 8.0.0a1
 [project]
-name = "demo_uniswap"
+name = "demo_tezos_token"
 version = "0.0.1"
-description = "Uniswap V3 pools, positions, etc. (advanced, uses TimescaleDB)"
+description = "FA1.2 token contract operations"
 license = { text = "MIT" }
 authors = [
     { name = "John Doe", email = "john_doe@example.com" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 dependencies = [
-    "dipdup>=7,<8",
+    "dipdup>=8,<9",
 ]
 
 [tool.pdm.dev-dependencies]
 dev = [
     "black",
     "ruff",
     "mypy",
@@ -30,27 +30,27 @@
 mypy = {cmd = "make mypy", help = "Lint with mypy"}
 image = {cmd = "make image", help = "Build Docker image"}
 up = {cmd = "make up", help = "Run Compose stack"}
 down = {cmd = "make down", help = "Stop Compose stack"}
 
 [tool.black]
 line-length = 120
-target-version = ['py311']
+target-version = ['py312']
 skip-string-normalization = true
 
 [tool.ruff]
 line-length = 120
-target-version = 'py311'
+target-version = 'py312'
 
 [tool.ruff.lint]
 extend-select = ["B", "C4", "FA", "G", "I", "PTH", "Q", "RET", "RUF", "TCH", "UP"]
 flake8-quotes = { inline-quotes = "single", multiline-quotes = "double" }
 isort = { force-single-line = true}
 
 [tool.mypy]
-python_version = "3.11"
+python_version = "3.12"
 plugins = ["pydantic.mypy"]
 strict = false
 
 [build-system]
 requires = ["pdm-backend"]
 build-backend = "pdm.backend"
```

### Comparing `dipdup-7.5.7/src/demo_uniswap/sql/on_reindex/20_create_ca_quotes_1m.sql` & `dipdup-8.0.0a1/src/demo_evm_uniswap/sql/on_reindex/20_create_ca_quotes_1m.sql`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_uniswap/sql/on_reindex/21_create_ca_quotes_1h.sql` & `dipdup-8.0.0a1/src/demo_evm_uniswap/sql/on_reindex/21_create_ca_quotes_1h.sql`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/demo_uniswap/sql/on_reindex/22_create_ca_quotes_1d.sql` & `dipdup-8.0.0a1/src/demo_evm_uniswap/sql/on_reindex/22_create_ca_quotes_1d.sql`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/api.py` & `dipdup-8.0.0a1/src/dipdup/api.py`

 * *Files 9% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 import dipdup.performance
 from dipdup.context import DipDupContext
 from dipdup.exceptions import Error
 from dipdup.utils import json_dumps
 
 
 def _method_wrapper(
-    ctx: DipDupContext,
+    ctx: 'DipDupContext',
     method: Callable[[DipDupContext, web.Request], Awaitable[web.Response]],
 ) -> Callable[[web.Request], Awaitable[web.Response]]:
     @functools.wraps(method)
     async def resolved_method(request: web.Request) -> web.Response:
         try:
             return await method(ctx, request)
         except TypeError as e:
@@ -28,25 +28,25 @@
             return web.Response(body=str(e), status=400)
         except Exception as e:
             return web.Response(body=str(e), status=500)
 
     return resolved_method
 
 
-async def _add_index(ctx: DipDupContext, request: web.Request) -> web.Response:
+async def _add_index(ctx: 'DipDupContext', request: web.Request) -> web.Response:
     await ctx.add_index(**(await request.json()))
     return web.Response()
 
 
-async def _add_contract(ctx: DipDupContext, request: web.Request) -> web.Response:
+async def _add_contract(ctx: 'DipDupContext', request: web.Request) -> web.Response:
     await ctx.add_contract(**(await request.json()))
     return web.Response()
 
 
-async def _performance(ctx: DipDupContext, request: web.Request) -> web.Response:
+async def _performance(ctx: 'DipDupContext', request: web.Request) -> web.Response:
     return web.json_response(
         dipdup.performance.get_stats(),
         dumps=lambda x: json_dumps(x, option=orjson.OPT_SORT_KEYS).decode(),
     )
 
 
 async def create_api(ctx: DipDupContext) -> web.Application:
```

### Comparing `dipdup-7.5.7/src/dipdup/cli.py` & `dipdup-8.0.0a1/src/dipdup/cli.py`

 * *Files 2% similar despite different names*

```diff
@@ -52,14 +52,16 @@
 
 # NOTE: Do not try to load config for these commands as they don't need it
 NO_CONFIG_CMDS = {
     'new',
     'install',
     'uninstall',
     'update',
+    'migrate',
+    'config',
 }
 # NOTE: Our signal handler conflicts with Click's one in prompt mode
 NO_SIGNALS_CMDS = {
     *NO_CONFIG_CMDS,
     None,
     'schema',
     'wipe',
@@ -133,15 +135,15 @@
 
     return cast(WrappedCommandT, wrapper)
 
 
 async def _check_version() -> None:
     if '+editable' in __version__:
         return
-    if '-rc' in __version__:
+    if not all(c.isdigit() or c == '.' for c in __version__):
         _logger.warning(
             'You are running a pre-release version of DipDup. Please, report any issues to the GitHub repository.'
         )
         _logger.info('Set `advanced.skip_version_check` flag in config to hide this message.')
         return
 
     import aiohttp
@@ -207,19 +209,19 @@
 @click.pass_context
 @_cli_wrapper
 async def cli(ctx: click.Context, config: list[str], env_file: list[str]) -> None:
     if _skip_cli_group():
         return
 
     # NOTE: https://github.com/python/cpython/issues/95778
-    # NOTE: Method is not available in early Python 3.11
+    # NOTE: Method is not available in early Python 3.12
     try:
         sys.set_int_max_str_digits(0)
     except AttributeError:
-        _logger.warning("You're running an outdated Python 3.11 release; consider upgrading")
+        _logger.warning("You're running an outdated Python 3.12 release; consider upgrading")
 
     from dotenv import load_dotenv
 
     from dipdup.exceptions import ConfigurationError
     from dipdup.sys import set_up_logging
 
     set_up_logging()
@@ -239,15 +241,20 @@
         logging.getLogger('dipdup').setLevel(logging.INFO)
         return
 
     from dipdup.config import DipDupConfig
     from dipdup.exceptions import InitializationRequiredError
     from dipdup.package import DipDupPackage
 
-    _config = DipDupConfig.load(config_paths)
+    _config = DipDupConfig.load(
+        paths=config_paths,
+        environment=True,
+        raw=False,
+        unsafe=True,
+    )
     _config.set_up_logging()
 
     if _config.sentry:
         from dipdup.sentry import init_sentry
 
         init_sentry(_config.sentry, _config.package)
 
@@ -319,58 +326,86 @@
         force=force,
         base=base or bool(include),
         include=set(include),
     )
 
 
 @cli.command()
+@click.option('--dry-run', '-n', is_flag=True, help='Print changes without applying them.')
 @click.pass_context
 @_cli_wrapper
-async def migrate(ctx: click.Context) -> None:
+async def migrate(ctx: click.Context, dry_run: bool) -> None:
     """
     Migrate project to the new spec version.
 
     If you're getting `MigrationRequiredError` after updating DipDup, this command will fix imports and type annotations to match the current `spec_version`. Review and commit changes after running it.
     """
-    _logger.info('Project is already at the latest version, no further actions required')
+    from dipdup.migrations.three_zero import ThreeZeroProjectMigration
+
+    # NOTE: Extract paths from arguments since we can't load config with old spec version
+    assert ctx.parent
+    config_paths: list[Path] = [Path(file) for file in ctx.parent.params['config']]
+
+    migration = ThreeZeroProjectMigration(tuple(config_paths), dry_run)
+    migration.migrate()
 
 
 @cli.group()
 @click.pass_context
 @_cli_wrapper
 async def config(ctx: click.Context) -> None:
     """Commands to manage DipDup configuration."""
     pass
 
 
 @config.command(name='export')
-@click.option('--unsafe', is_flag=True, help='Resolve environment variables or use default values from the config.')
+@click.option('--unsafe', is_flag=True, help='Use actual environment variables instead of default values.')
 @click.option('--full', '-f', is_flag=True, help='Resolve index templates.')
+@click.option('--raw', '-r', is_flag=True, help='Do not initialize config; preserve file structure.')
 @click.pass_context
 @_cli_wrapper
-async def config_export(ctx: click.Context, unsafe: bool, full: bool) -> None:
+async def config_export(
+    ctx: click.Context,
+    unsafe: bool,
+    full: bool,
+    raw: bool,
+) -> None:
     """
     Print config after resolving all links and, optionally, templates.
 
     WARNING: Avoid sharing output with 3rd-parties when `--unsafe` flag set - it may contain secrets!
     """
     from dipdup.config import DipDupConfig
+    from dipdup.yaml import DipDupYAMLConfig
 
-    config = DipDupConfig.load(
-        paths=ctx.obj.config._paths,
-        environment=unsafe,
-    )
-    if full:
-        config.initialize()
-    echo(config.dump())
+    config_paths = [Path(c) for c in ctx.parent.parent.params['config']]  # type: ignore[union-attr]
+    if raw:
+        raw_config, _ = DipDupYAMLConfig.load(
+            paths=config_paths,
+            environment=False,
+            raw=True,
+            unsafe=unsafe,
+        )
+        echo(raw_config.dump())
+
+    else:
+        config = DipDupConfig.load(
+            paths=config_paths,
+            environment=True,
+            raw=False,
+            unsafe=unsafe,
+        )
+        if full:
+            config.initialize()
+        echo(config.dump())
 
 
 @config.command(name='env')
 @click.option('--output', '-o', type=str, default=None, help='Output to file instead of stdout.')
-@click.option('--unsafe', is_flag=True, help='Resolve environment variables or use default values from the config.')
+@click.option('--unsafe', is_flag=True, help='Use actual environment variables instead of default values.')
 @click.option('--compose', '-c', is_flag=True, help='Output in docker-compose format.')
 @click.option('--internal', '-i', is_flag=True, help='Include internal variables.')
 @click.pass_context
 @_cli_wrapper
 async def config_env(
     ctx: click.Context,
     output: str | None,
@@ -380,17 +415,21 @@
 ) -> None:
     """Dump environment variables used in DipDup config.
 
     If variable is not set, default value will be used.
     """
     from dipdup.yaml import DipDupYAMLConfig
 
+    config_paths = [Path(c) for c in ctx.parent.parent.params['config']]  # type: ignore[union-attr]
+
     _, environment = DipDupYAMLConfig.load(
-        paths=ctx.obj.config._paths,
-        environment=unsafe,
+        paths=config_paths,
+        environment=True,
+        raw=False,
+        unsafe=unsafe,
     )
     if internal:
         environment.update(env.dump())
     if compose:
         content = 'services:\n  dipdup:\n    environment:\n'
         _tab = ' ' * 6
         for k, v in sorted(environment.items()):
@@ -655,26 +694,31 @@
     force: bool,
     replay: Path | None,
     template: str | None,
 ) -> None:
     """Create a new project interactively."""
     import os
 
+    from survey._widgets import Escape  # type: ignore[import-untyped]
+
     from dipdup.config import DipDupConfig
     from dipdup.project import answers_from_replay
     from dipdup.project import answers_from_terminal
     from dipdup.project import get_default_answers
     from dipdup.project import render_project
 
     if quiet:
         answers = get_default_answers()
     elif replay:
         answers = answers_from_replay(replay)
     else:
-        answers = answers_from_terminal(template)
+        try:
+            answers = answers_from_terminal(template)
+        except Escape:
+            return
 
     _logger.info('Rendering project')
     render_project(answers, force)
 
     _logger.info('Initializing project')
     config = DipDupConfig.load([Path(answers['package'])])
     config.initialize()
@@ -790,22 +834,22 @@
 
 
 @report.command(name='ls')
 @click.pass_context
 @_cli_wrapper
 async def report_ls(ctx: click.Context) -> None:
     """List reports."""
-    from ruamel.yaml import YAML
     from tabulate import tabulate
 
-    yaml = YAML(typ='base')
+    from dipdup.yaml import yaml_loader
+
     header = tuple(ReportHeader.__annotations__.keys())
     rows = []
     for path in get_reports():
-        event = yaml.load(path)
+        event = yaml_loader.load(path)
         row = [event.get(key, 'none')[:80] for key in header]
         rows.append(row)
 
     rows.sort(key=lambda row: str(row[3]))
     echo(tabulate(rows, headers=header))
 
 
@@ -860,11 +904,26 @@
     """Draw package tree."""
     from dipdup.package import DipDupPackage
     from dipdup.package import draw_package_tree
 
     config: DipDupConfig = ctx.obj.config
     package = DipDupPackage(config.package_path)
     package.create()
+
     tree = package.tree()
-    echo(f'{package.name} [{package.root.relative_to(Path.cwd())}]')
+    echo(f'{package.name} [{package.root}]')
     for line in draw_package_tree(package.root, tree):
         echo(line)
+
+
+@package.command(name='verify')
+@click.pass_context
+@_cli_wrapper
+async def package_verify(ctx: click.Context) -> None:
+    """Verify project package."""
+    from dipdup.package import DipDupPackage
+
+    config: DipDupConfig = ctx.obj.config
+    package = DipDupPackage(config.package_path)
+    package.create()
+
+    package.verify()
```

### Comparing `dipdup-7.5.7/src/dipdup/codegen/__init__.py` & `dipdup-8.0.0a1/src/dipdup/codegen/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -13,14 +13,15 @@
 from dipdup.config import DipDupConfig
 from dipdup.datasources import Datasource
 from dipdup.exceptions import FrameworkException
 from dipdup.package import DEFAULT_ENV
 from dipdup.package import KEEP_MARKER
 from dipdup.package import PACKAGE_MARKER
 from dipdup.package import DipDupPackage
+from dipdup.project import CODEGEN_HEADER
 from dipdup.project import render_base
 from dipdup.utils import load_template
 from dipdup.utils import pascal_to_snake
 from dipdup.utils import touch
 from dipdup.utils import write
 from dipdup.yaml import DipDupYAMLConfig
 
@@ -118,16 +119,18 @@
         output_path.parent.mkdir(parents=True, exist_ok=True)
         dmcg.generate(
             input_=schema_path,
             output=output_path,
             class_name=class_name,
             disable_timestamp=True,
             input_file_type=dmcg.InputFileType.JsonSchema,
-            target_python_version=dmcg.PythonVersion.PY_311,
+            target_python_version=dmcg.PythonVersion.PY_312,
+            custom_file_header=CODEGEN_HEADER,
             use_union_operator=True,
+            output_model_type=dmcg.DataModelType.PydanticV2BaseModel,
         )
 
     async def _generate_callback(self, callback_config: CallbackMixin, kind: str, sql: bool = False) -> None:
         original_callback = callback_config.callback
         subpackages = callback_config.callback.split('.')
         subpackages, callback = subpackages[:-1], subpackages[-1]
 
@@ -209,15 +212,15 @@
 
         config_chain = [
             *config._paths,
             config_path,
         ]
         _, environment = DipDupYAMLConfig.load(
             paths=config_chain,
-            environment=False,
+            environment=True,
         )
         env_lines = (f'{k}={v}' for k, v in sorted(environment.items()))
         lines: tuple[str, ...] = (
             '# This env file was generated automatically by DipDup. Do not edit it!',
             '# Create a copy with .env extension, fill it with your values and run DipDup with `--env-file` option.',
             '#',
             *env_lines,
```

### Comparing `dipdup-7.5.7/src/dipdup/codegen/evm_subsquid.py` & `dipdup-8.0.0a1/src/dipdup/codegen/evm.py`

 * *Files 10% similar despite different names*

```diff
@@ -3,35 +3,34 @@
 from typing import cast
 
 import eth_utils
 import orjson
 from web3 import Web3
 
 from dipdup.codegen import CodeGenerator
-from dipdup.config import AbiDatasourceConfig
+from dipdup.config import EvmIndexConfigU
 from dipdup.config import HandlerConfig
-from dipdup.config import SubsquidIndexConfigU
+from dipdup.config.abi_etherscan import AbiEtherscanDatasourceConfig
 from dipdup.config.evm import EvmContractConfig
-from dipdup.config.evm_subsquid import SubsquidIndexConfig
-from dipdup.config.evm_subsquid_events import SubsquidEventsHandlerConfig
-from dipdup.config.evm_subsquid_events import SubsquidEventsIndexConfig
-from dipdup.config.evm_subsquid_traces import SubsquidTracesHandlerConfig
-from dipdup.config.evm_subsquid_traces import SubsquidTracesIndexConfig
-from dipdup.config.evm_subsquid_transactions import SubsquidTransactionsHandlerConfig
-from dipdup.config.evm_subsquid_transactions import SubsquidTransactionsIndexConfig
+from dipdup.config.evm import EvmIndexConfig
+from dipdup.config.evm_events import EvmEventsHandlerConfig
+from dipdup.config.evm_events import EvmEventsIndexConfig
+from dipdup.config.evm_transactions import EvmTransactionsHandlerConfig
+from dipdup.config.evm_transactions import EvmTransactionsIndexConfig
 from dipdup.datasources import AbiDatasource
 from dipdup.exceptions import AbiNotAvailableError
 from dipdup.exceptions import ConfigurationError
 from dipdup.exceptions import DatasourceError
 from dipdup.exceptions import FrameworkException
 from dipdup.package import ConvertedAbi
 from dipdup.package import ConvertedEventAbi
 from dipdup.package import ConvertedMethodAbi
 from dipdup.package import DipDupPackage
 from dipdup.utils import json_dumps
+from dipdup.utils import snake_to_pascal
 from dipdup.utils import touch
 
 _abi_type_map: dict[str, str] = {
     'int': 'integer',
     'uint': 'integer',
     'address': 'string',
     'fixed': 'number',
@@ -92,17 +91,16 @@
             elif abi_item['type'] == 'event':
                 name = abi_item['name']
                 if name in converted_abi['events']:
                     raise NotImplementedError('Multiple events with the same name are not supported')
                 inputs = tuple((i['type'], i['indexed']) for i in abi_item['inputs'])
                 converted_abi['events'][name] = ConvertedEventAbi(
                     name=name,
-                    topic0=topic0_from_abi(abi_item),
+                    topic0=topic_from_abi(abi_item),
                     inputs=inputs,
-                    topic_count=len([i for i in inputs if i[1]]),
                 )
         abi_by_typename[abi_path.parent.stem] = converted_abi
 
     return abi_by_typename
 
 
 def abi_to_jsonschemas(
@@ -115,15 +113,15 @@
 
         for abi_item in abi:
             if abi_item['type'] == 'function':
                 name = abi_item['name']
                 if name not in methods:
                     continue
                 schema = jsonschema_from_abi(abi_item)
-                schema_path = package.schemas / abi_path.parent.stem / 'evm_methods' / f'{name}.json'
+                schema_path = package.schemas / abi_path.parent.stem / 'evm_transactions' / f'{name}.json'
             elif abi_item['type'] == 'event':
                 name = abi_item['name']
                 if name not in events:
                     continue
                 schema = jsonschema_from_abi(abi_item)
                 schema_path = package.schemas / abi_path.parent.stem / 'evm_events' / f'{name}.json'
             else:
@@ -131,48 +129,46 @@
 
             touch(schema_path)
             schema_path.write_bytes(json_dumps(schema))
 
 
 def sighash_from_abi(abi_item: dict[str, Any]) -> str:
     if abi_item.get('type') != 'function':
-        raise FrameworkException(f'`{abi_item["name"]}` is not a function; can\'t get sighash')
+        raise FrameworkException(f"`{abi_item['name']}` is not a function; can't get sighash")
 
     signature = f'{abi_item["name"]}({",".join([i["type"] for i in abi_item["inputs"]])})'
     return Web3.keccak(text=signature).hex()[:10]
 
 
-def topic0_from_abi(event: dict[str, Any]) -> str:
+def topic_from_abi(event: dict[str, Any]) -> str:
     if event.get('type') != 'event':
         raise FrameworkException(f'`{event["name"]}` is not an event')
 
     signature = f'{event["name"]}({",".join([i["type"] for i in event["inputs"]])})'
     return '0x' + eth_utils.crypto.keccak(text=signature).hex()
 
 
-class SubsquidCodeGenerator(CodeGenerator):
+class EvmCodeGenerator(CodeGenerator):
     async def generate_abi(self) -> None:
         for index_config in self._config.indexes.values():
-            if isinstance(index_config, SubsquidIndexConfig):
+            if isinstance(index_config, EvmIndexConfig):
                 await self._fetch_abi(index_config)
 
     async def generate_schemas(self) -> None:
         self._cleanup_schemas()
 
         handler_config: HandlerConfig
         events: set[str] = set()
         methods: set[str] = set()
 
         for index_config in self._config.indexes.values():
-            if isinstance(index_config, SubsquidEventsIndexConfig):
+            if isinstance(index_config, EvmEventsIndexConfig):
                 for handler_config in index_config.handlers:
                     events.add(handler_config.name)
-            elif isinstance(index_config, SubsquidTracesIndexConfig):
-                raise NotImplementedError
-            elif isinstance(index_config, SubsquidTransactionsIndexConfig):
+            elif isinstance(index_config, EvmTransactionsIndexConfig):
                 for handler_config in index_config.handlers:
                     if handler_config.method:
                         methods.add(handler_config.method)
 
         abi_to_jsonschemas(self._package, events, methods)
 
     async def generate_hooks(self) -> None:
@@ -180,47 +176,39 @@
 
     async def generate_system_hooks(self) -> None:
         pass
 
     async def generate_handlers(self) -> None:
         pass
 
-    async def _fetch_abi(self, index_config: SubsquidIndexConfigU) -> None:
-        if isinstance(index_config.abi, tuple):
-            datasource_configs = index_config.abi
-        elif index_config.abi:
-            datasource_configs = (index_config.abi,)
-        else:
-            datasource_configs = self._config.abi_datasources
+    async def _fetch_abi(self, index_config: EvmIndexConfigU) -> None:
+        datasource_configs = tuple(c for c in index_config.datasources if isinstance(c, AbiEtherscanDatasourceConfig))
+        if not datasource_configs:
+            raise ConfigurationError('No EVM ABI datasources found')
 
         contract: EvmContractConfig | None = None
 
         for handler_config in index_config.handlers:
-            if isinstance(handler_config, SubsquidEventsHandlerConfig):
+            if isinstance(handler_config, EvmEventsHandlerConfig):
                 contract = handler_config.contract
-            elif isinstance(handler_config, SubsquidTracesHandlerConfig):
-                raise NotImplementedError
-            elif isinstance(handler_config, SubsquidTransactionsHandlerConfig):
+            elif isinstance(handler_config, EvmTransactionsHandlerConfig):
                 contract = handler_config.typed_contract
 
             if not contract:
                 continue
 
             abi_path = self._package.abi / contract.module_name / 'abi.json'
             if abi_path.exists():
                 continue
 
             address = contract.address or contract.abi
             if not address:
                 raise ConfigurationError(f'`address` or `abi` must be specified for contract `{contract.module_name}`')
 
             for datasource_config in datasource_configs:
-                # NOTE: Pydantic won't catch this cause we resolve datasource aliases after validation.
-                if not isinstance(datasource_config, AbiDatasourceConfig):
-                    raise ConfigurationError('`abi` must be a list of ABI datasources')
 
                 datasource = cast(AbiDatasource[Any], self._datasources[datasource_config.name])
                 try:
                     abi_json = await datasource.get_abi(address)
                     break
                 except DatasourceError as e:
                     self._logger.warning('Failed to fetch ABI from `%s`: %s', datasource_config.name, e)
@@ -230,17 +218,24 @@
                     typename=contract.module_name,
                 )
 
             touch(abi_path)
             abi_path.write_bytes(json_dumps(abi_json))
 
     def get_typeclass_name(self, schema_path: Path) -> str:
-        return schema_path.stem
+        module_name = schema_path.stem
+        if schema_path.parent.name == 'evm_events':
+            class_name = f'{module_name}_payload'
+        elif schema_path.parent.name == 'evm_transactions':
+            class_name = f'{module_name}_input'
+        else:
+            class_name = module_name
+        return snake_to_pascal(class_name)
 
     async def _generate_type(self, schema_path: Path, force: bool) -> None:
         markers = {
             'evm_events',
-            'evm_methods',
+            'evm_transactions',
         }
         if not set(schema_path.parts).intersection(markers):
             return
         await super()._generate_type(schema_path, force)
```

### Comparing `dipdup-7.5.7/src/dipdup/codegen/tezos_tzkt.py` & `dipdup-8.0.0a1/src/dipdup/codegen/tezos.py`

 * *Files 2% similar despite different names*

```diff
@@ -19,30 +19,28 @@
 from dipdup.codegen import TypeClass
 from dipdup.config import DipDupConfig
 from dipdup.config import IndexTemplateConfig
 from dipdup.config import system_hooks
 from dipdup.config.tezos import TezosContractConfig
 from dipdup.config.tezos import is_contract_address
 from dipdup.config.tezos import is_rollup_address
-from dipdup.config.tezos_tzkt import TzktDatasourceConfig
-from dipdup.config.tezos_tzkt_big_maps import TzktBigMapsIndexConfig
-from dipdup.config.tezos_tzkt_events import TzktEventsIndexConfig
-from dipdup.config.tezos_tzkt_events import TzktEventsUnknownEventHandlerConfig
-from dipdup.config.tezos_tzkt_head import TzktHeadIndexConfig
-from dipdup.config.tezos_tzkt_operations import OperationsHandlerOriginationPatternConfig as OriginationPatternConfig
-from dipdup.config.tezos_tzkt_operations import OperationsHandlerPatternConfigU as PatternConfigU
-from dipdup.config.tezos_tzkt_operations import OperationsHandlerTransactionPatternConfig as TransactionPatternConfig
-from dipdup.config.tezos_tzkt_operations import TzktOperationsIndexConfig
-from dipdup.config.tezos_tzkt_operations import TzktOperationsUnfilteredIndexConfig
+from dipdup.config.tezos_big_maps import TezosBigMapsIndexConfig
+from dipdup.config.tezos_events import TezosEventsIndexConfig
+from dipdup.config.tezos_events import TezosEventsUnknownEventHandlerConfig
+from dipdup.config.tezos_operations import TezosOperationsHandlerOriginationPatternConfig as OriginationPatternConfig
+from dipdup.config.tezos_operations import TezosOperationsHandlerPatternConfigU as PatternConfigU
+from dipdup.config.tezos_operations import TezosOperationsHandlerTransactionPatternConfig as TransactionPatternConfig
+from dipdup.config.tezos_operations import TezosOperationsIndexConfig
+from dipdup.config.tezos_tzkt import TezosTzktDatasourceConfig
 from dipdup.datasources import Datasource
-from dipdup.datasources.tezos_tzkt import TzktDatasource
+from dipdup.datasources.tezos_tzkt import TezosTzktDatasource
 from dipdup.datasources.tezos_tzkt import late_tzkt_initialization
 from dipdup.exceptions import ConfigurationError
 from dipdup.exceptions import FrameworkException
-from dipdup.models.tezos_tzkt import DEFAULT_ENTRYPOINT
+from dipdup.models.tezos import DEFAULT_ENTRYPOINT
 from dipdup.package import DipDupPackage
 from dipdup.utils import json_dumps
 from dipdup.utils import pascal_to_snake
 from dipdup.utils import snake_to_pascal
 from dipdup.utils import write
 
 
@@ -81,15 +79,15 @@
             'additionalProperties': preprocess_storage_jsonschema(schema['additionalProperties']),
         }
     if schema.get('$comment') == 'big_map':
         return cast(dict[str, Any], schema['oneOf'][1])
     return schema
 
 
-class TzktCodeGenerator(CodeGenerator):
+class TezosCodeGenerator(CodeGenerator):
     """Generates package based on config, invoked from `init` CLI command"""
 
     def __init__(
         self,
         config: DipDupConfig,
         package: DipDupPackage,
         datasources: dict[str, Datasource[Any]],
@@ -115,65 +113,61 @@
         await late_tzkt_initialization(
             config=self._config,
             datasources=self._datasources,
             reindex_fn=None,
         )
 
         unused_operation_templates = [
-            t for t in self._config.templates.values() if isinstance(t, TzktOperationsIndexConfig)
+            t for t in self._config.templates.values() if isinstance(t, TezosOperationsIndexConfig)
         ]
 
         for index_config in self._config.indexes.values():
-            if isinstance(index_config, TzktOperationsIndexConfig):
+            if isinstance(index_config, TezosOperationsIndexConfig):
                 await self._fetch_operation_index_schema(index_config)
-                template = cast(TzktOperationsIndexConfig, index_config.parent)
+                template = cast(TezosOperationsIndexConfig, index_config.parent)
                 if template in unused_operation_templates:
                     unused_operation_templates.remove(template)
-            elif isinstance(index_config, TzktBigMapsIndexConfig):
+            elif isinstance(index_config, TezosBigMapsIndexConfig):
                 await self._fetch_big_map_index_schema(index_config)
-            elif isinstance(index_config, TzktEventsIndexConfig):
+            elif isinstance(index_config, TezosEventsIndexConfig):
                 await self._fetch_event_index_schema(index_config)
             else:
                 pass
 
         # NOTE: Euristics for complex cases like templated `similar_to` factories.
         # NOTE: Try different contracts and datasources from config until one succeeds.
         for template_config in unused_operation_templates:
             self._logger.warning(
                 'Unused operation template `%s`. Ignore this warning if it is used in a factory.', template_config.name
             )
-            datasource_name = template_config.datasource
-            if isinstance(datasource_name, str) and datasource_name in self._config.datasources:
-                datasource_config = self._config.get_tzkt_datasource(datasource_name)
-                template_config.datasource = datasource_config
-                await self._fetch_operation_index_schema(template_config)
-            else:
-                self._logger.info('Unresolved `datasource` field, trying to guess it.')
-                for possible_datasource_config in self._config.datasources.values():
-                    if not isinstance(possible_datasource_config, TzktDatasourceConfig):
-                        continue
-                    # NOTE: Do not modify config without necessity
-                    template_config.datasource = possible_datasource_config
-                    template_config.contracts = [
-                        c for c in self._config.contracts.values() if isinstance(c, TezosContractConfig)
-                    ]
-                    try:
-                        await self._fetch_operation_index_schema(template_config)
-                    except FrameworkException:
-                        continue
+            for datasource_name in template_config.datasources:
+                if isinstance(datasource_name, str) and datasource_name in self._config.datasources:
+                    datasource_config = self._config.get_tezos_tzkt_datasource(datasource_name)
+                    template_config.datasources = (datasource_config,)
+                    await self._fetch_operation_index_schema(template_config)
+                else:
+                    self._logger.info('Unresolved `datasource` field, trying to guess it.')
+                    for possible_datasource_config in self._config.datasources.values():
+                        if not isinstance(possible_datasource_config, TezosTzktDatasourceConfig):
+                            continue
+                        # NOTE: Do not modify config without necessity
+                        template_config.datasources = (possible_datasource_config,)
+                        template_config.contracts = [
+                            c for c in self._config.contracts.values() if isinstance(c, TezosContractConfig)
+                        ]
+                        try:
+                            await self._fetch_operation_index_schema(template_config)
+                        except FrameworkException:
+                            continue
 
     async def generate_handlers(self) -> None:
         """Generate handler stubs with typehints from templates if not exist"""
         for index_config in self._config.indexes.values():
             if isinstance(index_config, IndexTemplateConfig):
                 continue
-            # NOTE: Always single handler
-            if isinstance(index_config, TzktOperationsUnfilteredIndexConfig | TzktHeadIndexConfig):
-                await self._generate_callback(index_config.handler_config, 'handlers')
-                continue
 
             for handler_config in index_config.handlers:
                 await self._generate_callback(handler_config, 'handlers')
 
     async def generate_hooks(self) -> None:
         for hook_configs in self._config.hooks.values(), system_hooks.values():
             for hook_config in hook_configs:
@@ -203,20 +197,20 @@
         }
         if not set(schema_path.parts).intersection(markers):
             return
         await super()._generate_type(schema_path, force)
 
     async def _get_schema(
         self,
-        datasource_config: TzktDatasourceConfig,
+        datasource_config: TezosTzktDatasourceConfig,
         contract_config: TezosContractConfig,
     ) -> dict[str, Any]:
         """Get contract JSONSchema from TzKT or from cache"""
         datasource = self._datasources[datasource_config.name]
-        if not isinstance(datasource, TzktDatasource):
+        if not isinstance(datasource, TezosTzktDatasource):
             raise FrameworkException('`tzkt` datasource expected')
 
         if contract_config.address:
             address = contract_config.address
         elif contract_config.resolved_code_hash:
             address = await datasource.get_contract_address(contract_config.resolved_code_hash, 0)
         else:
@@ -237,15 +231,15 @@
             address_schemas_json = await datasource.get_jsonschemas(address)
             schemas[name][address] = address_schemas_json
         return schemas[name][address]
 
     async def _fetch_operation_pattern_schema(
         self,
         operation_pattern_config: PatternConfigU,
-        datasource_config: TzktDatasourceConfig,
+        datasource_config: TezosTzktDatasourceConfig,
     ) -> None:
         contract_config = operation_pattern_config.typed_contract
         if contract_config is None:
             return
 
         # NOTE: A very special case; unresolved `operation` template to spawn from factory indexes.
         if isinstance(contract_config, str) and contract_config in self._config.contracts:
@@ -311,27 +305,27 @@
         if not written and contract_config.typename is not None:
             existing_schema = orjson.loads(entrypoint_schema_path.read_text())
             if entrypoint_schema != existing_schema:
                 self._logger.warning(
                     'Contract `%s` falsely claims to be a `%s`', contract_config.address, contract_config.typename
                 )
 
-    async def _fetch_operation_index_schema(self, index_config: TzktOperationsIndexConfig) -> None:
+    async def _fetch_operation_index_schema(self, index_config: TezosOperationsIndexConfig) -> None:
         for handler_config in index_config.handlers:
             for operation_pattern_config in handler_config.pattern:
                 await self._fetch_operation_pattern_schema(
                     operation_pattern_config,
-                    index_config.datasource,
+                    index_config.datasources[0],
                 )
 
-    async def _fetch_big_map_index_schema(self, index_config: TzktBigMapsIndexConfig) -> None:
+    async def _fetch_big_map_index_schema(self, index_config: TezosBigMapsIndexConfig) -> None:
         for handler_config in index_config.handlers:
             contract_config = handler_config.contract
 
-            contract_schemas = await self._get_schema(index_config.datasource, contract_config)
+            contract_schemas = await self._get_schema(index_config.datasources[0], contract_config)
 
             contract_schemas_path = self._package.schemas / contract_config.module_name
             big_map_schemas_path = contract_schemas_path / 'tezos_big_maps'
 
             try:
                 big_map_schema = next(ep for ep in contract_schemas['bigMaps'] if ep['path'] == handler_config.path)
             except StopIteration as e:
@@ -348,22 +342,22 @@
                 ),
             )
 
             big_map_value_schema = big_map_schema['valueSchema']
             big_map_value_schema_path = big_map_schemas_path / f'{big_map_path}_value.json'
             write(big_map_value_schema_path, json_dumps(big_map_value_schema))
 
-    async def _fetch_event_index_schema(self, index_config: TzktEventsIndexConfig) -> None:
+    async def _fetch_event_index_schema(self, index_config: TezosEventsIndexConfig) -> None:
         for handler_config in index_config.handlers:
-            if isinstance(handler_config, TzktEventsUnknownEventHandlerConfig):
+            if isinstance(handler_config, TezosEventsUnknownEventHandlerConfig):
                 continue
 
             contract_config = handler_config.contract
             contract_schemas = await self._get_schema(
-                index_config.datasource,
+                index_config.random_datasource,
                 contract_config,
             )
             contract_schemas_path = self._package.schemas / contract_config.module_name
             event_schemas_path = contract_schemas_path / 'tezos_events'
 
             try:
                 event_schema = next(ep for ep in contract_schemas['events'] if ep['tag'] == handler_config.tag)
@@ -375,15 +369,15 @@
             event_tag = handler_config.tag.replace('.', '_')
             event_schema = event_schema['eventSchema']
             event_schema_path = event_schemas_path / f'{event_tag}.json'
             write(event_schema_path, json_dumps(event_schema))
 
     async def get_schemas(
         self,
-        datasource: TzktDatasource,
+        datasource: TezosTzktDatasource,
         contract_config: TezosContractConfig,
     ) -> dict[str, Any]:
         """Get contract JSONSchema from TzKT or from cache"""
         schemas: dict[str, Any] = {}
 
         if contract_config.address:
             address = contract_config.address
```

### Comparing `dipdup-7.5.7/src/dipdup/config/__init__.py` & `dipdup-8.0.0a1/src/dipdup/config/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -19,38 +19,43 @@
 import importlib
 import inspect
 import logging.config
 import re
 from abc import ABC
 from abc import abstractmethod
 from collections import Counter
+from collections import defaultdict
 from contextlib import suppress
-from dataclasses import field
 from pathlib import Path
 from pydoc import locate
+from types import NoneType
 from typing import TYPE_CHECKING
+from typing import Annotated
 from typing import Any
 from typing import Generic
 from typing import Literal
 from typing import TypeVar
 from typing import cast
 from urllib.parse import quote_plus
 from urllib.parse import urlparse
 
 import orjson
+from pydantic import BeforeValidator
 from pydantic import ConfigDict
-from pydantic import Extra
-from pydantic import validator
+from pydantic import Field
+from pydantic import TypeAdapter
+from pydantic import ValidationError
+from pydantic import field_validator
 from pydantic.dataclasses import dataclass
-from pydantic.json import pydantic_encoder
+from pydantic_core import to_jsonable_python
 
+from dipdup import __spec_version__
 from dipdup import env
 from dipdup.exceptions import ConfigInitializationException
 from dipdup.exceptions import ConfigurationError
-from dipdup.exceptions import FrameworkException
 from dipdup.exceptions import IndexAlreadyExistsError
 from dipdup.models import ReindexingAction
 from dipdup.models import ReindexingReason
 from dipdup.models import SkipHistory
 from dipdup.utils import pascal_to_snake
 from dipdup.yaml import DipDupYAMLConfig
 
@@ -62,30 +67,37 @@
 DEFAULT_POSTGRES_SCHEMA = 'public'
 DEFAULT_POSTGRES_DATABASE = 'postgres'
 DEFAULT_POSTGRES_USER = 'postgres'
 DEFAULT_POSTGRES_PORT = 5432
 DEFAULT_SQLITE_PATH = ':memory:'
 
 
+_T = TypeVar('_T')
+Alias = Annotated[_T, NoneType]
+
+Hex = Annotated[str, BeforeValidator(lambda v: hex(v) if isinstance(v, int) else v)]
+ToStr = Annotated[str | float, BeforeValidator(lambda v: str(v))]
+
+
 _logger = logging.getLogger(__name__)
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class SqliteDatabaseConfig:
     """
     SQLite connection config
 
     :param kind: always 'sqlite'
-    :param path: Path to .sqlite3 file, leave default for in-memory database (`:memory:`)
+    :param path: Path to .sqlite file, leave default for in-memory database (`:memory:`)
     :param immune_tables: List of tables to preserve during reindexing
     """
 
     kind: Literal['sqlite']
     path: str = DEFAULT_SQLITE_PATH
-    immune_tables: set[str] = field(default_factory=set)
+    immune_tables: set[str] = Field(default_factory=set)
 
     @property
     def schema_name(self) -> str:
         # NOTE: Used only as identifier in `dipdup_schema` dable, since Hasura integration is not supported for SQLite.
         return DEFAULT_POSTGRES_SCHEMA
 
     @property
@@ -99,15 +111,15 @@
 
     @property
     def connection_timeout(self) -> int:
         # NOTE: Fail immediately
         return 1
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class PostgresDatabaseConfig:
     """Postgres database connection config
 
     :param kind: always 'postgres'
     :param host: Host
     :param port: Port
     :param user: User
@@ -120,16 +132,16 @@
 
     kind: Literal['postgres']
     host: str
     user: str = DEFAULT_POSTGRES_USER
     database: str = DEFAULT_POSTGRES_DATABASE
     port: int = DEFAULT_POSTGRES_PORT
     schema_name: str = DEFAULT_POSTGRES_SCHEMA
-    password: str = field(default='', repr=False)
-    immune_tables: set[str] = field(default_factory=set)
+    password: str = Field(default='', repr=False)
+    immune_tables: set[str] = Field(default_factory=set)
     connection_timeout: int = 60
 
     @property
     def connection_string(self) -> str:
         # NOTE: `maxsize=1` is important! Concurrency will be broken otherwise.
         # NOTE: https://github.com/tortoise/tortoise-orm/issues/792
         connection_string = (
@@ -145,23 +157,24 @@
             'username': self.user,
             'password': self.password,
             'database': self.database,
             'host': self.host,
             'port': self.port,
         }
 
-    @validator('immune_tables', allow_reuse=True)
+    @field_validator('immune_tables')
+    @classmethod
     def _valid_immune_tables(cls, v: set[str]) -> set[str]:
         for table in v:
             if table.startswith('dipdup'):
                 raise ConfigurationError("Tables with `dipdup` prefix can't be immune")
         return v
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class HttpConfig:
     """Advanced configuration of HTTP client
 
     :param retry_count: Number of retries after request failed before giving up
     :param retry_sleep: Sleep time between retries
     :param retry_multiplier: Multiplier for sleep time between retries
     :param ratelimit_rate: Number of requests per period ("drops" in leaky bucket)
@@ -187,15 +200,15 @@
     request_timeout: int | None = None
     batch_size: int | None = None
     polling_interval: float | None = None
     replay_path: str | None = None
     alias: str | None = None
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class ResolvedHttpConfig:
     __doc__ = HttpConfig.__doc__
 
     retry_count: int = 10
     retry_sleep: float = 1.0
     retry_multiplier: float = 2.0
     ratelimit_rate: int = 0
@@ -222,17 +235,17 @@
                 continue
             for k, v in merge_config.__dict__.items():
                 if v is not None:
                     setattr(config, k, v)
         return config
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class NameMixin:
-    def __post_init_post_parse__(self) -> None:
+    def __post_init__(self) -> None:
         self._name: str | None = None
 
     @property
     def name(self) -> str:
         if self._name is None:
             raise ConfigInitializationException(f'{self.__class__.__name__} name is not set')
         return self._name
@@ -263,30 +276,30 @@
     :param kind: Defined by child class
     :param url: URL of the API
     :param http: HTTP connection tunables
     """
 
     kind: str
     url: str
-    http: HttpConfig | None
+    http: HttpConfig | None = None
 
 
 class AbiDatasourceConfig(DatasourceConfig):
     """Provider of EVM contract ABIs. Datasource kind starts with 'abi.'"""
 
     ...
 
 
 class IndexDatasourceConfig(DatasourceConfig):
     """Datasource that can be used as a primary source of historical data"""
 
     ...
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class CodegenMixin(ABC):
     """Base for pattern config classes containing methods required for codegen"""
 
     @abstractmethod
     def iter_imports(self, package: str) -> Iterator[tuple[str, str]]: ...
 
     @abstractmethod
@@ -315,114 +328,115 @@
             kwargs[name] = cast(type | None, locate(cls))
         return kwargs
 
 
 ParentT = TypeVar('ParentT')
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class ParentMixin(Generic[ParentT]):
     """`parent` field for index and template configs"""
 
-    def __post_init_post_parse__(self: ParentMixin[ParentT]) -> None:
+    def __post_init__(self: ParentMixin[ParentT]) -> None:
         self._parent: ParentT | None = None
 
     @property
     def parent(self) -> ParentT | None:
         return self._parent
 
     @parent.setter
     def parent(self, value: ParentT) -> None:
         self._parent = value
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class CallbackMixin(CodegenMixin):
     """Mixin for callback configs
 
     :param callback: Callback name
     """
 
     callback: str
 
-    def __post_init_post_parse__(self) -> None:
+    def __post_init__(self) -> None:
         if self.callback and self.callback != pascal_to_snake(self.callback, strip_dots=False):
             raise ConfigurationError('`callback` field must be a valid Python module name')
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class HandlerConfig(CallbackMixin, ParentMixin['IndexConfig']):
     """Base class for index handlers
 
     :param callback: Callback name
     """
 
-    def __post_init_post_parse__(self) -> None:
-        CallbackMixin.__post_init_post_parse__(self)
-        ParentMixin.__post_init_post_parse__(self)
+    def __post_init__(self) -> None:
+        CallbackMixin.__post_init__(self)
+        ParentMixin.__post_init__(self)
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class IndexTemplateConfig(NameMixin):
     """Index template config
 
     :param kind: always 'template'
     :param values: Values to be substituted in template (`<key>` -> `value`)
     :param first_level: Level to start indexing from
     :param last_level: Level to stop indexing at
     :param template: Template alias in `templates` section
 
     """
 
     kind = 'template'
     template: str
-    values: dict[str, str]
+    values: dict[str, Any]
     first_level: int = 0
     last_level: int = 0
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class IndexConfig(ABC, NameMixin, ParentMixin['ResolvedIndexConfigU']):
     """Index config
 
     :param kind: Defined by child class
-    :param datasource: Alias of index datasource in `datasources` section
+    :param datasources: Aliases of index datasources in `datasources` section
     """
 
     kind: str
-    datasource: DatasourceConfig
+    datasources: tuple[Alias[DatasourceConfig], ...]
 
-    def __post_init_post_parse__(self) -> None:
-        NameMixin.__post_init_post_parse__(self)
-        ParentMixin.__post_init_post_parse__(self)
+    def __post_init__(self) -> None:
+        NameMixin.__post_init__(self)
+        ParentMixin.__post_init__(self)
 
-        self.template_values: dict[str, str] = {}
+        self._template_values: dict[str, str] = {}
 
     @abstractmethod
     def get_subscriptions(self) -> set[Subscription]: ...
 
     def hash(self) -> str:
         """Calculate hash to ensure config has not changed since last run."""
         # FIXME: How to convert pydantic dataclass into dict without json.dumps? asdict is not recursive.
-        config_json = orjson.dumps(self, default=pydantic_encoder)
+        config_json = orjson.dumps(self, default=to_jsonable_python)
         config_dict = orjson.loads(config_json)
 
         self.strip(config_dict)
 
         config_json = orjson.dumps(config_dict)
         return hashlib.sha256(config_json).hexdigest()
 
     @classmethod
     def strip(cls, config_dict: dict[str, Any]) -> None:
         """Strip config from tunables that are not needed for hash calculation."""
-        config_dict['datasource'].pop('http', None)
-        config_dict['datasource'].pop('buffer_size', None)
+        for datasource in config_dict['datasources']:
+            datasource.pop('http', None)
+            datasource.pop('buffer_size', None)
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class HasuraConfig:
     """Config for the Hasura integration.
 
     :param url: URL of the Hasura instance.
     :param admin_secret: Admin secret of the Hasura instance.
     :param create_source: Whether source should be added to Hasura if missing.
     :param source: Hasura source for DipDup to configure, others will be left untouched.
@@ -431,67 +445,68 @@
     :param allow_inconsistent_metadata: Whether to ignore errors when applying Hasura metadata.
     :param camel_case: Whether to use camelCase instead of default pascal_case for the field names.
     :param rest: Enable REST API both for autogenerated and custom queries.
     :param http: HTTP connection tunables
     """
 
     url: str
-    admin_secret: str | None = field(default=None, repr=False)
+    admin_secret: str | None = Field(default=None, repr=False)
     create_source: bool = False
     source: str = 'default'
     select_limit: int = 1000
     allow_aggregations: bool = True
     allow_inconsistent_metadata: bool = False
     camel_case: bool = False
     rest: bool = True
     http: HttpConfig | None = None
 
-    @validator('url', allow_reuse=True)
+    @field_validator('url')
+    @classmethod
     def _valid_url(cls, v: str) -> str:
         parsed_url = urlparse(v)
         if not (parsed_url.scheme and parsed_url.netloc):
             raise ConfigurationError(f'`{v}` is not a valid Hasura URL')
         return v.rstrip('/')
 
     @property
     def headers(self) -> dict[str, str]:
         """Headers to include with every request"""
         if self.admin_secret:
             return {'X-Hasura-Admin-Secret': self.admin_secret}
         return {}
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class JobConfig(NameMixin):
     """Job schedule config
 
     :param hook: Name of hook to run
     :param args: Arguments to pass to the hook
     :param crontab: Schedule with crontab syntax (`* * * * *`)
     :param interval: Schedule with interval in seconds
     :param daemon: Run hook as a daemon (never stops)
     """
 
-    hook: HookConfig = field()
-    args: dict[str, Any] = field(default_factory=dict)
+    hook: Alias[HookConfig]
+    args: dict[str, Any] = Field(default_factory=dict)
     crontab: str | None = None
     interval: int | None = None
     daemon: bool = False
 
-    def __post_init_post_parse__(self) -> None:
+    def __post_init__(self) -> None:
         schedules_enabled = sum(int(bool(x)) for x in (self.crontab, self.interval, self.daemon))
         if schedules_enabled > 1:
             raise ConfigurationError('Only one of `crontab`, `interval` of `daemon` can be specified')
         if not schedules_enabled:
             raise ConfigurationError('One of `crontab`, `interval` or `daemon` must be specified')
 
-        NameMixin.__post_init_post_parse__(self)
+        NameMixin.__post_init__(self)
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class SentryConfig:
     """Config for Sentry integration.
 
     :param dsn: DSN of the Sentry instance
     :param environment: Environment; if not set, guessed from docker/ci/gha/local.
     :param server_name: Server name; defaults to obfuscated hostname.
     :param release: Release version; defaults to DipDup package version.
@@ -503,38 +518,38 @@
     environment: str | None = None
     server_name: str | None = None
     release: str | None = None
     user_id: str | None = None
     debug: bool = False
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class PrometheusConfig:
     """Config for Prometheus integration.
 
     :param host: Host to bind to
     :param port: Port to bind to
     :param update_interval: Interval to update some metrics in seconds
     """
 
     host: str
     port: int = 8000
     update_interval: float = 1.0
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class HookConfig(CallbackMixin):
     """Hook config
 
     :param callback: Callback name
     :param args: Mapping of argument names and annotations (checked lazily when possible)
     :param atomic: Wrap hook in a single database transaction
     """
 
-    args: dict[str, str] = field(default_factory=dict)
+    args: dict[str, str] = Field(default_factory=dict)
     atomic: bool = False
 
     def iter_arguments(self) -> Iterator[tuple[str, str]]:
         yield 'ctx', 'HookContext'
         for name, annotation in self.args.items():
             yield name, annotation.split('.')[-1]
 
@@ -542,15 +557,15 @@
         yield 'dipdup.context', 'HookContext'
         for _, annotation in self.args.items():
             with suppress(ValueError):
                 package, obj = annotation.rsplit('.', 1)
                 yield package, obj
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class SystemHookConfig(HookConfig):
     __doc__ = HookConfig.__doc__
 
 
 system_hooks = {
     # NOTE: Fires on every run after datasources and schema are initialized.
     # NOTE: Default: nothing.
@@ -576,60 +591,58 @@
     # NOTE: Default: nothing.
     'on_synchronized': SystemHookConfig(
         callback='on_synchronized',
     ),
 }
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class ApiConfig:
     """Management API config
 
     :param host: Host to bind to
     :param port: Port to bind to
     """
 
     host: str = '127.0.0.1'
     port: int = 46339  # dial INDEX 
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+# NOTE: Should be the only place where extras are allowed
+@dataclass(config=ConfigDict(extra='allow'), kw_only=True)
 class AdvancedConfig:
     """This section allows users to tune some system-wide options, either experimental or unsuitable for generic configurations.
 
     :param reindex: Mapping of reindexing reasons and actions DipDup performs.
     :param scheduler: `apscheduler` scheduler config.
     :param postpone_jobs: Do not start job scheduler until all indexes reach the realtime state.
     :param early_realtime: Establish realtime connection and start collecting messages while sync is in progress (faster, but consumes more RAM).
     :param skip_version_check: Disable warning about running unstable or out-of-date DipDup version.
     :param rollback_depth: A number of levels to keep for rollback.
     :param decimal_precision: Overwrite precision if it's not guessed correctly based on project models.
     :param unsafe_sqlite: Disable journaling and data integrity checks. Use only for testing.
     :param alt_operation_matcher: Use different algorithm to match Tezos operations (dev only)
     """
 
-    reindex: dict[ReindexingReason, ReindexingAction] = field(default_factory=dict)
+    reindex: dict[ReindexingReason, ReindexingAction] = Field(default_factory=dict)
     scheduler: dict[str, Any] | None = None
     postpone_jobs: bool = False
     early_realtime: bool = False
     skip_version_check: bool = False
     rollback_depth: int | None = None
     decimal_precision: int | None = None
     unsafe_sqlite: bool = False
     alt_operation_matcher: bool = False
 
-    class Config:
-        extra = 'allow'
-
 
-@dataclass
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class DipDupConfig:
     """Main indexer config
 
-    :param spec_version: Version of config specification, currently always `2.0`
+    :param spec_version: Version of config specification, currently always `3.0`
     :param package: Name of indexer's Python package, existing or not
     :param datasources: Mapping of datasource aliases and datasource configs
     :param database: Database config
     :param contracts: Mapping of contract aliases and contract configs
     :param indexes: Mapping of index aliases and index configs
     :param templates: Mapping of template aliases and index templates
     :param jobs: Mapping of job aliases and job configs
@@ -639,34 +652,34 @@
     :param prometheus: Prometheus integration config
     :param api: Management API config
     :param advanced: Advanced config
     :param custom: User-defined configuration to use in callbacks
     :param logging: Modify logging verbosity
     """
 
-    spec_version: str | float
+    spec_version: ToStr
     package: str
-    datasources: dict[str, DatasourceConfigU] = field(default_factory=dict)
-    database: SqliteDatabaseConfig | PostgresDatabaseConfig = field(
+    datasources: dict[str, DatasourceConfigU] = Field(default_factory=dict)
+    database: SqliteDatabaseConfig | PostgresDatabaseConfig = Field(
         default_factory=lambda *a, **kw: SqliteDatabaseConfig(kind='sqlite')
     )
-    contracts: dict[str, ContractConfigU] = field(default_factory=dict)
-    indexes: dict[str, IndexConfigU] = field(default_factory=dict)
-    templates: dict[str, ResolvedIndexConfigU] = field(default_factory=dict)
-    jobs: dict[str, JobConfig] = field(default_factory=dict)
-    hooks: dict[str, HookConfig] = field(default_factory=dict)
+    contracts: dict[str, ContractConfigU] = Field(default_factory=dict)
+    indexes: dict[str, IndexConfigU] = Field(default_factory=dict)
+    templates: dict[str, ResolvedIndexConfigU] = Field(default_factory=dict)
+    jobs: dict[str, JobConfig] = Field(default_factory=dict)
+    hooks: dict[str, HookConfig] = Field(default_factory=dict)
     hasura: HasuraConfig | None = None
     sentry: SentryConfig | None = None
     prometheus: PrometheusConfig | None = None
     api: ApiConfig | None = None
-    advanced: AdvancedConfig = field(default_factory=AdvancedConfig)
-    custom: dict[str, Any] = field(default_factory=dict)
+    advanced: AdvancedConfig = Field(default_factory=AdvancedConfig)
+    custom: dict[str, Any] = Field(default_factory=dict)
     logging: dict[str, str | int] | str | int = 'INFO'
 
-    def __post_init_post_parse__(self) -> None:
+    def __post_init__(self) -> None:
         if self.package != pascal_to_snake(self.package):
             raise ConfigurationError('Python package name must be in snake_case.')
 
         self._paths: list[Path] = []
         self._environment: dict[str, str] = {}
         self._json = DipDupYAMLConfig()
 
@@ -683,21 +696,50 @@
         return tuple(c for c in self.datasources.values() if isinstance(c, AbiDatasourceConfig))
 
     @classmethod
     def load(
         cls,
         paths: list[Path],
         environment: bool = True,
+        raw: bool = False,
+        unsafe: bool = False,
     ) -> DipDupConfig:
-        config_json, config_environment = DipDupYAMLConfig.load(paths, environment)
+        config_json, config_environment = DipDupYAMLConfig.load(
+            paths=paths,
+            environment=environment,
+            raw=raw,
+            unsafe=unsafe,
+        )
 
         try:
-            config = cls(**config_json)
+            config = TypeAdapter(cls).validate_python(config_json)
         except ConfigurationError:
             raise
+        except ValidationError as e:
+            msgs = []
+            errors_by_path = defaultdict(list)
+            for error in e.errors():
+                loc = error['loc']
+                index = 2 if isinstance(loc[-1], int) else 1
+                path = '.'.join(str(e) for e in loc[:-index])
+                errors_by_path[path].append(error)
+
+            for path, errors in errors_by_path.items():
+                fields = {error['loc'][-1] for error in errors}
+
+                # NOTE: If `kind` or `type` don't match the expected value, skip this class; it's a wrong Union member.
+                if 'kind' in fields or 'type' in fields:
+                    continue
+
+                for error in errors:
+                    path = '.'.join(str(e) for e in error['loc'])
+                    msgs.append(f'- {path}: {error["msg"]}')
+
+            msg = 'Config validation failed:\n\n' + '\n'.join(msgs)
+            raise ConfigurationError(msg) from e
         except Exception as e:
             raise ConfigurationError(str(e)) from e
 
         config._paths = paths
         config._json = config_json
         config._environment = config_environment
         return config
@@ -740,41 +782,44 @@
 
     def get_hook(self, name: str) -> HookConfig:
         try:
             return self.hooks[name]
         except KeyError as e:
             raise ConfigurationError(f'Hook `{name}` not found in `templates` config section') from e
 
-    def get_tzkt_datasource(self, name: str) -> TzktDatasourceConfig:
+    def get_tezos_tzkt_datasource(self, name: str) -> TezosTzktDatasourceConfig:
         datasource = self.get_datasource(name)
-        if not isinstance(datasource, TzktDatasourceConfig):
+        if not isinstance(datasource, TezosTzktDatasourceConfig):
             raise ConfigurationError('`datasource` field must refer to TzKT datasource')
         return datasource
 
-    def get_subsquid_datasource(self, name: str) -> SubsquidDatasourceConfig:
+    def get_evm_subsquid_datasource(self, name: str) -> EvmSubsquidDatasourceConfig:
         datasource = self.get_datasource(name)
-        if not isinstance(datasource, SubsquidDatasourceConfig):
+        if not isinstance(datasource, EvmSubsquidDatasourceConfig):
             raise ConfigurationError('`datasource` field must refer to Subsquid datasource')
         return datasource
 
     def get_evm_node_datasource(self, name: str) -> EvmNodeDatasourceConfig:
         datasource = self.get_datasource(name)
         if not isinstance(datasource, EvmNodeDatasourceConfig):
             raise ConfigurationError('`datasource` field must refer to TzKT datasource')
         return datasource
 
+    def get_abi_etherscan_datasource(self, name: str) -> AbiEtherscanDatasourceConfig:
+        datasource = self.get_datasource(name)
+        if not isinstance(datasource, AbiEtherscanDatasourceConfig):
+            raise ConfigurationError('`datasource` field must refer to Etherscan datasource')
+        return datasource
+
     def set_up_logging(self) -> None:
         loglevels = {}
-        if isinstance(self.logging, dict):
-            loglevels = {**self.logging}
-        else:
+        if not isinstance(self.logging, dict):
             loglevels['dipdup'] = self.logging
             loglevels[self.package] = self.logging
 
-        # NOTE: Environment vars have higher priority
         if env.DEBUG:
             loglevels['dipdup'] = 'DEBUG'
             loglevels[self.package] = 'DEBUG'
 
         for name, level in loglevels.items():
             try:
                 if isinstance(level, str):
@@ -793,24 +838,24 @@
         self._validate()
 
     def dump(self) -> str:
         return DipDupYAMLConfig(
             **orjson.loads(
                 orjson.dumps(
                     self,
-                    default=pydantic_encoder,
+                    default=to_jsonable_python,
                 )
             )
         ).dump()
 
     def add_index(
         self,
         name: str,
         template: str,
-        values: dict[str, str],
+        values: dict[str, Any],
         first_level: int = 0,
         last_level: int = 0,
     ) -> None:
         if name in self.indexes:
             raise IndexAlreadyExistsError(name)
         template_config = IndexTemplateConfig(
             template=template,
@@ -821,14 +866,21 @@
         template_config._name = name
         self._resolve_template(template_config)
         index_config = cast(ResolvedIndexConfigU, self.indexes[name])
         self._resolve_index_links(index_config)
         index_config._name = name
 
     def _validate(self) -> None:
+        # NOTE: Spec version
+        if self.spec_version != __spec_version__:
+            raise ConfigurationError(
+                f'Incompatible spec version: expected {__spec_version__}, got {self.spec_version}. '
+                'See https://dipdup.io/docs/config/spec_version'
+            )
+
         # NOTE: Hasura and metadata interface
         if self.hasura:
             if isinstance(self.database, SqliteDatabaseConfig):
                 raise ConfigurationError('SQLite database engine is not supported by Hasura')
 
         # NOTE: Hook names and callbacks
         for name, hook_config in self.hooks.items():
@@ -842,15 +894,15 @@
         if rollback_depth is None:
             rollback_depth = 0
             for name, datasource_config in self.datasources.items():
                 if not isinstance(datasource_config, IndexDatasourceConfig):
                     continue
                 rollback_depth = max(rollback_depth, datasource_config.rollback_depth or 0)
 
-                if not isinstance(datasource_config, TzktDatasourceConfig):
+                if not isinstance(datasource_config, TezosTzktDatasourceConfig):
                     continue
                 if datasource_config.buffer_size and self.advanced.rollback_depth:
                     raise ConfigurationError(
                         f'`{name}`: `buffer_size` option is incompatible with `advanced.rollback_depth`'
                     )
         elif self.advanced.rollback_depth is not None and rollback_depth > self.advanced.rollback_depth:
             raise ConfigurationError(
@@ -858,69 +910,61 @@
             )
         self.advanced.rollback_depth = rollback_depth
 
         if self.advanced.early_realtime:
             return
 
         # NOTE: Indexes that process only the current state imply early realtime.
-        from dipdup.config.tezos_tzkt_big_maps import TzktBigMapsIndexConfig
-        from dipdup.config.tezos_tzkt_token_balances import TzktTokenBalancesIndexConfig
+        from dipdup.config.tezos_big_maps import TezosBigMapsIndexConfig
+        from dipdup.config.tezos_token_balances import TezosTokenBalancesIndexConfig
 
         for name, index_config in self.indexes.items():
             is_big_maps = (
-                isinstance(index_config, TzktBigMapsIndexConfig) and index_config.skip_history != SkipHistory.never
+                isinstance(index_config, TezosBigMapsIndexConfig) and index_config.skip_history != SkipHistory.never
             )
-            is_token_balances = isinstance(index_config, TzktTokenBalancesIndexConfig)
+            is_token_balances = isinstance(index_config, TezosTokenBalancesIndexConfig)
             if is_big_maps or is_token_balances:
                 _logger.info('`%s` index is configured to skip history; implying `early_realtime` flag', name)
                 self.advanced.early_realtime = True
                 break
 
     def _resolve_template(self, template_config: IndexTemplateConfig) -> None:
         _logger.debug('Resolving index config `%s` from template `%s`', template_config.name, template_config.template)
 
         template = self.get_template(template_config.template)
-        raw_template = orjson.dumps(template, default=pydantic_encoder).decode()
+        raw_template = orjson.dumps(template, default=to_jsonable_python).decode()
         for key, value in template_config.values.items():
             value_regex = r'<[ ]*' + key + r'[ ]*>'
-            raw_template = re.sub(value_regex, value, raw_template)
+            raw_template = re.sub(
+                pattern=value_regex,
+                repl=str(value),
+                string=raw_template,
+            )
 
         if missing_value := re.search(r'<*>', raw_template):
             raise ConfigurationError(
                 f'`{template_config.name}` index config is missing required template value `{missing_value}`'
             )
 
         json_template = orjson.loads(raw_template)
         new_index_config = template.__class__(**json_template)
-        new_index_config.template_values = template_config.values
+        new_index_config._template_values = template_config.values
         new_index_config.parent = template
         new_index_config._name = template_config.name
-        if not isinstance(new_index_config, TzktHeadIndexConfig):
+        if not isinstance(new_index_config, TezosHeadIndexConfig):
             new_index_config.first_level |= template_config.first_level
             new_index_config.last_level |= template_config.last_level
         self.indexes[template_config.name] = new_index_config
 
     def _resolve_templates(self) -> None:
         for index_config in self.indexes.values():
             if isinstance(index_config, IndexTemplateConfig):
                 self._resolve_template(index_config)
 
     def _resolve_links(self) -> None:
-        for datasource_config in self.datasources.values():
-            if not isinstance(datasource_config, SubsquidDatasourceConfig):
-                continue
-            node_field = datasource_config.node
-            if isinstance(node_field, str):
-                datasource_config.node = self.datasources[node_field]
-            elif isinstance(node_field, tuple):
-                nodes = []
-                for node in node_field:
-                    nodes.append(self.get_evm_node_datasource(node) if isinstance(node, str) else node)
-                datasource_config.node = tuple(nodes)
-
         for index_config in self.indexes.values():
             if isinstance(index_config, IndexTemplateConfig):
                 raise ConfigInitializationException('Index templates must be resolved first')
 
             self._resolve_index_links(index_config)
 
         for job_config in self.jobs.values():
@@ -933,108 +977,98 @@
     def _resolve_index_links(self, index_config: ResolvedIndexConfigU) -> None:
         """Resolve contract and datasource configs by aliases.
 
         WARNING: str type checks are intentional! See `dipdup.config.patch_annotations`.
         """
         handler_config: HandlerConfig
 
-        # NOTE: Each index must have a corresponding index datasource
-        if isinstance(index_config.datasource, str):
-            name = index_config.datasource
-            if index_config.kind.startswith('tezos.tzkt'):
-                index_config.datasource = self.get_tzkt_datasource(name)
-            elif index_config.kind.startswith('evm.subsquid'):
-                try:
-                    index_config.datasource = self.get_subsquid_datasource(name)
-                except ConfigurationError:
-                    index_config.datasource = self.get_evm_node_datasource(name)
-            else:
-                raise FrameworkException(f'Unknown datasource type for index `{index_config.name}`')
+        datasources = list(index_config.datasources)
+        for i, datasource in enumerate(datasources):
+            if isinstance(datasource, str):
+                datasources[i] = self.get_datasource(datasource)  # type: ignore[assignment]
+        index_config.datasources = tuple(datasources)  # type: ignore[assignment]
 
-        if isinstance(index_config, TzktOperationsIndexConfig):
+        if isinstance(index_config, TezosOperationsIndexConfig):
             if index_config.contracts is not None:
                 for i, contract in enumerate(index_config.contracts):
                     if isinstance(contract, str):
                         index_config.contracts[i] = self.get_tezos_contract(contract)
 
             for handler_config in index_config.handlers:
                 handler_config.parent = index_config
                 for idx, pattern_config in enumerate(handler_config.pattern):
                     # NOTE: Untyped operations are named as `transaction_N` or `origination_N` based on their index
                     pattern_config._subgroup_index = idx
 
-                    if isinstance(pattern_config, OperationsHandlerTransactionPatternConfig):
+                    if isinstance(pattern_config, TezosOperationsHandlerTransactionPatternConfig):
                         if isinstance(pattern_config.destination, str):
                             pattern_config.destination = self.get_tezos_contract(pattern_config.destination)
                         if isinstance(pattern_config.source, str):
                             pattern_config.source = self.get_tezos_contract(pattern_config.source)
 
-                    elif isinstance(pattern_config, OperationsHandlerOriginationPatternConfig):
+                    elif isinstance(pattern_config, TezosOperationsHandlerOriginationPatternConfig):
                         if isinstance(pattern_config.source, str):
                             pattern_config.source = self.get_tezos_contract(pattern_config.source)
 
                         if isinstance(pattern_config.originated_contract, str):
                             pattern_config.originated_contract = self.get_tezos_contract(
                                 pattern_config.originated_contract
                             )
 
-                    elif isinstance(pattern_config, OperationsHandlerSmartRollupExecutePatternConfig):
+                    elif isinstance(pattern_config, TezosOperationsHandlerSmartRollupExecutePatternConfig):
                         if isinstance(pattern_config.destination, str):
                             pattern_config.destination = self.get_tezos_contract(pattern_config.destination)
 
-        elif isinstance(index_config, TzktBigMapsIndexConfig):
+        elif isinstance(index_config, TezosBigMapsIndexConfig):
             for handler_config in index_config.handlers:
                 handler_config.parent = index_config
                 if isinstance(handler_config.contract, str):
                     handler_config.contract = self.get_tezos_contract(handler_config.contract)
 
-        elif isinstance(index_config, TzktHeadIndexConfig):
-            index_config.handler_config.parent = index_config
+        elif isinstance(index_config, TezosHeadIndexConfig):
+            index_config.handlers[0].parent = index_config
 
-        elif isinstance(index_config, TzktTokenTransfersIndexConfig):
+        elif isinstance(index_config, TezosTokenTransfersIndexConfig):
             for handler_config in index_config.handlers:
                 handler_config.parent = index_config
 
                 if isinstance(handler_config.contract, str):
                     handler_config.contract = self.get_tezos_contract(handler_config.contract)
 
                 if isinstance(handler_config.from_, str):
                     handler_config.from_ = self.get_tezos_contract(handler_config.from_)
 
                 if isinstance(handler_config.to, str):
                     handler_config.to = self.get_tezos_contract(handler_config.to)
 
-        elif isinstance(index_config, TzktTokenBalancesIndexConfig):
+        elif isinstance(index_config, TezosTokenBalancesIndexConfig):
             for handler_config in index_config.handlers:
                 handler_config.parent = index_config
 
                 if isinstance(handler_config.contract, str):
                     handler_config.contract = self.get_tezos_contract(handler_config.contract)
 
-        elif isinstance(index_config, TzktOperationsUnfilteredIndexConfig):
-            index_config.handler_config.parent = index_config
+        elif isinstance(index_config, TezosOperationsUnfilteredIndexConfig):
+            index_config.handlers[0].parent = index_config
 
-        elif isinstance(index_config, TzktEventsIndexConfig):
+        elif isinstance(index_config, TezosEventsIndexConfig):
             for handler_config in index_config.handlers:
                 handler_config.parent = index_config
 
                 if isinstance(handler_config.contract, str):
                     handler_config.contract = self.get_tezos_contract(handler_config.contract)
 
-        elif isinstance(index_config, SubsquidEventsIndexConfig):
+        elif isinstance(index_config, EvmEventsIndexConfig):
             for handler_config in index_config.handlers:
                 handler_config.parent = index_config
 
                 if isinstance(handler_config.contract, str):
                     handler_config.contract = self.get_evm_contract(handler_config.contract)
 
-        elif isinstance(index_config, SubsquidTracesIndexConfig):
-            raise NotImplementedError
-
-        elif isinstance(index_config, SubsquidTransactionsIndexConfig):
+        elif isinstance(index_config, EvmTransactionsIndexConfig):
             for handler_config in index_config.handlers:
                 handler_config.parent = index_config
 
                 if isinstance(handler_config.to, str):
                     handler_config.to = self.get_evm_contract(handler_config.to)
 
                 if isinstance(handler_config.from_, str):
@@ -1062,112 +1096,110 @@
 
 
 """
 WARNING: A very dark magic ahead. Be extra careful when editing code below.
 """
 
 # NOTE: Reimport to avoid circular imports
-from dipdup.config.abi_etherscan import EtherscanDatasourceConfig
+from dipdup.config.abi_etherscan import AbiEtherscanDatasourceConfig
 from dipdup.config.coinbase import CoinbaseDatasourceConfig
 from dipdup.config.evm import EvmContractConfig
+from dipdup.config.evm_events import EvmEventsIndexConfig
 from dipdup.config.evm_node import EvmNodeDatasourceConfig
-from dipdup.config.evm_subsquid import SubsquidDatasourceConfig
-from dipdup.config.evm_subsquid_events import SubsquidEventsIndexConfig
-from dipdup.config.evm_subsquid_traces import SubsquidTracesIndexConfig
-from dipdup.config.evm_subsquid_transactions import SubsquidTransactionsIndexConfig
+from dipdup.config.evm_subsquid import EvmSubsquidDatasourceConfig
+from dipdup.config.evm_transactions import EvmTransactionsIndexConfig
 from dipdup.config.http import HttpDatasourceConfig
 from dipdup.config.ipfs import IpfsDatasourceConfig
 from dipdup.config.tezos import TezosContractConfig
-from dipdup.config.tezos_tzkt import TzktDatasourceConfig
-from dipdup.config.tezos_tzkt_big_maps import TzktBigMapsIndexConfig
-from dipdup.config.tezos_tzkt_events import TzktEventsIndexConfig
-from dipdup.config.tezos_tzkt_head import TzktHeadIndexConfig
-from dipdup.config.tezos_tzkt_operations import OperationsHandlerOriginationPatternConfig
-from dipdup.config.tezos_tzkt_operations import OperationsHandlerSmartRollupExecutePatternConfig
-from dipdup.config.tezos_tzkt_operations import OperationsHandlerTransactionPatternConfig
-from dipdup.config.tezos_tzkt_operations import TzktOperationsIndexConfig
-from dipdup.config.tezos_tzkt_operations import TzktOperationsUnfilteredIndexConfig
-from dipdup.config.tezos_tzkt_token_balances import TzktTokenBalancesIndexConfig
-from dipdup.config.tezos_tzkt_token_transfers import TzktTokenTransfersIndexConfig
+from dipdup.config.tezos_big_maps import TezosBigMapsIndexConfig
+from dipdup.config.tezos_events import TezosEventsIndexConfig
+from dipdup.config.tezos_head import TezosHeadIndexConfig
+from dipdup.config.tezos_operations import TezosOperationsHandlerOriginationPatternConfig
+from dipdup.config.tezos_operations import TezosOperationsHandlerSmartRollupExecutePatternConfig
+from dipdup.config.tezos_operations import TezosOperationsHandlerTransactionPatternConfig
+from dipdup.config.tezos_operations import TezosOperationsIndexConfig
+from dipdup.config.tezos_operations import TezosOperationsUnfilteredIndexConfig
+from dipdup.config.tezos_token_balances import TezosTokenBalancesIndexConfig
+from dipdup.config.tezos_token_transfers import TezosTokenTransfersIndexConfig
+from dipdup.config.tezos_tzkt import TezosTzktDatasourceConfig
 from dipdup.config.tzip_metadata import TzipMetadataDatasourceConfig
 
 # NOTE: Unions for Pydantic config deserialization
 ContractConfigU = EvmContractConfig | TezosContractConfig
 DatasourceConfigU = (
     CoinbaseDatasourceConfig
-    | EtherscanDatasourceConfig
+    | AbiEtherscanDatasourceConfig
     | HttpDatasourceConfig
     | IpfsDatasourceConfig
-    | SubsquidDatasourceConfig
+    | EvmSubsquidDatasourceConfig
     | EvmNodeDatasourceConfig
     | TzipMetadataDatasourceConfig
-    | TzktDatasourceConfig
+    | TezosTzktDatasourceConfig
 )
-TzktIndexConfigU = (
-    TzktBigMapsIndexConfig
-    | TzktEventsIndexConfig
-    | TzktHeadIndexConfig
-    | TzktOperationsIndexConfig
-    | TzktOperationsUnfilteredIndexConfig
-    | TzktTokenTransfersIndexConfig
-    | TzktTokenBalancesIndexConfig
+TezosIndexConfigU = (
+    TezosBigMapsIndexConfig
+    | TezosEventsIndexConfig
+    | TezosHeadIndexConfig
+    | TezosOperationsIndexConfig
+    | TezosOperationsUnfilteredIndexConfig
+    | TezosTokenTransfersIndexConfig
+    | TezosTokenBalancesIndexConfig
 )
-SubsquidIndexConfigU = SubsquidEventsIndexConfig | SubsquidTracesIndexConfig | SubsquidTransactionsIndexConfig
+EvmIndexConfigU = EvmEventsIndexConfig | EvmTransactionsIndexConfig
 
-ResolvedIndexConfigU = TzktIndexConfigU | SubsquidIndexConfigU
+ResolvedIndexConfigU = TezosIndexConfigU | EvmIndexConfigU
 IndexConfigU = ResolvedIndexConfigU | IndexTemplateConfig
 
 
-def _patch_annotations(replace_table: dict[str, str]) -> None:
+def _patch_annotations() -> None:
     """Patch dataclass annotations in runtime to allow using aliases in config files.
 
     DipDup YAML config uses string aliases for contracts and datasources. During `DipDupConfig.load` these
     aliases are resolved to actual configs from corresponding sections and never become strings again.
     This hack allows to add `str` in Unions before loading config so we don't need to write `isinstance(...)`
     checks everywhere.
-
-    You can revert these changes by calling `patch_annotations(orinal_annotations)`, but tests will fail.
     """
     self = importlib.import_module(__name__)
     submodules = tuple(inspect.getmembers(self, inspect.ismodule))
     submodules += ((__name__, self),)
 
     for name, submodule in submodules:
         if not submodule.__name__.startswith('dipdup.config'):
             continue
 
         for attr in dir(submodule):
             value = getattr(submodule, attr)
-            if hasattr(value, '__annotations__'):
+            if not hasattr(value, '__annotations__'):
+                continue
+
+            reload = False
+            for name, annotation in value.__annotations__.items():
                 # NOTE: All annotations are strings now
-                reload = False
-                for name, annotation in value.__annotations__.items():
-                    annotation = annotation if isinstance(annotation, str) else annotation.__class__.__name__
-                    if new_annotation := replace_table.get(annotation):
-                        value.__annotations__[name] = new_annotation
-                        reload = True
-
-                # NOTE: Wrap dataclass again to recreate magic methods
-                if reload:
-                    setattr(submodule, attr, dataclass(value))
-
-            if hasattr(value, '__pydantic_model__'):
-                value.__pydantic_model__.update_forward_refs()
-
-
-_original_to_aliased = {
-    'TzktDatasourceConfig': 'str | TzktDatasourceConfig',
-    'SubsquidDatasourceConfig': 'str | SubsquidDatasourceConfig',
-    'SubsquidDatasourceConfig | EvmNodeDatasourceConfig': 'str | SubsquidDatasourceConfig | EvmNodeDatasourceConfig',
-    'ContractConfig': 'str | ContractConfig',
-    'ContractConfig | None': 'str | ContractConfig | None',
-    'TezosContractConfig': 'str | TezosContractConfig',
-    'TezosContractConfig | None': 'str | TezosContractConfig | None',
-    'EvmContractConfig': 'str | EvmContractConfig',
-    'EvmContractConfig | None': 'str | EvmContractConfig | None',
-    'list[TezosContractConfig]': 'list[str | TezosContractConfig]',
-    'HookConfig': 'str | HookConfig',
-    'EvmNodeDatasourceConfig | tuple[EvmNodeDatasourceConfig, ...] | None': (
-        'str | tuple[str, ...] | EvmNodeDatasourceConfig | tuple[EvmNodeDatasourceConfig, ...] | None'
-    ),
-}
-_patch_annotations(_original_to_aliased)
+                if not isinstance(annotation, str):
+                    continue
+
+                # NOTE: Unwrap `Alias[...]` to 'str | ...' to allow using aliases in config files
+                unwrapped = annotation
+
+                while match := re.match(r'(.*)Alias\[(.*)', unwrapped):
+                    before, body = match.groups()
+                    body, after = body.split(']', 1)
+                    unwrapped = f'{before}str | {body}{after}'
+
+                if annotation != unwrapped:
+                    value.__annotations__[name] = unwrapped
+                    reload = True
+
+            if not reload:
+                continue
+
+            # NOTE: Wrap dataclass again to recreate magic methods.
+            # NOTE: We need to trick Pydantic that it's a native dataclass.
+            delattr(value, '__pydantic_validator__')
+            try:
+                value = dataclass(value)
+            except RuntimeError:
+                value = dataclass(value)
+            setattr(submodule, attr, value)
+
+
+_patch_annotations()
```

### Comparing `dipdup-7.5.7/src/dipdup/config/abi_etherscan.py` & `dipdup-8.0.0a1/src/dipdup/config/abi_etherscan.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,21 +1,20 @@
 from typing import Literal
 
 from pydantic import ConfigDict
-from pydantic import Extra
 from pydantic.dataclasses import dataclass
 
 from dipdup.config import AbiDatasourceConfig
 from dipdup.config import HttpConfig
 
 DEFAULT_ETHERSCAN_URL = 'https://api.etherscan.io/api'
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class EtherscanDatasourceConfig(AbiDatasourceConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class AbiEtherscanDatasourceConfig(AbiDatasourceConfig):
     """Etherscan datasource config
 
     :param kind: always 'abi.etherscan'
     :param url: API URL
     :param api_key: API key
     :param http: HTTP client configuration
     """
```

### Comparing `dipdup-7.5.7/src/dipdup/config/evm.py` & `dipdup-8.0.0a1/src/dipdup/config/evm.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,39 +1,49 @@
+from abc import ABC
 from typing import Literal
+from typing import TypeAlias
 
 from eth_utils.address import is_address
 from eth_utils.address import to_normalized_address
 from pydantic import ConfigDict
-from pydantic import Extra
-from pydantic import validator
+from pydantic import field_validator
 from pydantic.dataclasses import dataclass
 
+from dipdup.config import Alias
 from dipdup.config import ContractConfig
+from dipdup.config import Hex
+from dipdup.config import IndexConfig
+from dipdup.config.abi_etherscan import AbiEtherscanDatasourceConfig
+from dipdup.config.evm_node import EvmNodeDatasourceConfig
+from dipdup.config.evm_subsquid import EvmSubsquidDatasourceConfig
 from dipdup.exceptions import ConfigurationError
 
 EVM_ADDRESS_PREFIXES = ('0x',)
 EVM_ADDRESS_LENGTH = 42
 
+EvmDatasourceConfigU: TypeAlias = EvmSubsquidDatasourceConfig | EvmNodeDatasourceConfig | AbiEtherscanDatasourceConfig
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class EvmContractConfig(ContractConfig):
     """EVM contract config
 
     :param kind: Always `evm`
     :param address: Contract address
     :param abi: Contract ABI
     :param typename: Alias for the contract script
     """
 
     kind: Literal['evm']
-    address: str | None = None
-    abi: str | None = None
+    address: Hex | None = None
+    abi: Hex | None = None
     typename: str | None = None
 
-    @validator('address', 'abi', allow_reuse=True)
+    @field_validator('address', 'abi')
+    @classmethod
     def _valid_address(cls, v: str | None) -> str | None:
         # NOTE: It's a `config export` call with environment variable substitution disabled
         if not v or '$' in v:
             return v
 
         if not is_address(v):
             raise ValueError(f'{v} is not a valid EVM contract address')
@@ -41,7 +51,18 @@
         # See https://coincodex.com/article/2078/ethereum-address-checksum-explained/
         return to_normalized_address(v)
 
     def get_address(self) -> str:
         if self.address is None:
             raise ConfigurationError(f'`contracts.{self.name}`: `address` field is required`')
         return self.address
+
+
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class EvmIndexConfig(IndexConfig, ABC):
+    """EVM index that use Subsquid Network as a datasource
+
+    :param kind: starts with 'evm'
+    :param datasources: `evm` datasources to use
+    """
+
+    datasources: tuple[Alias[EvmDatasourceConfigU], ...]
```

### Comparing `dipdup-7.5.7/src/dipdup/config/evm_node.py` & `dipdup-8.0.0a1/src/dipdup/config/evm_node.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,21 +1,20 @@
 from __future__ import annotations
 
 from typing import Literal
 
 from pydantic import ConfigDict
-from pydantic import Extra
-from pydantic import validator
+from pydantic import field_validator
 from pydantic.dataclasses import dataclass
 
 from dipdup.config import HttpConfig
 from dipdup.config import IndexDatasourceConfig
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class EvmNodeDatasourceConfig(IndexDatasourceConfig):
     """Subsquid datasource config
 
     :param kind: Always 'evm.node'
     :param url: Ethereum node URL
     :param ws_url: Ethereum node WebSocket URL
     :param http: HTTP client configuration
@@ -28,18 +27,20 @@
     http: HttpConfig | None = None
     rollback_depth: int = 32
 
     @property
     def merge_subscriptions(self) -> bool:
         return False
 
-    @validator('url')
+    @field_validator('url')
+    @classmethod
     def _valid_url(cls, v: str) -> str:
         if not v.startswith(('http://', 'https://')):
             raise ValueError('Ethereum node URL must start with http(s)://')
         return v
 
-    @validator('ws_url')
+    @field_validator('ws_url')
+    @classmethod
     def _valid_ws_url(cls, v: str | None) -> str | None:
         if v and not v.startswith(('ws://', 'wss://')):
             raise ValueError('Ethereum node WebSocket URL must start with ws(s)://')
         return v
```

### Comparing `dipdup-7.5.7/src/dipdup/config/evm_subsquid.py` & `dipdup-8.0.0a1/src/dipdup/config/evm_subsquid.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,63 +1,40 @@
 from __future__ import annotations
 
-import random
-from abc import ABC
 from typing import Literal
 
 from pydantic import ConfigDict
-from pydantic import Extra
-from pydantic import validator
+from pydantic import field_validator
 from pydantic.dataclasses import dataclass
 
 from dipdup.config import HttpConfig
-from dipdup.config import IndexConfig
 from dipdup.config import IndexDatasourceConfig
-from dipdup.config.evm_node import EvmNodeDatasourceConfig
 from dipdup.exceptions import ConfigurationError
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class SubsquidDatasourceConfig(IndexDatasourceConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class EvmSubsquidDatasourceConfig(IndexDatasourceConfig):
     """Subsquid datasource config
 
     :param kind: always 'evm.subsquid'
     :param url: URL of Subsquid Network API
-    :param node: One or more `evm.node` datasource(s) for the same network
     :param http: HTTP client configuration
     """
 
     kind: Literal['evm.subsquid']
     url: str
-    node: EvmNodeDatasourceConfig | tuple[EvmNodeDatasourceConfig, ...] | None = None
     http: HttpConfig | None = None
 
     @property
-    def random_node(self) -> EvmNodeDatasourceConfig | None:
-        if not isinstance(self.node, tuple):
-            return self.node
-        return random.choice(self.node)
-
-    @property
     def merge_subscriptions(self) -> bool:
         return False
 
     @property
     def rollback_depth(self) -> int:
         return 0
 
-    @validator('url')
+    @field_validator('url')
+    @classmethod
     def _valid_url(cls, v: str) -> str:
         if not v.startswith(('http', 'https')):
             raise ConfigurationError('Subsquid Network URL must start with http(s)')
         return v
-
-
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class SubsquidIndexConfig(IndexConfig, ABC):
-    """EVM index that use Subsquid Network as a datasource
-
-    :param kind: starts with 'evm.subsquid'
-    :param datasource: Subsquid datasource config
-    """
-
-    datasource: SubsquidDatasourceConfig | EvmNodeDatasourceConfig
```

### Comparing `dipdup-7.5.7/src/dipdup/config/evm_subsquid_events.py` & `dipdup-8.0.0a1/src/dipdup/config/evm_events.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,79 +1,73 @@
 from __future__ import annotations
 
-from dataclasses import field
 from typing import TYPE_CHECKING
 from typing import Literal
 
 from pydantic import ConfigDict
-from pydantic import Extra
 from pydantic.dataclasses import dataclass
 
-from dipdup.config import AbiDatasourceConfig
+from dipdup.config import Alias
 from dipdup.config import HandlerConfig
 from dipdup.config.evm import EvmContractConfig
-from dipdup.config.evm_node import EvmNodeDatasourceConfig
-from dipdup.config.evm_subsquid import SubsquidDatasourceConfig
-from dipdup.config.evm_subsquid import SubsquidIndexConfig
+from dipdup.config.evm import EvmDatasourceConfigU
+from dipdup.config.evm import EvmIndexConfig
 from dipdup.models.evm_node import EvmNodeHeadSubscription
 from dipdup.models.evm_node import EvmNodeLogsSubscription
 from dipdup.utils import pascal_to_snake
 from dipdup.utils import snake_to_pascal
 
 if TYPE_CHECKING:
     from collections.abc import Iterator
 
     from dipdup.subscriptions import Subscription
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class SubsquidEventsHandlerConfig(HandlerConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class EvmEventsHandlerConfig(HandlerConfig):
     """Subsquid event handler
 
     :param callback: Callback name
     :param contract: EVM contract
     :param name: Event name
     """
 
-    contract: EvmContractConfig
+    contract: Alias[EvmContractConfig]
     name: str
 
     def iter_imports(self, package: str) -> Iterator[tuple[str, str]]:
         yield 'dipdup.context', 'HandlerContext'
-        yield 'dipdup.models.evm_subsquid', 'SubsquidEvent'
+        yield 'dipdup.models.evm', 'EvmEvent'
         yield package, 'models as models'
 
-        event_cls = snake_to_pascal(self.name)
+        event_cls = snake_to_pascal(self.name) + 'Payload'
         event_module = pascal_to_snake(self.name)
         module_name = self.contract.module_name
         yield f'{package}.types.{module_name}.evm_events.{event_module}', event_cls
 
     def iter_arguments(self) -> Iterator[tuple[str, str]]:
-        event_cls = snake_to_pascal(self.name)
+        event_cls = snake_to_pascal(self.name) + 'Payload'
         yield 'ctx', 'HandlerContext'
-        yield 'event', f'SubsquidEvent[{event_cls}]'
+        yield 'event', f'EvmEvent[{event_cls}]'
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class SubsquidEventsIndexConfig(SubsquidIndexConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class EvmEventsIndexConfig(EvmIndexConfig):
     """Subsquid datasource config
 
-    :param kind: Always 'evm.subsquid.events'
-    :param datasource: Subsquid datasource
+    :param kind: Always 'evm.events'
+    :param datasources: `evm` datasources to use
     :param handlers: Event handlers
-    :param abi: One or more `evm.abi` datasource(s) for the same network
     :param first_level: Level to start indexing from
     :param last_level: Level to stop indexing and disable this index
     """
 
-    kind: Literal['evm.subsquid.events']
-    datasource: SubsquidDatasourceConfig | EvmNodeDatasourceConfig
-    handlers: tuple[SubsquidEventsHandlerConfig, ...] = field(default_factory=tuple)
-    abi: AbiDatasourceConfig | tuple[AbiDatasourceConfig, ...] | None = None
-    node_only: bool = False
+    kind: Literal['evm.events']
+    datasources: tuple[Alias[EvmDatasourceConfigU], ...]
+    handlers: tuple[EvmEventsHandlerConfig, ...]
 
     first_level: int = 0
     last_level: int = 0
 
     def get_subscriptions(self) -> set[Subscription]:
         subs: set[Subscription] = {EvmNodeHeadSubscription()}
         for handler in self.handlers:
```

### Comparing `dipdup-7.5.7/src/dipdup/config/evm_subsquid_transactions.py` & `dipdup-8.0.0a1/src/dipdup/config/evm_transactions.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,95 +1,88 @@
 from __future__ import annotations
 
-from dataclasses import field
 from typing import TYPE_CHECKING
 from typing import Literal
 
 from pydantic import ConfigDict
-from pydantic import Extra
 from pydantic.dataclasses import dataclass
 
-from dipdup.config import AbiDatasourceConfig
+from dipdup.config import Alias
 from dipdup.config import CodegenMixin
 from dipdup.config import HandlerConfig
 from dipdup.config.evm import EvmContractConfig
-from dipdup.config.evm_node import EvmNodeDatasourceConfig
-from dipdup.config.evm_subsquid import SubsquidDatasourceConfig
-from dipdup.config.evm_subsquid import SubsquidIndexConfig
+from dipdup.config.evm import EvmDatasourceConfigU
+from dipdup.config.evm import EvmIndexConfig
 from dipdup.models.evm_node import EvmNodeHeadSubscription
 from dipdup.subscriptions import Subscription
 from dipdup.utils import pascal_to_snake
 from dipdup.utils import snake_to_pascal
 
 if TYPE_CHECKING:
     from collections.abc import Iterator
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class SubsquidTransactionsHandlerConfig(HandlerConfig, CodegenMixin):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class EvmTransactionsHandlerConfig(HandlerConfig, CodegenMixin):
     """Subsquid transaction handler
 
     :param callback: Callback name
     :param from_: Transaction sender
     :param to: Transaction receiver
     :param method: Method name
     """
 
-    # FIXME: Can't use `from_` field alias in dataclasses (fixed in `next` with Pydantic v2)
-    from_: EvmContractConfig | None = None
-    to: EvmContractConfig | None = None
+    # FIXME: Can't use `from_` field alias in dataclasses
+    from_: Alias[EvmContractConfig] | None = None
+    to: Alias[EvmContractConfig] | None = None
     method: str | None = None
 
     def iter_imports(self, package: str) -> Iterator[tuple[str, str]]:
         yield 'dipdup.context', 'HandlerContext'
         yield package, 'models as models'
 
         if self.typed_contract and self.method:
-            yield 'dipdup.models.evm_subsquid', 'SubsquidTransaction'
+            yield 'dipdup.models.evm', 'EvmTransaction'
             transaction_module = pascal_to_snake(self.method)
-            transaction_cls = snake_to_pascal(self.method)
+            transaction_cls = snake_to_pascal(self.method) + 'Input'
             module_name = self.typed_contract.module_name
-            yield f'{package}.types.{module_name}.evm_methods.{transaction_module}', transaction_cls
+            yield f'{package}.types.{module_name}.evm_transactions.{transaction_module}', transaction_cls
         else:
-            yield 'dipdup.models.evm_subsquid', 'SubsquidTransactionData'
-            yield 'dipdup.models.evm_node', 'EvmNodeTransactionData'
+            yield 'dipdup.models.evm', 'EvmTransactionData'
 
     def iter_arguments(self) -> Iterator[tuple[str, str]]:
         yield 'ctx', 'HandlerContext'
 
         if self.typed_contract and self.method:
-            transaction_cls = snake_to_pascal(self.method)
-            yield 'transaction', f'SubsquidTransaction[{transaction_cls}]'
+            transaction_cls = snake_to_pascal(self.method) + 'Input'
+            yield 'transaction', f'EvmTransaction[{transaction_cls}]'
         else:
-            yield 'transaction', 'SubsquidTransactionData | EvmNodeTransactionData'
+            yield 'transaction', 'EvmTransactionData'
 
     @property
     def typed_contract(self) -> EvmContractConfig | None:
         if self.method and self.to:
             return self.to
         return None
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class SubsquidTransactionsIndexConfig(SubsquidIndexConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class EvmTransactionsIndexConfig(EvmIndexConfig):
     """Index that uses Subsquid Network as a datasource for transactions
 
-    :param kind: always 'evm.subsquid.transactions'
-    :param datasource: Subsquid datasource config
+    :param kind: always 'evm.transactions'
+    :param datasources: `evm` datasources to use
     :param handlers: Transaction handlers
-    :param abi: One or many ABI datasource(s)
     :param first_level: Level to start indexing from
     :param last_level: Level to stop indexing at
     """
 
-    kind: Literal['evm.subsquid.transactions']
+    kind: Literal['evm.transactions']
 
-    datasource: SubsquidDatasourceConfig | EvmNodeDatasourceConfig
-    handlers: tuple[SubsquidTransactionsHandlerConfig, ...] = field(default_factory=tuple)
-    abi: AbiDatasourceConfig | tuple[AbiDatasourceConfig, ...] | None = None
-    node_only: bool = False
+    datasources: tuple[Alias[EvmDatasourceConfigU], ...]
+    handlers: tuple[EvmTransactionsHandlerConfig, ...]
 
     first_level: int = 0
     last_level: int = 0
 
     def get_subscriptions(self) -> set[Subscription]:
         return {EvmNodeHeadSubscription(transactions=True)}
```

### Comparing `dipdup-7.5.7/src/dipdup/config/http.py` & `dipdup-8.0.0a1/src/dipdup/config/http.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,18 +1,17 @@
 from typing import Literal
 
 from pydantic import ConfigDict
-from pydantic import Extra
 from pydantic.dataclasses import dataclass
 
 from dipdup.config import DatasourceConfig
 from dipdup.config import HttpConfig
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class HttpDatasourceConfig(DatasourceConfig):
     """Generic HTTP datasource config
 
     :param kind: always 'http'
     :param url: URL to fetch data from
     :param http: HTTP client configuration
     """
```

### Comparing `dipdup-7.5.7/src/dipdup/config/ipfs.py` & `dipdup-8.0.0a1/src/dipdup/config/ipfs.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,20 +1,19 @@
 from typing import Literal
 
 from pydantic import ConfigDict
-from pydantic import Extra
 from pydantic.dataclasses import dataclass
 
 from dipdup.config import DatasourceConfig
 from dipdup.config import HttpConfig
 
 DEFAULT_IPFS_URL = 'https://ipfs.io/ipfs'
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class IpfsDatasourceConfig(DatasourceConfig):
     """IPFS datasource config
 
     :param kind: always 'ipfs'
     :param url: IPFS node URL, e.g. https://ipfs.io/ipfs/
     :param http: HTTP client configuration
     """
```

### Comparing `dipdup-7.5.7/src/dipdup/config/tezos.py` & `dipdup-8.0.0a1/src/dipdup/config/tezos.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,22 @@
+import random
 from typing import Literal
 
 from pydantic import ConfigDict
-from pydantic import Extra
-from pydantic import validator
+from pydantic import field_validator
 from pydantic.dataclasses import dataclass
 
+from dipdup.config import Alias
 from dipdup.config import ContractConfig
+from dipdup.config import IndexConfig
+from dipdup.config.tezos_tzkt import TezosTzktDatasourceConfig
 from dipdup.exceptions import ConfigurationError
 from dipdup.exceptions import FrameworkException
+from dipdup.models.tezos_tzkt import HeadSubscription
+from dipdup.subscriptions import Subscription
 
 ADDRESS_LENGTH = 36
 SMART_CONTRACT_PREFIX = 'KT1'
 SMART_ROLLUP_PREFIX = 'sr1'
 WALLET_PREFIXES = ('tz1', 'tz2', 'tz3')
 
 
@@ -23,30 +28,31 @@
     return len(address) == ADDRESS_LENGTH and address.startswith(SMART_ROLLUP_PREFIX)
 
 
 def is_wallet_address(address: str) -> bool:
     return len(address) == ADDRESS_LENGTH and address.startswith(WALLET_PREFIXES)
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class TezosContractConfig(ContractConfig):
     """Tezos contract config.
 
     :param kind: Always `tezos`
     :param address: Contract address
     :param code_hash: Contract code hash or address to fetch it from
     :param typename: Alias for the contract script
     """
 
     kind: Literal['tezos']
     address: str | None = None
     code_hash: int | str | None = None
     typename: str | None = None
 
-    @validator('address', allow_reuse=True)
+    @field_validator('address')
+    @classmethod
     def _valid_address(cls, v: str | None) -> str | None:
         # NOTE: It's a `config export` call with environment variable substitution disabled
         if not v or '$' in v:
             return v
 
         if not any((is_contract_address(v), is_rollup_address(v), is_wallet_address(v))):
             raise ValueError(f'`{v}` is not a valid Tezos address')
@@ -59,7 +65,29 @@
         return self.address
 
     @property
     def resolved_code_hash(self) -> int | None:
         if isinstance(self.code_hash, str):
             raise FrameworkException('`code_hash` was not resolved during startup')
         return self.code_hash
+
+
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class TezosIndexConfig(IndexConfig):
+    """TzKT index config
+
+    :param kind: starts with 'tezos'
+    :param datasources: `tezos` datasources to use
+    """
+
+    datasources: tuple[Alias[TezosTzktDatasourceConfig], ...]
+
+    @property
+    def merge_subscriptions(self) -> bool:
+        return any(d.merge_subscriptions for d in self.datasources)
+
+    @property
+    def random_datasource(self) -> TezosTzktDatasourceConfig:
+        return random.choice(self.datasources)
+
+    def get_subscriptions(self) -> set[Subscription]:
+        return {HeadSubscription()}
```

### Comparing `dipdup-7.5.7/src/dipdup/config/tezos_tzkt.py` & `dipdup-8.0.0a1/src/dipdup/config/tezos_tzkt.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,35 +1,31 @@
 from typing import Literal
 from urllib.parse import urlparse
 
 from pydantic import ConfigDict
-from pydantic import Extra
 from pydantic.dataclasses import dataclass
 
 from dipdup.config import HttpConfig
-from dipdup.config import IndexConfig
 from dipdup.config import IndexDatasourceConfig
 from dipdup.exceptions import ConfigurationError
-from dipdup.models.tezos_tzkt import HeadSubscription
-from dipdup.subscriptions import Subscription
 
 TZKT_API_URLS: dict[str, str] = {
     'https://api.tzkt.io': 'mainnet',
     'https://api.ghostnet.tzkt.io': 'ghostnet',
     'https://api.limanet.tzkt.io': 'limanet',
     'https://staging.api.tzkt.io': 'staging',
 }
 
 
 DEFAULT_TZKT_URL = next(iter(TZKT_API_URLS.keys()))
 MAX_BATCH_SIZE = 10000
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class TzktDatasourceConfig(IndexDatasourceConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class TezosTzktDatasourceConfig(IndexDatasourceConfig):
     """TzKT datasource config
 
     :param kind: always 'tezos.tzkt'
     :param url: Base API URL, e.g. https://api.tzkt.io/
     :param http: HTTP client configuration
     :param buffer_size: Number of levels to keep in FIFO buffer before processing
     :param merge_subscriptions: Whether to merge realtime subscriptions
@@ -39,34 +35,20 @@
     kind: Literal['tezos.tzkt']
     url: str = DEFAULT_TZKT_URL
     http: HttpConfig | None = None
     buffer_size: int = 0
     merge_subscriptions: bool = False
     rollback_depth: int = 2
 
-    def __post_init_post_parse__(self) -> None:
-        super().__post_init_post_parse__()
+    def __post_init__(self) -> None:
+        super().__post_init__()
         self.url = self.url.rstrip('/')
 
         limit = MAX_BATCH_SIZE
         if self.http and self.http.batch_size and self.http.batch_size > limit:
             raise ConfigurationError(f'`batch_size` must be less than {limit}')
         # NOTE: It's a `config export` call with environment variable substitution disabled
         if '$' in self.url:
             return
         parsed_url = urlparse(self.url)
         if not (parsed_url.scheme and parsed_url.netloc):
             raise ConfigurationError(f'`{self.url}` is not a valid TzKT API URL')
-
-
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class TzktIndexConfig(IndexConfig):
-    """TzKT index config
-
-    :param kind: starts with 'tezos.tzkt'
-    :param datasource: `tezos.tzkt` datasource to use
-    """
-
-    datasource: TzktDatasourceConfig
-
-    def get_subscriptions(self) -> set[Subscription]:
-        return {HeadSubscription()}
```

### Comparing `dipdup-7.5.7/src/dipdup/config/tezos_tzkt_big_maps.py` & `dipdup-8.0.0a1/src/dipdup/config/tezos_big_maps.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,43 +1,43 @@
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 from typing import Any
 from typing import Literal
 
 from pydantic import ConfigDict
-from pydantic import Extra
 from pydantic.dataclasses import dataclass
 
+from dipdup.config import Alias
 from dipdup.config import ContractConfig
 from dipdup.config import HandlerConfig
 from dipdup.config.tezos import TezosContractConfig
-from dipdup.config.tezos_tzkt import TzktDatasourceConfig
-from dipdup.config.tezos_tzkt import TzktIndexConfig
+from dipdup.config.tezos import TezosIndexConfig
+from dipdup.config.tezos_tzkt import TezosTzktDatasourceConfig
 from dipdup.models import SkipHistory
 from dipdup.models.tezos_tzkt import BigMapSubscription
 from dipdup.utils import pascal_to_snake
 from dipdup.utils import snake_to_pascal
 
 if TYPE_CHECKING:
     from collections.abc import Iterator
 
     from dipdup.subscriptions import Subscription
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class TzktBigMapsHandlerConfig(HandlerConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class TezosBigMapsHandlerConfig(HandlerConfig):
     """Big map handler config
 
     :param callback: Callback name
     :param contract: Contract to fetch big map from
     :param path: Path to big map (alphanumeric string with dots)
     """
 
-    contract: TezosContractConfig
+    contract: Alias[TezosContractConfig]
     path: str
 
     @classmethod
     def format_key_import(cls, package: str, module_name: str, path: str) -> tuple[str, str]:
         key_cls = f'{snake_to_pascal(path)}Key'
         key_module = f'{pascal_to_snake(path)}_key'
         return f'{package}.types.{module_name}.tezos_big_maps.{key_module}', key_cls
@@ -48,57 +48,57 @@
         value_module = f'{pascal_to_snake(path)}_value'
         return f'{package}.types.{module_name}.tezos_big_maps.{value_module}', value_cls
 
     @classmethod
     def format_big_map_diff_argument(cls, path: str) -> tuple[str, str]:
         key_cls = f'{snake_to_pascal(path)}Key'
         value_cls = f'{snake_to_pascal(path)}Value'
-        return pascal_to_snake(path), f'TzktBigMapDiff[{key_cls}, {value_cls}]'
+        return pascal_to_snake(path), f'BigMapDiff[{key_cls}, {value_cls}]'
 
     def iter_imports(self, package: str) -> Iterator[tuple[str, str]]:
         yield 'dipdup.context', 'HandlerContext'
-        yield 'dipdup.models.tezos_tzkt', 'TzktBigMapDiff'
+        yield 'dipdup.models.tezos', 'TezosBigMapDiff'
         yield package, 'models as models'
 
         yield self.format_key_import(package, self.contract.module_name, self.path)
         yield self.format_value_import(package, self.contract.module_name, self.path)
 
     def iter_arguments(self) -> Iterator[tuple[str, str]]:
         yield 'ctx', 'HandlerContext'
         yield self.format_big_map_diff_argument(self.path)
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class TzktBigMapsIndexConfig(TzktIndexConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class TezosBigMapsIndexConfig(TezosIndexConfig):
     """Big map index config
 
-    :param kind: always 'tezos.tzkt.big_maps'
-    :param datasource: Index datasource to fetch big maps with
+    :param kind: always 'tezos.big_maps'
+    :param datasources: Tezos datasources to use
     :param handlers: Mapping of big map diff handlers
     :param skip_history: Fetch only current big map keys ignoring historical changes
     :param first_level: Level to start indexing from
     :param last_level: Level to stop indexing at
     """
 
-    kind: Literal['tezos.tzkt.big_maps']
-    datasource: TzktDatasourceConfig
-    handlers: tuple[TzktBigMapsHandlerConfig, ...]
+    kind: Literal['tezos.big_maps']
+    datasources: tuple[Alias[TezosTzktDatasourceConfig], ...]
+    handlers: tuple[TezosBigMapsHandlerConfig, ...]
 
     skip_history: SkipHistory = SkipHistory.never
 
     first_level: int = 0
     last_level: int = 0
 
     @property
     def contracts(self) -> set[ContractConfig]:
         return {handler_config.contract for handler_config in self.handlers}
 
     def get_subscriptions(self) -> set[Subscription]:
         subs = super().get_subscriptions()
-        if self.datasource.merge_subscriptions:
+        if self.merge_subscriptions:
             subs.add(BigMapSubscription())
         else:
             for handler_config in self.handlers:
                 address, path = handler_config.contract.address, handler_config.path
                 subs.add(BigMapSubscription(address=address, path=path))
         return subs
```

### Comparing `dipdup-7.5.7/src/dipdup/config/tezos_tzkt_events.py` & `dipdup-8.0.0a1/src/dipdup/config/tezos_events.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,102 +1,101 @@
 from __future__ import annotations
 
-from dataclasses import field
 from typing import TYPE_CHECKING
 from typing import Literal
 
 from pydantic import ConfigDict
-from pydantic import Extra
 from pydantic.dataclasses import dataclass
 
+from dipdup.config import Alias
 from dipdup.config import HandlerConfig
 from dipdup.config.tezos import TezosContractConfig
-from dipdup.config.tezos_tzkt import TzktDatasourceConfig
-from dipdup.config.tezos_tzkt import TzktIndexConfig
+from dipdup.config.tezos import TezosIndexConfig
+from dipdup.config.tezos_tzkt import TezosTzktDatasourceConfig
 from dipdup.models.tezos_tzkt import EventSubscription
 from dipdup.utils import pascal_to_snake
 from dipdup.utils import snake_to_pascal
 
 if TYPE_CHECKING:
     from collections.abc import Iterator
 
     from dipdup.subscriptions import Subscription
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class TzktEventsHandlerConfig(HandlerConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class TezosEventsHandlerConfig(HandlerConfig):
     """Event handler config
 
     :param callback: Callback name
     :param contract: Contract which emits event
     :param tag: Event tag
     """
 
-    contract: TezosContractConfig
+    contract: Alias[TezosContractConfig]
     tag: str
 
     def iter_imports(self, package: str) -> Iterator[tuple[str, str]]:
         yield 'dipdup.context', 'HandlerContext'
-        yield 'dipdup.models.tezos_tzkt', 'TzktEvent'
+        yield 'dipdup.models.tezos', 'TezosEvent'
         yield package, 'models as models'
 
         event_cls = snake_to_pascal(self.tag + '_payload')
         event_module = pascal_to_snake(self.tag)
         module_name = self.contract.module_name
         yield f'{package}.types.{module_name}.tezos_events.{event_module}', event_cls
 
     def iter_arguments(self) -> Iterator[tuple[str, str]]:
         event_cls = snake_to_pascal(self.tag + '_payload')
         yield 'ctx', 'HandlerContext'
-        yield 'event', f'TzktEvent[{event_cls}]'
+        yield 'event', f'TezosEvent[{event_cls}]'
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class TzktEventsUnknownEventHandlerConfig(HandlerConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class TezosEventsUnknownEventHandlerConfig(HandlerConfig):
     """Unknown event handler config
 
     :param callback: Callback name
     :param contract: Contract which emits event
     """
 
-    contract: TezosContractConfig
+    contract: Alias[TezosContractConfig]
 
     def iter_imports(self, package: str) -> Iterator[tuple[str, str]]:
         yield 'dipdup.context', 'HandlerContext'
-        yield 'dipdup.models.tezos_tzkt', 'TzktUnknownEvent'
+        yield 'dipdup.models.tezos', 'TezosUnknownEvent'
         yield package, 'models as models'
 
     def iter_arguments(self) -> Iterator[tuple[str, str]]:
         yield 'ctx', 'HandlerContext'
-        yield 'event', 'TzktUnknownEvent'
+        yield 'event', 'TezosUnknownEvent'
 
 
-TzktEventsHandlerConfigU = TzktEventsHandlerConfig | TzktEventsUnknownEventHandlerConfig
+TezosEventsHandlerConfigU = TezosEventsHandlerConfig | TezosEventsUnknownEventHandlerConfig
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class TzktEventsIndexConfig(TzktIndexConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class TezosEventsIndexConfig(TezosIndexConfig):
     """Event index config
 
-    :param kind: always 'tezos.tzkt.events'
-    :param datasource: Datasource config
+    :param kind: always 'tezos.events'
+    :param datasources: `evm` datasources to use
     :param handlers: Event handlers
     :param first_level: First block level to index
     :param last_level: Last block level to index
     """
 
-    kind: Literal['tezos.tzkt.events']
-    datasource: TzktDatasourceConfig
-    handlers: tuple[TzktEventsHandlerConfigU, ...] = field(default_factory=tuple)
+    kind: Literal['tezos.events']
+    datasources: tuple[Alias[TezosTzktDatasourceConfig], ...]
+    handlers: tuple[TezosEventsHandlerConfigU, ...]
 
     first_level: int = 0
     last_level: int = 0
 
     def get_subscriptions(self) -> set[Subscription]:
         subs = super().get_subscriptions()
-        if self.datasource.merge_subscriptions:
+        if self.merge_subscriptions:
             subs.add(EventSubscription())
         else:
             for handler_config in self.handlers:
                 address = handler_config.contract.address
                 subs.add(EventSubscription(address=address))
         return subs
```

### Comparing `dipdup-7.5.7/src/dipdup/config/tezos_tzkt_head.py` & `dipdup-8.0.0a1/src/dipdup/config/tezos_head.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,59 +1,58 @@
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 from typing import Literal
 
 from pydantic import ConfigDict
-from pydantic import Extra
 from pydantic.dataclasses import dataclass
 
+from dipdup.config import Alias
 from dipdup.config import HandlerConfig
-from dipdup.config.tezos_tzkt import TzktDatasourceConfig
-from dipdup.config.tezos_tzkt import TzktIndexConfig
+from dipdup.config.tezos import TezosIndexConfig
+from dipdup.config.tezos_tzkt import TezosTzktDatasourceConfig
 
 if TYPE_CHECKING:
     from collections.abc import Iterator
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class HeadHandlerConfig(HandlerConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class TezosTzktHeadHandlerConfig(HandlerConfig):
     """Head block handler config
 
     :param callback: Callback name
     """
 
     def iter_imports(self, package: str) -> Iterator[tuple[str, str]]:
         yield 'dipdup.context', 'HandlerContext'
-        yield 'dipdup.models.tezos_tzkt', 'TzktHeadBlockData'
+        yield 'dipdup.models.tezos', 'TezosHeadBlockData'
         yield package, 'models as models'
 
     def iter_arguments(self) -> Iterator[tuple[str, str]]:
         yield 'ctx', 'HandlerContext'
-        yield 'head', 'TzktHeadBlockData'
+        yield 'head', 'TezosHeadBlockData'
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class TzktHeadIndexConfig(TzktIndexConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class TezosHeadIndexConfig(TezosIndexConfig):
     """Head block index config
 
-    :param kind: always 'tezos.tzkt.head'
+    :param kind: always 'tezos.head'
     :param callback: Callback name
-    :param datasource: Index datasource to receive head blocks
-    :param handlers: Mapping of head block handlers
+    :param datasources: `tezos` datasources to use
     """
 
-    kind: Literal['tezos.tzkt.head']
-    datasource: TzktDatasourceConfig
+    kind: Literal['tezos.head']
+    datasources: tuple[Alias[TezosTzktDatasourceConfig], ...]
     callback: str
 
     @property
     def first_level(self) -> int:
         return 0
 
     @property
     def last_level(self) -> int:
         return 0
 
-    def __post_init_post_parse__(self) -> None:
-        super().__post_init_post_parse__()
-        self.handler_config = HeadHandlerConfig(callback=self.callback)
+    def __post_init__(self) -> None:
+        super().__post_init__()
+        self.handlers = (TezosTzktHeadHandlerConfig(callback=self.callback),)
```

### Comparing `dipdup-7.5.7/src/dipdup/config/tezos_tzkt_operations.py` & `dipdup-8.0.0a1/src/dipdup/config/tezos_operations.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,61 +1,61 @@
 from __future__ import annotations
 
-from dataclasses import field
 from typing import TYPE_CHECKING
 from typing import Any
 from typing import Literal
 from typing import cast
 
 from pydantic import ConfigDict
-from pydantic import Extra
 from pydantic.dataclasses import dataclass
+from pydantic.fields import Field
 
+from dipdup.config import Alias
 from dipdup.config import CodegenMixin
 from dipdup.config import HandlerConfig
 from dipdup.config.tezos import TezosContractConfig
-from dipdup.config.tezos_tzkt import TzktDatasourceConfig
-from dipdup.config.tezos_tzkt import TzktIndexConfig
+from dipdup.config.tezos import TezosIndexConfig
+from dipdup.config.tezos_tzkt import TezosTzktDatasourceConfig
 from dipdup.exceptions import ConfigInitializationException
 from dipdup.exceptions import ConfigurationError
+from dipdup.models.tezos import TezosOperationType
 from dipdup.models.tezos_tzkt import OriginationSubscription
 from dipdup.models.tezos_tzkt import SmartRollupExecuteSubscription
 from dipdup.models.tezos_tzkt import TransactionSubscription
-from dipdup.models.tezos_tzkt import TzktOperationType
 from dipdup.utils import pascal_to_snake
 from dipdup.utils import snake_to_pascal
 
 if TYPE_CHECKING:
     from collections.abc import Iterator
 
     from dipdup.subscriptions import Subscription
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class SubgroupIndexMixin:
     """`subgroup_index` field to track index of operation in group
 
     :param subgroup_index:
     """
 
-    def __post_init_post_parse__(self) -> None:
+    def __post_init__(self) -> None:
         self._subgroup_index: int | None = None
 
     @property
     def subgroup_index(self) -> int:
         if self._subgroup_index is None:
             raise ConfigInitializationException
         return self._subgroup_index
 
     @subgroup_index.setter
     def subgroup_index(self, value: int) -> None:
         self._subgroup_index = value
 
 
-class TezosPatternConfig(CodegenMixin):
+class TezosOperationsPatternConfig(CodegenMixin):
     """Base class for pattern config items.
 
     Contains methods for import and method signature generation during handler callbacks codegen.
     """
 
     @classmethod
     def format_storage_import(
@@ -80,85 +80,85 @@
         if alias:
             parameter_cls += f' as {snake_to_pascal(alias)}Parameter'
 
         return f'{package}.types.{module_name}.tezos_parameters.{parameter_module}', parameter_cls
 
     @classmethod
     def format_untyped_operation_import(cls) -> tuple[str, str]:
-        return 'dipdup.models.tezos_tzkt', 'TzktOperationData'
+        return 'dipdup.models.tezos', 'TezosOperationData'
 
     @classmethod
     def format_origination_argument(
         cls,
         module_name: str,
         optional: bool,
         alias: str | None,
     ) -> tuple[str, str]:
         arg_name = pascal_to_snake(alias or f'{module_name}_origination')
         storage_cls = f'{snake_to_pascal(module_name)}Storage'
         if optional:
-            return arg_name, f'TzktOrigination[{storage_cls}] | None'
-        return arg_name, f'TzktOrigination[{storage_cls}]'
+            return arg_name, f'TezosOrigination[{storage_cls}] | None'
+        return arg_name, f'TezosOrigination[{storage_cls}]'
 
     @classmethod
     def format_operation_argument(
         cls,
         module_name: str,
         entrypoint: str,
         optional: bool,
         alias: str | None,
     ) -> tuple[str, str]:
         arg_name = alias or entrypoint
         entrypoint = entrypoint.lstrip('_')
         parameter_cls = f'{snake_to_pascal(arg_name)}Parameter'
         storage_cls = f'{snake_to_pascal(module_name)}Storage'
         if optional:
-            return pascal_to_snake(arg_name), f'TzktTransaction[{parameter_cls}, {storage_cls}] | None'
-        return pascal_to_snake(arg_name), f'TzktTransaction[{parameter_cls}, {storage_cls}]'
+            return pascal_to_snake(arg_name), f'TezosTransaction[{parameter_cls}, {storage_cls}] | None'
+        return pascal_to_snake(arg_name), f'TezosTransaction[{parameter_cls}, {storage_cls}]'
 
     @classmethod
     def format_untyped_operation_argument(
         cls,
         type_: str,
         subgroup_index: int,
         optional: bool,
         alias: str | None,
     ) -> tuple[str, str]:
         arg_name = pascal_to_snake(alias or f'{type_}_{subgroup_index}')
         if optional:
-            return arg_name, 'TzktOperationData | None'
-        return arg_name, 'TzktOperationData'
+            return arg_name, 'TezosOperationData | None'
+        return arg_name, 'TezosOperationData'
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class OperationsHandlerTransactionPatternConfig(TezosPatternConfig, SubgroupIndexMixin):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class TezosOperationsHandlerTransactionPatternConfig(TezosOperationsPatternConfig, SubgroupIndexMixin):
     """Transaction handler pattern config
 
     :param type: always 'transaction'
     :param source: Match operations by source contract alias
     :param destination: Match operations by destination contract alias
     :param entrypoint: Match operations by contract entrypoint
     :param optional: Whether can operation be missing in operation group
     :param alias: Alias for operation (helps to avoid duplicates)
     """
 
     type: Literal['transaction'] = 'transaction'
-    source: TezosContractConfig | None = None
-    destination: TezosContractConfig | None = None
+    source: Alias[TezosContractConfig] | None = None
+    destination: Alias[TezosContractConfig] | None = None
     entrypoint: str | None = None
     optional: bool = False
     alias: str | None = None
 
-    def __post_init_post_parse__(self) -> None:
-        SubgroupIndexMixin.__post_init_post_parse__(self)
+    def __post_init__(self) -> None:
+        SubgroupIndexMixin.__post_init__(self)
 
     def iter_imports(self, package: str) -> Iterator[tuple[str, str]]:
         if self.typed_contract:
             module_name = self.typed_contract.module_name
-            yield 'dipdup.models.tezos_tzkt', 'TzktTransaction'
+            yield 'dipdup.models.tezos', 'TezosTransaction'
             yield self.format_parameter_import(
                 package,
                 module_name,
                 cast(str, self.entrypoint),
                 self.alias,
             )
             yield self.format_storage_import(package, module_name)
@@ -185,40 +185,40 @@
     @property
     def typed_contract(self) -> TezosContractConfig | None:
         if self.entrypoint and self.destination:
             return self.destination
         return None
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class OperationsHandlerOriginationPatternConfig(TezosPatternConfig, SubgroupIndexMixin):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class TezosOperationsHandlerOriginationPatternConfig(TezosOperationsPatternConfig, SubgroupIndexMixin):
     """Origination handler pattern config
 
     :param type: always 'origination'
     :param source: Match operations by source contract alias
     :param originated_contract: Match origination of exact contract
     :param optional: Whether can operation be missing in operation group
     :param strict: Match operations by storage only or by the whole code
     :param alias: Alias for operation (helps to avoid duplicates)
     """
 
     type: Literal['origination'] = 'origination'
-    source: TezosContractConfig | None = None
-    originated_contract: TezosContractConfig | None = None
+    source: Alias[TezosContractConfig] | None = None
+    originated_contract: Alias[TezosContractConfig] | None = None
     optional: bool = False
     strict: bool = False
     alias: str | None = None
 
     def iter_imports(self, package: str) -> Iterator[tuple[str, str]]:
         if self.typed_contract:
             module_name = self.typed_contract.module_name
-            yield 'dipdup.models.tezos_tzkt', 'TzktOrigination'
+            yield 'dipdup.models.tezos', 'TezosOrigination'
             yield self.format_storage_import(package, module_name)
         else:
-            yield 'dipdup.models.tezos_tzkt', 'TzktOperationData'
+            yield 'dipdup.models.tezos', 'TezosOperationData'
 
     def iter_arguments(self) -> Iterator[tuple[str, str]]:
         if self.typed_contract:
             yield self.format_origination_argument(
                 self.typed_contract.module_name,
                 self.optional,
                 self.alias,
@@ -234,90 +234,90 @@
     @property
     def typed_contract(self) -> TezosContractConfig | None:
         if self.originated_contract:
             return self.originated_contract
         return None
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class OperationsHandlerSmartRollupExecutePatternConfig(TezosPatternConfig, SubgroupIndexMixin):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class TezosOperationsHandlerSmartRollupExecutePatternConfig(TezosOperationsPatternConfig, SubgroupIndexMixin):
     """Operation handler pattern config
 
     :param type: always 'sr_execute'
     :param source: Match operations by source contract alias
     :param destination: Match operations by destination contract alias
     :param optional: Whether can operation be missing in operation group
     :param alias: Alias for operation (helps to avoid duplicates)
     """
 
     type: Literal['sr_execute'] = 'sr_execute'
-    source: TezosContractConfig | None = None
-    destination: TezosContractConfig | None = None
+    source: Alias[TezosContractConfig] | None = None
+    destination: Alias[TezosContractConfig] | None = None
     optional: bool = False
     alias: str | None = None
 
-    def __post_init_post_parse__(self) -> None:
-        SubgroupIndexMixin.__post_init_post_parse__(self)
+    def __post_init__(self) -> None:
+        SubgroupIndexMixin.__post_init__(self)
 
     def iter_imports(self, package: str) -> Iterator[tuple[str, str]]:
-        yield 'dipdup.models.tezos_tzkt', 'TzktSmartRollupExecute'
+        yield 'dipdup.models.tezos', 'TezosSmartRollupExecute'
 
     def iter_arguments(self) -> Iterator[tuple[str, str]]:
         arg_name = pascal_to_snake(self.alias or f'sr_execute_{self.subgroup_index}')
         if self.optional:
-            yield arg_name, 'TzktSmartRollupExecute | None'
+            yield arg_name, 'TezosSmartRollupExecute | None'
         else:
-            yield arg_name, 'TzktSmartRollupExecute'
+            yield arg_name, 'TezosSmartRollupExecute'
 
     @property
     def typed_contract(self) -> TezosContractConfig | None:
         if self.destination:
             return self.destination
         return None
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class TzktOperationsIndexConfig(TzktIndexConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class TezosOperationsIndexConfig(TezosIndexConfig):
     """Operation index config
 
-    :param kind: always 'tezos.tzkt.operations'
-    :param datasource: Alias of index datasource in `datasources` section
+    :param kind: always 'tezos.operations'
+    :param datasources: `tezos` datasources to use
     :param handlers: List of indexer handlers
     :param types: Types of transaction to fetch
     :param contracts: Aliases of contracts being indexed in `contracts` section
     :param first_level: Level to start indexing from
     :param last_level: Level to stop indexing at
     """
 
-    kind: Literal['tezos.tzkt.operations']
-    datasource: TzktDatasourceConfig
-    handlers: tuple[TzktOperationsHandlerConfig, ...]
-    contracts: list[TezosContractConfig] = field(default_factory=list)
-    types: tuple[TzktOperationType, ...] = (TzktOperationType.transaction,)
+    kind: Literal['tezos.operations']
+    datasources: tuple[Alias[TezosTzktDatasourceConfig], ...]
+    handlers: tuple[TezosOperationsHandlerConfig, ...]
+    contracts: list[Alias[TezosContractConfig]] = Field(default_factory=list)
+    types: tuple[TezosOperationType, ...] = (TezosOperationType.transaction,)
 
     first_level: int = 0
     last_level: int = 0
 
     def get_subscriptions(self) -> set[Subscription]:
         subs = super().get_subscriptions()
 
-        if TzktOperationType.transaction in self.types:
-            if self.datasource.merge_subscriptions:
+        if TezosOperationType.transaction in self.types:
+            if self.merge_subscriptions:
                 subs.add(TransactionSubscription())
             else:
                 for contract_config in self.contracts:
                     if not isinstance(contract_config, TezosContractConfig):
                         raise ConfigInitializationException
                     subs.add(TransactionSubscription(address=contract_config.address))
 
-        if TzktOperationType.origination in self.types:
+        if TezosOperationType.origination in self.types:
             subs.add(OriginationSubscription())
 
-        if TzktOperationType.sr_execute in self.types:
-            if self.datasource.merge_subscriptions:
+        if TezosOperationType.sr_execute in self.types:
+            if self.merge_subscriptions:
                 subs.add(SmartRollupExecuteSubscription())
             else:
                 for contract_config in self.contracts:
                     if not isinstance(contract_config, TezosContractConfig):
                         raise ConfigInitializationException
                     if contract_config.address and contract_config.address.startswith('sr1'):
                         subs.add(SmartRollupExecuteSubscription(address=contract_config.address))
@@ -328,33 +328,34 @@
     def strip(cls, config_dict: dict[str, Any]) -> None:
         super().strip(config_dict)
         for handler in config_dict['handlers']:
             for item in handler['pattern']:
                 item.pop('alias', None)
 
 
-OperationsHandlerPatternConfigU = (
-    OperationsHandlerTransactionPatternConfig
-    | OperationsHandlerOriginationPatternConfig
-    | OperationsHandlerSmartRollupExecutePatternConfig
+TezosOperationsHandlerPatternConfigU = (
+    TezosOperationsHandlerTransactionPatternConfig
+    | TezosOperationsHandlerOriginationPatternConfig
+    | TezosOperationsHandlerSmartRollupExecutePatternConfig
 )
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class TzktOperationsHandlerConfig(HandlerConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class TezosOperationsHandlerConfig(HandlerConfig):
     """Operation handler config
 
     :param callback: Callback name
     :param pattern: Filters to match operation groups
     """
 
-    pattern: tuple[OperationsHandlerPatternConfigU, ...]
+    pattern: tuple[TezosOperationsHandlerPatternConfigU, ...]
 
     def iter_imports(self, package: str) -> Iterator[tuple[str, str]]:
         yield 'dipdup.context', 'HandlerContext'
+        yield package, 'models as models'
         for pattern in self.pattern:
             yield from pattern.iter_imports(package)
 
     def iter_arguments(self) -> Iterator[tuple[str, str]]:
         yield 'ctx', 'HandlerContext'
 
         arg_names: set[str] = set()
@@ -367,57 +368,57 @@
                         f' `{self.callback}`\n              entrypoint: `{arg}`'
                     ),
                 )
             arg_names.add(arg)
             yield arg, arg_type
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class OperationUnfilteredHandlerConfig(HandlerConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class TezosOperationsUnfilteredHandlerConfig(HandlerConfig):
     """Handler of unfiltered operation index
 
     :param callback: Callback name
     """
 
     def iter_imports(self, package: str) -> Iterator[tuple[str, str]]:
         yield 'dipdup.context', 'HandlerContext'
-        yield 'dipdup.models.tezos_tzkt', 'TzktOperationData'
+        yield 'dipdup.models.tezos', 'TezosOperationData'
         yield package, 'models as models'
 
     def iter_arguments(self) -> Iterator[tuple[str, str]]:
         yield 'ctx', 'HandlerContext'
-        yield 'operation', 'TzktOperationData'
+        yield 'operation', 'TezosOperationData'
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class TzktOperationsUnfilteredIndexConfig(TzktIndexConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class TezosOperationsUnfilteredIndexConfig(TezosIndexConfig):
     """Operation index config
 
-    :param kind: always 'tezos.tzkt.operations_unfiltered'
-    :param datasource: Alias of index datasource in `datasources` section
+    :param kind: always 'tezos.operations_unfiltered'
+    :param datasources: `tezos` datasources to use
     :param callback: Callback name
     :param types: Types of transaction to fetch
 
     :param first_level: Level to start indexing from
     :param last_level: Level to stop indexing at
     """
 
-    kind: Literal['tezos.tzkt.operations_unfiltered']
-    datasource: TzktDatasourceConfig
+    kind: Literal['tezos.operations_unfiltered']
+    datasources: tuple[Alias[TezosTzktDatasourceConfig], ...]
     callback: str
-    types: tuple[TzktOperationType, ...] = (TzktOperationType.transaction,)
+    types: tuple[TezosOperationType, ...] = (TezosOperationType.transaction,)
 
     first_level: int = 0
     last_level: int = 0
 
-    def __post_init_post_parse__(self) -> None:
-        super().__post_init_post_parse__()
-        self.handler_config = OperationUnfilteredHandlerConfig(callback=self.callback)
+    def __post_init__(self) -> None:
+        super().__post_init__()
+        self.handlers = (TezosOperationsUnfilteredHandlerConfig(callback=self.callback),)
 
     def get_subscriptions(self) -> set[Subscription]:
         subs = super().get_subscriptions()
         subs.add(TransactionSubscription())
         return subs
 
 
-TzktOperationsHandlerConfigU = TzktOperationsHandlerConfig | OperationUnfilteredHandlerConfig
-TzktOperationsIndexConfigU = TzktOperationsIndexConfig | TzktOperationsUnfilteredIndexConfig
+TezosOperationsHandlerConfigU = TezosOperationsHandlerConfig | TezosOperationsUnfilteredHandlerConfig
+TezosOperationsIndexConfigU = TezosOperationsIndexConfig | TezosOperationsUnfilteredIndexConfig
```

### Comparing `dipdup-7.5.7/src/dipdup/config/tezos_tzkt_token_balances.py` & `dipdup-8.0.0a1/src/dipdup/config/tezos_token_balances.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,76 +1,75 @@
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 from typing import Literal
 
 from pydantic import ConfigDict
-from pydantic import Extra
 from pydantic.dataclasses import dataclass
-from pydantic.fields import Field
 
+from dipdup.config import Alias
 from dipdup.config import ContractConfig
 from dipdup.config import HandlerConfig
 from dipdup.config.tezos import TezosContractConfig
-from dipdup.config.tezos_tzkt import TzktDatasourceConfig
-from dipdup.config.tezos_tzkt import TzktIndexConfig
+from dipdup.config.tezos import TezosIndexConfig
+from dipdup.config.tezos_tzkt import TezosTzktDatasourceConfig
 from dipdup.models.tezos_tzkt import TokenBalanceSubscription
 
 if TYPE_CHECKING:
     from collections.abc import Iterator
 
     from dipdup.subscriptions import Subscription
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class TzktTokenBalancesHandlerConfig(HandlerConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class TezosTokenBalancesHandlerConfig(HandlerConfig):
     """Token balance handler config
 
     :param callback: Callback name
     :param contract: Filter by contract
     :param token_id: Filter by token ID
     """
 
-    contract: TezosContractConfig | None = None
+    contract: Alias[TezosContractConfig] | None = None
     token_id: int | None = None
 
     def iter_imports(self, package: str) -> Iterator[tuple[str, str]]:
         """This iterator result will be used in codegen to generate handler(s) template"""
         yield 'dipdup.context', 'HandlerContext'
-        yield 'dipdup.models.tezos_tzkt', 'TzktTokenBalanceData'
+        yield 'dipdup.models.tezos', 'TezosTokenBalanceData'
         yield package, 'models as models'
 
     def iter_arguments(self) -> Iterator[tuple[str, str]]:
         """This iterator result will be used in codegen to generate handler(s) template"""
         yield 'ctx', 'HandlerContext'
-        yield 'token_balance', 'TzktTokenBalanceData'
+        yield 'token_balance', 'TezosTokenBalanceData'
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class TzktTokenBalancesIndexConfig(TzktIndexConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class TezosTokenBalancesIndexConfig(TezosIndexConfig):
     """Token balance index config
 
-    :param kind: always 'tezos.tzkt.token_balances'
-    :param datasource: Index datasource to use
+    :param kind: always 'tezos.token_balances'
+    :param datasources: `tezos` datasources to use
     :param handlers: Mapping of token transfer handlers
 
     :param first_level: Level to start indexing from
     :param last_level: Level to stop indexing at
     """
 
-    kind: Literal['tezos.tzkt.token_balances']
-    datasource: TzktDatasourceConfig
-    handlers: tuple[TzktTokenBalancesHandlerConfig, ...] = Field(default_factory=tuple)
+    kind: Literal['tezos.token_balances']
+    datasources: tuple[Alias[TezosTzktDatasourceConfig], ...]
+    handlers: tuple[TezosTokenBalancesHandlerConfig, ...]
 
     first_level: int = 0
     last_level: int = 0
 
     def get_subscriptions(self) -> set[Subscription]:
         subs = super().get_subscriptions()
-        if self.datasource.merge_subscriptions:
+        if self.merge_subscriptions:
             subs.add(TokenBalanceSubscription())
         else:
             for handler_config in self.handlers:
                 contract = (
                     handler_config.contract.address if isinstance(handler_config.contract, ContractConfig) else None
                 )
                 subs.add(
```

### Comparing `dipdup-7.5.7/src/dipdup/config/tezos_tzkt_token_transfers.py` & `dipdup-8.0.0a1/src/dipdup/config/tezos_token_transfers.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,89 +1,88 @@
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 from typing import Literal
 
 from pydantic import ConfigDict
-from pydantic import Extra
 from pydantic.dataclasses import dataclass
-from pydantic.fields import Field
 
+from dipdup.config import Alias
 from dipdup.config import ContractConfig
 from dipdup.config import HandlerConfig
 from dipdup.config.tezos import TezosContractConfig
-from dipdup.config.tezos_tzkt import TzktDatasourceConfig
-from dipdup.config.tezos_tzkt import TzktIndexConfig
+from dipdup.config.tezos import TezosIndexConfig
+from dipdup.config.tezos_tzkt import TezosTzktDatasourceConfig
 from dipdup.models.tezos_tzkt import TokenTransferSubscription
 
 if TYPE_CHECKING:
     from collections.abc import Iterator
 
     from dipdup.subscriptions import Subscription
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class TzktTokenTransfersHandlerConfig(HandlerConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class TezosTokenTransfersHandlerConfig(HandlerConfig):
     """Token transfer handler config
 
     :param callback: Callback name
     :param contract: Filter by contract
     :param token_id: Filter by token ID
     :param from_: Filter by sender
     :param to: Filter by recipient
     """
 
-    contract: TezosContractConfig | None = None
+    contract: Alias[TezosContractConfig] | None = None
     token_id: int | None = None
-    # FIXME: Can't use `from_` field alias in dataclasses (fixed in `next` with Pydantic v2)
-    from_: TezosContractConfig | None = None
-    to: TezosContractConfig | None = None
+    # FIXME: Can't use `from_` field alias in dataclasses
+    from_: Alias[TezosContractConfig] | None = None
+    to: Alias[TezosContractConfig] | None = None
 
     def iter_imports(self, package: str) -> Iterator[tuple[str, str]]:
         yield 'dipdup.context', 'HandlerContext'
-        yield 'dipdup.models.tezos_tzkt', 'TzktTokenTransferData'
+        yield 'dipdup.models.tezos', 'TezosTokenTransferData'
         yield package, 'models as models'
 
     def iter_arguments(self) -> Iterator[tuple[str, str]]:
         yield 'ctx', 'HandlerContext'
-        yield 'token_transfer', 'TzktTokenTransferData'
+        yield 'token_transfer', 'TezosTokenTransferData'
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
-class TzktTokenTransfersIndexConfig(TzktIndexConfig):
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
+class TezosTokenTransfersIndexConfig(TezosIndexConfig):
     """Token transfer index config
 
-    :param kind: always 'tezos.tzkt.token_transfers'
-    :param datasource: Index datasource to use
+    :param kind: always 'tezos.token_transfers'
+    :param datasources: `tezos` datasources to use
     :param handlers: Mapping of token transfer handlers
 
     :param first_level: Level to start indexing from
     :param last_level: Level to stop indexing at
     """
 
-    kind: Literal['tezos.tzkt.token_transfers']
-    datasource: TzktDatasourceConfig
-    handlers: tuple[TzktTokenTransfersHandlerConfig, ...] = Field(default_factory=tuple)
+    kind: Literal['tezos.token_transfers']
+    datasources: tuple[Alias[TezosTzktDatasourceConfig], ...]
+    handlers: tuple[TezosTokenTransfersHandlerConfig, ...]
 
     first_level: int = 0
     last_level: int = 0
 
     def get_subscriptions(self) -> set[Subscription]:
         subs = super().get_subscriptions()
-        if self.datasource.merge_subscriptions:
+        if self.merge_subscriptions:
             subs.add(TokenTransferSubscription())  # type: ignore[call-arg]
         else:
             for handler_config in self.handlers:
                 contract = (
                     handler_config.contract.address if isinstance(handler_config.contract, ContractConfig) else None
                 )
                 from_ = handler_config.from_.address if isinstance(handler_config.from_, ContractConfig) else None
                 to = handler_config.to.address if isinstance(handler_config.to, ContractConfig) else None
                 subs.add(
-                    TokenTransferSubscription(  # type: ignore[call-arg]
+                    TokenTransferSubscription(
                         contract=contract,
                         from_=from_,
                         to=to,
                         token_id=handler_config.token_id,
                     )
                 )
         return subs
```

### Comparing `dipdup-7.5.7/src/dipdup/config/tzip_metadata.py` & `dipdup-8.0.0a1/src/dipdup/config/tzip_metadata.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,21 +1,20 @@
 from typing import Literal
 
 from pydantic import ConfigDict
-from pydantic import Extra
 from pydantic.dataclasses import dataclass
 
 from dipdup.config import DatasourceConfig
 from dipdup.config import HttpConfig
 from dipdup.models.tzip_metadata import TzipMetadataNetwork
 
 DEFAULT_TZIP_METADATA_URL = 'https://metadata.dipdup.net'
 
 
-@dataclass(config=ConfigDict(extra=Extra.forbid), kw_only=True)
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class TzipMetadataDatasourceConfig(DatasourceConfig):
     """DipDup Metadata datasource config
 
     :param kind: always 'tzip_metadata'
     :param network: Network name, e.g. mainnet, ghostnet, etc.
     :param url: GraphQL API URL, e.g. https://metadata.dipdup.net
     :param http: HTTP client configuration
```

### Comparing `dipdup-7.5.7/src/dipdup/context.py` & `dipdup-8.0.0a1/src/dipdup/context.py`

 * *Files 10% similar despite different names*

```diff
@@ -9,57 +9,66 @@
 from contextlib import suppress
 from pathlib import Path
 from pprint import pformat
 from typing import TYPE_CHECKING
 from typing import Any
 from typing import Literal
 from typing import TypeVar
-from typing import cast
 
 from tortoise.exceptions import OperationalError
 
 from dipdup import env
 from dipdup.config import ContractConfigU
 from dipdup.config import DipDupConfig
 from dipdup.config import HandlerConfig
 from dipdup.config import HookConfig
-from dipdup.config import ResolvedIndexConfigU
 from dipdup.config.evm import EvmContractConfig
-from dipdup.config.evm_node import EvmNodeDatasourceConfig
-from dipdup.config.evm_subsquid import SubsquidDatasourceConfig
-from dipdup.config.evm_subsquid_events import SubsquidEventsIndexConfig
-from dipdup.config.evm_subsquid_traces import SubsquidTracesIndexConfig
-from dipdup.config.evm_subsquid_transactions import SubsquidTransactionsIndexConfig
+from dipdup.config.evm import EvmIndexConfig
+from dipdup.config.evm_events import EvmEventsIndexConfig
+from dipdup.config.evm_transactions import EvmTransactionsIndexConfig
 from dipdup.config.tezos import TezosContractConfig
-from dipdup.config.tezos_tzkt_big_maps import TzktBigMapsIndexConfig
-from dipdup.config.tezos_tzkt_events import TzktEventsIndexConfig
-from dipdup.config.tezos_tzkt_head import TzktHeadIndexConfig
-from dipdup.config.tezos_tzkt_operations import TzktOperationsIndexConfig
-from dipdup.config.tezos_tzkt_operations import TzktOperationsUnfilteredIndexConfig
-from dipdup.config.tezos_tzkt_token_balances import TzktTokenBalancesIndexConfig
-from dipdup.config.tezos_tzkt_token_transfers import TzktTokenTransfersIndexConfig
+from dipdup.config.tezos import TezosIndexConfig
+from dipdup.config.tezos_big_maps import TezosBigMapsIndexConfig
+from dipdup.config.tezos_events import TezosEventsIndexConfig
+from dipdup.config.tezos_head import TezosHeadIndexConfig
+from dipdup.config.tezos_operations import TezosOperationsIndexConfig
+from dipdup.config.tezos_operations import TezosOperationsUnfilteredIndexConfig
+from dipdup.config.tezos_token_balances import TezosTokenBalancesIndexConfig
+from dipdup.config.tezos_token_transfers import TezosTokenTransfersIndexConfig
 from dipdup.database import execute_sql
 from dipdup.database import execute_sql_query
 from dipdup.database import get_connection
 from dipdup.database import wipe_schema
 from dipdup.datasources import Datasource
 from dipdup.datasources import IndexDatasource
+from dipdup.datasources.abi_etherscan import AbiEtherscanDatasource
 from dipdup.datasources.coinbase import CoinbaseDatasource
 from dipdup.datasources.evm_node import EvmNodeDatasource
-from dipdup.datasources.evm_subsquid import SubsquidDatasource
+from dipdup.datasources.evm_subsquid import EvmSubsquidDatasource
 from dipdup.datasources.http import HttpDatasource
 from dipdup.datasources.ipfs import IpfsDatasource
-from dipdup.datasources.tezos_tzkt import TzktDatasource
+from dipdup.datasources.tezos_tzkt import TezosTzktDatasource
 from dipdup.datasources.tzip_metadata import TzipMetadataDatasource
 from dipdup.exceptions import CallbackError
 from dipdup.exceptions import ConfigurationError
 from dipdup.exceptions import ContractAlreadyExistsError
 from dipdup.exceptions import FrameworkException
 from dipdup.exceptions import InitializationRequiredError
 from dipdup.exceptions import ReindexingRequiredError
+from dipdup.index import Index as IndexCls
+from dipdup.indexes.evm import EvmIndex
+from dipdup.indexes.evm_events.index import EvmEventsIndex
+from dipdup.indexes.evm_transactions.index import EvmTransactionsIndex
+from dipdup.indexes.tezos_big_maps.index import TezosBigMapsIndex
+from dipdup.indexes.tezos_events.index import TezosEventsIndex
+from dipdup.indexes.tezos_head.index import TezosHeadIndex
+from dipdup.indexes.tezos_operations.index import TezosOperationsIndex
+from dipdup.indexes.tezos_token_balances.index import TezosTokenBalancesIndex
+from dipdup.indexes.tezos_token_transfers.index import TezosTokenTransfersIndex
+from dipdup.indexes.tezos_tzkt import TezosIndex
 from dipdup.models import Contract
 from dipdup.models import ContractMetadata
 from dipdup.models import Head
 from dipdup.models import Index
 from dipdup.models import ModelUpdate
 from dipdup.models import ReindexingAction
 from dipdup.models import ReindexingReason
@@ -291,100 +300,80 @@
     def _link(self, new_ctx: DipDupContext) -> None:
         new_ctx._pending_indexes = self._pending_indexes
         new_ctx._pending_hooks = self._pending_hooks
         new_ctx._rolled_back_indexes = self._rolled_back_indexes
         new_ctx._handlers = self._handlers
         new_ctx._hooks = self._hooks
 
-    async def _spawn_index(self, name: str, state: Index | None = None) -> Any:
-        # NOTE: Avoiding circular import
-        from dipdup.indexes.evm_subsquid_events.index import SubsquidEventsIndex
-        from dipdup.indexes.evm_subsquid_traces.index import SubsquidTracesIndex
-        from dipdup.indexes.evm_subsquid_transactions.index import SubsquidTransactionsIndex
-        from dipdup.indexes.tezos_tzkt_big_maps.index import TzktBigMapsIndex
-        from dipdup.indexes.tezos_tzkt_events.index import TzktEventsIndex
-        from dipdup.indexes.tezos_tzkt_head.index import TzktHeadIndex
-        from dipdup.indexes.tezos_tzkt_operations.index import TzktOperationsIndex
-        from dipdup.indexes.tezos_tzkt_token_balances.index import TzktTokenBalancesIndex
-        from dipdup.indexes.tezos_tzkt_token_transfers.index import TzktTokenTransfersIndex
-
-        index_config = cast(ResolvedIndexConfigU, self.config.get_index(name))
-        index: (
-            TzktOperationsIndex
-            | TzktBigMapsIndex
-            | TzktHeadIndex
-            | TzktTokenBalancesIndex
-            | TzktTokenTransfersIndex
-            | TzktEventsIndex
-            | SubsquidEventsIndex
-            | SubsquidTracesIndex
-            | SubsquidTransactionsIndex
-        )
+    async def _spawn_index(
+        self,
+        name: str,
+        state: Index | None = None,
+    ) -> IndexCls[Any, Any, Any]:
 
-        datasource_name = index_config.datasource.name
-        datasource: TzktDatasource | SubsquidDatasource | EvmNodeDatasource
+        index_config = self.config.get_index(name)
 
-        if isinstance(index_config, TzktOperationsIndexConfig | TzktOperationsUnfilteredIndexConfig):
-            datasource = self.get_tzkt_datasource(datasource_name)
-            index = TzktOperationsIndex(self, index_config, datasource)
-        elif isinstance(index_config, TzktBigMapsIndexConfig):
-            datasource = self.get_tzkt_datasource(datasource_name)
-            index = TzktBigMapsIndex(self, index_config, datasource)
-        elif isinstance(index_config, TzktHeadIndexConfig):
-            datasource = self.get_tzkt_datasource(datasource_name)
-            index = TzktHeadIndex(self, index_config, datasource)
-        elif isinstance(index_config, TzktTokenBalancesIndexConfig):
-            datasource = self.get_tzkt_datasource(datasource_name)
-            index = TzktTokenBalancesIndex(self, index_config, datasource)
-        elif isinstance(index_config, TzktTokenTransfersIndexConfig):
-            datasource = self.get_tzkt_datasource(datasource_name)
-            index = TzktTokenTransfersIndex(self, index_config, datasource)
-        elif isinstance(index_config, TzktEventsIndexConfig):
-            datasource = self.get_tzkt_datasource(datasource_name)
-            index = TzktEventsIndex(self, index_config, datasource)
-        elif isinstance(index_config, SubsquidEventsIndexConfig):
-            datasource_config = index_config.datasource
-            if isinstance(datasource_config, SubsquidDatasourceConfig):
-                datasource = self.get_subsquid_datasource(datasource_name)
-            elif isinstance(datasource_config, EvmNodeDatasourceConfig):
-                datasource = self.get_evm_node_datasource(datasource_name)
-            else:
-                raise NotImplementedError
-            index = SubsquidEventsIndex(self, index_config, datasource)
-            for node_datasource in index.node_datasources:
-                node_datasource.add_index(index_config)
-        elif isinstance(index_config, SubsquidTracesIndexConfig):
-            raise NotImplementedError
-        elif isinstance(index_config, SubsquidTransactionsIndexConfig):
-            datasource_config = index_config.datasource
-            if isinstance(datasource_config, SubsquidDatasourceConfig):
-                datasource = self.get_subsquid_datasource(datasource_name)
-            elif isinstance(datasource_config, EvmNodeDatasourceConfig):
-                datasource = self.get_evm_node_datasource(datasource_name)
-            else:
-                raise NotImplementedError
-            index = SubsquidTransactionsIndex(self, index_config, datasource)
-            for node_datasource in index.node_datasources:
-                node_datasource.add_index(index_config)
+        index: IndexCls[Any, Any, Any]
+        if isinstance(index_config, EvmIndexConfig):
+            index = self._create_evm_index(index_config)
+        elif isinstance(index_config, TezosIndexConfig):
+            index = self._create_tezos_index(index_config)
         else:
             raise NotImplementedError
 
-        datasource.add_index(index_config)
-
-        handlers = (
-            (index_config.handler_config,)
-            if isinstance(index_config, TzktOperationsUnfilteredIndexConfig | TzktHeadIndexConfig)
-            else index_config.handlers
-        )
-        for handler_config in handlers:
+        for handler_config in index_config.handlers:
             self.register_handler(handler_config)
+
         await index.initialize_state(state)
 
         # NOTE: IndexDispatcher will handle further initialization when it's time
         self._pending_indexes.put_nowait(index)
+
+        return index
+
+    def _create_evm_index(self, index_config: EvmIndexConfig) -> EvmIndex[Any, Any, Any]:
+        datasource_configs = index_config.datasources
+        datasources = tuple(self.get_evm_datasource(c.name) for c in datasource_configs)
+        index_datasources = tuple(d for d in datasources if isinstance(d, IndexDatasource))
+
+        for datasource in index_datasources:
+            datasource.attach_index(index_config)
+
+        index: EvmIndex[Any, Any, Any]
+        if isinstance(index_config, EvmTransactionsIndexConfig):
+            index = EvmTransactionsIndex(self, index_config, index_datasources)
+        elif isinstance(index_config, EvmEventsIndexConfig):
+            index = EvmEventsIndex(self, index_config, index_datasources)
+        else:
+            raise NotImplementedError
+
+        return index
+
+    def _create_tezos_index(self, index_config: TezosIndexConfig) -> TezosIndex[Any, Any]:
+        datasources = tuple(self.get_tezos_tzkt_datasource(c.name) for c in index_config.datasources)
+
+        index: TezosIndex[Any, Any]
+        if isinstance(index_config, TezosOperationsIndexConfig | TezosOperationsUnfilteredIndexConfig):
+            index = TezosOperationsIndex(self, index_config, datasources)
+        elif isinstance(index_config, TezosBigMapsIndexConfig):
+            index = TezosBigMapsIndex(self, index_config, datasources)
+        elif isinstance(index_config, TezosHeadIndexConfig):
+            index = TezosHeadIndex(self, index_config, datasources)
+        elif isinstance(index_config, TezosTokenBalancesIndexConfig):
+            index = TezosTokenBalancesIndex(self, index_config, datasources)
+        elif isinstance(index_config, TezosTokenTransfersIndexConfig):
+            index = TezosTokenTransfersIndex(self, index_config, datasources)
+        elif isinstance(index_config, TezosEventsIndexConfig):
+            index = TezosEventsIndex(self, index_config, datasources)
+        else:
+            raise NotImplementedError
+
+        for datasource in datasources:
+            datasource.attach_index(index_config)
+
         return index
 
     # TODO: disable_index(name: str)
 
     async def update_contract_metadata(
         self,
         network: str,
@@ -430,42 +419,49 @@
         await TokenMetadata.update_or_create(
             network=network,
             contract=address,
             token_id=token_id,
             defaults={'metadata': metadata, 'update_id': update_id},
         )
 
-    def _get_datasource(self, name: str, type_: type[DatasourceT]) -> DatasourceT:
+    def _get_datasource(self, name: str, *types: type[DatasourceT]) -> DatasourceT:
         datasource = self.datasources.get(name)
         if not datasource:
             raise ConfigurationError(f'Datasource `{name}` is missing')
-        if not isinstance(datasource, type_):
-            raise ConfigurationError(f'Datasource `{name}` is not a `{type_.__name__}`')
+
+        for type_ in types:
+            if isinstance(datasource, type_):
+                break
+        else:
+            raise ConfigurationError(f"Datasource `{name}` is not a `{types}, it's {datasource}`")
+
         return datasource
 
-    def get_tzkt_datasource(self, name: str) -> TzktDatasource:
+    def get_tezos_tzkt_datasource(self, name: str) -> TezosTzktDatasource:
         """Get `tezos.tzkt` datasource by name"""
-        return self._get_datasource(name, TzktDatasource)
+        return self._get_datasource(name, TezosTzktDatasource)
 
-    def get_subsquid_datasource(self, name: str) -> SubsquidDatasource:
+    def get_evm_subsquid_datasource(self, name: str) -> EvmSubsquidDatasource:
         """Get `evm.subsquid` datasource by name"""
-        return self._get_datasource(name, SubsquidDatasource)
+        return self._get_datasource(name, EvmSubsquidDatasource)
 
     def get_evm_node_datasource(self, name: str) -> EvmNodeDatasource:
-        """Get `evm.node` datasource by name or by linked `evm.subsquid` datasource name"""
-        with suppress(ConfigurationError):
-            return self._get_datasource(name, EvmNodeDatasource)
-        with suppress(ConfigurationError):
-            subsquid = self._get_datasource(name, SubsquidDatasource)
-            # NOTE: Multiple nodes can be linked to a single subsquid. Network is the same, so grab any.
-            random_node = subsquid._config.random_node
-            if random_node is None:
-                raise ConfigurationError(f'No `evm.node` datasources linked to `{name}`')
-            return self._get_datasource(random_node.name, EvmNodeDatasource)
-        raise ConfigurationError(f'`{name}` datasource is neither `evm.node` nor `evm.subsquid`')
+        """Get `evm.node` datasource by name"""
+        return self._get_datasource(name, EvmNodeDatasource)
+
+    def get_abi_etherscan_datasource(self, name: str) -> AbiEtherscanDatasource:
+        """Get `abi.etherscan` datasource by name
+
+        :param name: Name of the datasource
+        """
+        return self._get_datasource(name, AbiEtherscanDatasource)
+
+    def get_evm_datasource(self, name: str) -> EvmSubsquidDatasource | EvmNodeDatasource | AbiEtherscanDatasource:
+        """Get `evm` datasource by name"""
+        return self._get_datasource(name, EvmSubsquidDatasource, EvmNodeDatasource, AbiEtherscanDatasource)  # type: ignore[return-value]
 
     def get_coinbase_datasource(self, name: str) -> CoinbaseDatasource:
         """Get `coinbase` datasource by name
 
         :param name: Name of the datasource
         """
         return self._get_datasource(name, CoinbaseDatasource)
@@ -549,33 +545,30 @@
         if key not in self._hooks:
             self._hooks[key] = hook_config
 
     async def fire_handler(
         self,
         name: str,
         index: str,
-        datasource: IndexDatasource[Any],
         fmt: str | None = None,
         *args: Any,
         **kwargs: Any,
     ) -> None:
         """Fire handler with given name and arguments.
 
         :param name: Handler name
         :param index: Index name
-        :param datasource: An instance of datasource that triggered the handler
         :param fmt: Format string for `ctx.logger` messages
         """
         module = f'{self.package.name}.handlers.{name}'
         handler_config = self._get_handler(name, index)
         new_ctx = HandlerContext._wrap(
             self,
             logger=FormattedLogger(module, fmt),
             handler_config=handler_config,
-            datasource=datasource,
         )
         # NOTE: Handlers are not atomic, levels are. Do not open transaction here.
         with self._callback_wrapper(module):
             fn = self.package.get_callback('handlers', name, name.split('.')[-1])
             await fn(new_ctx, *args, **kwargs)
 
     async def fire_hook(
@@ -749,53 +742,48 @@
 
     :param config: DipDup configuration
     :param package: DipDup package
     :param datasources: Mapping of available datasources
     :param transactions: Transaction manager (don't use it directly)
     :param logger: Context-aware logger instance
     :param handler_config: Configuration of the current handler
-    :param datasource: Index datasource instance
     """
 
     def __init__(
         self,
         config: DipDupConfig,
         package: DipDupPackage,
         datasources: dict[str, Datasource[Any]],
         transactions: TransactionManager,
         logger: FormattedLogger,
         handler_config: HandlerConfig,
-        datasource: IndexDatasource[Any],
     ) -> None:
         super().__init__(
             config=config,
             package=package,
             datasources=datasources,
             transactions=transactions,
         )
         self.logger = logger
         self.handler_config = handler_config
-        self.datasource = datasource
         self.template_values = _TemplateValues(
             handler_config.parent.name if handler_config.parent else 'unknown',
-            handler_config.parent.template_values if handler_config.parent else {},
+            handler_config.parent._template_values if handler_config.parent else {},
         )
 
     @classmethod
     def _wrap(
         cls,
         ctx: DipDupContext,
         logger: FormattedLogger,
         handler_config: HandlerConfig,
-        datasource: IndexDatasource[Any],
     ) -> HandlerContext:
         new_ctx = cls(
             config=ctx.config,
             package=ctx.package,
             datasources=ctx.datasources,
             transactions=ctx.transactions,
             logger=logger,
             handler_config=handler_config,
-            datasource=datasource,
         )
         ctx._link(new_ctx)
         return new_ctx
```

### Comparing `dipdup-7.5.7/src/dipdup/database.py` & `dipdup-8.0.0a1/src/dipdup/database.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/datasources/__init__.py` & `dipdup-8.0.0a1/src/dipdup/datasources/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -20,14 +20,38 @@
 DatasourceConfigT = TypeVar('DatasourceConfigT', bound=DatasourceConfig)
 IndexDatasourceConfigT = TypeVar('IndexDatasourceConfigT', bound=IndexDatasourceConfig)
 
 EmptyCallback = Callable[[], Awaitable[None]]
 RollbackCallback = Callable[['IndexDatasource[Any]', MessageType, int, int], Awaitable[None]]
 
 
+class EvmHistoryProvider:
+    pass
+
+
+class EvmRealtimeProvider:
+    pass
+
+
+class EvmAbiProvider:
+    pass
+
+
+class TezosHistoryProvider:
+    pass
+
+
+class TezosRealtimeProvider:
+    pass
+
+
+class TezosAbiProvider:
+    pass
+
+
 class Datasource(HTTPGateway, Generic[DatasourceConfigT]):
     _default_http_config = HttpConfig()
 
     def __init__(self, config: DatasourceConfigT) -> None:
         self._config = config
         http_config = ResolvedHttpConfig.create(self._default_http_config, config.http)
         http_config.alias = http_config.alias or config.name
@@ -64,15 +88,15 @@
 
     @abstractmethod
     async def subscribe(self) -> None: ...
 
     @abstractmethod
     async def initialize(self) -> None: ...
 
-    def add_index(self, index_config: IndexConfig) -> None:
+    def attach_index(self, index_config: IndexConfig) -> None:
         """Register index config in internal mappings and matchers. Find and register subscriptions."""
         for subscription in index_config.get_subscriptions():
             self._subscriptions.add(subscription)
 
     def set_sync_level(self, subscription: Subscription | None, level: int) -> None:
         self._subscriptions.set_sync_level(subscription, level)
 
@@ -98,39 +122,39 @@
 
     async def emit_rollback(self, type_: MessageType, from_level: int, to_level: int) -> None:
         for fn in self._on_rollback_callbacks:
             await fn(self, type_, from_level, to_level)
 
 
 def create_datasource(config: DatasourceConfig) -> Datasource[Any]:
-    from dipdup.config.abi_etherscan import EtherscanDatasourceConfig
+    from dipdup.config.abi_etherscan import AbiEtherscanDatasourceConfig
     from dipdup.config.coinbase import CoinbaseDatasourceConfig
     from dipdup.config.evm_node import EvmNodeDatasourceConfig
-    from dipdup.config.evm_subsquid import SubsquidDatasourceConfig
+    from dipdup.config.evm_subsquid import EvmSubsquidDatasourceConfig
     from dipdup.config.http import HttpDatasourceConfig
     from dipdup.config.ipfs import IpfsDatasourceConfig
-    from dipdup.config.tezos_tzkt import TzktDatasourceConfig
+    from dipdup.config.tezos_tzkt import TezosTzktDatasourceConfig
     from dipdup.config.tzip_metadata import TzipMetadataDatasourceConfig
-    from dipdup.datasources.abi_etherscan import EtherscanDatasource
+    from dipdup.datasources.abi_etherscan import AbiEtherscanDatasource
     from dipdup.datasources.coinbase import CoinbaseDatasource
     from dipdup.datasources.evm_node import EvmNodeDatasource
-    from dipdup.datasources.evm_subsquid import SubsquidDatasource
+    from dipdup.datasources.evm_subsquid import EvmSubsquidDatasource
     from dipdup.datasources.http import HttpDatasource
     from dipdup.datasources.ipfs import IpfsDatasource
-    from dipdup.datasources.tezos_tzkt import TzktDatasource
+    from dipdup.datasources.tezos_tzkt import TezosTzktDatasource
     from dipdup.datasources.tzip_metadata import TzipMetadataDatasource
 
     by_config: dict[type[DatasourceConfig], type[Datasource[Any]]] = {
-        EtherscanDatasourceConfig: EtherscanDatasource,
+        AbiEtherscanDatasourceConfig: AbiEtherscanDatasource,
         CoinbaseDatasourceConfig: CoinbaseDatasource,
-        TzktDatasourceConfig: TzktDatasource,
+        TezosTzktDatasourceConfig: TezosTzktDatasource,
         TzipMetadataDatasourceConfig: TzipMetadataDatasource,
         HttpDatasourceConfig: HttpDatasource,
         IpfsDatasourceConfig: IpfsDatasource,
-        SubsquidDatasourceConfig: SubsquidDatasource,
+        EvmSubsquidDatasourceConfig: EvmSubsquidDatasource,
         EvmNodeDatasourceConfig: EvmNodeDatasource,
     }
 
     try:
         return by_config[type(config)](config)
     except KeyError as e:
         raise FrameworkException(f'Unknown datasource type: {type(config)}') from e
```

### Comparing `dipdup-7.5.7/src/dipdup/datasources/abi_etherscan.py` & `dipdup-8.0.0a1/src/dipdup/datasources/abi_etherscan.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,20 +1,21 @@
 import asyncio
 from typing import Any
 from typing import cast
 
 import orjson
 
 from dipdup.config import HttpConfig
-from dipdup.config.abi_etherscan import EtherscanDatasourceConfig
+from dipdup.config.abi_etherscan import AbiEtherscanDatasourceConfig
 from dipdup.datasources import AbiDatasource
+from dipdup.datasources import EvmAbiProvider
 from dipdup.exceptions import DatasourceError
 
 
-class EtherscanDatasource(AbiDatasource[EtherscanDatasourceConfig]):
+class AbiEtherscanDatasource(AbiDatasource[AbiEtherscanDatasourceConfig], EvmAbiProvider):
     _default_http_config = HttpConfig(
         ratelimit_rate=1,
         ratelimit_period=5,
         ratelimit_sleep=15,
     )
 
     async def run(self) -> None:
```

### Comparing `dipdup-7.5.7/src/dipdup/datasources/coinbase.py` & `dipdup-8.0.0a1/src/dipdup/datasources/coinbase.py`

 * *Files 4% similar despite different names*

```diff
@@ -3,16 +3,16 @@
 from datetime import timedelta
 from typing import Any
 from typing import cast
 
 from dipdup.config import HttpConfig
 from dipdup.config.coinbase import CoinbaseDatasourceConfig
 from dipdup.datasources import Datasource
-from dipdup.models.coinbase import CandleData
-from dipdup.models.coinbase import CandleInterval
+from dipdup.models.coinbase import CoinbaseCandleData
+from dipdup.models.coinbase import CoinbaseCandleInterval
 
 CANDLES_REQUEST_LIMIT = 300
 API_URL = 'https://api.pro.coinbase.com'
 
 
 class CoinbaseDatasource(Datasource[CoinbaseDatasourceConfig]):
     _default_http_config = HttpConfig(
@@ -34,36 +34,36 @@
             ),
         )
 
     async def get_candles(
         self,
         since: datetime,
         until: datetime,
-        interval: CandleInterval,
+        interval: CoinbaseCandleInterval,
         ticker: str,
-    ) -> list[CandleData]:
+    ) -> list[CoinbaseCandleData]:
         candles = []
         for _since, _until in self._split_candle_requests(since, until, interval):
             candles_json = await self.request(
                 'get',
                 url=f'products/{ticker}/candles',
                 params={
                     'start': _since.replace(tzinfo=UTC).isoformat(),
                     'end': _until.replace(tzinfo=UTC).isoformat(),
                     'granularity': interval.seconds,
                 },
             )
-            candles += [CandleData.from_json(c) for c in candles_json]
+            candles += [CoinbaseCandleData.from_json(c) for c in candles_json]
         return sorted(candles, key=lambda c: c.timestamp)
 
     def _split_candle_requests(
         self,
         since: datetime,
         until: datetime,
-        interval: CandleInterval,
+        interval: CoinbaseCandleInterval,
     ) -> list[tuple[datetime, datetime]]:
         request_interval_limit = timedelta(seconds=interval.seconds * CANDLES_REQUEST_LIMIT)
         request_intervals = []
         while since + request_interval_limit < until:
             request_intervals.append((since, since + request_interval_limit))
             since += request_interval_limit
         request_intervals.append((since, until))
```

### Comparing `dipdup-7.5.7/src/dipdup/datasources/evm_node.py` & `dipdup-8.0.0a1/src/dipdup/datasources/evm_node.py`

 * *Files 7% similar despite different names*

```diff
@@ -16,44 +16,44 @@
 from web3 import AsyncWeb3
 from web3.middleware.async_cache import async_construct_simple_cache_middleware
 from web3.providers.async_base import AsyncJSONBaseProvider
 from web3.utils.caching import SimpleCache
 
 from dipdup.config import HttpConfig
 from dipdup.config.evm_node import EvmNodeDatasourceConfig
+from dipdup.datasources import EvmHistoryProvider
+from dipdup.datasources import EvmRealtimeProvider
 from dipdup.datasources import IndexDatasource
 from dipdup.exceptions import DatasourceError
 from dipdup.exceptions import FrameworkException
+from dipdup.models.evm import EvmEventData
+from dipdup.models.evm import EvmTransactionData
 from dipdup.models.evm_node import EvmNodeHeadData
 from dipdup.models.evm_node import EvmNodeHeadSubscription
-from dipdup.models.evm_node import EvmNodeLogData
 from dipdup.models.evm_node import EvmNodeLogsSubscription
 from dipdup.models.evm_node import EvmNodeSubscription
 from dipdup.models.evm_node import EvmNodeSyncingData
 from dipdup.models.evm_node import EvmNodeSyncingSubscription
-from dipdup.models.evm_node import EvmNodeTraceData
-from dipdup.models.evm_node import EvmNodeTransactionData
-from dipdup.models.evm_subsquid import SubsquidMessageType
+from dipdup.models.subsquid import SubsquidMessageType
 from dipdup.performance import caches
 from dipdup.performance import metrics
 from dipdup.pysignalr import Message
 from dipdup.pysignalr import WebsocketMessage
 from dipdup.pysignalr import WebsocketProtocol
 from dipdup.pysignalr import WebsocketTransport
 from dipdup.utils import Watchdog
 
 WEB3_CACHE_SIZE = 256
 NODE_LEVEL_TIMEOUT = 0.1
 NODE_LAST_MILE = 128
 
 
 HeadCallback = Callable[['EvmNodeDatasource', EvmNodeHeadData], Awaitable[None]]
-LogsCallback = Callable[['EvmNodeDatasource', tuple[EvmNodeLogData, ...]], Awaitable[None]]
-TracesCallback = Callable[['EvmNodeDatasource', tuple[EvmNodeTraceData, ...]], Awaitable[None]]
-TransactionsCallback = Callable[['EvmNodeDatasource', tuple[EvmNodeTransactionData, ...]], Awaitable[None]]
+LogsCallback = Callable[['EvmNodeDatasource', tuple[EvmEventData, ...]], Awaitable[None]]
+TransactionsCallback = Callable[['EvmNodeDatasource', tuple[EvmTransactionData, ...]], Awaitable[None]]
 SyncingCallback = Callable[['EvmNodeDatasource', EvmNodeSyncingData], Awaitable[None]]
 
 
 class MagicWeb3Provider(AsyncJSONBaseProvider):
     def __init__(self, datasource: 'EvmNodeDatasource') -> None:
         self._datasource = datasource
 
@@ -65,15 +65,15 @@
             ws=False,
         )
 
 
 @dataclass
 class LevelData:
     head: dict[str, Any] | None = None
-    logs: deque[dict[str, Any]] = field(default_factory=deque)
+    events: deque[dict[str, Any]] = field(default_factory=deque)
     fetch_transactions: bool = False
 
     created_at: float = field(default_factory=time.time)
 
     async def get_head(self) -> dict[str, Any]:
         await self.wait_level()
         if not self.head:
@@ -82,15 +82,15 @@
 
     async def wait_level(self) -> None:
         to_wait = NODE_LEVEL_TIMEOUT - (time.time() - self.created_at)
         if to_wait > 0:
             await asyncio.sleep(to_wait)
 
 
-class EvmNodeDatasource(IndexDatasource[EvmNodeDatasourceConfig]):
+class EvmNodeDatasource(IndexDatasource[EvmNodeDatasourceConfig], EvmHistoryProvider, EvmRealtimeProvider):
     _default_http_config = HttpConfig(
         batch_size=10,
         ratelimit_sleep=1,
         polling_interval=1.0,
     )
 
     def __init__(self, config: EvmNodeDatasourceConfig, merge_subscriptions: bool = False) -> None:
@@ -100,16 +100,15 @@
         self._requests: dict[str, tuple[asyncio.Event, Any]] = {}
         self._subscription_ids: dict[str, EvmNodeSubscription] = {}
         self._emitter_queue: Queue[LevelData] = Queue()
         self._level_data: defaultdict[str, LevelData] = defaultdict(LevelData)
         self._watchdog: Watchdog = Watchdog(self._http_config.connection_timeout)
 
         self._on_head_callbacks: set[HeadCallback] = set()
-        self._on_logs_callbacks: set[LogsCallback] = set()
-        self._on_traces_callbacks: set[TracesCallback] = set()
+        self._on_events_callbacks: set[LogsCallback] = set()
         self._on_transactions_callbacks: set[TransactionsCallback] = set()
         self._on_syncing_callbacks: set[SyncingCallback] = set()
 
     @property
     def web3(self) -> AsyncWeb3:
         if not self._web3_client:
             raise FrameworkException('web3 client is not initialized; is datasource running?')
@@ -167,26 +166,28 @@
                         type_,
                         from_level=known_level,
                         to_level=head.level - 1,
                     )
 
             known_level = head.level
 
-            if raw_logs := level_data.logs:
-                logs = tuple(EvmNodeLogData.from_json(log, head.timestamp) for log in raw_logs if not log['removed'])
-                if logs:
-                    self._logger.debug('Emitting %s logs', len(logs))
-                    await self.emit_logs(logs)
+            if raw_events := level_data.events:
+                events = tuple(
+                    EvmEventData.from_node_json(event, head.timestamp) for event in raw_events if not event['removed']
+                )
+                if events:
+                    self._logger.debug('Emitting %s events', len(events))
+                    await self.emit_events(events)
             if level_data.fetch_transactions:
                 full_block = await self.get_block_by_level(
                     block_number=head.level,
                     full_transactions=True,
                 )
                 transactions = tuple(
-                    EvmNodeTransactionData.from_json(transaction, head.timestamp)
+                    EvmTransactionData.from_node_json(transaction, head.timestamp)
                     for transaction in full_block['transactions']
                 )
                 if transactions:
                     self._logger.debug('Emitting %s transactions', len(transactions))
                     await self.emit_transactions(transactions)
 
             del self._level_data[head.hash]
@@ -224,52 +225,45 @@
             if isinstance(subscription, EvmNodeSubscription):
                 await self._subscribe(subscription)
 
     async def emit_head(self, head: EvmNodeHeadData) -> None:
         for fn in self._on_head_callbacks:
             await fn(self, head)
 
-    async def emit_logs(self, logs: tuple[EvmNodeLogData, ...]) -> None:
-        for fn in self._on_logs_callbacks:
-            await fn(self, logs)
+    async def emit_events(self, events: tuple[EvmEventData, ...]) -> None:
+        for fn in self._on_events_callbacks:
+            await fn(self, events)
 
     async def emit_syncing(self, syncing: EvmNodeSyncingData) -> None:
         for fn in self._on_syncing_callbacks:
             await fn(self, syncing)
 
-    async def emit_traces(self, traces: tuple[EvmNodeTraceData, ...]) -> None:
-        for fn in self._on_traces_callbacks:
-            await fn(self, traces)
-
-    async def emit_transactions(self, transactions: tuple[EvmNodeTransactionData, ...]) -> None:
+    async def emit_transactions(self, transactions: tuple[EvmTransactionData, ...]) -> None:
         for fn in self._on_transactions_callbacks:
             await fn(self, transactions)
 
     def call_on_head(self, fn: HeadCallback) -> None:
         self._on_head_callbacks.add(fn)
 
-    def call_on_logs(self, fn: LogsCallback) -> None:
-        self._on_logs_callbacks.add(fn)
-
-    def call_on_traces(self, fn: TracesCallback) -> None:
-        self._on_traces_callbacks.add(fn)
+    def call_on_events(self, fn: LogsCallback) -> None:
+        self._on_events_callbacks.add(fn)
 
     def call_on_transactions(self, fn: TransactionsCallback) -> None:
         self._on_transactions_callbacks.add(fn)
 
     def call_on_syncing(self, fn: SyncingCallback) -> None:
         self._on_syncing_callbacks.add(fn)
 
     async def get_block_by_hash(self, block_hash: str) -> dict[str, Any]:
         return await self._jsonrpc_request('eth_getBlockByHash', [block_hash, True])  # type: ignore[no-any-return]
 
     async def get_block_by_level(self, block_number: int, full_transactions: bool = False) -> dict[str, Any]:
         return await self._jsonrpc_request('eth_getBlockByNumber', [hex(block_number), full_transactions])  # type: ignore[no-any-return]
 
-    async def get_logs(self, params: dict[str, Any]) -> list[dict[str, Any]]:
+    async def get_events(self, params: dict[str, Any]) -> list[dict[str, Any]]:
         return await self._jsonrpc_request('eth_getLogs', [params])  # type: ignore[no-any-return]
 
     async def get_head_level(self) -> int:
         return int((await self._jsonrpc_request('eth_blockNumber', [])), 16)
 
     async def _subscribe(self, subscription: EvmNodeSubscription) -> None:
         self._logger.debug('Subscribing to %s', subscription)
@@ -296,14 +290,15 @@
             'id': request_id,
             'method': method,
             'params': params,
         }
 
         if ws:
             started_at = time.time()
+            namespace = f'{self._config.name}.ws'
             event = asyncio.Event()
             self._requests[request_id] = (event, None)
 
             message = WebsocketMessage(request)
             client = self._get_ws_client()
 
             async def _request() -> None:
@@ -313,16 +308,16 @@
             await asyncio.wait_for(
                 _request(),
                 timeout=self._http_config.request_timeout,
             )
             data = self._requests[request_id][1]
             del self._requests[request_id]
 
-            metrics.time_in_requests[self.name] += time.time() - started_at
-            metrics.requests_total[self.name] += 1
+            metrics.inc(f'{namespace}:time_in_requests', (time.time() - started_at) / 60)
+            metrics.inc(f'{namespace}:requests_total', 1.0)
         else:
             data = await self.request(
                 method='post',
                 url='',
                 json=request,
             )
 
@@ -368,15 +363,15 @@
             level_data = self._level_data[data['hash']]
             level_data.head = data
             if subscription.transactions:
                 level_data.fetch_transactions = True
             self._emitter_queue.put_nowait(level_data)
         elif isinstance(subscription, EvmNodeLogsSubscription):
             level_data = self._level_data[data['blockHash']]
-            level_data.logs.append(data)
+            level_data.events.append(data)
         elif isinstance(subscription, EvmNodeSyncingSubscription):
             syncing = EvmNodeSyncingData.from_json(data)
             await self.emit_syncing(syncing)
         else:
             raise NotImplementedError
 
     async def _on_error(self, message: CompletionMessage) -> None:
```

### Comparing `dipdup-7.5.7/src/dipdup/datasources/evm_subsquid.py` & `dipdup-8.0.0a1/src/dipdup/datasources/evm_subsquid.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,25 +7,26 @@
 from io import BytesIO
 from typing import Any
 from typing import cast
 
 import pyarrow.ipc  # type: ignore[import-untyped]
 
 from dipdup.config import HttpConfig
-from dipdup.config.evm_subsquid import SubsquidDatasourceConfig
+from dipdup.config.evm_subsquid import EvmSubsquidDatasourceConfig
 from dipdup.datasources import Datasource
+from dipdup.datasources import EvmHistoryProvider
 from dipdup.datasources import IndexDatasource
 from dipdup.exceptions import DatasourceError
 from dipdup.exceptions import FrameworkException
 from dipdup.http import safe_exceptions
+from dipdup.models.evm import EvmEventData
+from dipdup.models.evm import EvmTransactionData
 from dipdup.models.evm_subsquid import FieldSelection
 from dipdup.models.evm_subsquid import LogRequest
 from dipdup.models.evm_subsquid import Query
-from dipdup.models.evm_subsquid import SubsquidEventData
-from dipdup.models.evm_subsquid import SubsquidTransactionData
 from dipdup.models.evm_subsquid import TransactionRequest
 
 LOG_FIELDS: FieldSelection = {
     'block': {
         'timestamp': True,
     },
     'log': {
@@ -38,14 +39,15 @@
     },
 }
 TRANSACTION_FIELDS: FieldSelection = {
     'block': {
         'timestamp': True,
     },
     'transaction': {
+        # 'accessList': True,
         'chainId': True,
         'contractAddress': True,
         'cumulativeGasUsed': True,
         'effectiveGasPrice': True,
         'from': True,
         'gasPrice': True,
         'gas': True,
@@ -76,44 +78,48 @@
         for item in arch.filelist:
             with arch.open(item) as f, pyarrow.ipc.open_stream(f) as reader:
                 table: pyarrow.Table = reader.read_all()
                 data[item.filename] = table.to_pylist()
     return data
 
 
-class _SubsquidWorker(Datasource[Any]):
+class _EvmSubsquidWorker(Datasource[Any]):
     async def run(self) -> None:
         raise FrameworkException('Subsquid worker datasource should not be run')
 
     async def query(self, query: Query) -> list[dict[str, Any]]:
         self._logger.debug('Worker query: %s', query)
         response = await self.request(
             'post',
             url='',
             json=query,
         )
         return cast(list[dict[str, Any]], response)
 
 
-class SubsquidDatasource(IndexDatasource[SubsquidDatasourceConfig]):
+class EvmSubsquidDatasource(IndexDatasource[EvmSubsquidDatasourceConfig], EvmHistoryProvider):
     _default_http_config = HttpConfig(
         polling_interval=1.0,
     )
 
-    def __init__(self, config: SubsquidDatasourceConfig) -> None:
+    def __init__(self, config: EvmSubsquidDatasourceConfig) -> None:
+        self._started = asyncio.Event()
         super().__init__(config, False)
 
     async def run(self) -> None:
-        if self._config.node:
-            return
+        await self._started.wait()
+
         # NOTE: If node datasource is missing, just poll API in reasonable intervals.
         while True:
             await asyncio.sleep(self._http_config.polling_interval)
             await self.initialize()
 
+    async def start(self) -> None:
+        self._started.set()
+
     async def subscribe(self) -> None:
         pass
 
     # FIXME: Heavily copy-pasted from `HTTPGateway._retry_request`
     async def query_worker(self, query: Query, current_level: int) -> list[dict[str, Any]]:
         retry_sleep = self._http_config.retry_sleep
         attempt = 1
@@ -132,20 +138,20 @@
 
                 self._logger.info('Waiting %s seconds before retry', retry_sleep)
                 await asyncio.sleep(retry_sleep)
 
                 attempt += 1
                 retry_sleep *= self._http_config.retry_multiplier
 
-    async def iter_event_logs(
+    async def iter_event_events(
         self,
         topics: tuple[tuple[str | None, str], ...],
         first_level: int,
         last_level: int,
-    ) -> AsyncIterator[tuple[SubsquidEventData, ...]]:
+    ) -> AsyncIterator[tuple[EvmEventData, ...]]:
         current_level = first_level
 
         # TODO: Smarter query optimizator
         topics_by_address = defaultdict(list)
         for address, topic in topics:
             topics_by_address[address].append(topic)
 
@@ -163,46 +169,46 @@
                 'fromBlock': current_level,
                 'toBlock': last_level,
             }
             response = await self.query_worker(query, current_level)
 
             for level_item in response:
                 current_level = level_item['header']['number'] + 1
-                logs: deque[SubsquidEventData] = deque()
+                logs: deque[EvmEventData] = deque()
                 for raw_log in level_item['logs']:
                     logs.append(
-                        SubsquidEventData.from_json(
+                        EvmEventData.from_subsquid_json(
                             event_json=raw_log,
                             header=level_item['header'],
                         ),
                     )
                 yield tuple(logs)
 
     async def iter_transactions(
         self,
         first_level: int,
         last_level: int,
         filters: tuple[TransactionRequest, ...],
-    ) -> AsyncIterator[tuple[SubsquidTransactionData, ...]]:
+    ) -> AsyncIterator[tuple[EvmTransactionData, ...]]:
         current_level = first_level
 
         while current_level <= last_level:
             query: Query = {
                 'fields': TRANSACTION_FIELDS,
                 'fromBlock': current_level,
                 'toBlock': last_level,
                 'transactions': list(filters),
             }
             response = await self.query_worker(query, current_level)
 
             for level_item in response:
                 current_level = level_item['header']['number'] + 1
-                transactions: deque[SubsquidTransactionData] = deque()
+                transactions: deque[EvmTransactionData] = deque()
                 for raw_transaction in level_item['transactions']:
-                    transaction = SubsquidTransactionData.from_json(
+                    transaction = EvmTransactionData.from_subsquid_json(
                         transaction_json=raw_transaction,
                         header=level_item['header'],
                     )
                     # NOTE: `None` falue is for chains and block ranges not compliant with the post-Byzantinum
                     # hard fork EVM specification (e.g. before 4.370,000 on Ethereum).
                     if transaction.status != 0:
                         transactions.append(transaction)
@@ -216,15 +222,15 @@
 
         self.set_sync_level(None, level)
 
     async def get_head_level(self) -> int:
         response = await self.request('get', 'height')
         return int(response)
 
-    async def _get_worker(self, level: int) -> _SubsquidWorker:
+    async def _get_worker(self, level: int) -> _EvmSubsquidWorker:
         worker_url = (
             await self._http.request(
                 'get',
                 f'{self._config.url}/{level}/worker',
             )
         ).decode()
 
@@ -232,8 +238,8 @@
         worker_config.url = worker_url
         if not worker_config.http:
             worker_config.http = self._default_http_config
 
         # NOTE: Fail immediately; retries are handled one level up
         worker_config.http.retry_count = 0
 
-        return _SubsquidWorker(worker_config)
+        return _EvmSubsquidWorker(worker_config)
```

### Comparing `dipdup-7.5.7/src/dipdup/datasources/ipfs.py` & `dipdup-8.0.0a1/src/dipdup/datasources/ipfs.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/datasources/tezos_tzkt.py` & `dipdup-8.0.0a1/src/dipdup/datasources/tezos_tzkt.py`

 * *Files 2% similar despite different names*

```diff
@@ -22,34 +22,37 @@
 
 from dipdup.config import DipDupConfig
 from dipdup.config import HttpConfig
 from dipdup.config.tezos import SMART_CONTRACT_PREFIX
 from dipdup.config.tezos import SMART_ROLLUP_PREFIX
 from dipdup.config.tezos import TezosContractConfig
 from dipdup.config.tezos_tzkt import TZKT_API_URLS
-from dipdup.config.tezos_tzkt import TzktDatasourceConfig
+from dipdup.config.tezos_tzkt import TezosTzktDatasourceConfig
 from dipdup.datasources import Datasource
 from dipdup.datasources import IndexDatasource
+from dipdup.datasources import TezosAbiProvider
+from dipdup.datasources import TezosHistoryProvider
+from dipdup.datasources import TezosRealtimeProvider
 from dipdup.exceptions import DatasourceError
 from dipdup.exceptions import FrameworkException
 from dipdup.models import Head
 from dipdup.models import MessageType
 from dipdup.models import ReindexingReason
 from dipdup.models import RollbackMessage
+from dipdup.models.tezos import TezosBigMapData
+from dipdup.models.tezos import TezosBlockData
+from dipdup.models.tezos import TezosEventData
+from dipdup.models.tezos import TezosHeadBlockData
+from dipdup.models.tezos import TezosOperationData
+from dipdup.models.tezos import TezosQuoteData
+from dipdup.models.tezos import TezosTokenBalanceData
+from dipdup.models.tezos import TezosTokenTransferData
 from dipdup.models.tezos_tzkt import HeadSubscription
-from dipdup.models.tezos_tzkt import TzktBigMapData
-from dipdup.models.tezos_tzkt import TzktBlockData
-from dipdup.models.tezos_tzkt import TzktEventData
-from dipdup.models.tezos_tzkt import TzktHeadBlockData
-from dipdup.models.tezos_tzkt import TzktMessageType
-from dipdup.models.tezos_tzkt import TzktOperationData
-from dipdup.models.tezos_tzkt import TzktQuoteData
-from dipdup.models.tezos_tzkt import TzktSubscription
-from dipdup.models.tezos_tzkt import TzktTokenBalanceData
-from dipdup.models.tezos_tzkt import TzktTokenTransferData
+from dipdup.models.tezos_tzkt import TezosTzktMessageType
+from dipdup.models.tezos_tzkt import TezosTzktSubscription
 from dipdup.utils import split_by_chunks
 
 ORIGINATION_REQUEST_LIMIT = 100
 OPERATION_FIELDS = (
     'type',
     'id',
     'level',
@@ -139,33 +142,33 @@
     'payload',
     'contract',
     'codeHash',
     'transactionId',
 )
 
 
-HeadCallback = Callable[['TzktDatasource', TzktHeadBlockData], Awaitable[None]]
-OperationsCallback = Callable[['TzktDatasource', tuple[TzktOperationData, ...]], Awaitable[None]]
-TokenTransfersCallback = Callable[['TzktDatasource', tuple[TzktTokenTransferData, ...]], Awaitable[None]]
-TokenBalancesCallback = Callable[['TzktDatasource', tuple[TzktTokenBalanceData, ...]], Awaitable[None]]
-BigMapsCallback = Callable[['TzktDatasource', tuple[TzktBigMapData, ...]], Awaitable[None]]
-EventsCallback = Callable[['TzktDatasource', tuple[TzktEventData, ...]], Awaitable[None]]
+HeadCallback = Callable[['TezosTzktDatasource', TezosHeadBlockData], Awaitable[None]]
+OperationsCallback = Callable[['TezosTzktDatasource', tuple[TezosOperationData, ...]], Awaitable[None]]
+TokenTransfersCallback = Callable[['TezosTzktDatasource', tuple[TezosTokenTransferData, ...]], Awaitable[None]]
+TokenBalancesCallback = Callable[['TezosTzktDatasource', tuple[TezosTokenBalanceData, ...]], Awaitable[None]]
+BigMapsCallback = Callable[['TezosTzktDatasource', tuple[TezosBigMapData, ...]], Awaitable[None]]
+EventsCallback = Callable[['TezosTzktDatasource', tuple[TezosEventData, ...]], Awaitable[None]]
 
 
-class TzktMessageAction(Enum):
+class TezosTzktMessageAction(Enum):
     STATE = 0
     DATA = 1
     REORG = 2
 
 
 MessageData = dict[str, Any] | list[dict[str, Any]] | RollbackMessage
 
 
 class BufferedMessage(NamedTuple):
-    type: TzktMessageType
+    type: TezosTzktMessageType
     data: MessageData
 
 
 class MessageBuffer:
     """Buffers realtime TzKT messages and yields them by level.
 
     Initially, it was a mitigation for TzKT's reorgs.
@@ -175,21 +178,21 @@
         self._logger = logging.getLogger('dipdup.tzkt')
         self._size = size
         self._messages: dict[int, list[BufferedMessage]] = {}
 
     def __len__(self) -> int:
         return len(self._messages)
 
-    def add(self, type_: TzktMessageType, level: int, data: MessageData) -> None:
+    def add(self, type_: TezosTzktMessageType, level: int, data: MessageData) -> None:
         """Add a message to the buffer."""
         if level not in self._messages:
             self._messages[level] = []
         self._messages[level].append(BufferedMessage(type_, data))
 
-    def rollback(self, type_: TzktMessageType, channel_level: int, message_level: int) -> bool:
+    def rollback(self, type_: TezosTzktMessageType, channel_level: int, message_level: int) -> bool:
         """Drop buffered messages in reversed order while possible, return if successful."""
         self._logger.info('`%s` rollback requested: %s -> %s', type_.value, channel_level, message_level)
         levels = range(channel_level, message_level, -1)
         for level in levels:
             if level not in self._messages:
                 return False
 
@@ -227,42 +230,44 @@
     def get_code_hashes(self, address: str) -> tuple[int, int]:
         return self._address_to_hashes[address]
 
     def get_address(self, code_hash: int, type_hash: int) -> str:
         return self._hashes_to_address[(code_hash, type_hash)]
 
 
-class TzktDatasource(IndexDatasource[TzktDatasourceConfig]):
+class TezosTzktDatasource(
+    IndexDatasource[TezosTzktDatasourceConfig], TezosHistoryProvider, TezosRealtimeProvider, TezosAbiProvider
+):
     _default_http_config = HttpConfig(
         retry_sleep=1,
         retry_multiplier=1.1,
         retry_count=10,
         ratelimit_rate=100,
         ratelimit_period=1,
         connection_limit=25,
         batch_size=10000,
     )
 
     def __init__(
         self,
-        config: TzktDatasourceConfig,
+        config: TezosTzktDatasourceConfig,
     ) -> None:
         super().__init__(config)
         self._buffer = MessageBuffer(config.buffer_size)
         self._contract_hashes = ContractHashes()
 
         self._on_head_callbacks: set[HeadCallback] = set()
         self._on_operations_callbacks: set[OperationsCallback] = set()
         self._on_token_transfers_callbacks: set[TokenTransfersCallback] = set()
         self._on_token_balances_callbacks: set[TokenBalancesCallback] = set()
         self._on_big_maps_callbacks: set[BigMapsCallback] = set()
         self._on_events_callbacks: set[EventsCallback] = set()
 
         self._signalr_client: SignalRClient | None = None
-        self._channel_levels: defaultdict[TzktMessageType, int | None] = defaultdict(lambda: None)
+        self._channel_levels: defaultdict[TezosTzktMessageType, int | None] = defaultdict(lambda: None)
 
     async def __aenter__(self) -> None:
         try:
             await super().__aenter__()
 
             protocol = await self.request('get', 'v1/protocols/current')
             category = 'self-hosted'
@@ -316,35 +321,35 @@
 
     def call_on_big_maps(self, fn: BigMapsCallback) -> None:
         self._on_big_maps_callbacks.add(fn)
 
     def call_on_events(self, fn: EventsCallback) -> None:
         self._on_events_callbacks.add(fn)
 
-    async def emit_head(self, head: TzktHeadBlockData) -> None:
+    async def emit_head(self, head: TezosHeadBlockData) -> None:
         for fn in self._on_head_callbacks:
             await fn(self, head)
 
-    async def emit_operations(self, operations: tuple[TzktOperationData, ...]) -> None:
+    async def emit_operations(self, operations: tuple[TezosOperationData, ...]) -> None:
         for fn in self._on_operations_callbacks:
             await fn(self, operations)
 
-    async def emit_token_transfers(self, token_transfers: tuple[TzktTokenTransferData, ...]) -> None:
+    async def emit_token_transfers(self, token_transfers: tuple[TezosTokenTransferData, ...]) -> None:
         for fn in self._on_token_transfers_callbacks:
             await fn(self, token_transfers)
 
-    async def emit_token_balances(self, token_balances: tuple[TzktTokenBalanceData, ...]) -> None:
+    async def emit_token_balances(self, token_balances: tuple[TezosTokenBalanceData, ...]) -> None:
         for fn in self._on_token_balances_callbacks:
             await fn(self, token_balances)
 
-    async def emit_big_maps(self, big_maps: tuple[TzktBigMapData, ...]) -> None:
+    async def emit_big_maps(self, big_maps: tuple[TezosBigMapData, ...]) -> None:
         for fn in self._on_big_maps_callbacks:
             await fn(self, big_maps)
 
-    async def emit_events(self, events: tuple[TzktEventData, ...]) -> None:
+    async def emit_events(self, events: tuple[TezosEventData, ...]) -> None:
         for fn in self._on_events_callbacks:
             await fn(self, events)
 
     async def emit_rollback(self, type_: MessageType, from_level: int, to_level: int) -> None:
         for fn in self._on_rollback_callbacks:
             await fn(self, type_, from_level, to_level)
 
@@ -352,15 +357,15 @@
         for fn in self._on_connected_callbacks:
             await fn()
 
     async def emit_disconnected(self) -> None:
         for fn in self._on_disconnected_callbacks:
             await fn()
 
-    def get_channel_level(self, message_type: TzktMessageType) -> int:
+    def get_channel_level(self, message_type: TezosTzktMessageType) -> int:
         """Get current level of the channel, or sync level if no messages were received yet."""
         channel_level = self._channel_levels[message_type]
         if channel_level is None:
             # NOTE: If no data messages were received since run, use sync level instead
             # NOTE: There's only one sync level for all channels, otherwise `Index.process` would fail
             channel_level = self.get_sync_level(HeadSubscription())
             if channel_level is None:
@@ -577,39 +582,39 @@
         async for batch in self._iter_batches(
             self.get_contract_big_maps,
             address,
             cursor=False,
         ):
             yield batch
 
-    async def get_head_block(self) -> TzktHeadBlockData:
+    async def get_head_block(self) -> TezosHeadBlockData:
         """Get latest block (head)"""
         self._logger.info('Fetching latest block')
         head_block_json = await self.request(
             'get',
             url='v1/head',
         )
-        return TzktHeadBlockData.from_json(head_block_json)
+        return TezosHeadBlockData.from_json(head_block_json)
 
-    async def get_block(self, level: int) -> TzktBlockData:
+    async def get_block(self, level: int) -> TezosBlockData:
         """Get block by level"""
         self._logger.info('Fetching block %s', level)
         block_json = await self.request(
             'get',
             url=f'v1/blocks/{level}',
         )
-        return TzktBlockData.from_json(block_json)
+        return TezosBlockData.from_json(block_json)
 
     async def get_migration_originations(
         self,
         first_level: int | None = None,
         last_level: int | None = None,
         offset: int | None = None,
         limit: int | None = None,
-    ) -> tuple[TzktOperationData, ...]:
+    ) -> tuple[TezosOperationData, ...]:
         """Get contracts originated from migrations"""
         self._logger.info('Fetching contracts originated with migrations')
         params = self._get_request_params(
             first_level=first_level,
             last_level=last_level,
             offset=offset,
             limit=limit,
@@ -619,21 +624,21 @@
             kind='origination',
         )
         raw_migrations = await self._request_values_dict(
             'get',
             url='v1/operations/migrations',
             params=params,
         )
-        return tuple(TzktOperationData.from_migration_json(m) for m in raw_migrations)
+        return tuple(TezosOperationData.from_migration_json(m) for m in raw_migrations)
 
     async def iter_migration_originations(
         self,
         first_level: int | None = None,
         last_level: int | None = None,
-    ) -> AsyncIterator[tuple[TzktOperationData, ...]]:
+    ) -> AsyncIterator[tuple[TezosOperationData, ...]]:
         async for batch in self._iter_batches(
             self.get_migration_originations,
             first_level,
             last_level,
         ):
             yield batch
 
@@ -641,15 +646,15 @@
         self,
         addresses: set[str] | None = None,
         code_hashes: set[int] | None = None,
         first_level: int | None = None,
         last_level: int | None = None,
         offset: int | None = None,
         limit: int | None = None,
-    ) -> tuple[TzktOperationData, ...]:
+    ) -> tuple[TezosOperationData, ...]:
         offset, limit = offset or 0, limit or self.request_limit
         raw_originations: list[dict[str, Any]] = []
         params = self._get_request_params(
             first_level=first_level,
             last_level=last_level,
             offset=offset,
             limit=limit,
@@ -695,26 +700,26 @@
                     params=params,
                 )
             )
         elif addresses and code_hashes:
             raise FrameworkException('Either `addresses` or `code_hashes` should be specified')
 
         # NOTE: `type` field needs to be set manually when requesting operations by specific type
-        return tuple(TzktOperationData.from_json(op, type_='origination') for op in raw_originations)
+        return tuple(TezosOperationData.from_json(op, type_='origination') for op in raw_originations)
 
     async def get_transactions(
         self,
         field: str,
         addresses: set[str] | None,
         code_hashes: set[int] | None,
         first_level: int | None = None,
         last_level: int | None = None,
         offset: int | None = None,
         limit: int | None = None,
-    ) -> tuple[TzktOperationData, ...]:
+    ) -> tuple[TezosOperationData, ...]:
         params = self._get_request_params(
             first_level=first_level,
             last_level=last_level,
             # NOTE: This is intentional
             offset=None,
             limit=limit,
             select=TRANSACTION_OPERATION_FIELDS,
@@ -736,23 +741,23 @@
         raw_transactions = await self._request_values_dict(
             'get',
             url='v1/operations/transactions',
             params=params,
         )
 
         # NOTE: `type` field needs to be set manually when requesting operations by specific type
-        return tuple(TzktOperationData.from_json(op, type_='transaction') for op in raw_transactions)
+        return tuple(TezosOperationData.from_json(op, type_='transaction') for op in raw_transactions)
 
     async def iter_transactions(
         self,
         field: str,
         addresses: set[str],
         first_level: int,
         last_level: int,
-    ) -> AsyncIterator[tuple[TzktOperationData, ...]]:
+    ) -> AsyncIterator[tuple[TezosOperationData, ...]]:
         async for batch in self._iter_batches(
             self.get_transactions,
             field,
             addresses,
             first_level,
             last_level,
         ):
@@ -762,15 +767,15 @@
         self,
         field: str,
         addresses: set[str] | None,
         first_level: int | None = None,
         last_level: int | None = None,
         offset: int | None = None,
         limit: int | None = None,
-    ) -> tuple[TzktOperationData, ...]:
+    ) -> tuple[TezosOperationData, ...]:
         params = self._get_request_params(
             first_level=first_level,
             last_level=last_level,
             offset=None,
             limit=limit,
             select=SR_EXECUTE_OPERATION_FIELDS,
             values=True,
@@ -787,23 +792,23 @@
         raw_transactions = await self._request_values_dict(
             'get',
             url='v1/operations/sr_execute',
             params=params,
         )
 
         # NOTE: `type` field needs to be set manually when requesting operations by specific type
-        return tuple(TzktOperationData.from_json(op, type_='sr_execute') for op in raw_transactions)
+        return tuple(TezosOperationData.from_json(op, type_='sr_execute') for op in raw_transactions)
 
     async def iter_sr_execute(
         self,
         field: str,
         addresses: set[str],
         first_level: int,
         last_level: int,
-    ) -> AsyncIterator[tuple[TzktOperationData, ...]]:
+    ) -> AsyncIterator[tuple[TezosOperationData, ...]]:
         async for batch in self._iter_batches(
             self.get_sr_execute,
             field,
             addresses,
             first_level,
             last_level,
         ):
@@ -813,15 +818,15 @@
         self,
         addresses: set[str],
         paths: set[str],
         first_level: int,
         last_level: int,
         offset: int | None = None,
         limit: int | None = None,
-    ) -> tuple[TzktBigMapData, ...]:
+    ) -> tuple[TezosBigMapData, ...]:
         params = self._get_request_params(
             first_level=first_level,
             last_level=last_level,
             offset=offset,
             limit=limit,
         )
         raw_big_maps = await self.request(
@@ -829,70 +834,70 @@
             url='v1/bigmaps/updates',
             params={
                 **params,
                 'contract.in': ','.join(addresses),
                 'path.in': ','.join(paths),
             },
         )
-        return tuple(TzktBigMapData.from_json(bm) for bm in raw_big_maps)
+        return tuple(TezosBigMapData.from_json(bm) for bm in raw_big_maps)
 
     async def iter_big_maps(
         self,
         addresses: set[str],
         paths: set[str],
         first_level: int,
         last_level: int,
-    ) -> AsyncIterator[tuple[TzktBigMapData, ...]]:
+    ) -> AsyncIterator[tuple[TezosBigMapData, ...]]:
         async for batch in self._iter_batches(
             self.get_big_maps,
             addresses,
             paths,
             first_level,
             last_level,
             cursor=False,
         ):
             yield batch
 
-    async def get_quote(self, level: int) -> TzktQuoteData:
+    async def get_quote(self, level: int) -> TezosQuoteData:
         """Get quote for block"""
         self._logger.info('Fetching quotes for level %s', level)
         quote_json = await self.request(
             'get',
             url='v1/quotes',
             params={'level': level},
         )
-        return TzktQuoteData.from_json(quote_json[0])
+        return TezosQuoteData.from_json(quote_json[0])
 
     async def get_quotes(
         self,
         first_level: int,
         last_level: int,
         offset: int | None = None,
         limit: int | None = None,
-    ) -> tuple[TzktQuoteData, ...]:
+    ) -> tuple[TezosQuoteData, ...]:
         """Get quotes for blocks"""
         offset, limit = offset or 0, limit or self.request_limit
         self._logger.info('Fetching quotes for levels %s-%s', first_level, last_level)
         quotes_json = await self.request(
             'get',
             url='v1/quotes',
             params={
                 'level.ge': first_level,
                 'level.le': last_level,
                 'offset.cr': offset,
                 'limit': limit,
             },
         )
-        return tuple(TzktQuoteData.from_json(quote) for quote in quotes_json)
+        return tuple(TezosQuoteData.from_json(quote) for quote in quotes_json)
 
     async def iter_quotes(
         self,
         first_level: int,
         last_level: int,
-    ) -> AsyncIterator[tuple[TzktQuoteData, ...]]:
+    ) -> AsyncIterator[tuple[TezosQuoteData, ...]]:
         """Iterate quotes for blocks"""
         async for batch in self._iter_batches(
             self.get_quotes,
             first_level,
             last_level,
         ):
             yield batch
@@ -903,15 +908,15 @@
         token_ids: set[int],
         from_addresses: set[str],
         to_addresses: set[str],
         first_level: int,
         last_level: int,
         offset: int | None = None,
         limit: int | None = None,
-    ) -> tuple[TzktTokenTransferData, ...]:
+    ) -> tuple[TezosTokenTransferData, ...]:
         """Get token transfers for contract"""
         params = self._get_request_params(
             first_level,
             last_level,
             offset=offset or 0,
             limit=limit,
             select=TOKEN_TRANSFER_FIELDS,
@@ -921,25 +926,25 @@
                 'token.contract.in': ','.join(token_addresses),
                 'token.id.in': ','.join(str(token_id) for token_id in token_ids),
                 'from.in': ','.join(from_addresses),
                 'to.in': ','.join(to_addresses),
             },
         )
         raw_token_transfers = await self._request_values_dict('get', url='v1/tokens/transfers', params=params)
-        return tuple(TzktTokenTransferData.from_json(item) for item in raw_token_transfers)
+        return tuple(TezosTokenTransferData.from_json(item) for item in raw_token_transfers)
 
     async def iter_token_transfers(
         self,
         token_addresses: set[str],
         token_ids: set[int],
         from_addresses: set[str],
         to_addresses: set[str],
         first_level: int,
         last_level: int,
-    ) -> AsyncIterator[tuple[TzktTokenTransferData, ...]]:
+    ) -> AsyncIterator[tuple[TezosTokenTransferData, ...]]:
         """Iterate token transfers for contract"""
         async for batch in self._iter_batches(
             self.get_token_transfers,
             token_addresses,
             token_ids,
             from_addresses,
             to_addresses,
@@ -953,38 +958,38 @@
         self,
         token_addresses: set[str],
         token_ids: set[int],
         first_level: int | None = None,
         last_level: int | None = None,
         offset: int | None = None,
         limit: int | None = None,
-    ) -> tuple[TzktTokenBalanceData, ...]:
+    ) -> tuple[TezosTokenBalanceData, ...]:
         params = self._get_request_params(
             first_level,
             last_level,
             offset=offset or 0,
             limit=limit,
             select=TOKEN_BALANCE_FIELDS,
             values=True,
             cursor=True,
             **{
                 'token.contract.in': ','.join(token_addresses),
                 'token.id.in': ','.join(str(token_id) for token_id in token_ids),
             },
         )
         raw_token_balances = await self._request_values_dict('get', url='v1/tokens/balances', params=params)
-        return tuple(TzktTokenBalanceData.from_json(item) for item in raw_token_balances)
+        return tuple(TezosTokenBalanceData.from_json(item) for item in raw_token_balances)
 
     async def iter_token_balances(
         self,
         token_addresses: set[str],
         token_ids: set[int],
         first_level: int | None = None,
         last_level: int | None = None,
-    ) -> AsyncIterator[tuple[TzktTokenBalanceData, ...]]:
+    ) -> AsyncIterator[tuple[TezosTokenBalanceData, ...]]:
         async for batch in self._iter_batches(
             self.get_token_balances,
             token_addresses,
             token_ids,
             first_level,
             last_level,
             cursor=True,
@@ -995,15 +1000,15 @@
         self,
         addresses: set[str],
         tags: set[str],
         first_level: int,
         last_level: int,
         offset: int | None = None,
         limit: int | None = None,
-    ) -> tuple[TzktEventData, ...]:
+    ) -> tuple[TezosEventData, ...]:
         params = self._get_request_params(
             first_level,
             last_level,
             offset=offset or 0,
             limit=limit,
             select=EVENT_FIELDS,
             values=True,
@@ -1015,23 +1020,23 @@
         )
         offset, limit = offset or 0, limit or self.request_limit
         raw_events = await self._request_values_dict(
             'get',
             url='v1/contracts/events',
             params=params,
         )
-        return tuple(TzktEventData.from_json(e) for e in raw_events)
+        return tuple(TezosEventData.from_json(e) for e in raw_events)
 
     async def iter_events(
         self,
         addresses: set[str],
         tags: set[str],
         first_level: int,
         last_level: int,
-    ) -> AsyncIterator[tuple[TzktEventData, ...]]:
+    ) -> AsyncIterator[tuple[TezosEventData, ...]]:
         async for batch in self._iter_batches(
             self.get_events,
             addresses,
             tags,
             first_level,
             last_level,
             cursor=False,
@@ -1041,20 +1046,20 @@
     async def subscribe(self) -> None:
         missing_subscriptions = self._subscriptions.missing_subscriptions
         if not missing_subscriptions:
             return
 
         self._logger.info('Subscribing to %s channels', len(missing_subscriptions))
         for subscription in missing_subscriptions:
-            if not isinstance(subscription, TzktSubscription):
-                raise FrameworkException(f'Expected TzktSubscription, got {subscription}')
+            if not isinstance(subscription, TezosTzktSubscription):
+                raise FrameworkException(f'Expected TezosTzktSubscription, got {subscription}')
             await self._subscribe(subscription)
         self._logger.info('Subscribed to %s channels', len(missing_subscriptions))
 
-    async def _subscribe(self, subscription: TzktSubscription) -> None:
+    async def _subscribe(self, subscription: TezosTzktSubscription) -> None:
         self._logger.debug('Subscribing to %s', subscription)
         method = subscription.method
         request: list[dict[str, Any]] = subscription.get_request()
 
         event = Event()
 
         async def _on_subscribe(message: CompletionMessage) -> None:
@@ -1161,20 +1166,20 @@
             max_size=None,
         )
 
         self._signalr_client.on_open(self._on_connected)
         self._signalr_client.on_close(self._on_disconnected)
         self._signalr_client.on_error(self._on_error)
 
-        self._signalr_client.on('operations', partial(self._on_message, TzktMessageType.operation))
-        self._signalr_client.on('transfers', partial(self._on_message, TzktMessageType.token_transfer))
-        self._signalr_client.on('balances', partial(self._on_message, TzktMessageType.token_balance))
-        self._signalr_client.on('bigmaps', partial(self._on_message, TzktMessageType.big_map))
-        self._signalr_client.on('head', partial(self._on_message, TzktMessageType.head))
-        self._signalr_client.on('events', partial(self._on_message, TzktMessageType.event))
+        self._signalr_client.on('operations', partial(self._on_message, TezosTzktMessageType.operation))
+        self._signalr_client.on('transfers', partial(self._on_message, TezosTzktMessageType.token_transfer))
+        self._signalr_client.on('balances', partial(self._on_message, TezosTzktMessageType.token_balance))
+        self._signalr_client.on('bigmaps', partial(self._on_message, TezosTzktMessageType.big_map))
+        self._signalr_client.on('head', partial(self._on_message, TezosTzktMessageType.head))
+        self._signalr_client.on('events', partial(self._on_message, TezosTzktMessageType.event))
 
         return self._signalr_client
 
     async def _send(
         self,
         method: str,
         arguments: list[dict[str, Any]],
@@ -1195,21 +1200,21 @@
         self._contract_hashes.reset()
         await self.emit_disconnected()
 
     async def _on_error(self, message: CompletionMessage) -> NoReturn:
         """Raise exception from WS server's error message"""
         raise DatasourceError(datasource=self.name, msg=cast(str, message.error))
 
-    async def _on_message(self, type_: TzktMessageType, message: list[dict[str, Any]]) -> None:
+    async def _on_message(self, type_: TezosTzktMessageType, message: list[dict[str, Any]]) -> None:
         """Parse message received from Websocket, ensure it's correct in the current context and yield data."""
         # NOTE: Parse messages and either buffer or yield data
         for item in message:
-            action = TzktMessageAction(item['type'])
+            action = TezosTzktMessageAction(item['type'])
             # NOTE: Legacy, sync level returned by TzKT during negotiation
-            if action == TzktMessageAction.STATE:
+            if action == TezosTzktMessageAction.STATE:
                 continue
 
             message_level = item['state']
             channel_level = self.get_channel_level(type_)
             self._channel_levels[type_] = message_level
 
             self._logger.info(
@@ -1217,120 +1222,120 @@
                 type_.value,
                 action.name,
                 channel_level,
                 message_level,
             )
 
             # NOTE: Put data messages to buffer by level
-            if action == TzktMessageAction.DATA:
+            if action == TezosTzktMessageAction.DATA:
                 self._buffer.add(type_, message_level, item['data'])
 
             # NOTE: Try to process rollback automatically, emit if failed
-            elif action == TzktMessageAction.REORG:
+            elif action == TezosTzktMessageAction.REORG:
                 if self._buffer.rollback(type_, channel_level, message_level):
                     self._logger.info('Rolled back blocks were dropped from realtime message buffer')
                 else:
                     self._logger.info('Rolled back blocks are not buffered; proceeding to database rollback')
                     await self.emit_rollback(type_, channel_level, message_level)
 
             else:
                 raise NotImplementedError(f'Unknown message type: {action}')
 
         # NOTE: Process extensive data from buffer
         for buffered_message in self._buffer.yield_from():
-            if buffered_message.type == TzktMessageType.operation:
+            if buffered_message.type == TezosTzktMessageType.operation:
                 await self._process_operations_data(cast(list[dict[str, Any]], buffered_message.data))
-            elif buffered_message.type == TzktMessageType.token_transfer:
+            elif buffered_message.type == TezosTzktMessageType.token_transfer:
                 await self._process_token_transfers_data(cast(list[dict[str, Any]], buffered_message.data))
-            elif buffered_message.type == TzktMessageType.token_balance:
+            elif buffered_message.type == TezosTzktMessageType.token_balance:
                 await self._process_token_balances_data(cast(list[dict[str, Any]], buffered_message.data))
-            elif buffered_message.type == TzktMessageType.big_map:
+            elif buffered_message.type == TezosTzktMessageType.big_map:
                 await self._process_big_maps_data(cast(list[dict[str, Any]], buffered_message.data))
-            elif buffered_message.type == TzktMessageType.head:
+            elif buffered_message.type == TezosTzktMessageType.head:
                 await self._process_head_data(cast(dict[str, Any], buffered_message.data))
-            elif buffered_message.type == TzktMessageType.event:
+            elif buffered_message.type == TezosTzktMessageType.event:
                 await self._process_events_data(cast(list[dict[str, Any]], buffered_message.data))
             else:
                 raise NotImplementedError(f'Unknown message type: {buffered_message.type}')
 
     async def _process_operations_data(self, data: list[dict[str, Any]]) -> None:
         """Parse and emit raw operations from WS"""
-        level_operations: defaultdict[int, deque[TzktOperationData]] = defaultdict(deque)
+        level_operations: defaultdict[int, deque[TezosOperationData]] = defaultdict(deque)
 
         for operation_json in data:
             if operation_json['status'] != 'applied':
                 continue
             if 'hash' in operation_json:
-                operation = TzktOperationData.from_json(operation_json)
+                operation = TezosOperationData.from_json(operation_json)
             else:
-                operation = TzktOperationData.from_migration_json(operation_json)
+                operation = TezosOperationData.from_migration_json(operation_json)
             level_operations[operation.level].append(operation)
 
         for _level, operations in level_operations.items():
             await self.emit_operations(tuple(operations))
 
     async def _process_token_transfers_data(self, data: list[dict[str, Any]]) -> None:
         """Parse and emit raw token transfers from WS"""
-        level_token_transfers: defaultdict[int, deque[TzktTokenTransferData]] = defaultdict(deque)
+        level_token_transfers: defaultdict[int, deque[TezosTokenTransferData]] = defaultdict(deque)
 
         for token_transfer_json in data:
-            token_transfer = TzktTokenTransferData.from_json(token_transfer_json)
+            token_transfer = TezosTokenTransferData.from_json(token_transfer_json)
             level_token_transfers[token_transfer.level].append(token_transfer)
 
         for _level, token_transfers in level_token_transfers.items():
             await self.emit_token_transfers(tuple(token_transfers))
 
     async def _process_token_balances_data(self, data: list[dict[str, Any]]) -> None:
         """Parse and emit raw token balances from WS"""
-        level_token_balances: defaultdict[int, deque[TzktTokenBalanceData]] = defaultdict(deque)
+        level_token_balances: defaultdict[int, deque[TezosTokenBalanceData]] = defaultdict(deque)
 
         for token_balance_json in data:
-            token_balance = TzktTokenBalanceData.from_json(token_balance_json)
+            token_balance = TezosTokenBalanceData.from_json(token_balance_json)
             level_token_balances[token_balance.level].append(token_balance)
 
         for _level, token_balances in level_token_balances.items():
             await self.emit_token_balances(tuple(token_balances))
 
     async def _process_big_maps_data(self, data: list[dict[str, Any]]) -> None:
         """Parse and emit raw big map diffs from WS"""
-        level_big_maps: defaultdict[int, deque[TzktBigMapData]] = defaultdict(deque)
+        level_big_maps: defaultdict[int, deque[TezosBigMapData]] = defaultdict(deque)
 
-        big_maps: deque[TzktBigMapData] = deque()
+        big_maps: deque[TezosBigMapData] = deque()
         for big_map_json in data:
-            big_map = TzktBigMapData.from_json(big_map_json)
+            big_map = TezosBigMapData.from_json(big_map_json)
             level_big_maps[big_map.level].append(big_map)
 
         for _level, big_maps in level_big_maps.items():
             await self.emit_big_maps(tuple(big_maps))
 
     async def _process_head_data(self, data: dict[str, Any]) -> None:
         """Parse and emit raw head block from WS"""
-        block = TzktHeadBlockData.from_json(data)
+        block = TezosHeadBlockData.from_json(data)
         await self.emit_head(block)
 
     async def _process_events_data(self, data: list[dict[str, Any]]) -> None:
         """Parse and emit raw big map diffs from WS"""
-        level_events: defaultdict[int, deque[TzktEventData]] = defaultdict(deque)
+        level_events: defaultdict[int, deque[TezosEventData]] = defaultdict(deque)
 
-        events: deque[TzktEventData] = deque()
+        events: deque[TezosEventData] = deque()
         for event_json in data:
-            event = TzktEventData.from_json(event_json)
+            event = TezosEventData.from_json(event_json)
             level_events[event.level].append(event)
 
         for _level, events in level_events.items():
             await self.emit_events(tuple(events))
 
 
 async def late_tzkt_initialization(
     config: DipDupConfig,
     datasources: dict[str, Datasource[Any]],
     reindex_fn: Callable[..., Awaitable[None]] | None,
 ) -> None:
     """Tasks to perform after all datasources are initialized."""
-    tzkt_datasources = tuple(d for d in datasources.values() if isinstance(d, TzktDatasource))
+    tzkt_datasources = tuple(d for d in datasources.values() if isinstance(d, TezosTzktDatasource))
     tezos_contracts = tuple(c for c in config.contracts.values() if isinstance(c, TezosContractConfig))
 
     # NOTE: Late config initialization: resolve contract code hashes.
     for contract in tezos_contracts:
         code_hash = contract.code_hash
         if not isinstance(code_hash, str):
             continue
```

### Comparing `dipdup-7.5.7/src/dipdup/datasources/tzip_metadata.py` & `dipdup-8.0.0a1/src/dipdup/datasources/tzip_metadata.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/dipdup.py` & `dipdup-8.0.0a1/src/dipdup/dipdup.py`

 * *Files 10% similar despite different names*

```diff
@@ -36,59 +36,58 @@
 from dipdup.database import get_schema_hash
 from dipdup.database import preload_cached_models
 from dipdup.database import tortoise_wrapper
 from dipdup.datasources import Datasource
 from dipdup.datasources import IndexDatasource
 from dipdup.datasources import create_datasource
 from dipdup.datasources.evm_node import EvmNodeDatasource
-from dipdup.datasources.tezos_tzkt import TzktDatasource
+from dipdup.datasources.tezos_tzkt import TezosTzktDatasource
 from dipdup.datasources.tezos_tzkt import late_tzkt_initialization
 from dipdup.exceptions import ConfigInitializationException
 from dipdup.exceptions import FrameworkException
 from dipdup.hasura import HasuraGateway
-from dipdup.indexes.evm_subsquid_events.index import SubsquidEventsIndex
-from dipdup.indexes.evm_subsquid_transactions.index import SubsquidTransactionsIndex
-from dipdup.indexes.tezos_tzkt_big_maps.index import TzktBigMapsIndex
-from dipdup.indexes.tezos_tzkt_events.index import TzktEventsIndex
-from dipdup.indexes.tezos_tzkt_head.index import TzktHeadIndex
-from dipdup.indexes.tezos_tzkt_operations.index import TzktOperationsIndex
-from dipdup.indexes.tezos_tzkt_operations.index import extract_operation_subgroups
-from dipdup.indexes.tezos_tzkt_token_transfers.index import TzktTokenTransfersIndex
+from dipdup.indexes.evm_events.index import EvmEventsIndex
+from dipdup.indexes.evm_transactions.index import EvmTransactionsIndex
+from dipdup.indexes.tezos_big_maps.index import TezosBigMapsIndex
+from dipdup.indexes.tezos_events.index import TezosEventsIndex
+from dipdup.indexes.tezos_head.index import TezosHeadIndex
+from dipdup.indexes.tezos_operations.index import TezosOperationsIndex
+from dipdup.indexes.tezos_operations.index import extract_operation_subgroups
+from dipdup.indexes.tezos_token_transfers.index import TezosTokenTransfersIndex
 from dipdup.models import Contract
 from dipdup.models import ContractKind
 from dipdup.models import Head
 from dipdup.models import Index as IndexState
 from dipdup.models import IndexStatus
 from dipdup.models import MessageType
 from dipdup.models import ReindexingReason
 from dipdup.models import RollbackMessage
 from dipdup.models import Schema
+from dipdup.models.evm import EvmEventData
+from dipdup.models.evm import EvmTransactionData
 from dipdup.models.evm_node import EvmNodeHeadData
-from dipdup.models.evm_node import EvmNodeLogData
 from dipdup.models.evm_node import EvmNodeSyncingData
-from dipdup.models.evm_node import EvmNodeTraceData
-from dipdup.models.evm_node import EvmNodeTransactionData
-from dipdup.models.tezos_tzkt import TzktBigMapData
-from dipdup.models.tezos_tzkt import TzktEventData
-from dipdup.models.tezos_tzkt import TzktHeadBlockData
-from dipdup.models.tezos_tzkt import TzktOperationData
-from dipdup.models.tezos_tzkt import TzktTokenTransferData
+from dipdup.models.tezos import TezosBigMapData
+from dipdup.models.tezos import TezosEventData
+from dipdup.models.tezos import TezosHeadBlockData
+from dipdup.models.tezos import TezosOperationData
+from dipdup.models.tezos import TezosTokenTransferData
 from dipdup.package import DipDupPackage
 from dipdup.performance import caches
 from dipdup.performance import metrics
 from dipdup.prometheus import Metrics
 from dipdup.scheduler import SchedulerManager
 from dipdup.sys import fire_and_forget
 from dipdup.transactions import TransactionManager
 
 if TYPE_CHECKING:
     from dipdup.index import Index
 
-METRICS_INTERVAL = 1.0 if env.DEBUG else 5.0
-STATUS_INTERVAL = 1.0 if env.DEBUG else 5.0
+METRICS_INTERVAL = 1.0 if env.DEBUG else 2.0
+STATUS_INTERVAL = 1.0 if env.DEBUG else 10.0
 CLEANUP_INTERVAL = 60.0 * 5
 INDEX_DISPATCHER_INTERVAL = 0.1
 
 _logger = logging.getLogger(__name__)
 
 
 class IndexDispatcher:
@@ -98,65 +97,65 @@
         # FIXME: Tezos-specific
         self._entrypoint_filter: set[str] = set()
         self._address_filter: set[str] = set()
         self._code_hash_filter: set[int] = set()
         # NOTE: Monitoring purposes
         self._initial_levels: defaultdict[str, int] = defaultdict(int)
         self._previous_levels: defaultdict[str, int] = defaultdict(int)
-        self._last_levels_nonempty: int = 0
-        self._last_objects_indexed: int = 0
+        self._started_at: float = 0.0
+        self._metrics_at: float = 0.0
 
     async def run(
         self,
         spawn_datasources_event: Event,
         start_scheduler_event: Event,
         early_realtime: bool = False,
     ) -> None:
         _logger.info('Starting index dispatcher')
         self._started_at = time.time()
-        metrics.started_at = self._started_at
+        metrics.set('started_at', self._started_at)
 
         await self._subscribe_to_datasource_events()
         await self._load_index_state()
 
         on_synchronized_fired = False
         on_realtime_fired = False
 
         for index in self._indexes.values():
-            if isinstance(index, TzktOperationsIndex):
+            if isinstance(index, TezosOperationsIndex):
                 await self._apply_filters(index)
 
         while True:
             if not spawn_datasources_event.is_set() and not self.is_oneshot():
                 if self._every_index_is(IndexStatus.realtime) or early_realtime:
                     spawn_datasources_event.set()
 
             if spawn_datasources_event.is_set():
                 for datasource in self._ctx.datasources.values():
                     if not isinstance(datasource, IndexDatasource):
                         continue
                     await datasource.subscribe()
 
             tasks: deque[Awaitable[bool]] = deque()
-            for name, index in copy(self._indexes).items():
+            for _, index in copy(self._indexes).items():
+                # NOTE: Do not remove disabled indexes from the mapping or is_oneshot() check will fail
                 if index.state.status == IndexStatus.disabled:
-                    del self._indexes[name]
                     continue
 
                 tasks.append(index.process())
 
             indexes_processed = any(await gather(*tasks))
             indexes_spawned = False
 
             while not self._ctx._pending_indexes.empty():
                 index = self._ctx._pending_indexes.get_nowait()
                 self._indexes[index._config.name] = index
                 indexes_spawned = True
 
-                if isinstance(index, TzktOperationsIndex):
+                if isinstance(index, TezosOperationsIndex):
                     await self._apply_filters(index)
 
             if not indexes_spawned and self.is_oneshot():
                 _logger.info('No indexes left, exiting')
                 await self._on_synchronized()
                 [t.cancel() for t in asyncio.all_tasks() if t is not asyncio.current_task()]
 
@@ -168,35 +167,35 @@
                 if not on_realtime_fired and not indexes_processed:
                     await self._on_realtime()
                     on_realtime_fired = True
 
                 if not start_scheduler_event.is_set():
                     start_scheduler_event.set()
             else:
-                metrics.synchronized_at = 0
-                metrics.realtime_at = 0
+                metrics.set('synchronized_at', 0)
+                metrics.set('realtime_at', 0)
                 # NOTE: Fire `on_synchronized` hook when indexes will reach realtime state again
                 on_synchronized_fired = False
                 on_realtime_fired = False
 
             await asyncio.sleep(INDEX_DISPATCHER_INTERVAL)
 
     def is_oneshot(self) -> bool:
-        from dipdup.config.tezos_tzkt_head import TzktHeadIndexConfig
+        from dipdup.config.tezos_head import TezosHeadIndexConfig
 
         # NOTE: Empty config means indexes will be spawned later via API.
         if not self._indexes:
             return False
 
         if not self._ctx._pending_indexes.empty():
             return False
 
         # NOTE: Run forever if at least one index has no upper bound.
         for index in self._indexes.values():
-            if isinstance(index._config, TzktHeadIndexConfig):
+            if isinstance(index._config, TezosHeadIndexConfig):
                 return False
             if not index._config.last_level:
                 return False
 
         return True
 
     # TODO: Use ctx.metrics
@@ -204,15 +203,14 @@
         while True:
             await asyncio.sleep(update_interval)
             await self._update_prometheus()
 
     async def _update_prometheus(self) -> None:
         active, synced, realtime = 0, 0, 0
         for index in copy(self._indexes).values():
-            # FIXME: We don't remove disabled indexes from dispatcher anymore
             active += 1
             if index.synchronized:
                 synced += 1
             if index.realtime:
                 realtime += 1
 
         Metrics.set_indexes_count(active, synced, realtime)
@@ -247,74 +245,55 @@
 
             levels_interval += index.state.level - self._previous_levels[index.name]
             levels_indexed += index.state.level - initial_level
             levels_total += sync_level - initial_level
 
             self._previous_levels[index.name] = index.state.level
 
-        update_interval = time.time() - metrics.metrics_updated_at
-        metrics.metrics_updated_at = time.time()
+        update_interval = time.time() - self._metrics_at
+        self._metrics_at = time.time()
 
-        last_levels_nonempty, last_objects_indexed = self._last_levels_nonempty, self._last_objects_indexed
-        batch_levels_nonempty = metrics.levels_nonempty - last_levels_nonempty
-        batch_objects = metrics.objects_indexed - last_objects_indexed
-
-        levels_speed = levels_interval / update_interval
-        levels_speed_average = levels_indexed / (time.time() - self._started_at)
-        time_passed = time.time() - self._started_at
+        current_speed = levels_interval / update_interval
+        average_speed = levels_indexed / (time.time() - self._started_at)
+        time_passed = (time.time() - self._started_at) / 60
         time_left, progress = 0.0, 0.0
-        if levels_speed_average:
-            time_left = (levels_total - levels_indexed) / levels_speed_average
+        if average_speed:
+            time_left = (levels_total - levels_indexed) / average_speed / 60
         if levels_total:
             progress = levels_indexed / levels_total
 
-        metrics.levels_indexed = levels_indexed
-        metrics.levels_total = levels_total
-
-        metrics.levels_speed = levels_speed
-        metrics.levels_speed_average = levels_speed_average
-
-        metrics.objects_speed = batch_objects / update_interval
-        metrics.levels_nonempty_speed = batch_levels_nonempty / update_interval
-
-        metrics.time_passed = time_passed
-        metrics.time_left = time_left
-        metrics.progress = progress
-
-        self._last_levels_nonempty = metrics.levels_nonempty
-        self._last_objects_indexed = metrics.objects_indexed
+        metrics.set('levels_indexed', levels_indexed)
+        metrics.set('levels_total', levels_total)
+        metrics.set('current_speed', current_speed)
+        metrics.set('average_speed', average_speed)
+        metrics.set('time_passed', time_passed)
+        metrics.set('time_left', time_left)
+        metrics.set('progress', progress)
 
     async def _status_loop(self, update_interval: float) -> None:
         while True:
             await asyncio.sleep(update_interval)
-            self._log_status()
-
-    def _log_status(self) -> None:
-        total, indexed = metrics.levels_total, metrics.levels_indexed
-        if metrics.realtime_at:
-            _logger.info('realtime: %s levels indexed and counting', indexed)
-            return
-
-        progress, left = metrics.progress * 100, int(total - indexed)
-        if not progress:
-            scanned_levels = int(metrics.levels_indexed) or int(metrics.levels_nonempty)
-            msg = f'indexing: {scanned_levels:6} levels, estimating...'
-            _logger.info(msg)
-            return
+            await self._log_status()
 
-        levels_speed, objects_speed = int(metrics.levels_nonempty_speed), int(metrics.objects_speed)
-        msg = 'last mile' if metrics.synchronized_at else 'indexing'
-        msg += f': {progress:5.1f}% done, {left} levels left'
-
-        # NOTE: Resulting message is about 80 chars with the current logging format
-        msg += ' ' * (48 - len(msg))
-        msg += f' {levels_speed:5} L {objects_speed:5} O'
-        _logger.info(msg)
+    async def _log_status(self) -> None:
+        await self._update_metrics()
+        total, indexed = metrics['levels_total'], metrics['levels_indexed']
+        current_speed = int(metrics['current_speed'])
+        if metrics['realtime_at']:
+            _logger.info('realtime: %s levels and counting', indexed)
+        else:
+            _logger.info(
+                '%s: %.2f%%: %s levels left (%s lps)',
+                'last mile' if metrics['synchronized_at'] else 'indexing',
+                metrics['progress'] * 100,
+                total - indexed,
+                current_speed,
+            )
 
-    async def _apply_filters(self, index: TzktOperationsIndex) -> None:
+    async def _apply_filters(self, index: TezosOperationsIndex) -> None:
         entrypoints, addresses, code_hashes = await index.get_filters()
         self._entrypoint_filter.update(entrypoints)
         self._address_filter.update(addresses)
         self._code_hash_filter.update(code_hashes)
 
     def _every_index_is(self, status: IndexStatus) -> bool:
         if not self._indexes:
@@ -405,42 +384,41 @@
             await _process(index_state)
 
     async def _subscribe_to_datasource_events(self) -> None:
         for datasource in self._ctx.datasources.values():
             if isinstance(datasource, IndexDatasource):
                 datasource.call_on_rollback(self._on_rollback)
 
-            if isinstance(datasource, TzktDatasource):
+            if isinstance(datasource, TezosTzktDatasource):
                 datasource.call_on_head(self._on_tzkt_head)
                 datasource.call_on_operations(self._on_tzkt_operations)
                 datasource.call_on_token_transfers(self._on_tzkt_token_transfers)
                 datasource.call_on_big_maps(self._on_tzkt_big_maps)
                 datasource.call_on_events(self._on_tzkt_events)
             elif isinstance(datasource, EvmNodeDatasource):
                 datasource.call_on_head(self._on_evm_node_head)
-                datasource.call_on_logs(self._on_evm_node_logs)
-                datasource.call_on_traces(self._on_evm_node_traces)
+                datasource.call_on_events(self._on_evm_node_events)
                 datasource.call_on_transactions(self._on_evm_node_transactions)
                 datasource.call_on_syncing(self._on_evm_node_syncing)
 
-    async def _on_tzkt_head(self, datasource: TzktDatasource, head: TzktHeadBlockData) -> None:
+    async def _on_tzkt_head(self, datasource: TezosTzktDatasource, head: TezosHeadBlockData) -> None:
         # NOTE: Do not await query results, it may block Websocket loop. We do not use Head anyway.
         fire_and_forget(
             Head.update_or_create(
                 name=datasource.name,
                 defaults={
                     'level': head.level,
                     'hash': head.hash,
                     'timestamp': head.timestamp,
                 },
             ),
         )
         Metrics.set_datasource_head_updated(datasource.name)
         for index in self._indexes.values():
-            if isinstance(index, TzktHeadIndex) and index.datasource == datasource:
+            if isinstance(index, TezosHeadIndex) and datasource in index.datasources:
                 index.push_realtime_message(head)
 
     async def _on_evm_node_head(self, datasource: EvmNodeDatasource, head: EvmNodeHeadData) -> None:
         # NOTE: Do not await query results, it may block Websocket loop. We do not use Head anyway.
         fire_and_forget(
             Head.update_or_create(
                 name=datasource.name,
@@ -449,80 +427,75 @@
                     'hash': head.hash,
                     'timestamp': head.timestamp,
                 },
             ),
         )
         Metrics.set_datasource_head_updated(datasource.name)
 
-    async def _on_evm_node_logs(
+    async def _on_evm_node_events(
         self,
         datasource: EvmNodeDatasource,
-        logs: tuple[EvmNodeLogData, ...],
+        logs: tuple[EvmEventData, ...],
     ) -> None:
         for index in self._indexes.values():
-            if not isinstance(index, SubsquidEventsIndex):
+            if not isinstance(index, EvmEventsIndex):
                 continue
             if datasource not in index.node_datasources:
                 continue
             index.push_realtime_message(logs)
 
-    async def _on_evm_node_traces(
-        self,
-        datasource: EvmNodeDatasource,
-        traces: tuple[EvmNodeTraceData, ...],
-    ) -> None:
-        raise NotImplementedError
-
     async def _on_evm_node_transactions(
         self,
         datasource: EvmNodeDatasource,
-        transactions: tuple[EvmNodeTransactionData, ...],
+        transactions: tuple[EvmTransactionData, ...],
     ) -> None:
         for index in self._indexes.values():
-            if not isinstance(index, SubsquidTransactionsIndex):
+            if not isinstance(index, EvmTransactionsIndex):
                 continue
             if datasource not in index.node_datasources:
                 continue
             index.push_realtime_message(transactions)
 
     async def _on_evm_node_syncing(self, datasource: EvmNodeDatasource, syncing: EvmNodeSyncingData) -> None:
         raise NotImplementedError
 
-    async def _on_tzkt_operations(self, datasource: TzktDatasource, operations: tuple[TzktOperationData, ...]) -> None:
+    async def _on_tzkt_operations(
+        self, datasource: TezosTzktDatasource, operations: tuple[TezosOperationData, ...]
+    ) -> None:
         operation_subgroups = tuple(
             extract_operation_subgroups(
                 operations,
                 addresses=self._address_filter,
                 entrypoints=self._entrypoint_filter,
                 code_hashes=self._code_hash_filter,
             )
         )
 
         if not operation_subgroups:
             return
 
         for index in self._indexes.values():
-            if isinstance(index, TzktOperationsIndex) and index.datasource == datasource:
+            if isinstance(index, TezosOperationsIndex) and datasource in index.datasources:
                 index.push_realtime_message(operation_subgroups)
 
     async def _on_tzkt_token_transfers(
-        self, datasource: TzktDatasource, token_transfers: tuple[TzktTokenTransferData, ...]
+        self, datasource: TezosTzktDatasource, token_transfers: tuple[TezosTokenTransferData, ...]
     ) -> None:
         for index in self._indexes.values():
-            if isinstance(index, TzktTokenTransfersIndex) and index.datasource == datasource:
+            if isinstance(index, TezosTokenTransfersIndex) and datasource in index.datasources:
                 index.push_realtime_message(token_transfers)
 
-    async def _on_tzkt_big_maps(self, datasource: TzktDatasource, big_maps: tuple[TzktBigMapData, ...]) -> None:
+    async def _on_tzkt_big_maps(self, datasource: TezosTzktDatasource, big_maps: tuple[TezosBigMapData, ...]) -> None:
         for index in self._indexes.values():
-            if isinstance(index, TzktBigMapsIndex) and index.datasource == datasource:
+            if isinstance(index, TezosBigMapsIndex) and datasource in index.datasources:
                 index.push_realtime_message(big_maps)
 
-    async def _on_tzkt_events(self, datasource: TzktDatasource, events: tuple[TzktEventData, ...]) -> None:
+    async def _on_tzkt_events(self, datasource: TezosTzktDatasource, events: tuple[TezosEventData, ...]) -> None:
         for index in self._indexes.values():
-            if isinstance(index, TzktEventsIndex) and index.datasource == datasource:
+            if isinstance(index, TezosEventsIndex) and datasource in index.datasources:
                 index.push_realtime_message(events)
 
     async def _on_rollback(
         self,
         datasource: IndexDatasource[Any],
         type_: MessageType,
         from_level: int,
@@ -557,22 +530,22 @@
                 )
 
         _logger.info('`%s` rollback processed', channel)
 
     async def _on_synchronized(self) -> None:
         await self._ctx.fire_hook('on_synchronized')
 
-        metrics.synchronized_at = time.time()
+        metrics.set('synchronized_at', time.time())
 
     async def _on_realtime(self) -> None:
         # NOTE: We don't have system hook for this event!
         # await self._ctx.fire_hook('on_realtime')
         caches.clear()
 
-        metrics.realtime_at = time.time()
+        metrics.set('realtime_at', time.time())
 
 
 class DipDup:
     """Main indexer class.
 
     Spawns datasources, registers indexes, passes handler callbacks to executor"""
 
@@ -601,28 +574,28 @@
     async def init(
         self,
         force: bool = False,
         base: bool = False,
         include: set[str] | None = None,
     ) -> None:
         """Create new or update existing dipdup project"""
-        from dipdup.codegen.evm_subsquid import SubsquidCodeGenerator
-        from dipdup.codegen.tezos_tzkt import TzktCodeGenerator
+        from dipdup.codegen.evm import EvmCodeGenerator
+        from dipdup.codegen.tezos import TezosCodeGenerator
 
         await self._create_datasources()
 
         async with AsyncExitStack() as stack:
             for datasource in self._datasources.values():
                 await stack.enter_async_context(datasource)
 
             package = DipDupPackage(self._config.package_path)
 
             codegen_classes: tuple[type[CodeGenerator], ...] = (
-                TzktCodeGenerator,
-                SubsquidCodeGenerator,
+                TezosCodeGenerator,
+                EvmCodeGenerator,
             )
             for codegen_cls in codegen_classes:
                 codegen = codegen_cls(
                     config=self._config,
                     package=package,
                     datasources=self._datasources,
                     include=include,
@@ -825,15 +798,15 @@
 
     async def _initialize_datasources(self) -> None:
         init_tzkt = False
         for datasource in self._datasources.values():
             if not isinstance(datasource, IndexDatasource):
                 continue
             await datasource.initialize()
-            if isinstance(datasource, TzktDatasource):
+            if isinstance(datasource, TezosTzktDatasource):
                 init_tzkt = True
 
         if init_tzkt:
             await late_tzkt_initialization(
                 config=self._config,
                 datasources=self._datasources,
                 reindex_fn=self._ctx.reindex,
```

### Comparing `dipdup-7.5.7/src/dipdup/env.py` & `dipdup-8.0.0a1/src/dipdup/env.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 import importlib
 import importlib.util
 import platform
+import sys
 import tomllib
 from contextlib import suppress
 from os import environ as env
 from pathlib import Path
 
 from dipdup.exceptions import FrameworkException
 
@@ -21,14 +22,25 @@
         return str(content['tool']['poetry']['name'])
     raise FrameworkException('`pyproject.toml` found, but has neither `project` nor `tool.poetry` section')
 
 
 def get_package_path(package: str) -> Path:
     """Absolute path to the indexer package, existing or default"""
 
+    if PACKAGE_PATH:
+        spec = importlib.util.spec_from_file_location(package, PACKAGE_PATH / '__init__.py')
+        if spec is None:
+            raise ImportError(f'Failed to import `{package}` package from `{PACKAGE_PATH}`')
+        module = importlib.util.module_from_spec(spec)
+        sys.modules[package] = module
+        if spec.loader is None:
+            raise ImportError(f'Failed to import `{package}` package from `{PACKAGE_PATH}`')
+        spec.loader.exec_module(module)
+        return PACKAGE_PATH
+
     # NOTE: Integration tests run in isolated environment
     if TEST:
         return Path.cwd() / package
 
     # NOTE: If cwd is a package, use it
     if get_pyproject_name() == package:
         return Path.cwd()
@@ -71,39 +83,42 @@
 
 CI: bool
 DEBUG: bool
 DOCKER: bool
 NEXT: bool
 NO_SYMLINK: bool
 NO_VERSION_CHECK: bool
+PACKAGE_PATH: Path | None
 REPLAY_PATH: Path | None
 TEST: bool
 
 
 def dump() -> dict[str, str]:
     return {
         'DIPDUP_CI': get('DIPDUP_CI') or '',
         'DIPDUP_DEBUG': get('DIPDUP_DEBUG') or '',
         'DIPDUP_DOCKER': get('DIPDUP_DOCKER') or '',
         'DIPDUP_NEXT': get('DIPDUP_NEXT') or '',
         'DIPDUP_NO_SYMLINK': get('DIPDUP_NO_SYMLINK') or '',
         'DIPDUP_NO_VERSION_CHECK': get('DIPDUP_NO_VERSION_CHECK') or '',
+        'DIPDUP_PACKAGE_PATH': get('DIPDUP_PACKAGE_PATH') or '',
         'DIPDUP_REPLAY_PATH': get('DIPDUP_REPLAY_PATH') or '',
         'DIPDUP_TEST': get('DIPDUP_TEST') or '',
     }
 
 
 def read() -> None:
-    global CI, DEBUG, DOCKER, NEXT, NO_SYMLINK, NO_VERSION_CHECK, REPLAY_PATH, TEST
+    global CI, DEBUG, DOCKER, NEXT, NO_SYMLINK, NO_VERSION_CHECK, PACKAGE_PATH, REPLAY_PATH, TEST
     CI = get_bool('DIPDUP_CI')
     DEBUG = get_bool('DIPDUP_DEBUG')
     DOCKER = get_bool('DIPDUP_DOCKER')
     NEXT = get_bool('DIPDUP_NEXT')
     NO_SYMLINK = get_bool('DIPDUP_NO_SYMLINK')
     NO_VERSION_CHECK = get_bool('DIPDUP_NO_VERSION_CHECK')
+    PACKAGE_PATH = get_path('DIPDUP_PACKAGE_PATH')
     REPLAY_PATH = get_path('DIPDUP_REPLAY_PATH')
     TEST = get_bool('DIPDUP_TEST')
 
     if get('CI') == 'true':
         CI = True
     if platform.system() == 'Linux' and Path('/.dockerenv').exists():
         DOCKER = True
```

### Comparing `dipdup-7.5.7/src/dipdup/exceptions.py` & `dipdup-8.0.0a1/src/dipdup/exceptions.py`

 * *Files 2% similar despite different names*

```diff
@@ -42,15 +42,15 @@
 
     Instances of this class should have a nice help message explaining the error and how to fix it.
     """
 
     def __str__(self) -> str:
         if not self.__doc__:
             raise NotImplementedError(f'{self.__class__.__name__} has no docstring')
-        return self.__doc__ + ' -> ' + ' '.join(self.args)
+        return self.__doc__ + ' -> ' + ' '.join(self.args).split('\n')[0]
 
     def help(self) -> str:
         """Return a string containing a help message for this error."""
         return format_help(self._help())
 
     @classmethod
     def default_help(cls) -> str:
@@ -330,7 +330,12 @@
 
     def _help(self) -> str:
         return f"""
             `{self.host}` API version is not supported by `{self.datasource}` datasource.
 
             {self.reason}
         """
+
+
+# TODO: Human-readable Error
+class MigrationError(FrameworkException):
+    pass
```

### Comparing `dipdup-7.5.7/src/dipdup/fetcher.py` & `dipdup-8.0.0a1/src/dipdup/fetcher.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 from __future__ import annotations
 
 import asyncio
+import random
 from abc import ABC
 from abc import abstractmethod
 from collections import defaultdict
 from collections import deque
 from contextlib import suppress
 from typing import TYPE_CHECKING
 from typing import Any
@@ -14,34 +15,35 @@
 
 from dipdup.performance import queues
 
 if TYPE_CHECKING:
     from collections.abc import AsyncGenerator
     from collections.abc import AsyncIterator
 
-    from dipdup.datasources import IndexDatasource
+from dipdup.datasources import IndexDatasource
 
 
 class HasLevel(Protocol):
     level: int
 
     @property
     def block_number(self) -> int:
         return self.level
 
 
 Level = int
-FetcherBufferT = TypeVar('FetcherBufferT', bound=HasLevel)
-FetcherFilterT = TypeVar('FetcherFilterT')
+BufferT = TypeVar('BufferT', bound=HasLevel)
+FilterT = TypeVar('FilterT')
+DatasourceT = TypeVar('DatasourceT', bound=IndexDatasource[Any])
 
 
 async def yield_by_level(
-    iterable: AsyncIterator[tuple[FetcherBufferT, ...]]
-) -> AsyncGenerator[tuple[Level, tuple[FetcherBufferT, ...]], None]:
-    items: tuple[FetcherBufferT, ...] = ()
+    iterable: AsyncIterator[tuple[BufferT, ...]]
+) -> AsyncGenerator[tuple[Level, tuple[BufferT, ...]], None]:
+    items: tuple[BufferT, ...] = ()
 
     async for item_batch in iterable:
         items = items + item_batch
 
         # NOTE: Yield slices by level except the last one
         while True:
             for i in range(len(items) - 1):
@@ -56,19 +58,19 @@
                 break
 
     if items:
         yield items[0].level, items
 
 
 async def readahead_by_level(
-    fetcher_iter: AsyncIterator[tuple[FetcherBufferT, ...]],
+    fetcher_iter: AsyncIterator[tuple[BufferT, ...]],
     limit: int,
-) -> AsyncIterator[tuple[int, tuple[FetcherBufferT, ...]]]:
+) -> AsyncIterator[tuple[int, tuple[BufferT, ...]]]:
     queue_name = f'fetcher_readahead:{id(fetcher_iter)}'
-    queue: deque[tuple[int, tuple[FetcherBufferT, ...]]] = deque()
+    queue: deque[tuple[int, tuple[BufferT, ...]]] = deque()
     queues.add_queue(
         queue,
         name=queue_name,
         limit=limit,
     )
     has_more = asyncio.Event()
     need_more = asyncio.Event()
@@ -98,62 +100,70 @@
             break
         with suppress(asyncio.TimeoutError):
             await asyncio.wait_for(has_more.wait(), timeout=10)
 
     queues.remove_queue(queue_name)
 
 
-class FetcherChannel(ABC, Generic[FetcherBufferT, FetcherFilterT]):
+class FetcherChannel(ABC, Generic[BufferT, DatasourceT, FilterT]):
     def __init__(
         self,
-        buffer: defaultdict[Level, deque[FetcherBufferT]],
-        filter: set[FetcherFilterT],
+        buffer: defaultdict[Level, deque[BufferT]],
+        filter: set[FilterT],
         first_level: int,
         last_level: int,
-        datasource: IndexDatasource[Any],
+        datasources: tuple[DatasourceT, ...],
     ) -> None:
         super().__init__()
         self._buffer = buffer
         self._filter = filter
         self._first_level = first_level
         self._last_level = last_level
-        self._datasource = datasource
+        self._datasources = datasources
 
         self._head: int = 0
         self._offset: int = 0
 
     @property
     def head(self) -> int:
         return self._head
 
     @property
     def fetched(self) -> bool:
         return self._head >= self._last_level
 
+    @property
+    def random_datasource(self) -> DatasourceT:
+        return random.choice(self._datasources)
+
     @abstractmethod
     async def fetch(self) -> None:
         """Fetch a single `requets_limit` batch of items, bump channel offset"""
         ...
 
 
-class DataFetcher(ABC, Generic[FetcherBufferT]):
+class DataFetcher(ABC, Generic[BufferT, DatasourceT]):
     """Fetches contract data from REST API, merges them and yields by level."""
 
     def __init__(
         self,
-        datasource: IndexDatasource[Any],
+        datasources: tuple[DatasourceT, ...],
         first_level: int,
         last_level: int,
     ) -> None:
-        self._datasource = datasource
+        self._datasources = datasources
         self._first_level = first_level
         self._last_level = last_level
-        self._buffer: defaultdict[Level, deque[FetcherBufferT]] = defaultdict(deque)
+        self._buffer: defaultdict[Level, deque[BufferT]] = defaultdict(deque)
         self._head = 0
 
+    @property
+    def random_datasource(self) -> DatasourceT:
+        return random.choice(self._datasources)
+
     @abstractmethod
-    def fetch_by_level(self) -> AsyncIterator[tuple[int, tuple[FetcherBufferT, ...]]]:
+    def fetch_by_level(self) -> AsyncIterator[tuple[int, tuple[BufferT, ...]]]:
         """Iterate over events data from REST.
 
-        Resulting data is splitted by level, deduped, sorted and ready to be processed by TzktEventsIndex.
+        Resulting data is splitted by level, deduped, sorted and ready to be processed by TezosEventsIndex.
         """
         ...
```

### Comparing `dipdup-7.5.7/src/dipdup/fields.py` & `dipdup-8.0.0a1/src/dipdup/fields.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/hasura.py` & `dipdup-8.0.0a1/src/dipdup/hasura.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/http.py` & `dipdup-8.0.0a1/src/dipdup/http.py`

 * *Files 2% similar despite different names*

```diff
@@ -210,15 +210,15 @@
         method: str,
         url: str,
         weight: int = 1,
         raw: bool = False,
         **kwargs: Any,
     ) -> Any:
         """Wrapped aiohttp call with preconfigured headers and ratelimiting"""
-        metrics.requests_total[self._alias] += 1
+        metrics.inc(f'{self._alias}:requests_total', 1.0)
         if not url:
             url = self._path or '/'
         elif url.startswith('http'):
             url = url.replace(self._url, '').rstrip('/')
         else:
             url = f"{self._path.rstrip('/')}/{url}"
 
@@ -239,15 +239,15 @@
             method=method,
             url=url,
             headers=headers,
             raise_for_status=True,
             **kwargs,
         ) as response:
             await response.read()
-            metrics.time_in_requests[self._alias] += time.time() - started_at
+            metrics.inc(f'{self._alias}:time_in_requests', (time.time() - started_at) / 60)
             if raw:
                 return response
 
             # NOTE: Use raw=True if fail on 204 is not a desired behavior
             if response.status == HTTPStatus.NO_CONTENT:
                 raise InvalidRequestError('204 No Content', request_string)
             with suppress(JSONDecodeError):
```

### Comparing `dipdup-7.5.7/src/dipdup/index.py` & `dipdup-8.0.0a1/src/dipdup/index.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,29 +1,32 @@
 import time
 from abc import ABC
 from abc import abstractmethod
 from collections import deque
+from typing import TYPE_CHECKING
 from typing import Any
 from typing import Generic
 from typing import TypeVar
 from typing import cast
 
 import dipdup.models as models
 from dipdup.config import ResolvedIndexConfigU
-from dipdup.context import DipDupContext
 from dipdup.datasources import IndexDatasource
 from dipdup.exceptions import FrameworkException
 from dipdup.models import IndexStatus
 from dipdup.models import MessageType
 from dipdup.models import RollbackMessage
 from dipdup.performance import metrics
 from dipdup.performance import queues
 from dipdup.prometheus import Metrics
 from dipdup.utils import FormattedLogger
 
+if TYPE_CHECKING:
+    from dipdup.context import DipDupContext
+
 IndexConfigT = TypeVar('IndexConfigT', bound=ResolvedIndexConfigU)
 IndexQueueItemT = TypeVar('IndexQueueItemT', bound=Any)
 IndexDatasourceT = TypeVar('IndexDatasourceT', bound=IndexDatasource[Any])
 
 
 class Index(ABC, Generic[IndexConfigT, IndexQueueItemT, IndexDatasourceT]):
     """Base class for index implementations
@@ -35,31 +38,27 @@
 
     def __init_subclass__(cls, message_type: MessageType) -> None:
         cls.message_type = message_type
         return super().__init_subclass__()
 
     def __init__(
         self,
-        ctx: DipDupContext,
+        ctx: 'DipDupContext',
         config: IndexConfigT,
-        datasource: IndexDatasourceT,
+        datasources: tuple[IndexDatasourceT, ...],
     ) -> None:
         self._ctx = ctx
         self._config = config
-        self._datasource = datasource
+        self._datasources = datasources
         self._queue: deque[IndexQueueItemT] = deque()
         queues.add_queue(self._queue, f'index_realtime:{config.name}:{id(self)})')
 
         self._logger = FormattedLogger(__name__, fmt=f'{config.name}: ' + '{}')
         self._state: models.Index | None = None
 
-    @property
-    def datasources(self) -> tuple[IndexDatasource[Any], ...]:
-        return (self.datasource,)
-
     def push_realtime_message(self, message: IndexQueueItemT) -> None:
         """Push message to the queue"""
         self._queue.append(message)
 
         Metrics.set_levels_to_realtime(self._config.name, len(self._queue))
 
     @abstractmethod
@@ -113,44 +112,44 @@
         index_level = self.state.level
         if batch_level <= index_level:
             raise FrameworkException(f'Batch level is lower than index level: {batch_level} <= {index_level}')
 
         self._logger.debug('Processing data of level %s', batch_level)
         started_at = time.time()
 
-        # FIXME: TzktHeadIndexConfig, TzktOperationsUnfilteredIndexConfig still use own methods; see FIXMEs
-        matched_handlers = self._match_level_data(self._config.handlers, level_data)  # type: ignore[union-attr]
+        matched_handlers = self._match_level_data(self._config.handlers, level_data)
 
         total_matched = len(matched_handlers)
         Metrics.set_index_handlers_matched(total_matched)
-        metrics.handlers_matched[self.name] += total_matched
-        metrics.time_in_matcher[self.name] += time.time() - started_at
+        metrics[f'{self.name}:handlers_matched'] += total_matched
+        metrics[f'{self.name}:time_in_matcher'] += (time.time() - started_at) / 60
 
         # NOTE: We still need to bump index level but don't care if it will be done in existing transaction
         if not matched_handlers:
             await self._update_state(level=batch_level)
             return
 
         started_at = time.time()
         async with self._ctx.transactions.in_transaction(batch_level, sync_level, self.name):
             for handler_config, data in matched_handlers:
                 await self._call_matched_handler(handler_config, data)
             await self._update_state(level=batch_level)
-
-        metrics.objects_indexed += len(level_data)
-        metrics.levels_nonempty += 1
-        metrics.time_in_callbacks[self.name] += time.time() - started_at
+        metrics[f'{self.name}:time_in_callbacks'] += (time.time() - started_at) / 60
 
     @property
     def name(self) -> str:
         return self._config.name
 
     @property
-    def datasource(self) -> IndexDatasourceT:
-        return self._datasource
+    def datasources(self) -> tuple[IndexDatasourceT, ...]:
+        return self._datasources
+
+    @property
+    def random_datasource(self) -> IndexDatasourceT:
+        return self._datasources[0]
 
     @property
     def state(self) -> models.Index:
         if self._state is None:
             raise FrameworkException('Index state is not initialized')
         return self._state
 
@@ -161,15 +160,15 @@
     @property
     def realtime(self) -> bool:
         return self.state.status == IndexStatus.realtime and not self._queue
 
     def get_sync_level(self) -> int:
         """Get level index needs to be synchronized to depending on its subscription status"""
         subs = self._config.get_subscriptions()
-        sync_levels = {self.datasource.get_sync_level(s) for s in subs}
+        sync_levels = {d.get_sync_level(s) for s in subs for d in self.datasources}
         if not sync_levels:
             raise FrameworkException('Initialize config before starting `IndexDispatcher`')
         if None in sync_levels:
             raise FrameworkException('Call `set_sync_level` before starting `IndexDispatcher`')
         # NOTE: Multiple sync levels means index with new subscriptions was added in runtime.
         # NOTE: Choose the highest level; outdated realtime messages will be dropped from the queue anyway.
         return max(cast(set[int], sync_levels))
@@ -190,15 +189,15 @@
         self._state, _ = await models.Index.get_or_create(
             name=self._config.name,
             type=self._config.kind,
             defaults={
                 'level': index_level,
                 'config_hash': self._config.hash(),
                 'template': self._config.parent.name if self._config.parent else None,
-                'template_values': self._config.template_values,
+                'template_values': self._config._template_values,
             },
         )
 
     async def process(self) -> bool:
         if self.state.status == IndexStatus.disabled:
             raise FrameworkException('Index is in oneshot state and cannot be processed')
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/evm_node.py` & `dipdup-8.0.0a1/src/dipdup/indexes/evm_node.py`

 * *Files 10% similar despite different names*

```diff
@@ -4,33 +4,25 @@
 from collections import defaultdict
 from collections import deque
 from typing import Any
 from typing import Generic
 
 from dipdup.datasources.evm_node import EvmNodeDatasource
 from dipdup.exceptions import FrameworkException
+from dipdup.fetcher import BufferT
 from dipdup.fetcher import DataFetcher
-from dipdup.fetcher import FetcherBufferT
 
 EVM_NODE_READAHEAD_LIMIT = 5000
 MIN_BATCH_SIZE = 10
 MAX_BATCH_SIZE = 10000
 BATCH_SIZE_UP = 1.1
 BATCH_SIZE_DOWN = 0.5
 
 
-class EvmNodeFetcher(Generic[FetcherBufferT], DataFetcher[FetcherBufferT], ABC):
-    def __init__(
-        self,
-        datasources: tuple[EvmNodeDatasource, ...],
-        first_level: int,
-        last_level: int,
-    ) -> None:
-        super().__init__(datasources[0], first_level, last_level)
-        self._datasources = datasources
+class EvmNodeFetcher(Generic[BufferT], DataFetcher[BufferT, EvmNodeDatasource], ABC):
 
     def get_next_batch_size(self, batch_size: int, ratelimited: bool) -> int:
         if ratelimited:
             batch_size = int(batch_size * BATCH_SIZE_DOWN)
         else:
             batch_size = int(batch_size * BATCH_SIZE_UP)
 
@@ -66,24 +58,24 @@
                     name=f'get_block_range:{level}',
                 ),
             )
 
         await asyncio.gather(*tasks)
         return blocks
 
-    async def get_logs_batch(
+    async def get_events_batch(
         self,
         first_level: int,
         last_level: int,
         node: EvmNodeDatasource | None = None,
     ) -> dict[int, list[dict[str, Any]]]:
-        grouped_logs: defaultdict[int, list[dict[str, Any]]] = defaultdict(list)
+        grouped_events: defaultdict[int, list[dict[str, Any]]] = defaultdict(list)
         node = node or self.get_random_node()
-        logs = await node.get_logs(
+        logs = await node.get_events(
             {
                 'fromBlock': hex(first_level),
                 'toBlock': hex(last_level),
             },
         )
         for log in logs:
-            grouped_logs[int(log['blockNumber'], 16)].append(log)
-        return grouped_logs
+            grouped_events[int(log['blockNumber'], 16)].append(log)
+        return grouped_events
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/evm_subsquid.py` & `dipdup-8.0.0a1/src/dipdup/indexes/evm.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,38 +1,38 @@
 import random
 from abc import ABC
 from abc import abstractmethod
-from typing import Any
+from typing import TYPE_CHECKING
 from typing import Generic
 from typing import TypeVar
 from typing import cast
 
 from web3 import Web3
 
-from dipdup.config import SubsquidIndexConfigU
+from dipdup.config import EvmIndexConfigU
 from dipdup.config.evm import EvmContractConfig
-from dipdup.config.evm_node import EvmNodeDatasourceConfig
-from dipdup.config.evm_subsquid import SubsquidDatasourceConfig
-from dipdup.context import DipDupContext
 from dipdup.datasources import IndexDatasource
 from dipdup.datasources.evm_node import NODE_LAST_MILE
 from dipdup.datasources.evm_node import EvmNodeDatasource
-from dipdup.datasources.evm_subsquid import SubsquidDatasource
+from dipdup.datasources.evm_subsquid import EvmSubsquidDatasource
 from dipdup.exceptions import ConfigurationError
 from dipdup.exceptions import FrameworkException
 from dipdup.index import Index
 from dipdup.index import IndexQueueItemT
-from dipdup.models.evm_subsquid import SubsquidMessageType
+from dipdup.models.subsquid import SubsquidMessageType
 from dipdup.package import DipDupPackage
 from dipdup.prometheus import Metrics
 
-SUBSQUID_READAHEAD_LIMIT = 10000
+if TYPE_CHECKING:
+    from dipdup.context import DipDupContext
 
-IndexConfigT = TypeVar('IndexConfigT', bound=SubsquidIndexConfigU)
-DatasourceT = TypeVar('DatasourceT', bound=SubsquidDatasource | EvmNodeDatasource)
+EVM_SUBSQUID_READAHEAD_LIMIT = 10000
+
+IndexConfigT = TypeVar('IndexConfigT', bound=EvmIndexConfigU)
+DatasourceT = TypeVar('DatasourceT', bound=EvmSubsquidDatasource | EvmNodeDatasource)
 
 
 _sighashes: dict[str, str] = {}
 
 
 def get_sighash(package: DipDupPackage, method: str, to: EvmContractConfig | None = None) -> str:
     """Method in config is either a full signature or a method name. We need to convert it to a sighash first."""
@@ -45,62 +45,44 @@
     elif to:
         _sighashes[key] = package.get_converted_abi(to.module_name)['methods'][method]['sighash']
     else:
         raise ConfigurationError('`to` field is missing; `method` is expected to be a full signature')
     return _sighashes[key]
 
 
-class SubsquidIndex(
+class EvmIndex(
     Generic[IndexConfigT, IndexQueueItemT, DatasourceT],
     Index[IndexConfigT, IndexQueueItemT, DatasourceT],
     ABC,
     message_type=SubsquidMessageType,  # type: ignore[arg-type]
 ):
     def __init__(
         self,
-        ctx: DipDupContext,
+        ctx: 'DipDupContext',
         config: IndexConfigT,
-        datasource: DatasourceT,
+        datasources: tuple[DatasourceT, ...],
     ) -> None:
-        super().__init__(ctx, config, datasource)
-
-        if isinstance(datasource, SubsquidDatasource) and isinstance(config.datasource, SubsquidDatasourceConfig):
-            node_field = config.datasource.node
-            if node_field is None:
-                node_field = ()
-            elif isinstance(node_field, EvmNodeDatasourceConfig):
-                node_field = (node_field,)
-            self._node_datasources = tuple(
-                self._ctx.get_evm_node_datasource(node_config.name) for node_config in node_field
-            )
-        elif isinstance(datasource, EvmNodeDatasource) and isinstance(config.datasource, EvmNodeDatasourceConfig):
-            self._node_datasources = (datasource,)
-        else:
-            raise FrameworkException('Invalid datasource type')
+        super().__init__(ctx, config, datasources)
+        self.subsquid_datasources = tuple(d for d in datasources if isinstance(d, EvmSubsquidDatasource))
+        self.node_datasources = tuple(d for d in datasources if isinstance(d, EvmNodeDatasource))
+        self._subsquid_started: bool = False
 
     @abstractmethod
     async def _synchronize_subsquid(self, sync_level: int) -> None: ...
 
     @abstractmethod
     async def _synchronize_node(self, sync_level: int) -> None: ...
 
-    @property
-    def node_datasources(self) -> tuple[EvmNodeDatasource, ...]:
-        return self._node_datasources
-
-    @property
-    def datasources(self) -> tuple[IndexDatasource[Any], ...]:
-        return (self.datasource, *self.node_datasources)
-
     def get_sync_level(self) -> int:
         """Get level index needs to be synchronized to depending on its subscription status"""
         sync_levels = set()
         for sub in self._config.get_subscriptions():
-            sync_levels.add(self.datasource.get_sync_level(sub))
-            for datasource in self.node_datasources or ():
+            for datasource in self._datasources:
+                if not isinstance(datasource, IndexDatasource):
+                    continue
                 sync_levels.add(datasource.get_sync_level(sub))
 
         if None in sync_levels:
             sync_levels.remove(None)
         if not sync_levels:
             raise FrameworkException('Initialize config before starting `IndexDispatcher`')
 
@@ -120,31 +102,28 @@
 
         node_sync_level = await node.get_head_level()
         subsquid_lag = abs(node_sync_level - subsquid_level)
         subsquid_available = subsquid_level - index_level
         self._logger.info('Subsquid is %s levels behind; %s available', subsquid_lag, subsquid_available)
         if subsquid_available < NODE_LAST_MILE:
             return node_sync_level
-        if self._config.node_only:
-            self._logger.debug('`node_only` flag is set; using node anyway')
-            return node_sync_level
         return None
 
     async def _synchronize(self, sync_level: int) -> None:
         """Fetch event logs via Fetcher and pass to message callback"""
         index_level = await self._enter_sync_state(sync_level)
         if index_level is None:
             return
 
         levels_left = sync_level - index_level
         if levels_left <= 0:
             return
 
-        if isinstance(self.datasource, SubsquidDatasource):
-            subsquid_sync_level = await self.datasource.get_head_level()
+        if self.subsquid_datasources:
+            subsquid_sync_level = await self.subsquid_datasources[0].get_head_level()
             Metrics.set_sqd_processor_chain_height(subsquid_sync_level)
         else:
             subsquid_sync_level = 0
 
         node_sync_level = await self._get_node_sync_level(subsquid_sync_level, index_level)
 
         # NOTE: Fetch last blocks from node if there are not enough realtime messages in queue
@@ -152,8 +131,14 @@
             sync_level = min(sync_level, node_sync_level)
             self._logger.debug('Using node datasource; sync level: %s', sync_level)
             await self._synchronize_node(sync_level)
         else:
             sync_level = min(sync_level, subsquid_sync_level)
             await self._synchronize_subsquid(sync_level)
 
+        if not self.node_datasources and not self._subsquid_started:
+            self._subsquid_started = True
+            self._logger.info('No `evm.node` datasources available; polling Subsquid')
+            for datasource in self.subsquid_datasources:
+                await datasource.start()
+
         await self._exit_sync_state(sync_level)
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/evm_subsquid_events/fetcher.py` & `dipdup-8.0.0a1/src/dipdup/indexes/evm_events/fetcher.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,100 +1,100 @@
-import random
 import time
 from collections.abc import AsyncIterator
 
 from dipdup.datasources.evm_node import EvmNodeDatasource
-from dipdup.datasources.evm_subsquid import SubsquidDatasource
-from dipdup.fetcher import DataFetcher
+from dipdup.datasources.evm_subsquid import EvmSubsquidDatasource
 from dipdup.fetcher import readahead_by_level
+from dipdup.indexes.evm import EVM_SUBSQUID_READAHEAD_LIMIT
 from dipdup.indexes.evm_node import EVM_NODE_READAHEAD_LIMIT
 from dipdup.indexes.evm_node import MIN_BATCH_SIZE
 from dipdup.indexes.evm_node import EvmNodeFetcher
-from dipdup.indexes.evm_subsquid import SUBSQUID_READAHEAD_LIMIT
-from dipdup.models.evm_node import EvmNodeLogData
-from dipdup.models.evm_subsquid import SubsquidEventData
+from dipdup.indexes.evm_subsquid import EvmSubsquidFetcher
+from dipdup.models.evm import EvmEventData
 
 
-class SubsquidEventFetcher(DataFetcher[SubsquidEventData]):
-    _datasource: SubsquidDatasource
-
+class EvmSubsquidEventFetcher(EvmSubsquidFetcher[EvmEventData]):
     def __init__(
         self,
-        datasource: SubsquidDatasource,
+        datasources: tuple[EvmSubsquidDatasource, ...],
         first_level: int,
         last_level: int,
         topics: tuple[tuple[str | None, str], ...],
     ) -> None:
-        super().__init__(datasource, first_level, last_level)
+        super().__init__(datasources, first_level, last_level)
         self._topics = topics
 
-    async def fetch_by_level(self) -> AsyncIterator[tuple[int, tuple[SubsquidEventData, ...]]]:
-        event_iter = self._datasource.iter_event_logs(
+    async def fetch_by_level(self) -> AsyncIterator[tuple[int, tuple[EvmEventData, ...]]]:
+        event_iter = self.random_datasource.iter_event_events(
             self._topics,
             self._first_level,
             self._last_level,
         )
-        async for level, batch in readahead_by_level(event_iter, limit=SUBSQUID_READAHEAD_LIMIT):
+        async for level, batch in readahead_by_level(event_iter, limit=EVM_SUBSQUID_READAHEAD_LIMIT):
             yield level, batch
 
 
-class EvmNodeEventFetcher(EvmNodeFetcher[EvmNodeLogData]):
+class EvmNodeEventFetcher(EvmNodeFetcher[EvmEventData]):
     _datasource: EvmNodeDatasource
 
-    async def fetch_by_level(self) -> AsyncIterator[tuple[int, tuple[EvmNodeLogData, ...]]]:
+    async def fetch_by_level(self) -> AsyncIterator[tuple[int, tuple[EvmEventData, ...]]]:
         event_iter = self._fetch_by_level()
         async for level, batch in readahead_by_level(event_iter, limit=EVM_NODE_READAHEAD_LIMIT):
             yield level, batch
 
-    async def _fetch_by_level(self) -> AsyncIterator[tuple[EvmNodeLogData, ...]]:
+    async def _fetch_by_level(self) -> AsyncIterator[tuple[EvmEventData, ...]]:
         batch_size = MIN_BATCH_SIZE
         batch_first_level = self._first_level
         ratelimited: bool = False
 
         while batch_first_level <= self._last_level:
-            node = random.choice(self._datasources)
+            node = self.random_datasource
             batch_size = self.get_next_batch_size(batch_size, ratelimited)
             ratelimited = False
 
             started = time.time()
 
             batch_last_level = min(
                 batch_first_level + batch_size,
                 self._last_level,
             )
-            log_batch = await self.get_logs_batch(
+            event_batch = await self.get_events_batch(
                 batch_first_level,
                 batch_last_level,
                 node,
             )
 
             finished = time.time()
             if finished - started >= node._http_config.ratelimit_sleep:
                 ratelimited = True
 
             timestamps: dict[int, int] = {}
-            log_levels = list(log_batch.keys())
+            event_levels = list(event_batch.keys())
 
-            # NOTE: Split log_levels to chunks of batch_size
-            log_level_batches = [set(log_levels[i : i + batch_size]) for i in range(0, len(log_levels), batch_size)]
+            # NOTE: Split event_levels to chunks of batch_size
+            event_level_batches = [
+                set(event_levels[i : i + batch_size]) for i in range(0, len(event_levels), batch_size)
+            ]
 
-            for log_level_batch in log_level_batches:
+            for event_level_batch in event_level_batches:
 
                 started = time.time()
 
-                block_batch = await self.get_blocks_batch(log_level_batch)
+                block_batch = await self.get_blocks_batch(event_level_batch)
                 for level, block in block_batch.items():
                     timestamps[level] = int(block['timestamp'], 16)
 
                 finished = time.time()
                 if finished - started >= node._http_config.ratelimit_sleep:
                     ratelimited = True
 
-            for level, level_logs in log_batch.items():
-                if not level_logs:
+            for level, level_events in event_batch.items():
+                if not level_events:
                     continue
 
-                parsed_level_logs = tuple(EvmNodeLogData.from_json(log, timestamps[level]) for log in level_logs)
+                parsed_level_events = tuple(
+                    EvmEventData.from_node_json(event, timestamps[level]) for event in level_events
+                )
 
-                yield parsed_level_logs
+                yield parsed_level_events
 
             batch_first_level = batch_last_level + 1
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/evm_subsquid_events/index.py` & `dipdup-8.0.0a1/src/dipdup/indexes/evm_events/index.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,70 +1,76 @@
 from collections import deque
 from collections.abc import Iterable
 from typing import TYPE_CHECKING
 from typing import Any
 
-from dipdup.config.evm_subsquid_events import SubsquidEventsHandlerConfig
-from dipdup.config.evm_subsquid_events import SubsquidEventsIndexConfig
+from dipdup.config.evm_events import EvmEventsHandlerConfig
+from dipdup.config.evm_events import EvmEventsIndexConfig
 from dipdup.datasources.evm_node import EvmNodeDatasource
-from dipdup.datasources.evm_subsquid import SubsquidDatasource
+from dipdup.datasources.evm_subsquid import EvmSubsquidDatasource
 from dipdup.exceptions import ConfigInitializationException
 from dipdup.exceptions import FrameworkException
-from dipdup.indexes.evm_subsquid import SubsquidIndex
-from dipdup.indexes.evm_subsquid_events.fetcher import EvmNodeEventFetcher
-from dipdup.indexes.evm_subsquid_events.fetcher import SubsquidEventFetcher
-from dipdup.indexes.evm_subsquid_events.matcher import match_events
+from dipdup.indexes.evm import EvmIndex
+from dipdup.indexes.evm_events.fetcher import EvmNodeEventFetcher
+from dipdup.indexes.evm_events.fetcher import EvmSubsquidEventFetcher
+from dipdup.indexes.evm_events.matcher import match_events
 from dipdup.models import RollbackMessage
-from dipdup.models.evm_node import EvmNodeLogData
-from dipdup.models.evm_subsquid import SubsquidEvent
-from dipdup.models.evm_subsquid import SubsquidEventData
-from dipdup.models.evm_subsquid import SubsquidMessageType
+from dipdup.models.evm import EvmEvent
+from dipdup.models.evm import EvmEventData
+from dipdup.models.subsquid import SubsquidMessageType
 from dipdup.prometheus import Metrics
 
-QueueItem = tuple[EvmNodeLogData, ...] | RollbackMessage
-Datasource = SubsquidDatasource | EvmNodeDatasource
+QueueItem = tuple[EvmEventData, ...] | RollbackMessage
+EvmDatasource = EvmSubsquidDatasource | EvmNodeDatasource
 
 if TYPE_CHECKING:
     from dipdup.context import DipDupContext
 
 
-class SubsquidEventsIndex(
-    SubsquidIndex[SubsquidEventsIndexConfig, QueueItem, Datasource],
+class EvmEventsIndex(
+    EvmIndex[EvmEventsIndexConfig, QueueItem, EvmDatasource],
     message_type=SubsquidMessageType.logs,
 ):
-
     def __init__(
         self,
         ctx: 'DipDupContext',
-        config: SubsquidEventsIndexConfig,
-        datasource: Datasource,
+        config: EvmEventsIndexConfig,
+        datasources: tuple[EvmDatasource, ...],
     ) -> None:
-        super().__init__(ctx, config, datasource)
-        self._event_abis = {
-            handler.contract.module_name: self._ctx.package.get_converted_abi(handler.contract.module_name)['events']
-            for handler in self._config.handlers
-        }
+        super().__init__(ctx, config, datasources)
+        self._topics: dict[str, dict[str, str]] | None = None
+
+    @property
+    def topics(self) -> dict[str, dict[str, str]]:
+        if self._topics is None:
+            self._topics = {}
+            for handler_config in self._config.handlers:
+                typename = handler_config.contract.module_name
+                event_abi = self._ctx.package.get_converted_abi(typename)['events']
+                self._topics[typename] = {k: v['topic0'] for k, v in event_abi.items()}
+
+        return self._topics
 
     async def _synchronize_subsquid(self, sync_level: int) -> None:
         first_level = self.state.level + 1
         fetcher = self._create_subsquid_fetcher(first_level, sync_level)
 
-        async for _level, events in fetcher.fetch_by_level():
-            await self._process_level_data(events, sync_level)
+        async for _level, logs in fetcher.fetch_by_level():
+            await self._process_level_data(logs, sync_level)
             Metrics.set_sqd_processor_last_block(_level)
 
     async def _synchronize_node(self, sync_level: int) -> None:
         first_level = self.state.level + 1
         fetcher = self._create_node_fetcher(first_level, sync_level)
 
-        async for _level, events in fetcher.fetch_by_level():
-            await self._process_level_data(events, sync_level)
+        async for _level, logs in fetcher.fetch_by_level():
+            await self._process_level_data(logs, sync_level)
             Metrics.set_sqd_processor_last_block(_level)
 
-    def _create_subsquid_fetcher(self, first_level: int, last_level: int) -> SubsquidEventFetcher:
+    def _create_subsquid_fetcher(self, first_level: int, last_level: int) -> EvmSubsquidEventFetcher:
         addresses = set()
         topics: deque[tuple[str | None, str]] = deque()
 
         for handler_config in self._config.handlers:
             address = handler_config.contract.address
             if address is not None:
                 addresses.add(address)
@@ -72,49 +78,49 @@
                 raise NotImplementedError('Either contract address or ABI must be specified')
 
             event_abi = self._ctx.package.get_converted_abi(handler_config.contract.module_name)['events'][
                 handler_config.name
             ]
             topics.append((address, event_abi['topic0']))
 
-        if not isinstance(self._datasource, SubsquidDatasource):
-            raise FrameworkException('Creating subsquid fetcher with non-subsquid datasource')
+        if not self.subsquid_datasources:
+            raise FrameworkException('Creating EvmSubsquidEventFetcher, but no `evm.subsquid` datasources available')
 
-        return SubsquidEventFetcher(
-            datasource=self._datasource,
+        return EvmSubsquidEventFetcher(
+            datasources=self.subsquid_datasources,
             first_level=first_level,
             last_level=last_level,
             topics=tuple(topics),
         )
 
     def _create_node_fetcher(self, first_level: int, last_level: int) -> EvmNodeEventFetcher:
+        if not self.node_datasources:
+            raise FrameworkException('Creating EvmNodeEventFetcher, but no `evm.node` datasources available')
+
         return EvmNodeEventFetcher(
             datasources=self.node_datasources,
             first_level=first_level,
             last_level=last_level,
         )
 
     def _match_level_data(
         self,
-        handlers: tuple[SubsquidEventsHandlerConfig, ...],
-        level_data: Iterable[SubsquidEventData | EvmNodeLogData],
+        handlers: tuple[EvmEventsHandlerConfig, ...],
+        level_data: Iterable[EvmEventData],
     ) -> deque[Any]:
-        return match_events(self._ctx.package, handlers, level_data, self._event_abis)
+        return match_events(self._ctx.package, handlers, level_data, self.topics)
 
     async def _call_matched_handler(
         self,
-        handler_config: SubsquidEventsHandlerConfig,
-        event: SubsquidEvent[Any],
+        handler_config: EvmEventsHandlerConfig,
+        event: EvmEvent[Any],
     ) -> None:
-        if isinstance(handler_config, SubsquidEventsHandlerConfig) != isinstance(event, SubsquidEvent):
-            raise FrameworkException(f'Invalid handler config and event types: {handler_config}, {event}')
 
         if not handler_config.parent:
             raise ConfigInitializationException
 
         await self._ctx.fire_handler(
             handler_config.callback,
             handler_config.parent.name,
-            self.datasource,
             None,
             event,
         )
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/evm_subsquid_events/matcher.py` & `dipdup-8.0.0a1/src/dipdup/indexes/evm_events/matcher.py`

 * *Files 8% similar despite different names*

```diff
@@ -3,27 +3,25 @@
 from collections.abc import Iterable
 from itertools import cycle
 from typing import Any
 
 from eth_abi.abi import decode as decode_abi
 from eth_utils.hexadecimal import decode_hex
 
-from dipdup.config.evm_subsquid_events import SubsquidEventsHandlerConfig
-from dipdup.models.evm_node import EvmNodeLogData
-from dipdup.models.evm_subsquid import SubsquidEvent
-from dipdup.models.evm_subsquid import SubsquidEventData
-from dipdup.package import ConvertedEventAbi
+from dipdup.config.evm_events import EvmEventsHandlerConfig
+from dipdup.models.evm import EvmEvent
+from dipdup.models.evm import EvmEventData
 from dipdup.package import DipDupPackage
 from dipdup.utils import parse_object
 from dipdup.utils import pascal_to_snake
 from dipdup.utils import snake_to_pascal
 
 _logger = logging.getLogger(__name__)
 
-MatchedEventsT = tuple[SubsquidEventsHandlerConfig, SubsquidEvent[Any]]
+MatchedEventsT = tuple[EvmEventsHandlerConfig, EvmEvent[Any]]
 
 
 def decode_indexed_topics(indexed_inputs: tuple[str, ...], topics: tuple[str, ...]) -> tuple[Any, ...]:
     indexed_bytes = b''.join(decode_hex(topic) for topic in topics[1:])
     return decode_abi(indexed_inputs, indexed_bytes)
 
 
@@ -51,62 +49,60 @@
         else:
             values.append(next(non_indexed_values))
     return tuple(values)
 
 
 def prepare_event_handler_args(
     package: DipDupPackage,
-    handler_config: SubsquidEventsHandlerConfig,
-    matched_event: SubsquidEventData | EvmNodeLogData,
-) -> SubsquidEvent[Any]:
+    handler_config: EvmEventsHandlerConfig,
+    matched_event: EvmEventData,
+) -> EvmEvent[Any]:
     typename = handler_config.contract.module_name
     inputs = package.get_converted_abi(typename)['events'][handler_config.name]['inputs']
 
     type_ = package.get_type(
         typename=typename,
         module=f'evm_events.{pascal_to_snake(handler_config.name)}',
-        name=snake_to_pascal(handler_config.name),
+        name=snake_to_pascal(handler_config.name) + 'Payload',
     )
 
     data = decode_event_data(
         data=matched_event.data,
         topics=tuple(matched_event.topics),
         inputs=inputs,
     )
 
     typed_payload = parse_object(
         type_=type_,
         data=data,
         plain=True,
     )
-    return SubsquidEvent(
+    return EvmEvent(
         data=matched_event,
         payload=typed_payload,
     )
 
 
 def match_events(
     package: DipDupPackage,
-    handlers: Iterable[SubsquidEventsHandlerConfig],
-    events: Iterable[SubsquidEventData | EvmNodeLogData],
-    abis: dict[str, dict[str, ConvertedEventAbi]],
+    handlers: Iterable[EvmEventsHandlerConfig],
+    events: Iterable[EvmEventData],
+    topics: dict[str, dict[str, str]],
 ) -> deque[MatchedEventsT]:
-    """Try to match contract events with all index handlers."""
+    """Try to match event events with all index handlers."""
     matched_handlers: deque[MatchedEventsT] = deque()
 
     for event in events:
         if not event.topics:
             continue
 
         for handler_config in handlers:
             typename = handler_config.contract.module_name
-            abi = abis[typename][handler_config.name]
-            if event.topics[0] != abi['topic0']:
-                continue
-            if len(event.topics) != abi['topic_count'] + 1:
+            name = handler_config.name
+            if topics[typename][name] != event.topics[0]:
                 continue
 
             address = handler_config.contract.address
             if address and address != event.address:
                 continue
 
             arg = prepare_event_handler_args(package, handler_config, event)
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/evm_subsquid_transactions/fetcher.py` & `dipdup-8.0.0a1/src/dipdup/indexes/evm_transactions/fetcher.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,58 +1,53 @@
 import random
 import time
 from collections.abc import AsyncIterator
 
-from dipdup.datasources.evm_node import EvmNodeDatasource
-from dipdup.datasources.evm_subsquid import SubsquidDatasource
-from dipdup.fetcher import DataFetcher
+from dipdup.datasources.evm_subsquid import EvmSubsquidDatasource
 from dipdup.fetcher import readahead_by_level
+from dipdup.indexes.evm import EVM_SUBSQUID_READAHEAD_LIMIT
 from dipdup.indexes.evm_node import EVM_NODE_READAHEAD_LIMIT
 from dipdup.indexes.evm_node import MIN_BATCH_SIZE
 from dipdup.indexes.evm_node import EvmNodeFetcher
-from dipdup.indexes.evm_subsquid import SUBSQUID_READAHEAD_LIMIT
-from dipdup.models.evm_node import EvmNodeTransactionData
-from dipdup.models.evm_subsquid import SubsquidTransactionData
+from dipdup.indexes.evm_subsquid import EvmSubsquidFetcher
+from dipdup.models.evm import EvmTransactionData
 from dipdup.models.evm_subsquid import TransactionRequest
 
 
-class SubsquidTransactionFetcher(DataFetcher[SubsquidTransactionData]):
+class EvmSubsquidTransactionFetcher(EvmSubsquidFetcher[EvmTransactionData]):
     """Fetches transactions from REST API, merges them and yields by level."""
 
-    _datasource: SubsquidDatasource
-
     def __init__(
         self,
-        datasource: SubsquidDatasource,
+        datasources: tuple[EvmSubsquidDatasource, ...],
         first_level: int,
         last_level: int,
         filters: tuple[TransactionRequest, ...],
     ) -> None:
-        super().__init__(datasource, first_level, last_level)
+        super().__init__(datasources, first_level, last_level)
         self._filters = filters
 
-    async def fetch_by_level(self) -> AsyncIterator[tuple[int, tuple[SubsquidTransactionData, ...]]]:
-        transaction_iter = self._datasource.iter_transactions(
+    async def fetch_by_level(self) -> AsyncIterator[tuple[int, tuple[EvmTransactionData, ...]]]:
+        transaction_iter = self.random_datasource.iter_transactions(
             self._first_level,
             self._last_level,
             self._filters,
         )
-        async for level, batch in readahead_by_level(transaction_iter, limit=SUBSQUID_READAHEAD_LIMIT):
+        async for level, batch in readahead_by_level(transaction_iter, limit=EVM_SUBSQUID_READAHEAD_LIMIT):
             yield level, batch
 
 
-class EvmNodeTransactionFetcher(EvmNodeFetcher[EvmNodeTransactionData]):
-    _datasource: EvmNodeDatasource
+class EvmNodeTransactionFetcher(EvmNodeFetcher[EvmTransactionData]):
 
-    async def fetch_by_level(self) -> AsyncIterator[tuple[int, tuple[EvmNodeTransactionData, ...]]]:
+    async def fetch_by_level(self) -> AsyncIterator[tuple[int, tuple[EvmTransactionData, ...]]]:
         transaction_iter = self._fetch_by_level()
         async for level, batch in readahead_by_level(transaction_iter, limit=EVM_NODE_READAHEAD_LIMIT):
             yield level, batch
 
-    async def _fetch_by_level(self) -> AsyncIterator[tuple[EvmNodeTransactionData, ...]]:
+    async def _fetch_by_level(self) -> AsyncIterator[tuple[EvmTransactionData, ...]]:
         batch_size = MIN_BATCH_SIZE
         batch_first_level = self._first_level
         ratelimited: bool = False
 
         while batch_first_level <= self._last_level:
             node = random.choice(self._datasources)
             batch_size = self.get_next_batch_size(batch_size, ratelimited)
@@ -78,13 +73,13 @@
 
             for block in blocks:
                 timestamp = int(block['timestamp'], 16)
                 if not block['transactions']:
                     continue
 
                 parsed_level_transactions = tuple(
-                    EvmNodeTransactionData.from_json(transaction, timestamp) for transaction in block['transactions']
+                    EvmTransactionData.from_node_json(transaction, timestamp) for transaction in block['transactions']
                 )
 
                 yield parsed_level_transactions
 
             batch_first_level = batch_last_level + 1
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/evm_subsquid_transactions/index.py` & `dipdup-8.0.0a1/src/dipdup/indexes/evm_transactions/index.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,51 +1,49 @@
 from collections import deque
 from typing import Any
 
-from dipdup.config.evm_subsquid_transactions import SubsquidTransactionsHandlerConfig
-from dipdup.config.evm_subsquid_transactions import SubsquidTransactionsIndexConfig
+from dipdup.config.evm_transactions import EvmTransactionsHandlerConfig
+from dipdup.config.evm_transactions import EvmTransactionsIndexConfig
 from dipdup.datasources.evm_node import EvmNodeDatasource
-from dipdup.datasources.evm_subsquid import SubsquidDatasource
+from dipdup.datasources.evm_subsquid import EvmSubsquidDatasource
 from dipdup.exceptions import ConfigInitializationException
-from dipdup.exceptions import FrameworkException
-from dipdup.indexes.evm_subsquid import SubsquidIndex
-from dipdup.indexes.evm_subsquid import get_sighash
-from dipdup.indexes.evm_subsquid_transactions.fetcher import EvmNodeTransactionFetcher
-from dipdup.indexes.evm_subsquid_transactions.fetcher import SubsquidTransactionFetcher
-from dipdup.indexes.evm_subsquid_transactions.matcher import match_transactions
+from dipdup.indexes.evm import EvmIndex
+from dipdup.indexes.evm import get_sighash
+from dipdup.indexes.evm_transactions.fetcher import EvmNodeTransactionFetcher
+from dipdup.indexes.evm_transactions.fetcher import EvmSubsquidTransactionFetcher
+from dipdup.indexes.evm_transactions.matcher import match_transactions
 from dipdup.models import RollbackMessage
-from dipdup.models.evm_node import EvmNodeTransactionData
-from dipdup.models.evm_subsquid import SubsquidMessageType
-from dipdup.models.evm_subsquid import SubsquidTransaction
+from dipdup.models.evm import EvmTransaction
+from dipdup.models.evm import EvmTransactionData
 from dipdup.models.evm_subsquid import TransactionRequest
+from dipdup.models.subsquid import SubsquidMessageType
 from dipdup.prometheus import Metrics
 
-QueueItem = tuple[EvmNodeTransactionData, ...] | RollbackMessage
-Datasource = SubsquidDatasource | EvmNodeDatasource
+QueueItem = tuple[EvmTransactionData, ...] | RollbackMessage
+EvmDatasource = EvmSubsquidDatasource | EvmNodeDatasource
 
 
-class SubsquidTransactionsIndex(
-    SubsquidIndex[SubsquidTransactionsIndexConfig, QueueItem, Datasource],
+class EvmTransactionsIndex(
+    EvmIndex[EvmTransactionsIndexConfig, QueueItem, EvmDatasource],
     message_type=SubsquidMessageType.transactions,
 ):
     def _match_level_data(self, handlers: Any, level_data: Any) -> deque[Any]:
         return match_transactions(self._ctx.package, handlers, level_data)
 
     async def _call_matched_handler(
         self,
-        handler_config: SubsquidTransactionsHandlerConfig,
-        transaction: SubsquidTransaction[Any],
+        handler_config: EvmTransactionsHandlerConfig,
+        transaction: EvmTransaction[Any],
     ) -> None:
         if not handler_config.parent:
             raise ConfigInitializationException
 
         await self._ctx.fire_handler(
             handler_config.callback,
             handler_config.parent.name,
-            self.datasource,
             None,
             transaction,
         )
 
     async def _synchronize_subsquid(self, sync_level: int) -> None:
         first_level = self.state.level + 1
         fetcher = self._create_subsquid_fetcher(first_level, sync_level)
@@ -58,34 +56,31 @@
         first_level = self.state.level + 1
         fetcher = self._create_node_fetcher(first_level, sync_level)
 
         async for _level, transactions in fetcher.fetch_by_level():
             await self._process_level_data(transactions, sync_level)
             Metrics.set_sqd_processor_last_block(_level)
 
-    def _create_subsquid_fetcher(self, first_level: int, last_level: int) -> SubsquidTransactionFetcher:
+    def _create_subsquid_fetcher(self, first_level: int, last_level: int) -> EvmSubsquidTransactionFetcher:
 
         filters: deque[TransactionRequest] = deque()
         for handler_config in self._config.handlers:
             query: TransactionRequest = {}
             if (from_ := handler_config.from_) and from_.address:
                 query['from'] = [from_.address]
             if (to_ := handler_config.to) and to_.address:
                 query['to'] = [to_.address]
             if method := handler_config.method:
                 query['sighash'] = [get_sighash(self._ctx.package, method, to_)]
             if not query:
                 raise NotImplementedError
             filters.append(query)
 
-        if not isinstance(self._datasource, SubsquidDatasource):
-            raise FrameworkException('Creating subsquid fetcher with non-subsquid datasource')
-
-        return SubsquidTransactionFetcher(
-            datasource=self._datasource,
+        return EvmSubsquidTransactionFetcher(
+            datasources=self.subsquid_datasources,
             first_level=first_level,
             last_level=last_level,
             filters=tuple(filters),
         )
 
     def _create_node_fetcher(self, first_level: int, last_level: int) -> EvmNodeTransactionFetcher:
         return EvmNodeTransactionFetcher(
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/evm_subsquid_transactions/matcher.py` & `dipdup-8.0.0a1/src/dipdup/indexes/evm_transactions/matcher.py`

 * *Files 8% similar despite different names*

```diff
@@ -3,77 +3,77 @@
 from collections.abc import Iterable
 from typing import Any
 
 import eth_abi.decoding
 from eth_abi.abi import decode as decode_abi
 from eth_utils.hexadecimal import decode_hex
 
-from dipdup.config.evm_subsquid_transactions import SubsquidTransactionsHandlerConfig
+from dipdup.config.evm_transactions import EvmTransactionsHandlerConfig
 from dipdup.exceptions import FrameworkException
-from dipdup.indexes.evm_subsquid import get_sighash
-from dipdup.models.evm_node import EvmNodeTransactionData
-from dipdup.models.evm_subsquid import SubsquidTransaction
-from dipdup.models.evm_subsquid import SubsquidTransactionData
+from dipdup.indexes.evm import get_sighash
+from dipdup.models.evm import EvmTransaction
+from dipdup.models.evm import EvmTransactionData
 from dipdup.package import DipDupPackage
 from dipdup.utils import parse_object
 from dipdup.utils import pascal_to_snake
 from dipdup.utils import snake_to_pascal
 
 _logger = logging.getLogger(__name__)
 
 MatchedTransactionsT = tuple[
-    SubsquidTransactionsHandlerConfig, SubsquidTransaction[Any] | SubsquidTransactionData | EvmNodeTransactionData
+    EvmTransactionsHandlerConfig,
+    EvmTransaction[Any] | EvmTransactionData,
 ]
 
 
 # NOTE: Completely disable padding validation. If data is in Subsquid, node was ok with it.
 eth_abi.decoding.ByteStringDecoder.validate_padding_bytes = lambda *a, **kw: None  # type: ignore[method-assign]
 eth_abi.decoding.FixedByteSizeDecoder.validate_padding_bytes = lambda *a, **kw: None  # type: ignore[method-assign]
 eth_abi.decoding.SignedFixedDecoder.validate_padding_bytes = lambda *a, **kw: None  # type: ignore[method-assign]
 eth_abi.decoding.SignedIntegerDecoder.validate_padding_bytes = lambda *a, **kw: None  # type: ignore[method-assign]
 eth_abi.decoding.SingleDecoder.validate_padding_bytes = lambda *a, **kw: None  # type: ignore[method-assign]
 
 
 def prepare_transaction_handler_args(
     package: DipDupPackage,
-    handler_config: SubsquidTransactionsHandlerConfig,
-    matched_transaction: SubsquidTransactionData | EvmNodeTransactionData,
-) -> SubsquidTransaction[Any]:
+    handler_config: EvmTransactionsHandlerConfig,
+    matched_transaction: EvmTransactionData,
+) -> EvmTransaction[Any]:
     method, contract = handler_config.method, handler_config.to
     if not method or not contract:
         raise FrameworkException('`method` and `to` are required for typed transaction handler')
     typename = contract.module_name
 
     inputs = package.get_converted_abi(typename)['methods'][method]['inputs']
     data = decode_abi(
         types=tuple(input['type'] for input in inputs),
         data=decode_hex(matched_transaction.input[10:]),
         strict=False,
     )
 
     type_ = package.get_type(
         typename=typename,
-        module=f'evm_methods.{pascal_to_snake(method)}',
-        name=snake_to_pascal(method),
+        module=f'evm_transactions.{pascal_to_snake(method)}',
+        name=snake_to_pascal(method) + 'Input',
     )
     typed_input = parse_object(
         type_=type_,
         data=data,
         plain=True,
     )
-    return SubsquidTransaction(
+    return EvmTransaction(
         data=matched_transaction,
         input=typed_input,
     )
 
 
 def match_transactions(
     package: DipDupPackage,
-    handlers: Iterable[SubsquidTransactionsHandlerConfig],
-    transactions: Iterable[SubsquidTransactionData | EvmNodeTransactionData],
+    handlers: Iterable[EvmTransactionsHandlerConfig],
+    transactions: Iterable[EvmTransactionData],
 ) -> deque[MatchedTransactionsT]:
     """Try to match contract transactions with all index handlers."""
     matched_handlers: deque[MatchedTransactionsT] = deque()
 
     for transaction in transactions:
         for handler_config in handlers:
             # NOTE: Don't match by `abi` contract field, it's only for codegen
@@ -82,17 +82,21 @@
             if (to := handler_config.to) and to.address not in (transaction.to, None):
                 continue
             if method := handler_config.method:
                 sighash = get_sighash(package, method, to)
                 if sighash != transaction.sighash:
                     continue
 
-            arg = (
-                prepare_transaction_handler_args(package, handler_config, transaction)
-                if handler_config.typed_contract
-                else transaction
+            matched_handlers.append(
+                (
+                    handler_config,
+                    (
+                        prepare_transaction_handler_args(package, handler_config, transaction)
+                        if handler_config.typed_contract
+                        else transaction
+                    ),
+                )
             )
-            matched_handlers.append((handler_config, arg))
             break
 
     _logger.debug('%d handlers matched', len(matched_handlers))
     return matched_handlers
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_big_maps/fetcher.py` & `dipdup-8.0.0a1/src/dipdup/indexes/tezos_big_maps/fetcher.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,94 +1,92 @@
 from __future__ import annotations
 
 import logging
 from typing import TYPE_CHECKING
 
-from dipdup.fetcher import DataFetcher
+from dipdup.config.tezos_big_maps import TezosBigMapsHandlerConfig
 from dipdup.fetcher import readahead_by_level
 from dipdup.indexes.tezos_tzkt import TZKT_READAHEAD_LIMIT
-from dipdup.models.tezos_tzkt import TzktBigMapData
+from dipdup.indexes.tezos_tzkt import TezosTzktFetcher
+from dipdup.models.tezos import TezosBigMapData
 
 if TYPE_CHECKING:
     from collections.abc import AsyncGenerator
     from collections.abc import Iterable
 
-    from dipdup.config.tezos_tzkt_big_maps import TzktBigMapsHandlerConfig
-    from dipdup.config.tezos_tzkt_big_maps import TzktBigMapsIndexConfig
-    from dipdup.datasources.tezos_tzkt import TzktDatasource
+    from dipdup.config.tezos_big_maps import TezosBigMapsIndexConfig
+    from dipdup.datasources.tezos_tzkt import TezosTzktDatasource
 
 
-def get_big_map_addresses(handlers: Iterable[TzktBigMapsHandlerConfig]) -> set[str]:
+def get_big_map_addresses(handlers: Iterable[TezosBigMapsHandlerConfig]) -> set[str]:
     """Get addresses to fetch big map diffs from during initial synchronization"""
     addresses = set()
     for handler_config in handlers:
         addresses.add(handler_config.contract.get_address())
     return addresses
 
 
-def get_big_map_paths(handlers: Iterable[TzktBigMapsHandlerConfig]) -> set[str]:
+def get_big_map_paths(handlers: Iterable[TezosBigMapsHandlerConfig]) -> set[str]:
     """Get addresses to fetch big map diffs from during initial synchronization"""
     paths = set()
     for handler_config in handlers:
         paths.add(handler_config.path)
     return paths
 
 
-def get_big_map_pairs(handlers: Iterable[TzktBigMapsHandlerConfig]) -> set[tuple[str, str]]:
+def get_big_map_pairs(handlers: Iterable[TezosBigMapsHandlerConfig]) -> set[tuple[str, str]]:
     """Get address-path pairs for fetch big map diffs during sync with `skip_history`"""
     pairs = set()
     for handler_config in handlers:
         pairs.add(
             (
                 handler_config.contract.get_address(),
                 handler_config.path,
             )
         )
     return pairs
 
 
-class BigMapFetcher(DataFetcher[TzktBigMapData]):
+class BigMapFetcher(TezosTzktFetcher[TezosBigMapData]):
     """Fetches bigmap diffs from REST API, merges them and yields by level."""
 
-    _datasource: TzktDatasource
-
     def __init__(
         self,
-        datasource: TzktDatasource,
+        datasources: tuple[TezosTzktDatasource, ...],
         first_level: int,
         last_level: int,
         big_map_addresses: set[str],
         big_map_paths: set[str],
     ) -> None:
-        super().__init__(datasource, first_level, last_level)
+        super().__init__(datasources, first_level, last_level)
         self._logger = logging.getLogger('dipdup.fetcher')
         self._big_map_addresses = big_map_addresses
         self._big_map_paths = big_map_paths
 
     @classmethod
     def create(
         cls,
-        config: TzktBigMapsIndexConfig,
-        datasource: TzktDatasource,
+        config: TezosBigMapsIndexConfig,
+        datasources: tuple[TezosTzktDatasource, ...],
         first_level: int,
         last_level: int,
     ) -> BigMapFetcher:
         big_map_addresses = get_big_map_addresses(config.handlers)
         big_map_paths = get_big_map_paths(config.handlers)
 
         return BigMapFetcher(
-            datasource=datasource,
+            datasources=datasources,
             first_level=first_level,
             last_level=last_level,
             big_map_addresses=big_map_addresses,
             big_map_paths=big_map_paths,
         )
 
-    async def fetch_by_level(self) -> AsyncGenerator[tuple[int, tuple[TzktBigMapData, ...]], None]:
-        big_map_iter = self._datasource.iter_big_maps(
+    async def fetch_by_level(self) -> AsyncGenerator[tuple[int, tuple[TezosBigMapData, ...]], None]:
+        big_map_iter = self.random_datasource.iter_big_maps(
             self._big_map_addresses,
             self._big_map_paths,
             self._first_level,
             self._last_level,
         )
         async for level, batch in readahead_by_level(big_map_iter, limit=TZKT_READAHEAD_LIMIT):
             yield level, batch
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_big_maps/index.py` & `dipdup-8.0.0a1/src/dipdup/indexes/tezos_big_maps/index.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,33 +1,32 @@
 from collections import deque
 from datetime import datetime
 from typing import Any
 
-from dipdup.config.tezos_tzkt_big_maps import TzktBigMapsHandlerConfig
-from dipdup.config.tezos_tzkt_big_maps import TzktBigMapsIndexConfig
+from dipdup.config.tezos_big_maps import TezosBigMapsHandlerConfig
+from dipdup.config.tezos_big_maps import TezosBigMapsIndexConfig
 from dipdup.exceptions import ConfigInitializationException
 from dipdup.exceptions import ConfigurationError
-from dipdup.indexes.tezos_tzkt import TzktIndex
-from dipdup.indexes.tezos_tzkt_big_maps.fetcher import BigMapFetcher
-from dipdup.indexes.tezos_tzkt_big_maps.fetcher import get_big_map_pairs
-from dipdup.indexes.tezos_tzkt_big_maps.matcher import match_big_maps
+from dipdup.indexes.tezos_big_maps.fetcher import BigMapFetcher
+from dipdup.indexes.tezos_big_maps.fetcher import get_big_map_pairs
+from dipdup.indexes.tezos_big_maps.matcher import match_big_maps
+from dipdup.indexes.tezos_tzkt import TezosIndex
 from dipdup.models import RollbackMessage
 from dipdup.models import SkipHistory
-from dipdup.models.tezos_tzkt import TzktBigMapAction
-from dipdup.models.tezos_tzkt import TzktBigMapData
-from dipdup.models.tezos_tzkt import TzktBigMapDiff
-from dipdup.models.tezos_tzkt import TzktMessageType
-from dipdup.performance import metrics
-
-QueueItem = tuple[TzktBigMapData, ...] | RollbackMessage
+from dipdup.models.tezos import TezosBigMapAction
+from dipdup.models.tezos import TezosBigMapData
+from dipdup.models.tezos import TezosBigMapDiff
+from dipdup.models.tezos_tzkt import TezosTzktMessageType
 
+QueueItem = tuple[TezosBigMapData, ...] | RollbackMessage
 
-class TzktBigMapsIndex(
-    TzktIndex[TzktBigMapsIndexConfig, QueueItem],
-    message_type=TzktMessageType.big_map,
+
+class TezosBigMapsIndex(
+    TezosIndex[TezosBigMapsIndexConfig, QueueItem],
+    message_type=TezosTzktMessageType.big_map,
 ):
     async def _synchronize(self, sync_level: int) -> None:
         """Fetch operations via Fetcher and pass to message callback"""
         index_level = await self._enter_sync_state(sync_level)
         if index_level is None:
             return
 
@@ -42,15 +41,15 @@
 
     async def _synchronize_full(self, index_level: int, sync_level: int) -> None:
         first_level = index_level + 1
         self._logger.info('Fetching big map diffs from level %s to %s', first_level, sync_level)
 
         fetcher = BigMapFetcher.create(
             self._config,
-            self._datasource,
+            self._datasources,
             first_level,
             sync_level,
         )
 
         async for _, big_maps in fetcher.fetch_by_level():
             await self._process_level_data(big_maps, sync_level)
 
@@ -59,57 +58,54 @@
         if not self._ctx.config.advanced.early_realtime:
             raise ConfigurationError('`skip_history` requires `early_realtime` feature flag to be enabled')
 
         big_map_pairs = get_big_map_pairs(self._config.handlers)
         big_map_ids: set[tuple[int, str, str]] = set()
 
         for address, path in big_map_pairs:
-            async for contract_big_maps in self._datasource.iter_contract_big_maps(address):
+            async for contract_big_maps in self.random_datasource.iter_contract_big_maps(address):
                 for contract_big_map in contract_big_maps:
                     if contract_big_map['path'] == path:
                         big_map_ids.add((int(contract_big_map['ptr']), address, path))
 
         # NOTE: Do not use `_process_level_data` here; we want to maintain transaction manually.
         async with self._ctx.transactions.in_transaction(head_level, head_level, self.name):
             for big_map_id, address, path in big_map_ids:
-                async for big_map_keys in self._datasource.iter_big_map(big_map_id, head_level):
+                async for big_map_keys in self.random_datasource.iter_big_map(big_map_id, head_level):
                     big_map_data = tuple(
-                        TzktBigMapData(
+                        TezosBigMapData(
                             id=big_map_key['id'],
                             level=head_level,
                             operation_id=head_level,
                             timestamp=datetime.now(),
                             bigmap=big_map_id,
                             contract_address=address,
                             path=path,
-                            action=TzktBigMapAction.ADD_KEY,
+                            action=TezosBigMapAction.ADD_KEY,
                             active=big_map_key['active'],
                             key=big_map_key['key'],
                             value=big_map_key['value'],
                         )
                         for big_map_key in big_map_keys
                     )
-                    metrics.objects_indexed += len(big_map_data)
-
                     matched_handlers = match_big_maps(self._ctx.package, self._config.handlers, big_map_data)
                     for handler_config, big_map_diff in matched_handlers:
                         await self._call_matched_handler(handler_config, big_map_diff)
 
             await self._update_state(level=head_level)
 
     async def _call_matched_handler(
-        self, handler_config: TzktBigMapsHandlerConfig, level_data: TzktBigMapDiff[Any, Any]
+        self, handler_config: TezosBigMapsHandlerConfig, level_data: TezosBigMapDiff[Any, Any]
     ) -> None:
         if not handler_config.parent:
             raise ConfigInitializationException
 
         await self._ctx.fire_handler(
             handler_config.callback,
             handler_config.parent.name,
-            self.datasource,
             # NOTE: missing `operation_id` field in API to identify operation
             None,
             level_data,
         )
 
     def _match_level_data(self, handlers: Any, level_data: Any) -> deque[Any]:
         return match_big_maps(self._ctx.package, handlers, level_data)
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_big_maps/matcher.py` & `dipdup-8.0.0a1/src/dipdup/indexes/tezos_big_maps/matcher.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,71 +1,71 @@
 import logging
 from collections import deque
 from collections.abc import Iterable
 from typing import TYPE_CHECKING
 from typing import Any
 
-from dipdup.codegen.tezos_tzkt import get_big_map_key_type
-from dipdup.codegen.tezos_tzkt import get_big_map_value_type
-from dipdup.config.tezos_tzkt_big_maps import TzktBigMapsHandlerConfig
-from dipdup.models.tezos_tzkt import TzktBigMapData
-from dipdup.models.tezos_tzkt import TzktBigMapDiff
+from dipdup.codegen.tezos import get_big_map_key_type
+from dipdup.codegen.tezos import get_big_map_value_type
+from dipdup.config.tezos_big_maps import TezosBigMapsHandlerConfig
+from dipdup.models.tezos import TezosBigMapData
+from dipdup.models.tezos import TezosBigMapDiff
 from dipdup.package import DipDupPackage
 from dipdup.utils import parse_object
 
 if TYPE_CHECKING:
     from pydantic import BaseModel
 
 _logger = logging.getLogger('dipdup.matcher')
 
-MatchedBigMapsT = tuple[TzktBigMapsHandlerConfig, TzktBigMapDiff[Any, Any]]
+MatchedBigMapsT = tuple[TezosBigMapsHandlerConfig, TezosBigMapDiff[Any, Any]]
 
 
 def prepare_big_map_handler_args(
     package: DipDupPackage,
-    handler_config: TzktBigMapsHandlerConfig,
-    matched_big_map: TzktBigMapData,
-) -> TzktBigMapDiff[Any, Any]:
+    handler_config: TezosBigMapsHandlerConfig,
+    matched_big_map: TezosBigMapData,
+) -> TezosBigMapDiff[Any, Any]:
     _logger.debug('%s: `%s` handler matched!', matched_big_map.operation_id, handler_config.callback)
 
     key: BaseModel | None = None
     value: BaseModel | None = None
 
     if matched_big_map.action.has_key and matched_big_map.key is not None:
         type_ = get_big_map_key_type(package, handler_config.contract.module_name, handler_config.path)
         key = parse_object(type_, matched_big_map.key) if type_ else None
 
     if matched_big_map.action.has_value and matched_big_map.value is not None:
         type_ = get_big_map_value_type(package, handler_config.contract.module_name, handler_config.path)
         value = parse_object(type_, matched_big_map.value) if type_ else None
 
-    return TzktBigMapDiff(
+    return TezosBigMapDiff(
         data=matched_big_map,
         action=matched_big_map.action,
         key=key,
         value=value,
     )
 
 
 def match_big_map(
-    handler_config: TzktBigMapsHandlerConfig,
-    big_map: TzktBigMapData,
+    handler_config: TezosBigMapsHandlerConfig,
+    big_map: TezosBigMapData,
 ) -> bool:
     """Match single big map diff with pattern"""
     if handler_config.path != big_map.path:
         return False
     if handler_config.contract.address != big_map.contract_address:
         return False
     return True
 
 
 def match_big_maps(
     package: DipDupPackage,
-    handlers: Iterable[TzktBigMapsHandlerConfig],
-    big_maps: Iterable[TzktBigMapData],
+    handlers: Iterable[TezosBigMapsHandlerConfig],
+    big_maps: Iterable[TezosBigMapData],
 ) -> deque[MatchedBigMapsT]:
     """Try to match big map diffs with all index handlers."""
     matched_handlers: deque[MatchedBigMapsT] = deque()
 
     for handler_config in handlers:
         for big_map in big_maps:
             big_map_matched = match_big_map(handler_config, big_map)
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_events/fetcher.py` & `dipdup-8.0.0a1/src/dipdup/indexes/tezos_token_transfers/fetcher.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,43 +1,46 @@
 from __future__ import annotations
 
 import logging
 from typing import TYPE_CHECKING
 
-from dipdup.fetcher import DataFetcher
 from dipdup.fetcher import readahead_by_level
 from dipdup.indexes.tezos_tzkt import TZKT_READAHEAD_LIMIT
-from dipdup.models.tezos_tzkt import TzktEventData
+from dipdup.indexes.tezos_tzkt import TezosTzktFetcher
+from dipdup.models.tezos import TezosTokenTransferData
 
 if TYPE_CHECKING:
-    from collections.abc import AsyncGenerator
+    from collections.abc import AsyncIterator
 
-    from dipdup.datasources.tezos_tzkt import TzktDatasource
+    from dipdup.datasources.tezos_tzkt import TezosTzktDatasource
 
 
-class EventFetcher(DataFetcher[TzktEventData]):
-    _datasource: TzktDatasource
+class TokenTransferFetcher(TezosTzktFetcher[TezosTokenTransferData]):
 
     def __init__(
         self,
-        datasource: TzktDatasource,
+        datasources: tuple[TezosTzktDatasource, ...],
+        token_addresses: set[str],
+        token_ids: set[int],
+        from_addresses: set[str],
+        to_addresses: set[str],
         first_level: int,
         last_level: int,
-        event_addresses: set[str],
-        event_tags: set[str],
     ) -> None:
+        super().__init__(datasources, first_level, last_level)
         self._logger = logging.getLogger('dipdup.fetcher')
-        self._datasource = datasource
-        self._first_level = first_level
-        self._last_level = last_level
-        self._event_addresses = event_addresses
-        self._event_tags = event_tags
-
-    async def fetch_by_level(self) -> AsyncGenerator[tuple[int, tuple[TzktEventData, ...]], None]:
-        event_iter = self._datasource.iter_events(
-            self._event_addresses,
-            self._event_tags,
+        self._token_addresses = token_addresses
+        self._token_ids = token_ids
+        self._from_addresses = from_addresses
+        self._to_addresses = to_addresses
+
+    async def fetch_by_level(self) -> AsyncIterator[tuple[int, tuple[TezosTokenTransferData, ...]]]:
+        token_transfer_iter = self.random_datasource.iter_token_transfers(
+            self._token_addresses,
+            self._token_ids,
+            self._from_addresses,
+            self._to_addresses,
             self._first_level,
             self._last_level,
         )
-        async for level, batch in readahead_by_level(event_iter, limit=TZKT_READAHEAD_LIMIT):
+        async for level, batch in readahead_by_level(token_transfer_iter, limit=TZKT_READAHEAD_LIMIT):
             yield level, batch
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_events/index.py` & `dipdup-8.0.0a1/src/dipdup/indexes/tezos_events/index.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,36 +1,36 @@
 from collections import deque
 from typing import Any
 
-from dipdup.config.tezos_tzkt_events import TzktEventsHandlerConfig
-from dipdup.config.tezos_tzkt_events import TzktEventsHandlerConfigU
-from dipdup.config.tezos_tzkt_events import TzktEventsIndexConfig
+from dipdup.config.tezos_events import TezosEventsHandlerConfig
+from dipdup.config.tezos_events import TezosEventsHandlerConfigU
+from dipdup.config.tezos_events import TezosEventsIndexConfig
 from dipdup.exceptions import ConfigInitializationException
 from dipdup.exceptions import FrameworkException
-from dipdup.indexes.tezos_tzkt import TzktIndex
-from dipdup.indexes.tezos_tzkt_events.fetcher import EventFetcher
-from dipdup.indexes.tezos_tzkt_events.matcher import match_events
+from dipdup.indexes.tezos_events.fetcher import EventFetcher
+from dipdup.indexes.tezos_events.matcher import match_events
+from dipdup.indexes.tezos_tzkt import TezosIndex
 from dipdup.models import RollbackMessage
-from dipdup.models.tezos_tzkt import TzktEvent
-from dipdup.models.tezos_tzkt import TzktEventData
-from dipdup.models.tezos_tzkt import TzktMessageType
-from dipdup.models.tezos_tzkt import TzktUnknownEvent
+from dipdup.models.tezos import TezosEvent
+from dipdup.models.tezos import TezosEventData
+from dipdup.models.tezos import TezosUnknownEvent
+from dipdup.models.tezos_tzkt import TezosTzktMessageType
 
-QueueItem = tuple[TzktEventData, ...] | RollbackMessage
+QueueItem = tuple[TezosEventData, ...] | RollbackMessage
 
 
-class TzktEventsIndex(
-    TzktIndex[TzktEventsIndexConfig, QueueItem],
-    message_type=TzktMessageType.event,
+class TezosEventsIndex(
+    TezosIndex[TezosEventsIndexConfig, QueueItem],
+    message_type=TezosTzktMessageType.event,
 ):
     def _create_fetcher(self, first_level: int, last_level: int) -> EventFetcher:
         event_addresses = self._get_event_addresses()
         event_tags = self._get_event_tags()
         return EventFetcher(
-            datasource=self._datasource,
+            datasources=self._datasources,
             first_level=first_level,
             last_level=last_level,
             event_addresses=event_addresses,
             event_tags=event_tags,
         )
 
     async def _synchronize(self, sync_level: int) -> None:
@@ -45,26 +45,25 @@
 
         async for _, events in fetcher.fetch_by_level():
             await self._process_level_data(events, sync_level)
 
         await self._exit_sync_state(sync_level)
 
     async def _call_matched_handler(
-        self, handler_config: TzktEventsHandlerConfigU, level_data: TzktEvent[Any] | TzktUnknownEvent
+        self, handler_config: TezosEventsHandlerConfigU, level_data: TezosEvent[Any] | TezosUnknownEvent
     ) -> None:
-        if isinstance(handler_config, TzktEventsHandlerConfig) != isinstance(level_data, TzktEvent):
+        if isinstance(handler_config, TezosEventsHandlerConfig) != isinstance(level_data, TezosEvent):
             raise FrameworkException(f'Invalid handler config and event types: {handler_config}, {level_data}')
 
         if not handler_config.parent:
             raise ConfigInitializationException
 
         await self._ctx.fire_handler(
             handler_config.callback,
             handler_config.parent.name,
-            self.datasource,
             str(level_data.data.transaction_id),
             level_data,
         )
 
     def _get_event_addresses(self) -> set[str]:
         """Get addresses to fetch events during initial synchronization"""
         addresses = set()
@@ -72,13 +71,13 @@
             addresses.add(handler_config.contract.get_address())
         return addresses
 
     def _get_event_tags(self) -> set[str]:
         """Get tags to fetch events during initial synchronization"""
         paths = set()
         for handler_config in self._config.handlers:
-            if isinstance(handler_config, TzktEventsHandlerConfig):
+            if isinstance(handler_config, TezosEventsHandlerConfig):
                 paths.add(handler_config.tag)
         return paths
 
     def _match_level_data(self, handlers: Any, level_data: Any) -> deque[Any]:
         return match_events(self._ctx.package, handlers, level_data)
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_events/matcher.py` & `dipdup-8.0.0a1/src/dipdup/indexes/tezos_events/matcher.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,93 +1,95 @@
 import logging
 from collections import deque
 from collections.abc import Iterable
 from contextlib import suppress
 from copy import copy
 from typing import Any
 
-from dipdup.codegen.tezos_tzkt import get_event_payload_type
-from dipdup.config.tezos_tzkt_events import TzktEventsHandlerConfig
-from dipdup.config.tezos_tzkt_events import TzktEventsHandlerConfigU
-from dipdup.config.tezos_tzkt_events import TzktEventsUnknownEventHandlerConfig
+from dipdup.codegen.tezos import get_event_payload_type
+from dipdup.config.tezos_events import TezosEventsHandlerConfig
+from dipdup.config.tezos_events import TezosEventsHandlerConfigU
+from dipdup.config.tezos_events import TezosEventsUnknownEventHandlerConfig
 from dipdup.exceptions import FrameworkException
 from dipdup.exceptions import InvalidDataError
-from dipdup.models.tezos_tzkt import TzktEvent
-from dipdup.models.tezos_tzkt import TzktEventData
-from dipdup.models.tezos_tzkt import TzktUnknownEvent
+from dipdup.models.tezos import TezosEvent
+from dipdup.models.tezos import TezosEventData
+from dipdup.models.tezos import TezosUnknownEvent
 from dipdup.package import DipDupPackage
 from dipdup.utils import parse_object
 
 _logger = logging.getLogger('dipdup.matcher')
 
 
 MatchedEventsT = (
-    tuple[TzktEventsHandlerConfig, TzktEvent[Any]] | tuple[TzktEventsUnknownEventHandlerConfig, TzktUnknownEvent]
+    tuple[TezosEventsHandlerConfig, TezosEvent[Any]] | tuple[TezosEventsUnknownEventHandlerConfig, TezosUnknownEvent]
 )
 
 
 def prepare_event_handler_args(
     package: DipDupPackage,
-    handler_config: TzktEventsHandlerConfigU,
-    matched_event: TzktEventData,
-) -> TzktEvent[Any] | TzktUnknownEvent | None:
+    handler_config: TezosEventsHandlerConfigU,
+    matched_event: TezosEventData,
+) -> TezosEvent[Any] | TezosUnknownEvent | None:
     _logger.debug('%s: `%s` handler matched!', matched_event.level, handler_config.callback)
 
-    if isinstance(handler_config, TzktEventsUnknownEventHandlerConfig):
-        return TzktUnknownEvent(
+    if isinstance(handler_config, TezosEventsUnknownEventHandlerConfig):
+        return TezosUnknownEvent(
             data=matched_event,
             payload=matched_event.payload,
         )
 
     type_ = get_event_payload_type(
         package=package,
         typename=handler_config.contract.module_name,
         tag=handler_config.tag,
     )
     if not matched_event.payload:
         raise FrameworkException('Event is typed, but payload is empty')
 
     with suppress(InvalidDataError):
         typed_payload = parse_object(type_, matched_event.payload)
-        return TzktEvent(
+        return TezosEvent(
             data=matched_event,
             payload=typed_payload,
         )
 
     return None
 
 
-def match_event(handler_config: TzktEventsHandlerConfigU, event: TzktEventData) -> bool:
+def match_event(handler_config: TezosEventsHandlerConfigU, event: TezosEventData) -> bool:
     """Match single contract event with pattern"""
-    if isinstance(handler_config, TzktEventsHandlerConfig) and handler_config.tag != event.tag:
+    if isinstance(handler_config, TezosEventsHandlerConfig) and handler_config.tag != event.tag:
         return False
     if handler_config.contract.address != event.contract_address:
         return False
     return True
 
 
 def match_events(
     package: DipDupPackage,
-    handlers: Iterable[TzktEventsHandlerConfigU],
-    events: Iterable[TzktEventData],
+    handlers: Iterable[TezosEventsHandlerConfigU],
+    events: Iterable[TezosEventData],
 ) -> deque[MatchedEventsT]:
     """Try to match contract events with all index handlers."""
     matched_handlers: deque[MatchedEventsT] = deque()
     events = deque(events)
 
     for handler_config in handlers:
         # NOTE: Matched events are dropped after processing
         for event in copy(events):
             if not match_event(handler_config, event):
                 continue
 
             arg = prepare_event_handler_args(package, handler_config, event)
-            if isinstance(arg, TzktEvent) and isinstance(handler_config, TzktEventsHandlerConfig):
+            if isinstance(arg, TezosEvent) and isinstance(handler_config, TezosEventsHandlerConfig):
                 matched_handlers.append((handler_config, arg))
-            elif isinstance(arg, TzktUnknownEvent) and isinstance(handler_config, TzktEventsUnknownEventHandlerConfig):
+            elif isinstance(arg, TezosUnknownEvent) and isinstance(
+                handler_config, TezosEventsUnknownEventHandlerConfig
+            ):
                 matched_handlers.append((handler_config, arg))
             elif arg is None:
                 continue
             else:
                 raise FrameworkException(f'Unexpected handler config type: {type(handler_config)}')
 
             events.remove(event)
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_head/index.py` & `dipdup-8.0.0a1/src/dipdup/indexes/tezos_head/index.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 from collections import deque
 from typing import Any
 
-from dipdup.config.tezos_tzkt_head import HeadHandlerConfig
-from dipdup.config.tezos_tzkt_head import TzktHeadIndexConfig
+from dipdup.config.tezos_head import TezosHeadIndexConfig
+from dipdup.config.tezos_head import TezosTzktHeadHandlerConfig
 from dipdup.exceptions import ConfigInitializationException
 from dipdup.exceptions import FrameworkException
-from dipdup.indexes.tezos_tzkt import TzktIndex
+from dipdup.indexes.tezos_tzkt import TezosIndex
 from dipdup.models import IndexStatus
 from dipdup.models import RollbackMessage
-from dipdup.models.tezos_tzkt import TzktHeadBlockData
-from dipdup.models.tezos_tzkt import TzktMessageType
+from dipdup.models.tezos import TezosHeadBlockData
+from dipdup.models.tezos_tzkt import TezosTzktMessageType
 
-HeadQueueItem = TzktHeadBlockData | RollbackMessage
+HeadQueueItem = TezosHeadBlockData | RollbackMessage
 
 
-class TzktHeadIndex(
-    TzktIndex[TzktHeadIndexConfig, HeadQueueItem],
-    message_type=TzktMessageType.head,
+class TezosHeadIndex(
+    TezosIndex[TezosHeadIndexConfig, HeadQueueItem],
+    message_type=TezosTzktMessageType.head,
 ):
     async def _synchronize(self, sync_level: int) -> None:
         self._logger.info('Setting index level to %s and moving on', sync_level)
         await self._update_state(status=IndexStatus.realtime, level=sync_level)
 
     # FIXME: Use method from Index
     async def _process_queue(self) -> None:
@@ -43,22 +43,23 @@
                 raise FrameworkException(f'Batch level is lower than index level: {batch_level} <= {index_level}')
 
             async with self._ctx.transactions.in_transaction(batch_level, message_level, self.name):
                 self._logger.debug('Processing head info of level %s', batch_level)
                 await self._call_matched_handler(self._config.handler_config, message)
                 await self._update_state(level=batch_level)
 
-    async def _call_matched_handler(self, handler_config: HeadHandlerConfig, level_data: TzktHeadBlockData) -> None:
+    async def _call_matched_handler(
+        self, handler_config: TezosTzktHeadHandlerConfig, level_data: TezosHeadBlockData
+    ) -> None:
         if not handler_config.parent:
             raise ConfigInitializationException
 
         await self._ctx.fire_handler(
             handler_config.callback,
             handler_config.parent.name,
-            self.datasource,
             level_data.hash,
             level_data,
         )
 
     # FIXME: Use method from Index
     def _match_level_data(self, handlers: Any, level_data: Any) -> deque[Any]:
         raise NotImplementedError
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_operations/fetcher.py` & `dipdup-8.0.0a1/src/dipdup/indexes/tezos_operations/fetcher.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,66 +1,66 @@
 from __future__ import annotations
 
 import logging
+import random
 from abc import abstractmethod
 from typing import TYPE_CHECKING
 from typing import Any
 from typing import Generic
 
-from dipdup.config.tezos_tzkt_operations import OperationsHandlerOriginationPatternConfig as OriginationPatternConfig
-from dipdup.config.tezos_tzkt_operations import (
-    OperationsHandlerSmartRollupExecutePatternConfig as SmartRollupExecutePatternConfig,
+from dipdup.config.tezos_operations import TezosOperationsHandlerOriginationPatternConfig as OriginationPatternConfig
+from dipdup.config.tezos_operations import (
+    TezosOperationsHandlerSmartRollupExecutePatternConfig as SmartRollupExecutePatternConfig,
 )
-from dipdup.config.tezos_tzkt_operations import OperationsHandlerTransactionPatternConfig as TransactionPatternConfig
-from dipdup.config.tezos_tzkt_operations import TzktOperationsIndexConfig
-from dipdup.config.tezos_tzkt_operations import TzktOperationsUnfilteredIndexConfig
+from dipdup.config.tezos_operations import TezosOperationsHandlerTransactionPatternConfig as TransactionPatternConfig
+from dipdup.config.tezos_operations import TezosOperationsIndexConfig
+from dipdup.config.tezos_operations import TezosOperationsUnfilteredIndexConfig
+from dipdup.datasources.tezos_tzkt import TezosTzktDatasource
 from dipdup.exceptions import ConfigurationError
 from dipdup.exceptions import FrameworkException
-from dipdup.fetcher import DataFetcher
 from dipdup.fetcher import FetcherChannel
-from dipdup.fetcher import FetcherFilterT
+from dipdup.fetcher import FilterT
 from dipdup.fetcher import readahead_by_level
 from dipdup.indexes.tezos_tzkt import TZKT_READAHEAD_LIMIT
-from dipdup.models.tezos_tzkt import TzktOperationData
-from dipdup.models.tezos_tzkt import TzktOperationType
+from dipdup.indexes.tezos_tzkt import TezosTzktFetcher
+from dipdup.models.tezos import TezosOperationData
+from dipdup.models.tezos import TezosOperationType
 
 if TYPE_CHECKING:
     from collections import defaultdict
     from collections import deque
     from collections.abc import AsyncIterator
 
-    from dipdup.datasources.tezos_tzkt import TzktDatasource
 
 _logger = logging.getLogger('dipdup.fetcher')
 
 
-def dedup_operations(operations: tuple[TzktOperationData, ...]) -> tuple[TzktOperationData, ...]:
+def dedup_operations(operations: tuple[TezosOperationData, ...]) -> tuple[TezosOperationData, ...]:
     """Merge and sort operations fetched from multiple endpoints"""
     return tuple(
         sorted(
             (({op.id: op for op in operations}).values()),
             key=lambda op: op.id,
         )
     )
 
 
-def get_operations_head(operations: tuple[TzktOperationData, ...]) -> int:
+def get_operations_head(operations: tuple[TezosOperationData, ...]) -> int:
     """Get latest block level (head) of sorted operations batch"""
     for i in range(len(operations) - 1)[::-1]:
         if operations[i].level != operations[i + 1].level:
             return operations[i].level
     return operations[0].level
 
 
 async def get_transaction_filters(
-    config: TzktOperationsIndexConfig,
-    datasource: TzktDatasource,
+    config: TezosOperationsIndexConfig,
 ) -> tuple[set[str], set[int]]:
     """Get addresses to fetch transactions from during initial synchronization"""
-    if TzktOperationType.transaction not in config.types:
+    if TezosOperationType.transaction not in config.types:
         return set(), set()
 
     code_hash: int | str | None
     addresses: set[str] = set()
     hashes: set[int] = set()
 
     # NOTE: Don't try to guess contracts from handlers if set implicitly
@@ -90,19 +90,19 @@
                 if code_hash := pattern_config.destination.resolved_code_hash:
                     hashes.add(code_hash)
 
     return addresses, hashes
 
 
 async def get_origination_filters(
-    config: TzktOperationsIndexConfig,
-    datasource: TzktDatasource,
+    config: TezosOperationsIndexConfig,
+    datasources: tuple[TezosTzktDatasource, ...],
 ) -> tuple[set[str], set[int]]:
     """Get addresses to fetch origination from during initial synchronization"""
-    if TzktOperationType.origination not in config.types:
+    if TezosOperationType.origination not in config.types:
         return set(), set()
 
     addresses: set[str] = set()
     hashes: set[int] = set()
 
     for handler_config in config.handlers:
         for pattern_config in handler_config.pattern:
@@ -117,27 +117,28 @@
 
             if pattern_config.source:
                 _logger.warning(
                     "`source.address` filter significantly hurts indexing performance and doesn't support strict"
                     " typing. Consider using `originated_contract.code_hash` instead"
                 )
                 if address := pattern_config.source.address:
+                    datasource = random.choice(datasources)
                     async for batch in datasource.iter_originated_contracts(address):
                         addresses.update(item['address'] for item in batch)
                 if code_hash := pattern_config.source.resolved_code_hash:
                     raise FrameworkException('Invalid transaction filter `source.code_hash`')
 
     return addresses, hashes
 
 
 async def get_sr_execute_filters(
-    config: TzktOperationsIndexConfig,
+    config: TezosOperationsIndexConfig,
 ) -> set[str]:
     """Get addresses to fetch smart rollup executions from during initial synchronization"""
-    if TzktOperationType.sr_execute not in config.types:
+    if TezosOperationType.sr_execute not in config.types:
         return set()
 
     addresses: set[str] = set()
 
     if config.contracts:
         for contract in config.contracts:
             if contract.address:
@@ -161,112 +162,111 @@
                     raise ConfigurationError('Invalid `sr_execute` filter: `destination.code_hash`')
 
     addresses = {a for a in addresses if a.startswith('sr1')}
     _logger.info('Fetching smart rollup executions from %s addresses', len(addresses))
     return addresses
 
 
-class OriginationAddressFetcherChannel(FetcherChannel[TzktOperationData, str]):
-    _datasource: TzktDatasource
+class OriginationAddressFetcherChannel(FetcherChannel[TezosOperationData, TezosTzktDatasource, str]):
 
     async def fetch(self) -> None:
         if not self._filter:
             self._head = self._last_level
             self._offset = self._last_level
             return
 
         # FIXME: No pagination because of URL length limit workaround
-        originations = await self._datasource.get_originations(
+        originations = await self.random_datasource.get_originations(
             addresses=self._filter,
             first_level=self._first_level,
             last_level=self._last_level,
         )
 
         for op in originations:
             self._buffer[op.level].append(op)
 
         self._head = self._last_level
         self._offset = self._last_level
 
 
-class OriginationHashFetcherChannel(FetcherChannel[TzktOperationData, int]):
-    _datasource: TzktDatasource
+class OriginationHashFetcherChannel(FetcherChannel[TezosOperationData, TezosTzktDatasource, int]):
 
     async def fetch(self) -> None:
         if not self._filter:
             self._head = self._last_level
             self._offset = self._last_level
             return
 
-        originations = await self._datasource.get_originations(
+        datasource = self.random_datasource
+        originations = await datasource.get_originations(
             code_hashes=self._filter,
             offset=self._offset,
             first_level=self._first_level,
             last_level=self._last_level,
         )
 
         for op in originations:
             self._buffer[op.level].append(op)
 
-        if len(originations) < self._datasource.request_limit:
+        if len(originations) < datasource.request_limit:
             self._head = self._last_level
         else:
             self._offset = originations[-1].id
             self._head = get_operations_head(originations)
 
 
-class MigrationOriginationFetcherChannel(FetcherChannel[TzktOperationData, None]):
-    _datasource: TzktDatasource
+class MigrationOriginationFetcherChannel(FetcherChannel[TezosOperationData, TezosTzktDatasource, None]):
 
     async def fetch(self) -> None:
         if self._filter:
             raise FrameworkException("Migration origination fetcher channel doesn't support filters")
 
-        originations = await self._datasource.get_migration_originations(
+        datasource = self.random_datasource
+        originations = await datasource.get_migration_originations(
             first_level=self._first_level,
             last_level=self._last_level,
             offset=self._offset,
         )
 
         for op in originations:
             if op.originated_contract_address:
-                code_hash, type_hash = await self._datasource.get_contract_hashes(op.originated_contract_address)
+                code_hash, type_hash = await datasource.get_contract_hashes(op.originated_contract_address)
                 op_dict = op.__dict__
                 op_dict.update(
                     originated_contract_code_hash=code_hash,
                     originated_contract_type_hash=type_hash,
                 )
-                op = TzktOperationData(**op_dict)
+                op = TezosOperationData(**op_dict)
 
             self._buffer[op.level].append(op)
 
-        if len(originations) < self._datasource.request_limit:
+        if len(originations) < datasource.request_limit:
             self._head = self._last_level
         else:
             self._offset = originations[-1].id
             self._head = get_operations_head(originations)
 
 
-class TransactionBaseFetcherChannel(FetcherChannel[TzktOperationData, FetcherFilterT], Generic[FetcherFilterT]):
-    _datasource: TzktDatasource
-
+class TransactionBaseFetcherChannel(FetcherChannel[TezosOperationData, TezosTzktDatasource, FilterT], Generic[FilterT]):
     def __init__(
         self,
-        buffer: defaultdict[int, deque[TzktOperationData]],
-        filter: set[FetcherFilterT],
+        buffer: defaultdict[int, deque[TezosOperationData]],
+        filter: set[FilterT],
         first_level: int,
         last_level: int,
-        datasource: TzktDatasource,
+        datasources: tuple[TezosTzktDatasource, ...],
         field: str,
     ) -> None:
-        super().__init__(buffer, filter, first_level, last_level, datasource)
+        super().__init__(buffer, filter, first_level, last_level, datasources)
         self._field = field
+        # FIXME: First datasource only
+        self._datasource = self._datasources[0]
 
     @abstractmethod
-    async def _get_transactions(self) -> tuple[TzktOperationData, ...]:
+    async def _get_transactions(self) -> tuple[TezosOperationData, ...]:
         raise NotImplementedError
 
     async def fetch(self) -> None:
         if not self._filter:
             self._head = self._last_level
             self._offset = self._last_level
             return
@@ -280,192 +280,192 @@
             self._head = self._last_level
         else:
             self._offset = transactions[-1].id
             self._head = get_operations_head(transactions)
 
 
 class TransactionAddressFetcherChannel(TransactionBaseFetcherChannel[str]):
-    async def _get_transactions(self) -> tuple[TzktOperationData, ...]:
+    async def _get_transactions(self) -> tuple[TezosOperationData, ...]:
         return await self._datasource.get_transactions(
             field=self._field,
             addresses=self._filter,
             code_hashes=None,
             offset=self._offset,
             first_level=self._first_level,
             last_level=self._last_level,
         )
 
 
 class TransactionHashFetcherChannel(TransactionBaseFetcherChannel[int]):
-    async def _get_transactions(self) -> tuple[TzktOperationData, ...]:
+    async def _get_transactions(self) -> tuple[TezosOperationData, ...]:
         return await self._datasource.get_transactions(
             field=self._field,
             addresses=None,
             code_hashes=self._filter,
             offset=self._offset,
             first_level=self._first_level,
             last_level=self._last_level,
         )
 
 
-class SmartRollupExecuteAddressFetcherChannel(FetcherChannel[TzktOperationData, str]):
-    _datasource: TzktDatasource
+class SmartRollupExecuteAddressFetcherChannel(FetcherChannel[TezosOperationData, TezosTzktDatasource, str]):
 
     def __init__(
         self,
-        buffer: defaultdict[int, deque[TzktOperationData]],
+        buffer: defaultdict[int, deque[TezosOperationData]],
         filter: set[str],
         first_level: int,
         last_level: int,
-        datasource: TzktDatasource,
+        datasources: tuple[TezosTzktDatasource, ...],
         field: str,
     ) -> None:
-        super().__init__(buffer, filter, first_level, last_level, datasource)
+        super().__init__(buffer, filter, first_level, last_level, datasources)
         self._field = field
 
     async def fetch(self) -> None:
         if not self._filter:
             self._head = self._last_level
             self._offset = self._last_level
             return
 
-        operations = await self._datasource.get_sr_execute(
+        datasource = self.random_datasource
+        operations = await datasource.get_sr_execute(
             field=self._field,
             addresses=self._filter,
             offset=self._offset,
             first_level=self._first_level,
             last_level=self._last_level,
         )
 
         for op in operations:
             self._buffer[op.level].append(op)
 
-        if len(operations) < self._datasource.request_limit:
+        if len(operations) < datasource.request_limit:
             self._head = self._last_level
         else:
             self._offset = operations[-1].id
             self._head = get_operations_head(operations)
 
 
-class OperationUnfilteredFetcherChannel(FetcherChannel[TzktOperationData, None]):
-    _datasource: TzktDatasource
+class OperationsUnfilteredFetcherChannel(FetcherChannel[TezosOperationData, TezosTzktDatasource, None]):
 
     def __init__(
         self,
-        buffer: defaultdict[int, deque[TzktOperationData]],
+        buffer: defaultdict[int, deque[TezosOperationData]],
         first_level: int,
         last_level: int,
-        datasource: TzktDatasource,
-        type: TzktOperationType,
+        datasources: tuple[TezosTzktDatasource, ...],
+        type: TezosOperationType,
     ) -> None:
-        super().__init__(buffer, set(), first_level, last_level, datasource)
+        super().__init__(buffer, set(), first_level, last_level, datasources)
         self._type = type
 
     async def fetch(self) -> None:
+        datasource = self.random_datasource
         match self._type:
-            case TzktOperationType.origination:
-                operations = await self._datasource.get_originations(
+            case TezosOperationType.origination:
+                operations = await datasource.get_originations(
                     addresses=None,
                     code_hashes=None,
                     first_level=self._first_level,
                     last_level=self._last_level,
                     offset=self._offset,
                 )
-            case TzktOperationType.transaction:
-                operations = await self._datasource.get_transactions(
+            case TezosOperationType.transaction:
+                operations = await datasource.get_transactions(
                     field='',
                     addresses=None,
                     code_hashes=None,
                     first_level=self._first_level,
                     last_level=self._last_level,
                     offset=self._offset,
                 )
-            case TzktOperationType.sr_execute:
-                operations = await self._datasource.get_sr_execute(
+            case TezosOperationType.sr_execute:
+                operations = await datasource.get_sr_execute(
                     field='',
                     addresses=None,
                     first_level=self._first_level,
                     last_level=self._last_level,
                     offset=self._offset,
                 )
             case _:
                 raise FrameworkException('Unsupported operation type')
 
         for op in operations:
             self._buffer[op.level].append(op)
 
-        if len(operations) < self._datasource.request_limit:
+        if len(operations) < datasource.request_limit:
             self._head = self._last_level
         else:
             self._offset = operations[-1].id
             self._head = get_operations_head(operations)
 
 
-class OperationFetcher(DataFetcher[TzktOperationData]):
+class OperationsFetcher(TezosTzktFetcher[TezosOperationData]):
     """Fetches operations from multiple REST API endpoints, merges them and yields by level.
 
     Offet of every endpoint is tracked separately.
     """
 
     def __init__(
         self,
-        datasource: TzktDatasource,
+        datasources: tuple[TezosTzktDatasource, ...],
         first_level: int,
         last_level: int,
         transaction_addresses: set[str],
         transaction_hashes: set[int],
         origination_addresses: set[str],
         origination_hashes: set[int],
         sr_execute_addresses: set[str],
         migration_originations: bool = False,
     ) -> None:
-        super().__init__(datasource, first_level, last_level)
+        super().__init__(datasources, first_level, last_level)
         self._transaction_addresses = transaction_addresses
         self._transaction_hashes = transaction_hashes
         self._origination_addresses = origination_addresses
         self._origination_hashes = origination_hashes
         self._sr_execute_addresses = sr_execute_addresses
         self._migration_originations = migration_originations
 
     @classmethod
     async def create(
         cls,
-        config: TzktOperationsIndexConfig,
-        datasource: TzktDatasource,
+        config: TezosOperationsIndexConfig,
+        datasources: tuple[TezosTzktDatasource, ...],
         first_level: int,
         last_level: int,
-    ) -> OperationFetcher:
-        transaction_addresses, transaction_hashes = await get_transaction_filters(config, datasource)
-        origination_addresses, origination_hashes = await get_origination_filters(config, datasource)
+    ) -> OperationsFetcher:
+        transaction_addresses, transaction_hashes = await get_transaction_filters(config)
+        origination_addresses, origination_hashes = await get_origination_filters(config, datasources)
         sr_execute_addresses = await get_sr_execute_filters(config)
 
-        return OperationFetcher(
-            datasource=datasource,
+        return OperationsFetcher(
+            datasources=datasources,
             first_level=first_level,
             last_level=last_level,
             transaction_addresses=transaction_addresses,
             transaction_hashes=transaction_hashes,
             origination_addresses=origination_addresses,
             origination_hashes=origination_hashes,
             sr_execute_addresses=sr_execute_addresses,
-            migration_originations=TzktOperationType.migration in config.types,
+            migration_originations=TezosOperationType.migration in config.types,
         )
 
-    async def fetch_by_level(self) -> AsyncIterator[tuple[int, tuple[TzktOperationData, ...]]]:
+    async def fetch_by_level(self) -> AsyncIterator[tuple[int, tuple[TezosOperationData, ...]]]:
         """Iterate over operations fetched with multiple REST requests with different filters.
 
-        Resulting data is split by level, deduped, sorted and ready to be processed by TzktOperationsIndex.
+        Resulting data is split by level, deduped, sorted and ready to be processed by TezosOperationsIndex.
         """
         channel_kwargs = {
             'buffer': self._buffer,
-            'datasource': self._datasource,
+            'datasources': self._datasources,
             'first_level': self._first_level,
             'last_level': self._last_level,
         }
-        channels: tuple[FetcherChannel[TzktOperationData, Any], ...] = (
+        channels: tuple[FetcherChannel[TezosOperationData, Any, Any], ...] = (
             TransactionAddressFetcherChannel(
                 filter=self._transaction_addresses,
                 field='sender',
                 **channel_kwargs,  # type: ignore[arg-type]
             ),
             TransactionAddressFetcherChannel(
                 filter=self._transaction_addresses,
@@ -499,16 +499,16 @@
                 filter=self._sr_execute_addresses,
                 field='rollup',
                 **channel_kwargs,  # type: ignore[arg-type]
             ),
         )
 
         async def _merged_iter(
-            merging_channels: tuple[FetcherChannel[TzktOperationData, Any], ...]
-        ) -> AsyncIterator[tuple[TzktOperationData, ...]]:
+            merging_channels: tuple[FetcherChannel[TezosOperationData, Any, Any], ...]
+        ) -> AsyncIterator[tuple[TezosOperationData, ...]]:
             while True:
                 min_channel = sorted(merging_channels, key=lambda x: x.head)[0]
                 await min_channel.fetch()
 
                 # NOTE: It's a different channel now, but with greater head level
                 next_min_channel = sorted(merging_channels, key=lambda x: x.head)[0]
                 next_min_head = next_min_channel.head
@@ -533,69 +533,69 @@
                 raise FrameworkException('Operations left in queue')
 
         event_iter = _merged_iter(channels)
         async for level, operations in readahead_by_level(event_iter, limit=TZKT_READAHEAD_LIMIT):
             yield level, operations
 
 
-class OperationUnfilteredFetcher(DataFetcher[TzktOperationData]):
+class OperationsUnfilteredFetcher(TezosTzktFetcher[TezosOperationData]):
     def __init__(
         self,
-        datasource: TzktDatasource,
+        datasources: tuple[TezosTzktDatasource, ...],
         first_level: int,
         last_level: int,
         transactions: bool,
         originations: bool,
         migration_originations: bool,
     ) -> None:
-        super().__init__(datasource, first_level, last_level)
+        super().__init__(datasources, first_level, last_level)
         self._transactions = transactions
         self._originations = originations
         self._migration_originations = migration_originations
 
     @classmethod
     async def create(
         cls,
-        config: TzktOperationsUnfilteredIndexConfig,
-        datasource: TzktDatasource,
+        config: TezosOperationsUnfilteredIndexConfig,
+        datasources: tuple[TezosTzktDatasource, ...],
         first_level: int,
         last_level: int,
-    ) -> OperationUnfilteredFetcher:
-        return OperationUnfilteredFetcher(
-            datasource=datasource,
+    ) -> OperationsUnfilteredFetcher:
+        return OperationsUnfilteredFetcher(
+            datasources=datasources,
             first_level=first_level,
             last_level=last_level,
-            transactions=TzktOperationType.transaction in config.types,
-            originations=TzktOperationType.origination in config.types,
-            migration_originations=TzktOperationType.migration in config.types,
+            transactions=TezosOperationType.transaction in config.types,
+            originations=TezosOperationType.origination in config.types,
+            migration_originations=TezosOperationType.migration in config.types,
         )
 
-    async def fetch_by_level(self) -> AsyncIterator[tuple[int, tuple[TzktOperationData, ...]]]:
+    async def fetch_by_level(self) -> AsyncIterator[tuple[int, tuple[TezosOperationData, ...]]]:
         """Iterate over operations fetched with multiple REST requests with different filters.
 
-        Resulting data is split by level, deduped, sorted and ready to be processed by TzktOperationsIndex.
+        Resulting data is split by level, deduped, sorted and ready to be processed by TezosOperationsIndex.
         """
         channel_kwargs = {
             'buffer': self._buffer,
-            'datasource': self._datasource,
+            'datasources': self._datasources,
             'first_level': self._first_level,
             'last_level': self._last_level,
         }
-        channels: tuple[FetcherChannel[TzktOperationData, Any], ...] = ()
+        channels: tuple[FetcherChannel[TezosOperationData, Any, Any], ...] = ()
         if self._transactions:
             channels += (
-                OperationUnfilteredFetcherChannel(
-                    type=TzktOperationType.transaction,
+                OperationsUnfilteredFetcherChannel(
+                    type=TezosOperationType.transaction,
                     **channel_kwargs,  # type: ignore[arg-type]
                 ),
             )
         if self._originations:
             channels += (
-                OperationUnfilteredFetcherChannel(
-                    type=TzktOperationType.origination,
+                OperationsUnfilteredFetcherChannel(
+                    type=TezosOperationType.origination,
                     **channel_kwargs,  # type: ignore[arg-type]
                 ),
             )
         if self._migration_originations:
             channels += (
                 MigrationOriginationFetcherChannel(
                     filter=set(),
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_operations/index.py` & `dipdup-8.0.0a1/src/dipdup/indexes/tezos_operations/index.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,62 +1,65 @@
 import logging
 from collections import defaultdict
 from collections import deque
 from collections.abc import Iterable
 from collections.abc import Iterator
 from collections.abc import Sequence
+from typing import TYPE_CHECKING
 from typing import Any
 
-from dipdup.config.tezos_tzkt_operations import OperationsHandlerOriginationPatternConfig as OriginationPatternConfig
-from dipdup.config.tezos_tzkt_operations import (
-    OperationsHandlerSmartRollupExecutePatternConfig as SmartRollupExecutePatternConfig,
+from dipdup.config.tezos_operations import TezosOperationsHandlerConfig
+from dipdup.config.tezos_operations import TezosOperationsHandlerConfigU
+from dipdup.config.tezos_operations import TezosOperationsHandlerOriginationPatternConfig as OriginationPatternConfig
+from dipdup.config.tezos_operations import (
+    TezosOperationsHandlerSmartRollupExecutePatternConfig as SmartRollupExecutePatternConfig,
 )
-from dipdup.config.tezos_tzkt_operations import OperationsHandlerTransactionPatternConfig as TransactionPatternConfig
-from dipdup.config.tezos_tzkt_operations import TzktOperationsHandlerConfig
-from dipdup.config.tezos_tzkt_operations import TzktOperationsHandlerConfigU
-from dipdup.config.tezos_tzkt_operations import TzktOperationsIndexConfig
-from dipdup.config.tezos_tzkt_operations import TzktOperationsIndexConfigU
-from dipdup.config.tezos_tzkt_operations import TzktOperationsUnfilteredIndexConfig
-from dipdup.context import DipDupContext
-from dipdup.datasources.tezos_tzkt import TzktDatasource
+from dipdup.config.tezos_operations import TezosOperationsHandlerTransactionPatternConfig as TransactionPatternConfig
+from dipdup.config.tezos_operations import TezosOperationsIndexConfig
+from dipdup.config.tezos_operations import TezosOperationsIndexConfigU
+from dipdup.config.tezos_operations import TezosOperationsUnfilteredIndexConfig
+from dipdup.datasources.tezos_tzkt import TezosTzktDatasource
 from dipdup.exceptions import ConfigInitializationException
 from dipdup.exceptions import FrameworkException
-from dipdup.indexes.tezos_tzkt import TzktIndex
-from dipdup.indexes.tezos_tzkt_operations.fetcher import OperationFetcher
-from dipdup.indexes.tezos_tzkt_operations.fetcher import OperationUnfilteredFetcher
-from dipdup.indexes.tezos_tzkt_operations.matcher import MatchedOperationsT
-from dipdup.indexes.tezos_tzkt_operations.matcher import OperationsHandlerArgumentU
-from dipdup.indexes.tezos_tzkt_operations.matcher import OperationSubgroup
-from dipdup.indexes.tezos_tzkt_operations.matcher import match_operation_subgroup
-from dipdup.indexes.tezos_tzkt_operations.matcher import match_operation_unfiltered_subgroup
+from dipdup.indexes.tezos_operations.fetcher import OperationsFetcher
+from dipdup.indexes.tezos_operations.fetcher import OperationsUnfilteredFetcher
+from dipdup.indexes.tezos_operations.matcher import MatchedOperationsT
+from dipdup.indexes.tezos_operations.matcher import OperationSubgroup
+from dipdup.indexes.tezos_operations.matcher import TezosOperationsHandlerArgumentU
+from dipdup.indexes.tezos_operations.matcher import match_operation_subgroup
+from dipdup.indexes.tezos_operations.matcher import match_operation_unfiltered_subgroup
+from dipdup.indexes.tezos_tzkt import TezosIndex
 from dipdup.models import RollbackMessage
-from dipdup.models.tezos_tzkt import DEFAULT_ENTRYPOINT
-from dipdup.models.tezos_tzkt import TzktMessageType
-from dipdup.models.tezos_tzkt import TzktOperationData
-from dipdup.performance import metrics
+from dipdup.models.tezos import DEFAULT_ENTRYPOINT
+from dipdup.models.tezos import TezosOperationData
+from dipdup.models.tezos_tzkt import TezosTzktMessageType
 from dipdup.prometheus import Metrics
 
+if TYPE_CHECKING:
+    from dipdup.context import DipDupContext
+
 _logger = logging.getLogger('dipdup.matcher')
 
+
 QueueItem = tuple[OperationSubgroup, ...] | RollbackMessage
 
 
-def entrypoint_filter(handlers: tuple[TzktOperationsHandlerConfig, ...]) -> set[str]:
+def entrypoint_filter(handlers: tuple[TezosOperationsHandlerConfig, ...]) -> set[str]:
     """Set of entrypoints to filter operations with before an actual matching"""
     entrypoints = set()
     for handler_config in handlers:
         for pattern_config in handler_config.pattern:
             if not isinstance(pattern_config, TransactionPatternConfig):
                 continue
             entrypoints.add(pattern_config.entrypoint or DEFAULT_ENTRYPOINT)
 
     return entrypoints
 
 
-def address_filter(handlers: tuple[TzktOperationsHandlerConfig, ...]) -> set[str]:
+def address_filter(handlers: tuple[TezosOperationsHandlerConfig, ...]) -> set[str]:
     """Set of addresses (any field) to filter operations with before an actual matching"""
     addresses = set()
     for handler_config in handlers:
         for pattern_config in handler_config.pattern:
             if isinstance(pattern_config, TransactionPatternConfig):
                 if pattern_config.source:
                     if address := pattern_config.source.address:
@@ -72,15 +75,15 @@
                 if pattern_config.destination:
                     if address := pattern_config.destination.address:
                         addresses.add(address)
 
     return addresses
 
 
-def code_hash_filter(handlers: tuple[TzktOperationsHandlerConfig, ...]) -> set[int]:
+def code_hash_filter(handlers: tuple[TezosOperationsHandlerConfig, ...]) -> set[int]:
     """Set of code hashes to filter operations with before an actual matching"""
     code_hashes: set[int] = set()
     for handler_config in handlers:
         for pattern_config in handler_config.pattern:
             if isinstance(pattern_config, TransactionPatternConfig):
                 if pattern_config.source:
                     if code_hash := pattern_config.source.resolved_code_hash:
@@ -97,22 +100,22 @@
                     if code_hash := pattern_config.originated_contract.resolved_code_hash:
                         code_hashes.add(code_hash)
 
     return code_hashes
 
 
 def extract_operation_subgroups(
-    operations: Iterable[TzktOperationData],
+    operations: Iterable[TezosOperationData],
     addresses: set[str],
     entrypoints: set[str],
     code_hashes: set[int],
 ) -> Iterator[OperationSubgroup]:
     filtered: int = 0
     levels: set[int] = set()
-    operation_subgroups: defaultdict[tuple[str, int], deque[TzktOperationData]] = defaultdict(deque)
+    operation_subgroups: defaultdict[tuple[str, int], deque[TezosOperationData]] = defaultdict(deque)
 
     _operation_index = -1
     for _operation_index, op in enumerate(operations):
         # NOTE: Filtering out operations that are not part of any index
         if op.type == 'transaction':
             entrypoint = op.entrypoint or DEFAULT_ENTRYPOINT
             if entrypoints and entrypoint not in entrypoints:
@@ -146,31 +149,31 @@
         yield OperationSubgroup(
             hash=hash_,
             counter=counter,
             operations=tuple(operations),
         )
 
 
-class TzktOperationsIndex(
-    TzktIndex[TzktOperationsIndexConfigU, QueueItem],
-    message_type=TzktMessageType.operation,
+class TezosOperationsIndex(
+    TezosIndex[TezosOperationsIndexConfigU, QueueItem],
+    message_type=TezosTzktMessageType.operation,
 ):
     def __init__(
         self,
-        ctx: DipDupContext,
-        config: TzktOperationsIndexConfigU,
-        datasource: TzktDatasource,
+        ctx: 'DipDupContext',
+        config: TezosOperationsIndexConfigU,
+        datasources: tuple[TezosTzktDatasource, ...],
     ) -> None:
-        super().__init__(ctx, config, datasource)
+        super().__init__(ctx, config, datasources)
         self._entrypoint_filter: set[str] = set()
         self._address_filter: set[str] = set()
         self._code_hash_filter: set[int] = set()
 
     async def get_filters(self) -> tuple[set[str], set[str], set[int]]:
-        if isinstance(self._config, TzktOperationsUnfilteredIndexConfig):
+        if isinstance(self._config, TezosOperationsUnfilteredIndexConfig):
             return set(), set(), set()
 
         if self._entrypoint_filter or self._address_filter or self._code_hash_filter:
             return self._entrypoint_filter, self._address_filter, self._code_hash_filter
 
         for code_hash in code_hash_filter(self._config.handlers):
             self._code_hash_filter.add(code_hash)
@@ -201,26 +204,28 @@
                 continue
 
             await self._process_level_operations(message, message_level)
 
         else:
             Metrics.set_levels_to_realtime(self._config.name, 0)
 
-    async def _create_fetcher(self, first_level: int, sync_level: int) -> OperationFetcher | OperationUnfilteredFetcher:
-        if isinstance(self._config, TzktOperationsIndexConfig):
-            return await OperationFetcher.create(
+    async def _create_fetcher(
+        self, first_level: int, sync_level: int
+    ) -> OperationsFetcher | OperationsUnfilteredFetcher:
+        if isinstance(self._config, TezosOperationsIndexConfig):
+            return await OperationsFetcher.create(
                 self._config,
-                self._datasource,
+                self._datasources,
                 first_level,
                 sync_level,
             )
-        if isinstance(self._config, TzktOperationsUnfilteredIndexConfig):
-            return await OperationUnfilteredFetcher.create(
+        if isinstance(self._config, TezosOperationsUnfilteredIndexConfig):
+            return await OperationsUnfilteredFetcher.create(
                 self._config,
-                self._datasource,
+                self._datasources,
                 first_level,
                 sync_level,
             )
         raise NotImplementedError
 
     async def _synchronize(self, sync_level: int) -> None:
         """Fetch operations via Fetcher and pass to message callback"""
@@ -263,16 +268,15 @@
         index_level = self.state.level
         if batch_level <= index_level:
             raise FrameworkException(f'Batch level is lower than index level: {batch_level} <= {index_level}')
 
         self._logger.debug('Processing %s operation subgroups of level %s', len(operation_subgroups), batch_level)
         matched_handlers: deque[MatchedOperationsT] = deque()
         for operation_subgroup in operation_subgroups:
-            metrics.objects_indexed += len(operation_subgroup.operations)
-            if isinstance(self._config, TzktOperationsUnfilteredIndexConfig):
+            if isinstance(self._config, TezosOperationsUnfilteredIndexConfig):
                 subgroup_handlers = match_operation_unfiltered_subgroup(
                     index=self._config,
                     operation_subgroup=operation_subgroup,
                 )
             else:
                 subgroup_handlers = match_operation_subgroup(
                     self._ctx.package,
@@ -290,36 +294,33 @@
             matched_handlers += subgroup_handlers
 
         Metrics.set_index_handlers_matched(len(matched_handlers))
 
         # NOTE: We still need to bump index level but don't care if it will be done in existing transaction
         if not matched_handlers:
             await self._update_state(level=batch_level)
-            metrics.levels_nonempty += 1
             return
 
         async with self._ctx.transactions.in_transaction(batch_level, sync_level, self.name):
             for operation_subgroup, handler_config, args in matched_handlers:
                 await self._call_matched_handler(handler_config, (operation_subgroup, args))
             await self._update_state(level=batch_level)
-            metrics.levels_nonempty += 1
 
     async def _call_matched_handler(
         self,
-        handler_config: TzktOperationsHandlerConfigU,
-        level_data: tuple[OperationSubgroup, Sequence[OperationsHandlerArgumentU]],
+        handler_config: TezosOperationsHandlerConfigU,
+        level_data: tuple[OperationSubgroup, Sequence[TezosOperationsHandlerArgumentU]],
     ) -> None:
         operation_subgroup, args = level_data
         if not handler_config.parent:
             raise ConfigInitializationException
 
         await self._ctx.fire_handler(
             handler_config.callback,
             handler_config.parent.name,
-            self.datasource,
             operation_subgroup.hash + ': {}',
             *args,
         )
 
     # FIXME: Use method from Index
     def _match_level_data(self, handlers: Any, level_data: Any) -> deque[Any]:
         raise NotImplementedError
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_operations/matcher.py` & `dipdup-8.0.0a1/src/dipdup/indexes/tezos_operations/matcher.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,59 +1,64 @@
+from __future__ import annotations
+
 import logging
 from collections import deque
-from collections.abc import Iterable
+from typing import TYPE_CHECKING
 from typing import Any
 
 from pydantic.dataclasses import dataclass
 
-from dipdup.codegen.tezos_tzkt import get_parameter_type
-from dipdup.codegen.tezos_tzkt import get_storage_type
-from dipdup.config.tezos_tzkt_operations import OperationsHandlerOriginationPatternConfig as OriginationPatternConfig
-from dipdup.config.tezos_tzkt_operations import (
-    OperationsHandlerSmartRollupExecutePatternConfig as SmartRollupExecutePatternConfig,
+from dipdup.codegen.tezos import get_parameter_type
+from dipdup.codegen.tezos import get_storage_type
+from dipdup.config.tezos_operations import TezosOperationsHandlerConfig
+from dipdup.config.tezos_operations import TezosOperationsHandlerConfigU
+from dipdup.config.tezos_operations import TezosOperationsHandlerOriginationPatternConfig as OriginationPatternConfig
+from dipdup.config.tezos_operations import (
+    TezosOperationsHandlerSmartRollupExecutePatternConfig as SmartRollupExecutePatternConfig,
 )
-from dipdup.config.tezos_tzkt_operations import OperationsHandlerTransactionPatternConfig as TransactionPatternConfig
-from dipdup.config.tezos_tzkt_operations import TzktOperationsHandlerConfig
-from dipdup.config.tezos_tzkt_operations import TzktOperationsHandlerConfigU
-from dipdup.config.tezos_tzkt_operations import TzktOperationsUnfilteredIndexConfig
+from dipdup.config.tezos_operations import TezosOperationsHandlerTransactionPatternConfig as TransactionPatternConfig
+from dipdup.config.tezos_operations import TezosOperationsUnfilteredIndexConfig
 from dipdup.exceptions import FrameworkException
-from dipdup.indexes.tezos_tzkt_operations.parser import deserialize_storage
-from dipdup.models.tezos_tzkt import TzktOperationData
-from dipdup.models.tezos_tzkt import TzktOperationType
-from dipdup.models.tezos_tzkt import TzktOrigination
-from dipdup.models.tezos_tzkt import TzktSmartRollupExecute
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.indexes.tezos_operations.parser import deserialize_storage
+from dipdup.models.tezos import TezosOperationData
+from dipdup.models.tezos import TezosOperationType
+from dipdup.models.tezos import TezosOrigination
+from dipdup.models.tezos import TezosSmartRollupExecute
+from dipdup.models.tezos import TezosTransaction
 from dipdup.package import DipDupPackage
 from dipdup.utils import parse_object
 
+if TYPE_CHECKING:
+    from collections.abc import Iterable
+
 _logger = logging.getLogger('dipdup.matcher')
 
 
 @dataclass(frozen=True)
 class OperationSubgroup:
     """Operations of a single contract call"""
 
     hash: str
     counter: int
-    operations: tuple[TzktOperationData, ...]
+    operations: tuple[TezosOperationData, ...]
 
 
-OperationsHandlerArgumentU = (
-    TzktTransaction[Any, Any] | TzktOrigination[Any] | TzktSmartRollupExecute | TzktOperationData | None
+TezosOperationsHandlerArgumentU = (
+    TezosTransaction[Any, Any] | TezosOrigination[Any] | TezosSmartRollupExecute | TezosOperationData | None
 )
-MatchedOperationsT = tuple[OperationSubgroup, TzktOperationsHandlerConfigU, deque[OperationsHandlerArgumentU]]
+MatchedOperationsT = tuple[OperationSubgroup, TezosOperationsHandlerConfigU, deque[TezosOperationsHandlerArgumentU]]
 
 
 def prepare_operation_handler_args(
     package: DipDupPackage,
-    handler_config: TzktOperationsHandlerConfig,
-    matched_operations: deque[TzktOperationData | None],
-) -> deque[OperationsHandlerArgumentU]:
+    handler_config: TezosOperationsHandlerConfig,
+    matched_operations: deque[TezosOperationData | None],
+) -> deque[TezosOperationsHandlerArgumentU]:
     """Prepare handler arguments, parse parameter and storage."""
-    args: deque[OperationsHandlerArgumentU] = deque()
+    args: deque[TezosOperationsHandlerArgumentU] = deque()
     # NOTE: There can be more pattern items than matched operations; some of them are optional.
     for pattern_config, operation_data in zip(handler_config.pattern, matched_operations, strict=False):
         if operation_data is None:
             args.append(None)
 
         elif isinstance(pattern_config, TransactionPatternConfig):
             if not pattern_config.typed_contract or not pattern_config.entrypoint:
@@ -63,15 +68,15 @@
             typename = pattern_config.typed_contract.module_name
             type_ = get_parameter_type(package, typename, pattern_config.entrypoint)
             parameter = parse_object(type_, operation_data.parameter_json) if type_ else None
 
             storage_type = get_storage_type(package, typename)
             operation_data, storage = deserialize_storage(operation_data, storage_type)
 
-            typed_transaction: TzktTransaction[Any, Any] = TzktTransaction(
+            typed_transaction: TezosTransaction[Any, Any] = TezosTransaction(
                 data=operation_data,
                 parameter=parameter,
                 storage=storage,
             )
             args.append(typed_transaction)
 
         elif isinstance(pattern_config, OriginationPatternConfig):
@@ -79,33 +84,33 @@
                 args.append(operation_data)
                 continue
 
             typename = pattern_config.typed_contract.module_name
             storage_type = get_storage_type(package, typename)
             operation_data, storage = deserialize_storage(operation_data, storage_type)
 
-            typed_origination = TzktOrigination(
+            typed_origination = TezosOrigination(
                 data=operation_data,
                 storage=storage,
             )
             args.append(typed_origination)
 
         elif isinstance(pattern_config, SmartRollupExecutePatternConfig):
-            sr_execute: TzktSmartRollupExecute = TzktSmartRollupExecute.create(operation_data)
+            sr_execute: TezosSmartRollupExecute = TezosSmartRollupExecute.create(operation_data)
             args.append(sr_execute)
 
         else:
             raise NotImplementedError
 
     return args
 
 
 def match_transaction(
     pattern_config: TransactionPatternConfig,
-    operation: TzktOperationData,
+    operation: TezosOperationData,
 ) -> bool:
     """Match a single transaction with pattern"""
     if entrypoint := pattern_config.entrypoint:
         if entrypoint != operation.entrypoint:
             return False
     if destination := pattern_config.destination:
         if destination.address not in (operation.target_address, None):
@@ -119,15 +124,15 @@
             return False
 
     return True
 
 
 def match_origination(
     pattern_config: OriginationPatternConfig,
-    operation: TzktOperationData,
+    operation: TezosOperationData,
 ) -> bool:
     if source := pattern_config.source:
         if source.address not in (operation.sender_address, None):
             return False
         if source.code_hash:
             raise FrameworkException('Invalid origination filter `source.code_hash`')
 
@@ -138,53 +143,53 @@
             return False
 
     return True
 
 
 def match_sr_execute(
     pattern_config: SmartRollupExecutePatternConfig,
-    operation: TzktOperationData,
+    operation: TezosOperationData,
 ) -> bool:
     if source := pattern_config.source:
         if source.address not in (operation.sender_address, None):
             return False
     if destination := pattern_config.destination:
         if destination.address not in (operation.target_address, None):
             return False
 
     return True
 
 
 def match_operation_unfiltered_subgroup(
-    index: TzktOperationsUnfilteredIndexConfig,
+    index: TezosOperationsUnfilteredIndexConfig,
     operation_subgroup: OperationSubgroup,
 ) -> deque[MatchedOperationsT]:
     matched_handlers: deque[MatchedOperationsT] = deque()
 
     for operation in operation_subgroup.operations:
-        if TzktOperationType[operation.type] in index.types:
-            matched_handlers.append((operation_subgroup, index.handler_config, deque([operation])))
+        if TezosOperationType[operation.type] in index.types:
+            matched_handlers.append((operation_subgroup, index.handlers[0], deque([operation])))
 
     return matched_handlers
 
 
 def match_operation_subgroup(
     package: DipDupPackage,
-    handlers: Iterable[TzktOperationsHandlerConfig],
+    handlers: Iterable[TezosOperationsHandlerConfig],
     operation_subgroup: OperationSubgroup,
     alt: bool = False,
 ) -> deque[MatchedOperationsT]:
     """Try to match operation subgroup with all index handlers."""
     matched_handlers: deque[MatchedOperationsT] = deque()
     operations = operation_subgroup.operations
 
     for handler_config in handlers:
         subgroup_index = 0
         pattern_index = 0
-        matched_operations: deque[TzktOperationData | None] = deque()
+        matched_operations: deque[TezosOperationData | None] = deque()
 
         # TODO: Ensure complex cases work, e.g. when optional argument is followed by required one
         while subgroup_index < len(operations):
             operation = operations[subgroup_index]
             pattern_config = handler_config.pattern[pattern_index]
 
             matched = False
@@ -229,21 +234,21 @@
         return matched_handlers
 
     # NOTE: Alternative algorithm. Sort matched handlers by the internal incremental TzKT id of the last operation in matched pattern.
     index_list = list(range(len(matched_handlers)))
     id_list = []
     for handler in matched_handlers:
         last_operation = handler[2][-1]
-        if isinstance(last_operation, TzktOperationData):
+        if isinstance(last_operation, TezosOperationData):
             id_list.append(last_operation.id)
-        elif isinstance(last_operation, TzktOrigination):
+        elif isinstance(last_operation, TezosOrigination):
             id_list.append(last_operation.data.id)
-        elif isinstance(last_operation, TzktTransaction):
+        elif isinstance(last_operation, TezosTransaction):
             id_list.append(last_operation.data.id)
-        elif isinstance(last_operation, TzktSmartRollupExecute):
+        elif isinstance(last_operation, TezosSmartRollupExecute):
             id_list.append(last_operation.data.id)
         else:
             raise FrameworkException('Type of the first handler argument is unknown')
 
     sorted_index_list = [x for _, x in sorted(zip(id_list, index_list, strict=True))]
     if index_list == sorted_index_list:
         return matched_handlers
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_operations/parser.py` & `dipdup-8.0.0a1/src/dipdup/indexes/tezos_operations/parser.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,90 +1,86 @@
 from collections.abc import Iterable
 from contextlib import suppress
 from functools import lru_cache
 from itertools import groupby
 from types import UnionType
 from typing import Any
+from typing import Optional
 from typing import TypeVar
 from typing import Union
 from typing import cast
 from typing import get_args
 from typing import get_origin
 
 from pydantic import BaseModel
-from pydantic import Extra
 
 from dipdup.exceptions import InvalidDataError
-from dipdup.models.tezos_tzkt import TzktOperationData
+from dipdup.models.tezos import TezosOperationData
 from dipdup.utils import parse_object
 
 StorageType = TypeVar('StorageType', bound=BaseModel)
 
 
 IntrospectionError = (KeyError, IndexError, AttributeError)
 
 
 def extract_root_outer_type(storage_type: type[BaseModel]) -> type[BaseModel]:
     """Extract Pydantic __root__ type"""
-    root_field = storage_type.__fields__['__root__']
-    if root_field.allow_none:
+    root_field = storage_type.model_fields['root']
+    if not root_field.is_required():
         # NOTE: Optional is a magic _SpecialForm
-        return cast(type[BaseModel], root_field.type_ | None)
+        return cast(type[BaseModel], Optional[root_field.annotation])  # noqa: UP007
 
-    return root_field.outer_type_  # type: ignore[no-any-return]
+    return root_field.annotation  # type: ignore[return-value]
 
 
 def is_array_type(storage_type: type[Any]) -> bool:
     """TzKT can return bigmaps as objects or as arrays of key-value objects. Guess it from storage type."""
     # NOTE: list[...]
     if get_origin(storage_type) == list:
         return True
 
-    # NOTE: Pydantic model with __root__ field subclassing List
+    # NOTE: Pydantic model with root field subclassing List
     with suppress(*IntrospectionError):
         root_type = extract_root_outer_type(storage_type)
         return is_array_type(root_type)
 
     # NOTE: Something else
     return False
 
 
 def get_list_elt_type(list_type: type[Any]) -> type[Any]:
     """Extract list item type from list type"""
     # NOTE: regular list
     if get_origin(list_type) == list:
         return get_args(list_type)[0]  # type: ignore[no-any-return]
 
-    # NOTE: Pydantic model with __root__ field subclassing List
+    # NOTE: Pydantic model with root field subclassing List
     root_type = extract_root_outer_type(list_type)
     return get_list_elt_type(root_type)
 
 
 def get_dict_value_type(dict_type: type[Any], key: str | None = None) -> type[Any]:
     """Extract dict value types from field type"""
     # NOTE: Regular dict
     if get_origin(dict_type) == dict:
         return get_args(dict_type)[1]  # type: ignore[no-any-return]
 
-    # NOTE: Pydantic model with __root__ field subclassing Dict
+    # NOTE: Pydantic model with root field subclassing Dict
     with suppress(*IntrospectionError):
         root_type = extract_root_outer_type(dict_type)
         return get_dict_value_type(root_type, key)
 
     if key is None:
         raise KeyError('Field name or alias is required for object introspection')
 
     # NOTE: Pydantic model, find corresponding field and return it's type
-    fields = dict_type.__fields__
-    for field in fields.values():
-        if key in (field.name, field.alias):
-            # NOTE: Pydantic does not preserve outer_type_ for Optional
-            if field.allow_none:
-                return cast(type[Any], field.type_ | None)
-            return field.outer_type_  # type: ignore[no-any-return]
+    for name, field in dict_type.model_fields.items():
+        if key in (name, field.alias):
+            return field.annotation  # type: ignore[no-any-return]
 
     # NOTE: Either we try the wrong Union path or model was modifier by user
     raise KeyError(f'Field `{key}` not found in {dict_type}')
 
 
 def unwrap_union_type(union_type: type[Any]) -> tuple[bool, tuple[type[Any], ...]]:
     """Check if the type is either optional or union and return arg types if so"""
@@ -155,47 +151,41 @@
     elif isinstance(storage, list):
         elt_type = get_list_elt_type(storage_type)
         for i, _ in enumerate(storage):
             storage[i] = _process_storage(storage[i], elt_type, bigmap_diffs)
 
     # NOTE: Dict, process recursively
     elif isinstance(storage, dict):
-        # NOTE: Ignore missing fields along with extra ones
-        ignore = getattr(getattr(storage_type, 'Config', None), 'extra', None) == Extra.ignore
-
         for key, value in storage.items():
-            try:
-                value_type = get_dict_value_type(storage_type, key)
-                storage[key] = _process_storage(value, value_type, bigmap_diffs)
-            except IntrospectionError:
-                if not ignore:
-                    raise
+            value_type = get_dict_value_type(storage_type, key)
+            storage[key] = _process_storage(value, value_type, bigmap_diffs)
+
     # NOTE: Leave others untouched
     else:
         pass
 
     return storage
 
 
 def deserialize_storage(
-    operation_data: TzktOperationData,
+    operation_data: TezosOperationData,
     storage_type: type[StorageType],
-) -> tuple[TzktOperationData, StorageType]:
+) -> tuple[TezosOperationData, StorageType]:
     """Merge big map diffs and deserialize raw storage into typeclass"""
     bigmap_diffs = _preprocess_bigmap_diffs(operation_data.diffs)
 
     try:
         # NOTE: op data is frozen, repack in-place 
         operation_data_dict = operation_data.__dict__
         operation_data_dict['storage'] = _process_storage(
             storage=operation_data_dict['storage'],
             storage_type=storage_type,
             bigmap_diffs=bigmap_diffs,
         )
-        operation_data = TzktOperationData(**operation_data_dict)
+        operation_data = TezosOperationData(**operation_data_dict)
         return operation_data, parse_object(storage_type, operation_data.storage)
     except IntrospectionError as e:
         raise InvalidDataError(e.args[0], storage_type, operation_data.storage) from e
 
 
 # NOTE: Very smol; no need to track in performance stats
 is_array_type = lru_cache(None)(is_array_type)  # type: ignore[assignment]
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_token_balances/index.py` & `dipdup-8.0.0a1/src/dipdup/indexes/tezos_token_balances/index.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 from collections import deque
 from typing import Any
 
-from dipdup.config.tezos_tzkt_token_balances import TzktTokenBalancesHandlerConfig
-from dipdup.config.tezos_tzkt_token_balances import TzktTokenBalancesIndexConfig
+from dipdup.config.tezos_token_balances import TezosTokenBalancesHandlerConfig
+from dipdup.config.tezos_token_balances import TezosTokenBalancesIndexConfig
 from dipdup.exceptions import ConfigInitializationException
-from dipdup.indexes.tezos_tzkt import TzktIndex
-from dipdup.indexes.tezos_tzkt_token_balances.matcher import match_token_balances
+from dipdup.indexes.tezos_token_balances.matcher import match_token_balances
+from dipdup.indexes.tezos_tzkt import TezosIndex
 from dipdup.models import RollbackMessage
-from dipdup.models.tezos_tzkt import TzktMessageType
-from dipdup.models.tezos_tzkt import TzktTokenBalanceData
+from dipdup.models.tezos import TezosTokenBalanceData
+from dipdup.models.tezos_tzkt import TezosTzktMessageType
 
-QueueItem = tuple[TzktTokenBalanceData, ...] | RollbackMessage
+QueueItem = tuple[TezosTokenBalanceData, ...] | RollbackMessage
 
 
-class TzktTokenBalancesIndex(
-    TzktIndex[TzktTokenBalancesIndexConfig, QueueItem],
-    message_type=TzktMessageType.token_balance,
+class TezosTokenBalancesIndex(
+    TezosIndex[TezosTokenBalancesIndexConfig, QueueItem],
+    message_type=TezosTzktMessageType.token_balance,
 ):
     async def _synchronize(self, sync_level: int) -> None:
         await self._enter_sync_state(sync_level)
         await self._synchronize_actual(sync_level)
         await self._exit_sync_state(sync_level)
 
     async def _synchronize_actual(self, head_level: int) -> None:
@@ -31,33 +31,32 @@
             if handler.contract and handler.contract.address is not None:
                 addresses.add(handler.contract.address)
             if handler.token_id is not None:
                 token_ids.add(handler.token_id)
 
         async with self._ctx.transactions.in_transaction(head_level, head_level, self.name):
             # NOTE: If index is out of date fetch balances as of the current head.
-            async for balances_batch in self._datasource.iter_token_balances(
+            async for balances_batch in self.random_datasource.iter_token_balances(
                 addresses, token_ids, last_level=head_level
             ):
                 matched_handlers = match_token_balances(self._config.handlers, balances_batch)
                 for handler_config, matched_balance_data in matched_handlers:
                     await self._call_matched_handler(handler_config, matched_balance_data)
 
             await self._update_state(level=head_level)
 
     async def _call_matched_handler(
-        self, handler_config: TzktTokenBalancesHandlerConfig, token_balance: TzktTokenBalanceData
+        self, handler_config: TezosTokenBalancesHandlerConfig, token_balance: TezosTokenBalanceData
     ) -> None:
         if not handler_config.parent:
             raise ConfigInitializationException
 
         await self._ctx.fire_handler(
             handler_config.callback,
             handler_config.parent.name,
-            self.datasource,
             # NOTE: missing `operation_id` field in API to identify operation
             None,
             token_balance,
         )
 
     def _match_level_data(self, handlers: Any, level_data: Any) -> deque[Any]:
         return match_token_balances(handlers, level_data)
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_token_transfers/fetcher.py` & `dipdup-8.0.0a1/src/dipdup/indexes/tezos_events/fetcher.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,47 +1,37 @@
 from __future__ import annotations
 
-import logging
 from typing import TYPE_CHECKING
 
-from dipdup.fetcher import DataFetcher
 from dipdup.fetcher import readahead_by_level
 from dipdup.indexes.tezos_tzkt import TZKT_READAHEAD_LIMIT
-from dipdup.models.tezos_tzkt import TzktTokenTransferData
+from dipdup.indexes.tezos_tzkt import TezosTzktFetcher
+from dipdup.models.tezos import TezosEventData
 
 if TYPE_CHECKING:
-    from collections.abc import AsyncIterator
+    from collections.abc import AsyncGenerator
 
-    from dipdup.datasources.tezos_tzkt import TzktDatasource
+    from dipdup.datasources.tezos_tzkt import TezosTzktDatasource
 
 
-class TokenTransferFetcher(DataFetcher[TzktTokenTransferData]):
-    _datasource: TzktDatasource
-
+class EventFetcher(TezosTzktFetcher[TezosEventData]):
     def __init__(
         self,
-        datasource: TzktDatasource,
-        token_addresses: set[str],
-        token_ids: set[int],
-        from_addresses: set[str],
-        to_addresses: set[str],
+        datasources: tuple[TezosTzktDatasource, ...],
         first_level: int,
         last_level: int,
+        event_addresses: set[str],
+        event_tags: set[str],
     ) -> None:
-        super().__init__(datasource, first_level, last_level)
-        self._logger = logging.getLogger('dipdup.fetcher')
-        self._token_addresses = token_addresses
-        self._token_ids = token_ids
-        self._from_addresses = from_addresses
-        self._to_addresses = to_addresses
-
-    async def fetch_by_level(self) -> AsyncIterator[tuple[int, tuple[TzktTokenTransferData, ...]]]:
-        token_transfer_iter = self._datasource.iter_token_transfers(
-            self._token_addresses,
-            self._token_ids,
-            self._from_addresses,
-            self._to_addresses,
+        super().__init__(datasources, first_level, last_level)
+        self._event_addresses = event_addresses
+        self._event_tags = event_tags
+
+    async def fetch_by_level(self) -> AsyncGenerator[tuple[int, tuple[TezosEventData, ...]], None]:
+        event_iter = self.random_datasource.iter_events(
+            self._event_addresses,
+            self._event_tags,
             self._first_level,
             self._last_level,
         )
-        async for level, batch in readahead_by_level(token_transfer_iter, limit=TZKT_READAHEAD_LIMIT):
+        async for level, batch in readahead_by_level(event_iter, limit=TZKT_READAHEAD_LIMIT):
             yield level, batch
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_token_transfers/index.py` & `dipdup-8.0.0a1/src/dipdup/indexes/tezos_token_transfers/index.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 from collections import deque
 from typing import Any
 
-from dipdup.config.tezos_tzkt_token_transfers import TzktTokenTransfersHandlerConfig
-from dipdup.config.tezos_tzkt_token_transfers import TzktTokenTransfersIndexConfig
+from dipdup.config.tezos_token_transfers import TezosTokenTransfersHandlerConfig
+from dipdup.config.tezos_token_transfers import TezosTokenTransfersIndexConfig
 from dipdup.exceptions import ConfigInitializationException
-from dipdup.indexes.tezos_tzkt import TzktIndex
-from dipdup.indexes.tezos_tzkt_token_transfers.fetcher import TokenTransferFetcher
-from dipdup.indexes.tezos_tzkt_token_transfers.matcher import match_token_transfers
+from dipdup.indexes.tezos_token_transfers.fetcher import TokenTransferFetcher
+from dipdup.indexes.tezos_token_transfers.matcher import match_token_transfers
+from dipdup.indexes.tezos_tzkt import TezosIndex
 from dipdup.models import RollbackMessage
-from dipdup.models.tezos_tzkt import TzktMessageType
-from dipdup.models.tezos_tzkt import TzktTokenTransferData
+from dipdup.models.tezos import TezosTokenTransferData
+from dipdup.models.tezos_tzkt import TezosTzktMessageType
 
-QueueItem = tuple[TzktTokenTransferData, ...] | RollbackMessage
+QueueItem = tuple[TezosTokenTransferData, ...] | RollbackMessage
 
 
-class TzktTokenTransfersIndex(
-    TzktIndex[TzktTokenTransfersIndexConfig, QueueItem],
-    message_type=TzktMessageType.token_transfer,
+class TezosTokenTransfersIndex(
+    TezosIndex[TezosTokenTransfersIndexConfig, QueueItem],
+    message_type=TezosTzktMessageType.token_transfer,
 ):
     def _create_fetcher(self, first_level: int, last_level: int) -> TokenTransferFetcher:
         token_addresses: set[str] = set()
         token_ids: set[int] = set()
         from_addresses: set[str] = set()
         to_addresses: set[str] = set()
         for handler_config in self._config.handlers:
@@ -30,15 +30,15 @@
                 token_ids.add(handler_config.token_id)
             if handler_config.from_:
                 from_addresses.add(handler_config.from_.get_address())
             if handler_config.to:
                 to_addresses.add(handler_config.to.get_address())
 
         return TokenTransferFetcher(
-            datasource=self._datasource,
+            datasources=self._datasources,
             token_addresses=token_addresses,
             token_ids=token_ids,
             from_addresses=from_addresses,
             to_addresses=to_addresses,
             first_level=first_level,
             last_level=last_level,
         )
@@ -55,23 +55,22 @@
 
         async for _, token_transfers in fetcher.fetch_by_level():
             await self._process_level_data(token_transfers, sync_level)
 
         await self._exit_sync_state(sync_level)
 
     async def _call_matched_handler(
-        self, handler_config: TzktTokenTransfersHandlerConfig, token_transfer: TzktTokenTransferData
+        self, handler_config: TezosTokenTransfersHandlerConfig, token_transfer: TezosTokenTransferData
     ) -> None:
         if not handler_config.parent:
             raise ConfigInitializationException
 
         await self._ctx.fire_handler(
             handler_config.callback,
             handler_config.parent.name,
-            self.datasource,
             # NOTE: missing `operation_id` field in API to identify operation
             None,
             token_transfer,
         )
 
     def _match_level_data(self, handlers: Any, level_data: Any) -> deque[Any]:
         return match_token_transfers(handlers, level_data)
```

### Comparing `dipdup-7.5.7/src/dipdup/indexes/tezos_tzkt_token_transfers/matcher.py` & `dipdup-8.0.0a1/src/dipdup/indexes/tezos_token_transfers/matcher.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 import logging
 from collections import deque
 from collections.abc import Iterable
 
-from dipdup.config.tezos_tzkt_token_transfers import TzktTokenTransfersHandlerConfig
-from dipdup.models.tezos_tzkt import TzktTokenTransferData
+from dipdup.config.tezos_token_transfers import TezosTokenTransfersHandlerConfig
+from dipdup.models.tezos import TezosTokenTransferData
 
 _logger = logging.getLogger('dipdup.matcher')
 
-MatchedTokenTransfersT = tuple[TzktTokenTransfersHandlerConfig, TzktTokenTransferData]
+MatchedTokenTransfersT = tuple[TezosTokenTransfersHandlerConfig, TezosTokenTransferData]
 
 
 def match_token_transfer(
-    handler_config: TzktTokenTransfersHandlerConfig,
-    token_transfer: TzktTokenTransferData,
+    handler_config: TezosTokenTransfersHandlerConfig,
+    token_transfer: TezosTokenTransferData,
 ) -> bool:
     """Match single token transfer with pattern"""
     if handler_config.contract:
         if handler_config.contract.address != token_transfer.contract_address:
             return False
     if handler_config.token_id is not None:
         if handler_config.token_id != token_transfer.token_id:
@@ -27,15 +27,15 @@
     if handler_config.to:
         if handler_config.to.address != token_transfer.to_address:
             return False
     return True
 
 
 def match_token_transfers(
-    handlers: Iterable[TzktTokenTransfersHandlerConfig], token_transfers: Iterable[TzktTokenTransferData]
+    handlers: Iterable[TezosTokenTransfersHandlerConfig], token_transfers: Iterable[TezosTokenTransferData]
 ) -> deque[MatchedTokenTransfersT]:
     """Try to match token transfers with all index handlers."""
 
     matched_handlers: deque[MatchedTokenTransfersT] = deque()
 
     for token_transfer in token_transfers:
         for handler_config in handlers:
```

### Comparing `dipdup-7.5.7/src/dipdup/install.py` & `dipdup-8.0.0a1/src/dipdup/install.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 """This script (un)installs DipDup and its dependencies with pipx.
 
 WARNING: No imports allowed here except stdlib! Otherwise, `curl | python` magic will break.
-And no 3.11-only code too. Just to print nice colored "not supported" message instead of crashing.
+And no 3.12-only code too. Just to print nice colored "not supported" message instead of crashing.
 
 Some functions are importable to use in `dipdup.cli`.
 This script is also available as `dipdup-install` or `python -m dipdup.install`.
 """
 
 import argparse
 import os
@@ -15,42 +15,49 @@
 from shutil import which
 from typing import Any
 from typing import NoReturn
 from typing import cast
 
 GITHUB = 'https://github.com/dipdup-io/dipdup.git'
 WHICH_CMDS = (
-    'python3.11',
+    'python3.12',
     'pipx',
     'dipdup',
     'pdm',
     'poetry',
     'pyvenv',
     'pyenv',
 )
 ENV_VARS = (
     'SHELL',
     'VIRTUAL_ENV',
     'PATH',
     'PYTHONPATH',
 )
 
-WELCOME_ASCII = """\0
+# NOTE: '\0' is to avoid truncating newlines by asyncclick
+WELCOME_ASCII = (
+    '\0'
+    + r"""
         ____   _         ____              
        / __ \ (_)____   / __ \ __  __ ____ 
-      / / / // // __ \ / / / // / / // __ \\
+      / / / // // __ \ / / / // / / // __ \
      / /_/ // // /_/ // /_/ // /_/ // /_/ /
     /_____//_// .___//_____/ \__,_// .___/ 
              /_/                  /_/      
 """
-EPILOG = """\0
+)
+EPILOG = (
+    '\0'
+    + """
 Documentation:         https://dipdup.io/docs
 GitHub:                https://github.com/dipdup-io/dipdup
 Discord:               https://discord.gg/aG8XKuwsQd
 """
+)
 
 
 class Colors:
     """ANSI color codes"""
 
     BLUE = '\033[34m'
     GREEN = '\033[92m'
@@ -142,27 +149,27 @@
                 **kwargs,
                 check=True,
             )
         except subprocess.CalledProcessError as e:
             fail(f'{cmd} failed: {e.cmd} {e.returncode}')
 
     def ensure_pipx(self) -> None:
-        if not sys.version.startswith('3.11'):
-            fail('DipDup requires Python 3.11')
+        if not sys.version.startswith('3.12'):
+            fail('DipDup requires Python 3.12')
 
         """Ensure pipx is installed for current user"""
         if self._commands.get('pipx'):
             return
 
         echo('Installing pipx')
         if sys.base_prefix != sys.prefix:
-            self.run_cmd('python3.11', '-m', 'pip', 'install', '-q', 'pipx')
+            self.run_cmd('python3.12', '-m', 'pip', 'install', '-q', 'pipx')
         else:
-            self.run_cmd('python3.11', '-m', 'pip', 'install', '--user', '-q', 'pipx')
-        self.run_cmd('python3.11', '-m', 'pipx', 'ensurepath')
+            self.run_cmd('python3.12', '-m', 'pip', 'install', '--user', '-q', 'pipx')
+        self.run_cmd('python3.12', '-m', 'pipx', 'ensurepath')
         pipx_path = str(Path.home() / '.local' / 'bin')
         os.environ['PATH'] = pipx_path + os.pathsep + os.environ['PATH']
         self._commands['pipx'] = which('pipx')
 
 
 def install(
     quiet: bool,
@@ -181,19 +188,19 @@
     env.prepare()
     if not quiet:
         env.print()
 
     force_str = '--force' if force else ''
     pipx_packages = env._pipx_packages
 
-    python_inter_pipx = cast(str, which('python3.11'))
+    python_inter_pipx = cast(str, which('python3.12'))
     if 'pyenv' in python_inter_pipx:
         python_inter_pipx = (
             subprocess.run(
-                ['pyenv', 'which', 'python3.11'],
+                ['pyenv', 'which', 'python3.12'],
                 capture_output=True,
                 text=True,
             )
             .stdout.strip()
             .split('\n')[0]
         )
```

### Comparing `dipdup-7.5.7/src/dipdup/models/__init__.py` & `dipdup-8.0.0a1/src/dipdup/models/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -45,24 +45,24 @@
 # NOTE: Skip expensive copy() calls on each queryset update. Doesn't affect us. Definitely will be in Kleinmann officially.
 tortoise.queryset.QuerySet._clone = lambda self: self  # type: ignore[method-assign]
 
 
 class IndexType(Enum):
     """Enum for `dipdup.models.Index`"""
 
-    evm_subsquid_events = 'evm.subsquid.events'
-    evm_subsquid_transactions = 'evm.subsquid.transactions'
-    evm_subsquid_traces = 'evm.subsquid.traces'
-    tezos_tzkt_big_maps = 'tezos.tzkt.big_maps'
-    tezos_tzkt_events = 'tezos.tzkt.events'
-    tezos_tzkt_head = 'tezos.tzkt.head'
-    tezos_tzkt_operations = 'tezos.tzkt.operations'
-    tezos_tzkt_operations_unfiltered = 'tezos.tzkt.operations_unfiltered'
-    tezos_tzkt_token_transfers = 'tezos.tzkt.token_transfers'
-    tezos_tzkt_token_balances = 'tezos.tzkt.token_balances'
+    evm_events = 'evm.events'
+    evm_transactions = 'evm.transactions'
+    evm_subsquid_traces = 'evm.traces'
+    tezos_big_maps = 'tezos.big_maps'
+    tezos_events = 'tezos.events'
+    tezos_head = 'tezos.head'
+    tezos_operations = 'tezos.operations'
+    tezos_operations_unfiltered = 'tezos.operations_unfiltered'
+    tezos_token_transfers = 'tezos.token_transfers'
+    tezos_token_balances = 'tezos.token_balances'
 
 
 class MessageType:
     value: str
 
 
 @dataclass(frozen=True)
@@ -304,27 +304,27 @@
         for model in models:
             if update := ModelUpdate.from_model(model, ModelUpdateAction.DELETE):
                 get_pending_updates().append(update)
 
         return await super()._execute()
 
 
-class BulkUpdateQuery(TortoiseBulkUpdateQuery):
+class BulkUpdateQuery(TortoiseBulkUpdateQuery):  # type: ignore[type-arg]
     async def _execute(self) -> int:
         for model in self.objects:
             if update := ModelUpdate.from_model(
                 cast(Model, model),
                 ModelUpdateAction.UPDATE,
             ):
                 get_pending_updates().append(update)
 
         return await super()._execute()
 
 
-class BulkCreateQuery(TortoiseBulkCreateQuery):
+class BulkCreateQuery(TortoiseBulkCreateQuery):  # type: ignore[type-arg]
     async def _execute(self) -> list[MODEL]:
         for model in self.objects:
             if update := ModelUpdate.from_model(
                 cast(Model, model),
                 ModelUpdateAction.INSERT,
             ):
                 get_pending_updates().append(update)
```

### Comparing `dipdup-7.5.7/src/dipdup/models/evm_node.py` & `dipdup-8.0.0a1/src/dipdup/models/evm.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,204 +1,201 @@
 from abc import ABC
+from dataclasses import dataclass
 from typing import Any
-from typing import Literal
+from typing import Generic
+from typing import Self
+from typing import TypeVar
 
-from pydantic.dataclasses import dataclass
+from pydantic import BaseModel
 
 from dipdup.fetcher import HasLevel
-from dipdup.subscriptions import Subscription
-
-
-class EvmNodeSubscription(ABC, Subscription):
-    name: str
-
-    def get_params(self) -> list[Any]:
-        return [self.name]
-
-
-@dataclass(frozen=True)
-class EvmNodeHeadSubscription(EvmNodeSubscription):
-    name: Literal['newHeads'] = 'newHeads'
-    transactions: bool = False
-
-
-@dataclass(frozen=True)
-class EvmNodeLogsSubscription(EvmNodeSubscription):
-    name: Literal['logs'] = 'logs'
-    address: str | tuple[str, ...] | None = None
-    topics: tuple[tuple[str, ...], ...] | None = None
-
-    def get_params(self) -> list[Any]:
-        return [
-            *super().get_params(),
-            {'address': self.address, 'topics': self.topics},
-        ]
 
 
 @dataclass(frozen=True)
-class EvmNodeSyncingSubscription(EvmNodeSubscription):
-    name: Literal['syncing'] = 'syncing'
-
-
-@dataclass(frozen=True)
-class EvmNodeHeadData(HasLevel):
-    base_fee_per_gas: int
-    difficulty: int
-    extra_data: str
-    gas_limit: int
-    gas_used: int
-    hash: str
-    level: int
-    logs_bloom: str
-    miner: str
-    mix_hash: str
-    nonce: str
-    number: int
-    parent_hash: str
-    receipts_root: str
-    sha3_uncles: str
-    state_root: str
-    timestamp: int
-    transactions_root: str
-    withdrawals_root: str | None
-
-    @classmethod
-    def from_json(cls, block_json: dict[str, Any]) -> 'EvmNodeHeadData':
-        # NOTE: Skale Nebula
-        if 'baseFeePerGas' not in block_json:
-            block_json['baseFeePerGas'] = '0x0'
-
-        return cls(
-            base_fee_per_gas=int(block_json['baseFeePerGas'], 16),
-            difficulty=int(block_json['difficulty'], 16),
-            extra_data=block_json['extraData'],
-            gas_limit=int(block_json['gasLimit'], 16),
-            gas_used=int(block_json['gasUsed'], 16),
-            hash=block_json['hash'],
-            level=int(block_json['number'], 16),
-            logs_bloom=block_json['logsBloom'],
-            miner=block_json['miner'],
-            mix_hash=block_json['mixHash'],
-            nonce=block_json['nonce'],
-            number=int(block_json['number'], 16),
-            parent_hash=block_json['parentHash'],
-            receipts_root=block_json['receiptsRoot'],
-            sha3_uncles=block_json['sha3Uncles'],
-            state_root=block_json['stateRoot'],
-            timestamp=int(block_json['timestamp'], 16),
-            transactions_root=block_json['transactionsRoot'],
-            withdrawals_root=block_json.get('withdrawalsRoot', None),
-        )
-
-
-@dataclass(frozen=True)
-class EvmNodeLogData(HasLevel):
+class EvmEventData(HasLevel):
     address: str
     block_hash: str
     data: str
     level: int
     log_index: int
+    removed: bool
+    timestamp: int
     topics: tuple[str, ...]
     transaction_hash: str
     transaction_index: int
-    removed: bool
-
-    timestamp: int
 
     @classmethod
-    def from_json(cls, log_json: dict[str, Any], timestamp: int) -> 'EvmNodeLogData':
+    def from_node_json(cls, event_json: dict[str, Any], timestamp: int) -> 'EvmEventData':
         # NOTE: Skale Nebula
-        if 'removed' not in log_json:
-            log_json['removed'] = False
+        if 'removed' not in event_json:
+            event_json['removed'] = False
 
         return cls(
-            address=log_json['address'],
-            block_hash=log_json['blockHash'],
-            data=log_json['data'],
-            level=int(log_json['blockNumber'], 16),
-            log_index=int(log_json['logIndex'], 16),
-            topics=log_json['topics'],
-            transaction_hash=log_json['transactionHash'],
-            transaction_index=int(log_json['transactionIndex'], 16),
-            removed=log_json['removed'],
+            address=event_json['address'],
+            block_hash=event_json['blockHash'],
+            data=event_json['data'],
+            level=int(event_json['blockNumber'], 16),
+            log_index=int(event_json['logIndex'], 16),
+            topics=event_json['topics'],
+            transaction_hash=event_json['transactionHash'],
+            transaction_index=int(event_json['transactionIndex'], 16),
+            removed=event_json['removed'],
             timestamp=timestamp,
         )
 
-
-@dataclass(frozen=True)
-class EvmNodeTraceData(HasLevel): ...
+    @classmethod
+    def from_subsquid_json(cls, event_json: dict[str, Any], header: dict[str, Any]) -> Self:
+        return cls(
+            address=event_json['address'],
+            block_hash=header['hash'],
+            data=event_json['data'],
+            level=header['number'],
+            log_index=event_json['logIndex'],
+            timestamp=header['timestamp'],
+            topics=tuple(event_json['topics']),
+            removed=False,
+            transaction_hash=event_json['transactionHash'],
+            transaction_index=event_json['transactionIndex'],
+        )
 
 
 @dataclass(frozen=True)
-class EvmNodeTransactionData(HasLevel):
+class EvmTransactionData(HasLevel, ABC):
     access_list: tuple[dict[str, Any], ...] | None
     block_hash: str
     chain_id: int | None
-    data: str | None
+    contract_address: str | None
+    cumulative_gas_used: int | None
+    effective_gas_price: int | None
     from_: str
     gas: int
     gas_price: int
+    gas_used: int | None
     hash: str
     input: str
     level: int
     max_fee_per_gas: int | None
     max_priority_fee_per_gas: int | None
     nonce: int
     r: str | None
     s: str | None
+    status: int | None
     timestamp: int
     to: str | None
+    # FIXME: Missing in some nodes. Which ones?
     transaction_index: int | None
     type: int | None
+    # FIXME: Missing in some nodes. Which ones?
     value: int | None
     v: int | None
+    y_parity: bool | None
 
     @property
     def sighash(self) -> str:
         return self.input[:10]
 
     @classmethod
-    def from_json(cls, transaction_json: dict[str, Any], timestamp: int) -> 'EvmNodeTransactionData':
+    def from_node_json(
+        cls,
+        transaction_json: dict[str, Any],
+        timestamp: int,
+    ) -> Self:
         return cls(
             access_list=tuple(transaction_json['accessList']) if 'accessList' in transaction_json else None,
             block_hash=transaction_json['blockHash'],
             chain_id=int(transaction_json['chainId'], 16) if 'chainId' in transaction_json else None,
-            data=transaction_json.get('data'),
+            contract_address=None,
+            cumulative_gas_used=None,
+            effective_gas_price=None,
             from_=transaction_json['from'],
             gas=int(transaction_json['gas'], 16),
             gas_price=int(transaction_json['gasPrice'], 16),
+            gas_used=None,
             hash=transaction_json['hash'],
             input=transaction_json['input'],
             level=int(transaction_json['blockNumber'], 16),
             max_fee_per_gas=int(transaction_json['maxFeePerGas'], 16) if 'maxFeePerGas' in transaction_json else None,
             max_priority_fee_per_gas=(
                 int(transaction_json['maxPriorityFeePerGas'], 16)
                 if 'maxPriorityFeePerGas' in transaction_json
                 else None
             ),
             nonce=int(transaction_json['nonce'], 16),
             r=transaction_json.get('r'),
             s=transaction_json.get('s'),
+            status=1,
             timestamp=timestamp,
             to=transaction_json.get('to'),
             transaction_index=(
                 int(transaction_json['transactionIndex'], 16) if 'transactionIndex' in transaction_json else None
             ),
             type=int(transaction_json['type'], 16) if 'type' in transaction_json else None,
             value=int(transaction_json['value'], 16) if 'value' in transaction_json else None,
             v=int(transaction_json['v'], 16) if 'v' in transaction_json else None,
+            y_parity=None,
         )
 
-
-@dataclass(frozen=True)
-class EvmNodeSyncingData:
-    current_block: int
-    highest_block: int
-    starting_block: int
-
     @classmethod
-    def from_json(cls, syncing_json: dict[str, Any]) -> 'EvmNodeSyncingData':
+    def from_subsquid_json(
+        cls,
+        transaction_json: dict[str, Any],
+        header: dict[str, Any],
+    ) -> Self:
+        cumulative_gas_used = (
+            int(transaction_json['cumulativeGasUsed'], 16) if transaction_json['cumulativeGasUsed'] else None
+        )
+        effective_gas_price = (
+            int(transaction_json['effectiveGasPrice'], 16) if transaction_json['effectiveGasPrice'] else None
+        )
+        max_fee_per_gas = int(transaction_json['maxFeePerGas'], 16) if transaction_json['maxFeePerGas'] else None
+        max_priority_fee_per_gas = (
+            int(transaction_json['maxPriorityFeePerGas'], 16) if transaction_json['maxPriorityFeePerGas'] else None
+        )
+        v = int(transaction_json['v'], 16) if transaction_json['v'] else None
+        y_parity = bool(int(transaction_json['yParity'], 16)) if transaction_json['yParity'] else None
         return cls(
-            current_block=int(syncing_json['currentBlock'], 16),
-            highest_block=int(syncing_json['highestBlock'], 16),
-            starting_block=int(syncing_json['startingBlock'], 16),
+            # FIXME: 500
+            # access_list=tuple(transaction_json['accessList']) if transaction_json['accessList'] else None,
+            access_list=None,
+            block_hash=header['hash'],
+            chain_id=transaction_json['chainId'],
+            contract_address=transaction_json['contractAddress'],
+            cumulative_gas_used=cumulative_gas_used,
+            effective_gas_price=effective_gas_price,
+            from_=transaction_json['from'],
+            gas=int(transaction_json['gas'], 16),
+            gas_price=int(transaction_json['gasPrice'], 16),
+            gas_used=int(transaction_json['gasUsed'], 16),
+            hash=transaction_json['hash'],
+            input=transaction_json['input'],
+            level=header['number'],
+            max_fee_per_gas=max_fee_per_gas,
+            max_priority_fee_per_gas=max_priority_fee_per_gas,
+            nonce=transaction_json['nonce'],
+            r=transaction_json['r'],
+            s=transaction_json['s'],
+            # sighash=transaction_json['sighash'],
+            status=transaction_json['status'],
+            timestamp=header['timestamp'],
+            to=transaction_json['to'],
+            transaction_index=transaction_json['transactionIndex'],
+            type=transaction_json['type'],
+            value=int(transaction_json['value'], 16),
+            v=v,
+            y_parity=y_parity,
         )
+
+
+PayloadT = TypeVar('PayloadT', bound=BaseModel)
+InputT = TypeVar('InputT', bound=BaseModel)
+
+
+@dataclass(frozen=True)
+class EvmEvent(Generic[PayloadT]):
+    data: EvmEventData
+    payload: PayloadT
+
+
+@dataclass(frozen=True)
+class EvmTransaction(Generic[InputT]):
+    data: EvmTransactionData
+    input: InputT
```

### Comparing `dipdup-7.5.7/src/dipdup/models/tezos_tzkt.py` & `dipdup-8.0.0a1/src/dipdup/models/tezos.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,191 +1,56 @@
-from abc import abstractmethod
 from datetime import UTC
 from datetime import datetime
 from decimal import Decimal
 from enum import Enum
 from typing import Any
 from typing import Generic
-from typing import Literal
 from typing import TypeVar
 
 from pydantic import BaseModel
 from pydantic import Field
 from pydantic.dataclasses import dataclass
 
-from dipdup.exceptions import FrameworkException
 from dipdup.fetcher import HasLevel
-from dipdup.models import MessageType
-from dipdup.subscriptions import Subscription
 
 DEFAULT_ENTRYPOINT = 'default'
 
 ParameterType = TypeVar('ParameterType', bound=BaseModel)
 StorageType = TypeVar('StorageType', bound=BaseModel)
 KeyType = TypeVar('KeyType', bound=BaseModel)
 ValueType = TypeVar('ValueType', bound=BaseModel)
 EventType = TypeVar('EventType', bound=BaseModel)
 
 
 def _parse_timestamp(timestamp: str) -> datetime:
     return datetime.fromisoformat(timestamp[:-1]).replace(tzinfo=UTC)
 
 
-class TzktTokenStandard(Enum):
+class TezosTokenStandard(Enum):
     FA12 = 'fa1.2'
     FA2 = 'fa2'
 
 
-class TzktOperationType(Enum):
+class TezosOperationType(Enum):
     """Type of blockchain operation
 
     :param transaction: transaction
     :param origination: origination
     :param migration: migration
     :param sr_execute: sr_execute
     """
 
     transaction = 'transaction'
     origination = 'origination'
     migration = 'migration'
     sr_execute = 'sr_execute'
 
 
-class TzktMessageType(MessageType, Enum):
-    """Enum for realtime message types"""
-
-    operation = 'operation'
-    big_map = 'big_map'
-    head = 'head'
-    token_transfer = 'token_transfer'
-    token_balance = 'token_balance'
-    event = 'event'
-
-
-class TzktSubscription(Subscription):
-    type: str
-    method: str
-
-    @abstractmethod
-    def get_request(self) -> Any: ...
-
-
-@dataclass(frozen=True)
-class HeadSubscription(TzktSubscription):
-    type: Literal['head'] = 'head'
-    method: Literal['SubscribeToHead'] = 'SubscribeToHead'
-
-    def get_request(self) -> list[dict[str, str]]:
-        return []
-
-
 @dataclass(frozen=True)
-class OriginationSubscription(TzktSubscription):
-    type: Literal['origination'] = 'origination'
-    method: Literal['SubscribeToOperations'] = 'SubscribeToOperations'
-
-    def get_request(self) -> list[dict[str, Any]]:
-        return [{'types': 'origination'}]
-
-
-@dataclass(frozen=True)
-class TransactionSubscription(TzktSubscription):
-    type: Literal['transaction'] = 'transaction'
-    method: Literal['SubscribeToOperations'] = 'SubscribeToOperations'
-    address: str | None = None
-
-    def get_request(self) -> list[dict[str, Any]]:
-        request: dict[str, Any] = {'types': 'transaction'}
-        if self.address:
-            request['address'] = self.address
-        return [request]
-
-
-@dataclass(frozen=True)
-class SmartRollupExecuteSubscription(TzktSubscription):
-    type: Literal['sr_execute'] = 'sr_execute'
-    method: Literal['SubscribeToOperations'] = 'SubscribeToOperations'
-    address: str | None = None
-
-    def get_request(self) -> list[dict[str, Any]]:
-        request: dict[str, Any] = {'types': 'sr_execute'}
-        if self.address:
-            request['address'] = self.address
-        return [request]
-
-
-# TODO: Add `ptr` and `tags` filters?
-@dataclass(frozen=True)
-class BigMapSubscription(TzktSubscription):
-    type: Literal['big_map'] = 'big_map'
-    method: Literal['SubscribeToBigMaps'] = 'SubscribeToBigMaps'
-    address: str | None = None
-    path: str | None = None
-
-    def get_request(self) -> list[dict[str, Any]]:
-        if self.address and self.path:
-            return [{'address': self.address, 'paths': [self.path]}]
-        if not self.address and not self.path:
-            return [{}]
-        raise FrameworkException('Either both `address` and `path` should be set or none of them')
-
-
-@dataclass(frozen=True)
-class TokenTransferSubscription(TzktSubscription):
-    type: Literal['token_transfer'] = 'token_transfer'
-    method: Literal['SubscribeToTokenTransfers'] = 'SubscribeToTokenTransfers'
-    contract: str | None = None
-    token_id: int | None = None
-    from_: str | None = Field(None, alias='from')  # type: ignore[misc]
-    to: str | None = None
-
-    def get_request(self) -> list[dict[str, Any]]:
-        request: dict[str, Any] = {}
-        if self.token_id:
-            request['tokenId'] = self.token_id
-        if self.contract:
-            request['contract'] = self.contract
-        if self.from_:
-            request['from'] = self.from_
-        if self.to:
-            request['to'] = self.to
-        return [request]
-
-
-@dataclass(frozen=True)
-class TokenBalanceSubscription(TzktSubscription):
-    type: Literal['token_balance'] = 'token_balance'
-    method: Literal['SubscribeToTokenBalances'] = 'SubscribeToTokenBalances'
-    contract: str | None = None
-    token_id: int | None = None
-
-    def get_request(self) -> list[dict[str, Any]]:
-        request: dict[str, Any] = {}
-        if self.token_id:
-            request['tokenId'] = self.token_id
-        if self.contract:
-            request['contract'] = self.contract
-        return [request]
-
-
-@dataclass(frozen=True)
-class EventSubscription(TzktSubscription):
-    type: Literal['event'] = 'event'
-    method: Literal['SubscribeToEvents'] = 'SubscribeToEvents'
-    address: str | None = None
-
-    def get_request(self) -> list[dict[str, Any]]:
-        if self.address:
-            return [{'address': self.address}]
-
-        return [{}]
-
-
-@dataclass(frozen=True)
-class TzktOperationData(HasLevel):
+class TezosOperationData(HasLevel):
     """Basic structure for operations from TzKT response"""
 
     type: str
     id: int
     level: int
     timestamp: datetime
     hash: str
@@ -217,15 +82,15 @@
     commitment_json: dict[str, Any] = Field(default_factory=dict)
 
     @classmethod
     def from_json(
         cls,
         operation_json: dict[str, Any],
         type_: str | None = None,
-    ) -> 'TzktOperationData':
+    ) -> 'TezosOperationData':
         """Convert raw operation message from WS/REST into dataclass"""
         # NOTE: Migration originations are handled in a separate method
         sender_json = operation_json.get('sender') or {}
         target_json = operation_json.get('target') or {}
         initiator_json = operation_json.get('initiator') or {}
         delegate_json = operation_json.get('delegate') or {}
         parameter_json = operation_json.get('parameter') or {}
@@ -245,15 +110,15 @@
             if entrypoint is None:
                 entrypoint = DEFAULT_ENTRYPOINT
 
                 # NOTE: Empty parameter in this case means `{"prim": "Unit"}`
                 if parameter is None:
                     parameter = {}
 
-        return TzktOperationData(
+        return TezosOperationData(
             type=type_ or operation_json['type'],
             id=operation_json['id'],
             level=operation_json['level'],
             timestamp=_parse_timestamp(operation_json['timestamp']),
             block=operation_json.get('block'),
             hash=operation_json['hash'],
             counter=operation_json['counter'],
@@ -283,17 +148,17 @@
             commitment_json=commitment_json,
         )
 
     @classmethod
     def from_migration_json(
         cls,
         migration_origination_json: dict[str, Any],
-    ) -> 'TzktOperationData':
+    ) -> 'TezosOperationData':
         """Convert raw migration message from REST into dataclass"""
-        return TzktOperationData(
+        return TezosOperationData(
             type='migration',
             id=migration_origination_json['id'],
             level=migration_origination_json['level'],
             timestamp=_parse_timestamp(migration_origination_json['timestamp']),
             block=migration_origination_json.get('block'),
             originated_contract_address=migration_origination_json['account']['address'],
             originated_contract_alias=migration_origination_json['account'].get('alias'),
@@ -309,44 +174,44 @@
             target_address=None,
             target_code_hash=None,
             initiator_address=None,
         )
 
 
 @dataclass(frozen=True)
-class TzktTransaction(Generic[ParameterType, StorageType]):
+class TezosTransaction(Generic[ParameterType, StorageType]):
     """Wrapper for matched transaction with typed data passed to the handler"""
 
-    data: TzktOperationData
+    data: TezosOperationData
     parameter: ParameterType
     storage: StorageType
 
 
 @dataclass(frozen=True)
-class TzktOrigination(Generic[StorageType]):
+class TezosOrigination(Generic[StorageType]):
     """Wrapper for matched origination with typed data passed to the handler"""
 
-    data: TzktOperationData
+    data: TezosOperationData
     storage: StorageType
 
 
 @dataclass(frozen=True)
-class TzktSmartRollupCommitment:
+class TezosSmartRollupCommitment:
     id: int
     initiator_address: str
     initiator_alias: str | None
     inbox_level: int
     state: str
     hash: str | None
     ticks: int
     first_level: int
     first_time: datetime
 
     @classmethod
-    def create(cls, operation_data: TzktOperationData) -> 'TzktSmartRollupCommitment':
+    def create(cls, operation_data: TezosOperationData) -> 'TezosSmartRollupCommitment':
         commitment_data = operation_data.commitment_json
         initiator_data = commitment_data.get('initiator') or {}
         return cls(
             id=commitment_data['id'],
             initiator_address=initiator_data['address'],
             initiator_alias=initiator_data.get('alias'),
             inbox_level=commitment_data['inboxLevel'],
@@ -355,72 +220,76 @@
             ticks=commitment_data['ticks'],
             first_level=commitment_data['firstLevel'],
             first_time=commitment_data['firstTime'],
         )
 
 
 @dataclass(frozen=True)
-class TzktSmartRollupExecute:
+class TezosSmartRollupExecute:
     """Wrapper for matched smart rollup execute to the handler"""
 
-    data: TzktOperationData
-    commitment: TzktSmartRollupCommitment
+    data: TezosOperationData
+    commitment: TezosSmartRollupCommitment
 
     @classmethod
-    def create(cls, operation_data: TzktOperationData) -> 'TzktSmartRollupExecute':
-        commitment = TzktSmartRollupCommitment.create(operation_data)
+    def create(cls, operation_data: TezosOperationData) -> 'TezosSmartRollupExecute':
+        commitment = TezosSmartRollupCommitment.create(operation_data)
         return cls(
             data=operation_data,
             commitment=commitment,
         )
 
 
-class TzktBigMapAction(Enum):
+class TezosBigMapAction(Enum):
     """Mapping for action in TzKT response"""
 
     ALLOCATE = 'allocate'
     ADD_KEY = 'add_key'
     UPDATE_KEY = 'update_key'
     REMOVE_KEY = 'remove_key'
     REMOVE = 'remove'
 
     @property
     def has_key(self) -> bool:
-        return self in (TzktBigMapAction.ADD_KEY, TzktBigMapAction.UPDATE_KEY, TzktBigMapAction.REMOVE_KEY)
+        return self in (
+            TezosBigMapAction.ADD_KEY,
+            TezosBigMapAction.UPDATE_KEY,
+            TezosBigMapAction.REMOVE_KEY,
+        )
 
     @property
     def has_value(self) -> bool:
-        return self in (TzktBigMapAction.ADD_KEY, TzktBigMapAction.UPDATE_KEY)
+        return self in (TezosBigMapAction.ADD_KEY, TezosBigMapAction.UPDATE_KEY)
 
 
 @dataclass(frozen=True)
-class TzktBigMapData(HasLevel):
+class TezosBigMapData(HasLevel):
     """Basic structure for big map diffs from TzKT response"""
 
     id: int
     level: int
     operation_id: int
     timestamp: datetime
     bigmap: int
     contract_address: str
     path: str
-    action: TzktBigMapAction
+    action: TezosBigMapAction
     active: bool
     key: Any | None = None
     value: Any | None = None
 
     @classmethod
     def from_json(
         cls,
         big_map_json: dict[str, Any],
-    ) -> 'TzktBigMapData':
+    ) -> 'TezosBigMapData':
         """Convert raw big map diff message from WS/REST into dataclass"""
-        action = TzktBigMapAction(big_map_json['action'])
-        active = action not in (TzktBigMapAction.REMOVE, TzktBigMapAction.REMOVE_KEY)
-        return TzktBigMapData(
+        action = TezosBigMapAction(big_map_json['action'])
+        active = action not in (TezosBigMapAction.REMOVE, TezosBigMapAction.REMOVE_KEY)
+        return TezosBigMapData(
             id=big_map_json['id'],
             level=big_map_json['level'],
             # NOTE: missing `operation_id` field in API to identify operation
             operation_id=big_map_json['level'],
             timestamp=_parse_timestamp(big_map_json['timestamp']),
             bigmap=big_map_json['bigmap'],
             contract_address=big_map_json['contract']['address'],
@@ -429,25 +298,25 @@
             active=active,
             key=big_map_json.get('content', {}).get('key'),
             value=big_map_json.get('content', {}).get('value'),
         )
 
 
 @dataclass(frozen=True)
-class TzktBigMapDiff(Generic[KeyType, ValueType]):
+class TezosBigMapDiff(Generic[KeyType, ValueType]):
     """Wrapper for matched big map diff with typed data passed to the handler"""
 
-    action: TzktBigMapAction
-    data: TzktBigMapData
+    action: TezosBigMapAction
+    data: TezosBigMapData
     key: KeyType | None
     value: ValueType | None
 
 
 @dataclass(frozen=True)
-class TzktBlockData(HasLevel):
+class TezosBlockData(HasLevel):
     """Basic structure for blocks received from TzKT REST API"""
 
     level: int
     hash: str
     timestamp: datetime
     proto: int
     validations: int
@@ -459,17 +328,17 @@
     baker_address: str | None = None
     baker_alias: str | None = None
 
     @classmethod
     def from_json(
         cls,
         block_json: dict[str, Any],
-    ) -> 'TzktBlockData':
+    ) -> 'TezosBlockData':
         """Convert raw block message from REST into dataclass"""
-        return TzktBlockData(
+        return TezosBlockData(
             level=block_json['level'],
             hash=block_json['hash'],
             timestamp=_parse_timestamp(block_json['timestamp']),
             proto=block_json['proto'],
             priority=block_json.get('priority'),
             validations=block_json['validations'],
             deposit=block_json['deposit'],
@@ -478,15 +347,15 @@
             nonce_revealed=block_json['nonceRevealed'],
             baker_address=block_json.get('baker', {}).get('address'),
             baker_alias=block_json.get('baker', {}).get('alias'),
         )
 
 
 @dataclass(frozen=True)
-class TzktHeadBlockData(HasLevel):
+class TezosHeadBlockData(HasLevel):
     """Basic structure for head block received from TzKT SignalR API"""
 
     chain: str
     chain_id: str
     cycle: int
     level: int
     hash: str
@@ -508,17 +377,17 @@
     quote_eth: Decimal
     quote_gbp: Decimal
 
     @classmethod
     def from_json(
         cls,
         head_block_json: dict[str, Any],
-    ) -> 'TzktHeadBlockData':
+    ) -> 'TezosHeadBlockData':
         """Convert raw head block message from WS/REST into dataclass"""
-        return TzktHeadBlockData(
+        return TezosHeadBlockData(
             chain=head_block_json['chain'],
             chain_id=head_block_json['chainId'],
             cycle=head_block_json['cycle'],
             level=head_block_json['level'],
             hash=head_block_json['hash'],
             protocol=head_block_json['protocol'],
             next_protocol=head_block_json['nextProtocol'],
@@ -537,102 +406,102 @@
             quote_krw=Decimal(head_block_json['quoteKrw']),
             quote_eth=Decimal(head_block_json['quoteEth']),
             quote_gbp=Decimal(head_block_json['quoteGbp']),
         )
 
 
 @dataclass(frozen=True)
-class TzktQuoteData(HasLevel):
+class TezosQuoteData(HasLevel):
     """Basic structure for quotes received from TzKT REST API"""
 
     level: int
     timestamp: datetime
     btc: Decimal
     eur: Decimal
     usd: Decimal
     cny: Decimal
     jpy: Decimal
     krw: Decimal
     eth: Decimal
     gbp: Decimal
 
     @classmethod
-    def from_json(cls, quote_json: dict[str, Any]) -> 'TzktQuoteData':
+    def from_json(cls, quote_json: dict[str, Any]) -> 'TezosQuoteData':
         """Convert raw quote message from REST into dataclass"""
-        return TzktQuoteData(
+        return TezosQuoteData(
             level=quote_json['level'],
             timestamp=_parse_timestamp(quote_json['timestamp']),
             btc=Decimal(quote_json['btc']),
             eur=Decimal(quote_json['eur']),
             usd=Decimal(quote_json['usd']),
             cny=Decimal(quote_json['cny']),
             jpy=Decimal(quote_json['jpy']),
             krw=Decimal(quote_json['krw']),
             eth=Decimal(quote_json['eth']),
             gbp=Decimal(quote_json['gbp']),
         )
 
 
 @dataclass(frozen=True)
-class TzktTokenTransferData(HasLevel):
+class TezosTokenTransferData(HasLevel):
     """Basic structure for token transver received from TzKT SignalR API"""
 
     id: int
     level: int
     timestamp: datetime
     tzkt_token_id: int
     contract_address: str | None = None
     contract_alias: str | None = None
     token_id: int | None = None
-    standard: TzktTokenStandard | None = None
+    standard: TezosTokenStandard | None = None
     metadata: dict[str, Any] | None = None
     from_alias: str | None = None
     from_address: str | None = None
     to_alias: str | None = None
     to_address: str | None = None
     amount: int | None = None
     tzkt_transaction_id: int | None = None
     tzkt_origination_id: int | None = None
     tzkt_migration_id: int | None = None
 
     @classmethod
-    def from_json(cls, token_transfer_json: dict[str, Any]) -> 'TzktTokenTransferData':
+    def from_json(cls, token_transfer_json: dict[str, Any]) -> 'TezosTokenTransferData':
         """Convert raw token transfer message from REST or WS into dataclass"""
         token_json = token_transfer_json.get('token') or {}
         contract_json = token_json.get('contract') or {}
         from_json = token_transfer_json.get('from') or {}
         to_json = token_transfer_json.get('to') or {}
         standard = token_json.get('standard')
         metadata = token_json.get('metadata')
         amount = token_transfer_json.get('amount')
         amount = int(amount) if amount is not None else None
 
-        return TzktTokenTransferData(
+        return TezosTokenTransferData(
             id=token_transfer_json['id'],
             level=token_transfer_json['level'],
             timestamp=_parse_timestamp(token_transfer_json['timestamp']),
             tzkt_token_id=token_json['id'],
             contract_address=contract_json.get('address'),
             contract_alias=contract_json.get('alias'),
             token_id=token_json.get('tokenId'),
-            standard=TzktTokenStandard(standard) if standard else None,
+            standard=TezosTokenStandard(standard) if standard else None,
             metadata=metadata if isinstance(metadata, dict) else {},
             from_alias=from_json.get('alias'),
             from_address=from_json.get('address'),
             to_alias=to_json.get('alias'),
             to_address=to_json.get('address'),
             amount=amount,
             tzkt_transaction_id=token_transfer_json.get('transactionId'),
             tzkt_origination_id=token_transfer_json.get('originationId'),
             tzkt_migration_id=token_transfer_json.get('migrationId'),
         )
 
 
 @dataclass(frozen=True)
-class TzktTokenBalanceData(HasLevel):
+class TezosTokenBalanceData(HasLevel):
     """Basic structure for token transver received from TzKT SignalR API"""
 
     id: int
     transfers_count: int
     first_level: int
     first_time: datetime
     # NOTE: Level of the block where the token balance has been changed for the last time.
@@ -640,85 +509,85 @@
     last_time: datetime
     account_address: str | None = None
     account_alias: str | None = None
     tzkt_token_id: int | None = None
     contract_address: str | None = None
     contract_alias: str | None = None
     token_id: int | None = None
-    standard: TzktTokenStandard | None = None
+    standard: TezosTokenStandard | None = None
     metadata: dict[str, Any] | None = None
 
     balance: str | None = None
     balance_value: float | None = None
 
     @property
     def level(self) -> int:  # type: ignore[override]
         return self.last_level
 
     @classmethod
-    def from_json(cls, token_transfer_json: dict[str, Any]) -> 'TzktTokenBalanceData':
+    def from_json(cls, token_transfer_json: dict[str, Any]) -> 'TezosTokenBalanceData':
         """Convert raw token transfer message from REST or WS into dataclass"""
         token_json = token_transfer_json.get('token') or {}
         standard = token_json.get('standard')
         metadata = token_json.get('metadata')
         contract_json = token_json.get('contract') or {}
 
-        return TzktTokenBalanceData(
+        return TezosTokenBalanceData(
             id=token_transfer_json['id'],
             transfers_count=token_transfer_json['transfersCount'],
             first_level=token_transfer_json['firstLevel'],
             first_time=_parse_timestamp(token_transfer_json['firstTime']),
             last_level=token_transfer_json['lastLevel'],
             last_time=_parse_timestamp(token_transfer_json['lastTime']),
             account_address=token_transfer_json.get('account', {}).get('address'),
             account_alias=token_transfer_json.get('account', {}).get('alias'),
             tzkt_token_id=token_json['id'],
             contract_address=contract_json.get('address'),
             contract_alias=contract_json.get('alias'),
             token_id=token_json.get('tokenId'),
-            standard=TzktTokenStandard(standard) if standard else None,
+            standard=TezosTokenStandard(standard) if standard else None,
             metadata=metadata if isinstance(metadata, dict) else {},
             balance=token_transfer_json.get('balance'),
             balance_value=token_transfer_json.get('balanceValue'),
         )
 
 
 @dataclass(frozen=True)
-class TzktEventData(HasLevel):
+class TezosEventData(HasLevel):
     """Basic structure for events received from TzKT REST API"""
 
     id: int
     level: int
     timestamp: datetime
     tag: str
     payload: Any | None
     contract_address: str
     contract_alias: str | None = None
     contract_code_hash: int | None = None
     transaction_id: int | None = None
 
     @classmethod
-    def from_json(cls, event_json: dict[str, Any]) -> 'TzktEventData':
+    def from_json(cls, event_json: dict[str, Any]) -> 'TezosEventData':
         """Convert raw event message from WS/REST into dataclass"""
-        return TzktEventData(
+        return TezosEventData(
             id=event_json['id'],
             level=event_json['level'],
             timestamp=_parse_timestamp(event_json['timestamp']),
             tag=event_json['tag'],
             payload=event_json.get('payload'),
             contract_address=event_json['contract']['address'],
             contract_alias=event_json['contract'].get('alias'),
             contract_code_hash=event_json['codeHash'],
             transaction_id=event_json.get('transactionId'),
         )
 
 
 @dataclass(frozen=True)
-class TzktEvent(Generic[EventType]):
-    data: TzktEventData
+class TezosEvent(Generic[EventType]):
+    data: TezosEventData
     payload: EventType
 
 
 @dataclass(frozen=True)
-class TzktUnknownEvent:
-    data: TzktEventData
+class TezosUnknownEvent:
+    data: TezosEventData
     payload: Any | None
```

### Comparing `dipdup-7.5.7/src/dipdup/package.py` & `dipdup-8.0.0a1/src/dipdup/package.py`

 * *Files 2% similar despite different names*

```diff
@@ -22,14 +22,15 @@
 from dipdup.utils import touch
 
 KEEP_MARKER = '.keep'
 PACKAGE_MARKER = '__init__.py'
 PEP_561_MARKER = 'py.typed'
 DEFAULT_ENV = '.env.default'
 
+
 EVM_ABI_JSON = 'abi.json'
 
 _branch = '   '
 _tee = ' '
 _last = ' '
 
 _logger = logging.getLogger(__name__)
@@ -51,15 +52,14 @@
     return tuple(lines)
 
 
 class ConvertedEventAbi(TypedDict):
     name: str
     topic0: str
     inputs: tuple[tuple[str, bool], ...]
-    topic_count: int
 
 
 class ConvertedMethodAbi(TypedDict):
     name: str
     sighash: str
     inputs: tuple[dict[str, str], ...]
     outputs: tuple[dict[str, str], ...]
@@ -68,14 +68,16 @@
 class ConvertedAbi(TypedDict):
     events: dict[str, ConvertedEventAbi]
     methods: dict[str, ConvertedMethodAbi]
 
 
 class DipDupPackage:
     def __init__(self, root: Path) -> None:
+        _logger.info('Loading package `%s` from `%s`', root.name, root)
+
         self.root = root
         self.name = root.name
 
         # NOTE: Package sections with .keep markers
         self.abi = root / 'abi'
         self.configs = root / 'configs'
         self.deploy = root / 'deploy'
@@ -193,11 +195,11 @@
             if not path.exists():
                 raise InitializationRequiredError(f'`{path}` does not exist')
             self._evm_abis[typename] = orjson.loads(path.read_bytes())
         return self._evm_abis[typename]
 
     def get_converted_abi(self, typename: str) -> ConvertedAbi:
         if not self._converted_abis:
-            from dipdup.codegen.evm_subsquid import convert_abi
+            from dipdup.codegen.evm import convert_abi
 
             self._converted_abis = convert_abi(self)
         return self._converted_abis[typename]
```

### Comparing `dipdup-7.5.7/src/dipdup/performance.py` & `dipdup-8.0.0a1/src/dipdup/performance.py`

 * *Files 16% similar despite different names*

```diff
@@ -19,16 +19,14 @@
 from functools import lru_cache
 from itertools import chain
 from typing import TYPE_CHECKING
 from typing import Any
 from typing import cast
 
 from async_lru import alru_cache
-from pydantic import Field
-from pydantic.dataclasses import dataclass
 
 from dipdup.exceptions import FrameworkException
 
 if TYPE_CHECKING:
 
     from dipdup.models import CachedModel
 
@@ -36,15 +34,15 @@
 
 
 class _CacheManager:
     def __init__(self) -> None:
         self._plain: dict[str, dict[Any, Any]] = {}
         self._lru: dict[str, Callable[..., Any]] = {}
         self._alru: dict[str, Callable[..., Coroutine[Any, Any, None]]] = {}
-        self._models: set[type[CachedModel]] = set()
+        self._models: set['type[CachedModel]'] = set()
 
     def add_plain(
         self,
         obj: dict[Any, Any],
         name: str,
     ) -> None:
         self._plain[name] = obj
@@ -170,65 +168,35 @@
                     'size': size,
                     'limit': None,
                     'full': None,
                 }
         return stats
 
 
-@dataclass
-class _MetricManager:
-    # NOTE: General metrics
-    levels_indexed: int = 0
-    levels_nonempty: int = 0
-    levels_total: int = 0
-    objects_indexed: int = 0
-
-    # NOTE: Index metrics
-    handlers_matched: defaultdict[str, int] = Field(default_factory=lambda: defaultdict(int))
-    time_in_matcher: defaultdict[str, float] = Field(default_factory=lambda: defaultdict(float))
-    time_in_callbacks: defaultdict[str, float] = Field(default_factory=lambda: defaultdict(float))
-
-    # NOTE: Datasource metrics
-    time_in_requests: defaultdict[str, float] = Field(default_factory=lambda: defaultdict(float))
-    requests_total: defaultdict[str, int] = Field(default_factory=lambda: defaultdict(int))
-
-    # NOTE: Various timestamps
-    started_at: float = 0.0
-    synchronized_at: float = 0.0
-    realtime_at: float = 0.0
-    metrics_updated_at: float = 0.0
-
-    # NOTE: Speed estimates
-    levels_speed: float = 0.0
-    levels_speed_average: float = 0.0
-    levels_nonempty_speed: float = 0.0
-    objects_speed: float = 0.0
-
-    # NOTE: Time estimates
-    time_passed: float = 0.0
-    time_left: float = 0.0
-    progress: float = 0.0
+class _MetricManager(defaultdict[str, float]):
+    """Usage:
 
-    def stats(self) -> dict[str, Any]:
-        result = {}
-        for k, v in self.__dict__.items():
-            if k.startswith('_'):
-                continue
-            if isinstance(v, defaultdict):
-                for kk, vv in v.items():
-                    result[f'{k}:{kk}'] = vv
-            else:
-                result[k] = v
-        return result
+    metrics.inc('metric', 0.1)
+    metrics.set('metric', 0.1)
+    """
+
+    def __init__(self) -> None:
+        super().__init__(float)
+
+    def set(self, name: str, value: float) -> None:
+        self[name] = value
+
+    def inc(self, name: str, value: float) -> None:
+        self[name] += value
 
 
 caches = _CacheManager()
 queues = _QueueManager()
 metrics = _MetricManager()
 
 
 def get_stats() -> dict[str, Any]:
     return {
         'caches': caches.stats(),
         'queues': queues.stats(),
-        'metrics': metrics.stats(),
+        'metrics': metrics,
     }
```

### Comparing `dipdup-7.5.7/src/dipdup/project.py` & `dipdup-8.0.0a1/src/dipdup/project.py`

 * *Files 10% similar despite different names*

```diff
@@ -2,78 +2,83 @@
 
 Ask user some question with Click; render Jinja2 templates with answers.
 """
 
 import logging
 import re
 from pathlib import Path
-from typing import TypedDict
 
+from pydantic import ConfigDict
+from pydantic import TypeAdapter
 from pydantic.dataclasses import dataclass
 from tabulate import tabulate
+from typing_extensions import TypedDict
 
 from dipdup import __version__
 from dipdup.cli import big_yellow_echo
 from dipdup.cli import echo
+from dipdup.config import ToStr
 from dipdup.env import get_package_path
 from dipdup.env import get_pyproject_name
 from dipdup.utils import load_template
 from dipdup.utils import write
 from dipdup.yaml import DipDupYAMLConfig
 
 _logger = logging.getLogger(__name__)
 
+CODEGEN_HEADER = f'# generated by DipDup { __version__.split("+")[0]}'
+
 
 # NOTE: All templates are stored in src/dipdup/projects
 TEMPLATES: dict[str, tuple[str, ...]] = {
     'evm': (
         'demo_evm_events',
         'demo_evm_transactions',
-        'demo_uniswap',
+        'demo_evm_uniswap',
     ),
     'tezos': (
-        'demo_auction',
-        'demo_big_maps',
-        'demo_dao',
-        'demo_dex',
-        'demo_domains',
-        'demo_events',
-        'demo_etherlink',
-        'demo_factories',
-        'demo_head',
-        'demo_nft_marketplace',
-        'demo_raw',
-        'demo_token',
-        'demo_token_transfers',
+        'demo_tezos_auction',
+        'demo_tezos_big_maps',
+        'demo_tezos_dao',
+        'demo_tezos_dex',
+        'demo_tezos_domains',
+        'demo_tezos_events',
+        'demo_tezos_etherlink',
+        'demo_tezos_factories',
+        'demo_tezos_head',
+        'demo_tezos_nft_marketplace',
+        'demo_tezos_raw',
+        'demo_tezos_token',
+        'demo_tezos_token_transfers',
     ),
     'other': ('demo_blank',),
 }
 
 # TODO: demo_jobs
 # TODO: demo_backup
 # TODO: demo_sql
 # TODO: demo_timescale
 # TODO: demo_cli
 
 
 class Answers(TypedDict):
     """Answers for survey/replay in order of appearance"""
 
-    dipdup_version: str
+    dipdup_version: ToStr
     template: str
     package: str
     version: str
     description: str
     license: str
     name: str
     email: str
     postgres_image: str
     postgres_data_path: str
     hasura_image: str
-    line_length: str
+    line_length: int
     package_manager: str
 
 
 def get_default_answers() -> Answers:
     return Answers(
         dipdup_version=__version__.split('.')[0],
         template='demo_blank',
@@ -82,15 +87,15 @@
         description='A blockchain indexer built with DipDup',
         license='MIT',
         name='John Doe',
         email='john_doe@example.com',
         postgres_image='postgres:15',
         postgres_data_path='/var/lib/postgresql/data',
         hasura_image='hasura/graphql-engine:latest',
-        line_length='120',
+        line_length=120,
         package_manager='pdm',
     )
 
 
 def get_package_answers(package: str | None = None) -> Answers | None:
     if not package:
         package = get_pyproject_name()
@@ -100,17 +105,17 @@
     replay_path = get_package_path(package) / 'configs' / 'replay.yaml'
     if not replay_path.is_file():
         return None
 
     return answers_from_replay(replay_path)
 
 
-@dataclass
+@dataclass(config=ConfigDict(extra='forbid'), kw_only=True)
 class ReplayConfig:
-    spec_version: str | float
+    spec_version: ToStr
     replay: Answers
 
 
 def prompt_anyof(
     question: str,
     options: tuple[str, ...],
     comments: tuple[str, ...],
@@ -273,15 +278,15 @@
 
 def answers_from_replay(path: Path) -> Answers:
     yaml_config, _ = DipDupYAMLConfig.load([path])
     yaml_config['replay'] = {
         **get_default_answers(),
         **yaml_config['replay'],
     }
-    return ReplayConfig(**yaml_config).replay
+    return TypeAdapter(ReplayConfig).validate_python(yaml_config).replay
 
 
 def render_project(
     answers: Answers,
     force: bool = False,
 ) -> None:
     """Render project from template"""
@@ -356,11 +361,11 @@
 def _render(answers: Answers, template_path: Path, output_path: Path, force: bool) -> None:
     if output_path.exists() and not force:
         _logger.info('File `%s` already exists, skipping', output_path)
 
     _logger.info('Generating `%s`', output_path)
     template = load_template(str(template_path))
     content = template.render(
-        project=answers,
-        __version__=__version__,
+        project={k: str(v) for k, v in answers.items()},
+        header=CODEGEN_HEADER,
     )
     write(output_path, content, overwrite=force)
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/base/Makefile.j2` & `dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/Makefile`

 * *Files 23% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 .PHONY: $(MAKECMDGOALS)
 MAKEFLAGS += --no-print-directory
 ##
 ##   DipDup developer tools
 ##
-PACKAGE={{ project.package }}
+PACKAGE=demo_tezos_nft_marketplace
 TAG=latest
 COMPOSE=deploy/compose.yaml
 
 help:           ## Show this help (default)
 	@grep -Fh "##" $(MAKEFILE_LIST) | grep -Fv grep -F | sed -e 's/\\$$//' | sed -e 's/##//'
 
 all:            ## Run an entire CI pipeline
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/base/README.md.j2` & `dipdup-8.0.0a1/src/demo_tezos_dex/README.md`

 * *Files 27% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# {{project.package}}
+# demo_tezos_dex
 
-{{project.description}}
+DEX balances and liquidity (Quipuswap)
 
 ## Installation
 
 This project is based on [DipDup](https://dipdup.io), a framework for building featureful dapps.
 
-You need a Linux/macOS system with Python 3.11 installed. To install DipDup with pipx for the current user:
+You need a Linux/macOS system with Python 3.12 installed. To install DipDup with pipx or use our installer:
 
 ```shell
-curl -Lsf https://dipdup.io/install.py | python3
+curl -Lsf https://dipdup.io/install.py | python3.12
 ```
 
 See the [Installation](https://dipdup.io/docs/installation) page for all options.
 
 ## Usage
 
 Run the indexer in memory:
@@ -37,20 +37,13 @@
 docker-compose up
 ```
 
 ## Development setup
 
 To set up the development environment:
 
-{% if project.package_manager == 'pdm' -%}
 ```shell
 pdm install
 $(pdm venv activate)
 ```
-{%- elif project.package_manager == 'poetry' -%}
-```shell
-poetry install
-poetry shell
-```
-{%- endif %}
 
-Run `make all` to run full CI check or `make help` to see other available commands.
+Run `make all` to run full CI check or `make help` to see other available commands.
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/base/configs/dipdup.compose.yaml.j2` & `dipdup-8.0.0a1/src/dipdup/projects/base/configs/dipdup.compose.yaml.j2`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/projects/base/configs/dipdup.swarm.yaml.j2` & `dipdup-8.0.0a1/src/demo_tezos_nft_marketplace/configs/dipdup.swarm.yaml`

 * *Files 19% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 database:
   kind: postgres
-  host: ${POSTGRES_HOST:-{{ project.package }}_db}
+  host: ${POSTGRES_HOST:-demo_tezos_nft_marketplace_db}
   port: 5432
   user: ${POSTGRES_USER:-dipdup}
   password: ${POSTGRES_PASSWORD}
   database: ${POSTGRES_DB:-dipdup}
 
 hasura:
-  url: http://${HASURA_HOST:-{{ project.package }}_hasura}:8080
+  url: http://${HASURA_HOST:-demo_tezos_nft_marketplace_hasura}:8080
   admin_secret: ${HASURA_SECRET}
   allow_aggregations: ${HASURA_ALLOW_AGGREGATIONS:-false}
   select_limit: ${HASURA_SELECT_LIMIT:-100}
   camel_case: ${HASURA_CAMEL_CASE:-true}
 
 sentry:
   dsn: ${SENTRY_DSN:-''}
   environment: ${SENTRY_ENVIRONMENT:-''}
 
 prometheus:
   host: 0.0.0.0
 
 api:
-  host: 0.0.0.0
+  host: 0.0.0.0
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/base/deploy/compose.swarm.yaml.j2` & `dipdup-8.0.0a1/src/demo_tezos_factories/deploy/compose.swarm.yaml`

 * *Files 16% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 version: "3.8"
-name: {{ project.package }}
+name: demo_tezos_factories
 
 services:
   dipdup:
-    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-{{ project.dipdup_version }}}
+    image: ${IMAGE:-ghcr.io/dipdup-io/dipdup}:${TAG:-8}
     depends_on:
       - db
       - hasura
     command: ["-c", "dipdup.yaml", "-c", "configs/dipdup.swarm.yaml", "run"]
     env_file: .env
     networks:
       - internal
@@ -25,17 +25,17 @@
       driver: "json-file"
       options:
         max-size: "10m"
         max-file: "10"
         tag: "\{\{.Name\}\}.\{\{.ImageID\}\}"
 
   db:
-    image: {{ project.postgres_image }}
+    image: postgres:15
     volumes:
-      - db:{{ project.postgres_data_path }}
+      - db:/var/lib/postgresql/data
     env_file: .env
     environment:
       - POSTGRES_USER=dipdup
       - POSTGRES_DB=dipdup
       - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
     healthcheck:
       test: ["CMD-SHELL", "pg_isready -U postgres"]
@@ -47,19 +47,19 @@
     deploy:
       mode: replicated
       replicas: 1
       placement: *placement
     logging: *logging
 
   hasura:
-    image: {{ project.hasura_image }}
+    image: hasura/graphql-engine:latest
     depends_on:
       - db
     environment:
-      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@{{ project.package }}_db:5432/dipdup
+      - HASURA_GRAPHQL_DATABASE_URL=postgres://dipdup:${POSTGRES_PASSWORD}@demo_tezos_factories_db:5432/dipdup
       - HASURA_GRAPHQL_ADMIN_SECRET=${HASURA_SECRET}
       - HASURA_GRAPHQL_ENABLE_CONSOLE=true
       - HASURA_GRAPHQL_DEV_MODE=false
       - HASURA_GRAPHQL_LOG_LEVEL=warn
       - HASURA_GRAPHQL_ENABLE_TELEMETRY=false
       - HASURA_GRAPHQL_UNAUTHORIZED_ROLE=user
       - HASURA_GRAPHQL_STRINGIFY_NUMERIC_TYPES=true
@@ -85,8 +85,8 @@
   db:
 
 networks:
   internal:
   traefik-public:
     external: true
   prometheus-private:
-    external: true
+    external: true
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/base/deploy/compose.yaml.j2` & `dipdup-8.0.0a1/src/dipdup/projects/base/deploy/compose.yaml.j2`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/projects/base/pyproject.toml.j2` & `dipdup-8.0.0a1/src/dipdup/projects/base/pyproject.toml.j2`

 * *Files 3% similar despite different names*

```diff
@@ -1,33 +1,33 @@
-# Generated by DipDup {{ __version__ }}
+{{ header }}
 {%- if project.package_manager == 'none' %}
 [project]
 name = "{{ project.package }}"
 version = "{{ project.version }}"
 description = "{{ project.description }}"
 license = { text = "{{ project.license }}" }
 authors = [
     { name = "{{ project.name }}", email = "{{ project.email }}" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 dependencies = [
     "dipdup>={{ project.dipdup_version }},<{{ project.dipdup_version | int + 1 }}",
 ]
 {%- elif project.package_manager == 'pdm' %}
 [project]
 name = "{{ project.package }}"
 version = "{{ project.version }}"
 description = "{{ project.description }}"
 license = { text = "{{ project.license }}" }
 authors = [
     { name = "{{ project.name }}", email = "{{ project.email }}" },
 ]
 readme = "README.md"
-requires-python = ">=3.11,<3.12"
+requires-python = ">=3.12,<3.13"
 dependencies = [
     "dipdup>={{ project.dipdup_version }},<{{ project.dipdup_version | int + 1 }}",
 ]
 
 [tool.pdm.dev-dependencies]
 dev = [
     "black",
@@ -54,38 +54,38 @@
 license = "{{ project.license }}"
 authors = [
     "{{ project.name }} <{{ project.email }}>",
 ]
 readme = "README.md"
 
 [tool.poetry.dependencies]
-python = ">=3.11,<3.12"
+python = ">=3.12,<3.13"
 dipdup = ">={{ project.dipdup_version }},<{{ project.dipdup_version | int + 1 }}"
 
 [tool.poetry.group.dev.dependencies]
 black = "*"
 ruff = "*"
 mypy = "*"
 {% endif %}
 [tool.black]
 line-length = {{ project.line_length }}
-target-version = ['py311']
+target-version = ['py312']
 skip-string-normalization = true
 
 [tool.ruff]
 line-length = {{ project.line_length }}
-target-version = 'py311'
+target-version = 'py312'
 
 [tool.ruff.lint]
 extend-select = ["B", "C4", "FA", "G", "I", "PTH", "Q", "RET", "RUF", "TCH", "UP"]
 flake8-quotes = { inline-quotes = "single", multiline-quotes = "double" }
 isort = { force-single-line = true}
 
 [tool.mypy]
-python_version = "3.11"
+python_version = "3.12"
 plugins = ["pydantic.mypy"]
 strict = false
 
 {% if project.package_manager == 'pdm' -%}
 [build-system]
 requires = ["pdm-backend"]
 build-backend = "pdm.backend"
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_auction/dipdup.yaml.j2` & `dipdup-8.0.0a1/tests/configs/demo_tezos_auction.yml`

 * *Files 8% similar despite different names*

```diff
@@ -1,29 +1,33 @@
-spec_version: 2.0
-package: {{ project.package }}
+spec_version: 3.0
+package: demo_tezos_auction
+
+datasources:
+  tzkt:
+    kind: tezos.tzkt
+    url: ${TZKT_URL:-https://api.tzkt.io}
+    http:
+      replay_path: ${DIPDUP_REPLAY_PATH:-}
 
 contracts:
   tzcolors_minter:
     kind: tezos
     address: KT1FyaDqiMQWg7Exo7VUiXAgZbd2kCzo3d4s
     typename: tzcolors_minter
   tzcolors_auction:
     kind: tezos
     address: KT1CpeSQKdkhWi4pinYcseCFKmDhs5M74BkU
     typename: tzcolors_auction
 
-datasources:
-  tzkt:
-    kind: tezos.tzkt
-    url: ${TZKT_URL:-https://api.tzkt.io}
 
 templates:
-  auction:
-    kind: tezos.tzkt.operations
-    datasource: <datasource>
+  tzcolors_auction:
+    kind: tezos.operations
+    datasources:
+      - <datasource>
     contracts:
       - <auction>
     handlers:
       - callback: on_create_auction
         pattern:
           - type: transaction
             destination: <auction>
@@ -34,15 +38,19 @@
             destination: <auction>
             entrypoint: bid
       - callback: on_withdraw
         pattern:
           - type: transaction
             destination: <auction>
             entrypoint: withdraw
+    first_level: 1335654
+    last_level: 1340654
 
 indexes:
-  tzcolors:
-    template: auction
+  tzcolors_auction:
+    template: tzcolors_auction
     values:
       datasource: tzkt
       minter: tzcolors_minter
       auction: tzcolors_auction
+
+logging: WARN
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_auction/handlers/on_bid.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_auction/handlers/on_bid.py.j2`

 * *Files 2% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 import {{project.package}}.models as models
 from {{project.package}}.types.tzcolors_auction.tezos_parameters.bid import BidParameter
 from {{project.package}}.types.tzcolors_auction.tezos_storage import TzcolorsAuctionStorage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_bid(
     ctx: HandlerContext,
-    bid: TzktTransaction[BidParameter, TzcolorsAuctionStorage],
+    bid: TezosTransaction[BidParameter, TzcolorsAuctionStorage],
 ) -> None:
     assert bid.data.amount is not None
 
     auction = await models.Auction.filter(
-        id=bid.parameter.__root__,
+        id=bid.parameter.root,
     ).get()
 
     bidder, _ = await models.User.get_or_create(address=bid.data.sender_address)
     await models.Bid(
         auction=auction,
         bidder=bidder,
         bid_amount=bid.data.amount,
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_auction/handlers/on_create_auction.py.j2` & `dipdup-8.0.0a1/src/demo_tezos_auction/handlers/on_create_auction.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-import {{project.package}}.models as models
-from {{project.package}}.types.tzcolors_auction.tezos_parameters.create_auction import CreateAuctionParameter
-from {{project.package}}.types.tzcolors_auction.tezos_storage import TzcolorsAuctionStorage
+import demo_tezos_auction.models as models
+from demo_tezos_auction.types.tzcolors_auction.tezos_parameters.create_auction import CreateAuctionParameter
+from demo_tezos_auction.types.tzcolors_auction.tezos_storage import TzcolorsAuctionStorage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_create_auction(
     ctx: HandlerContext,
-    create_auction: TzktTransaction[CreateAuctionParameter, TzcolorsAuctionStorage],
+    create_auction: TezosTransaction[CreateAuctionParameter, TzcolorsAuctionStorage],
 ) -> None:
     holder, _ = await models.User.get_or_create(address=create_auction.data.sender_address)
 
     token, _ = await models.Token.get_or_create(
         id=create_auction.parameter.token_id,
         address=create_auction.parameter.token_address,
         defaults={
@@ -38,8 +38,8 @@
     bid = models.Bid(
         auction=auction,
         bidder=holder,
         bid_amount=create_auction.parameter.bid_amount,
         level=create_auction.data.level,
         timestamp=create_auction.data.timestamp,
     )
-    await bid.save()
+    await bid.save()
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_auction/handlers/on_withdraw.py.j2` & `dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa12_withdraw_profit.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,22 +1,24 @@
-import {{project.package}}.models as models
-from {{project.package}}.types.tzcolors_auction.tezos_parameters.withdraw import WithdrawParameter
-from {{project.package}}.types.tzcolors_auction.tezos_storage import TzcolorsAuctionStorage
+from decimal import Decimal
+
+import demo_tezos_dex.models as models
+from demo_tezos_dex.types.quipu_fa12.tezos_parameters.withdraw_profit import WithdrawProfitParameter
+from demo_tezos_dex.types.quipu_fa12.tezos_storage import QuipuFa12Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosOperationData
+from dipdup.models.tezos import TezosTransaction
 
 
-async def on_withdraw(
+async def on_fa12_withdraw_profit(
     ctx: HandlerContext,
-    withdraw: TzktTransaction[WithdrawParameter, TzcolorsAuctionStorage],
+    withdraw_profit: TezosTransaction[WithdrawProfitParameter, QuipuFa12Storage],
+    transaction_0: TezosOperationData | None = None,
 ) -> None:
-    auction = await models.Auction.filter(
-        id=withdraw.parameter.__root__,
-    ).get()
-
-    token = await auction.token
+    symbol = ctx.template_values['symbol']
+    trader = withdraw_profit.data.sender_address
 
-    token.holder = await auction.bidder
-    await token.save()
+    position, _ = await models.Position.get_or_create(trader=trader, symbol=symbol)
+    if transaction_0:
+        assert transaction_0.amount is not None
+        position.realized_pl += Decimal(transaction_0.amount) / (10**6)
 
-    auction.status = models.AuctionStatus.FINISHED
-    await auction.save()
+        await position.save()
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_auction/models/__init__.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_auction/models/__init__.py.j2`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_big_maps/dipdup.yaml.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_big_maps/dipdup.yaml.j2`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-spec_version: 2.0
+spec_version: 3.0
 package: {{ project.package }}
 
 contracts:
   mainnet_name_registry:
     kind: tezos
     address: KT1GBZmSxmnKJXGMdMLbugPfLyUPmuLSMwKS
     typename: name_registry
@@ -10,16 +10,17 @@
 datasources:
   tzkt_mainnet:
     kind: tezos.tzkt
     url: ${TZKT_URL:-https://api.tzkt.io}
 
 templates:
   big_maps:
-    kind: tezos.tzkt.big_maps
-    datasource: <datasource>
+    kind: tezos.big_maps
+    datasources:
+      - <datasource>
     skip_history: once
     handlers:
       - callback: on_update_records
         contract: <name_registry>
         path: store.records
       - callback: on_update_expiry_map
         contract: <name_registry>
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_big_maps/handlers/on_update_expiry_map.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_big_maps/handlers/on_update_expiry_map.py.j2`

 * *Files 15% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 import {{project.package}}.models as models
 from {{project.package}}.types.name_registry.tezos_big_maps.store_expiry_map_key import StoreExpiryMapKey
 from {{project.package}}.types.name_registry.tezos_big_maps.store_expiry_map_value import StoreExpiryMapValue
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktBigMapDiff
+from dipdup.models.tezos import TezosBigMapDiff
 
 
 async def on_update_expiry_map(
     ctx: HandlerContext,
-    store_expiry_map: TzktBigMapDiff[StoreExpiryMapKey, StoreExpiryMapValue],
+    store_expiry_map: TezosBigMapDiff[StoreExpiryMapKey, StoreExpiryMapValue],
 ) -> None:
     if not store_expiry_map.action.has_value:
         return
     assert store_expiry_map.key
     assert store_expiry_map.value
 
-    timestamp = store_expiry_map.value.__root__
-    record_name = bytes.fromhex(store_expiry_map.key.__root__).decode()
+    timestamp = store_expiry_map.value.root
+    record_name = bytes.fromhex(store_expiry_map.key.root).decode()
     await models.Expiry.update_or_create(
         id=record_name,
         defaults={'timestamp': timestamp},
     )
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_big_maps/handlers/on_update_records.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_big_maps/handlers/on_update_records.py.j2`

 * *Files 16% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 import {{project.package}}.models as models
 from {{project.package}}.types.name_registry.tezos_big_maps.store_records_key import StoreRecordsKey
 from {{project.package}}.types.name_registry.tezos_big_maps.store_records_value import StoreRecordsValue
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktBigMapDiff
+from dipdup.models.tezos import TezosBigMapDiff
 
 
 async def on_update_records(
     ctx: HandlerContext,
-    store_records: TzktBigMapDiff[StoreRecordsKey, StoreRecordsValue],
+    store_records: TezosBigMapDiff[StoreRecordsKey, StoreRecordsValue],
 ) -> None:
     if not store_records.action.has_value:
         return
     assert store_records.key
     assert store_records.value
 
-    record_name = bytes.fromhex(store_records.key.__root__).decode()
+    record_name = bytes.fromhex(store_records.key.root).decode()
     record_path = record_name.split('.')
     ctx.logger.info('Processing `%s`', record_name)
 
     level = store_records.value.level
     if len(record_path) != int(level):
         ctx.logger.warning('`%s`: expected %s chunks, got %s', record_name, level, len(record_path))
         return
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_big_maps/models/__init__.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_big_maps/models/__init__.py.j2`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_dao/dipdup.yaml.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dao/dipdup.yaml.j2`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-spec_version: 2.0
+spec_version: 3.0
 package: {{ project.package }}
 
 contracts:
   registry:
     kind: tezos
     code_hash: KT19CF3KKrvdW77ttFomCuin2k4uAVkryYqh
     typename: registry
@@ -10,16 +10,17 @@
 datasources:
   tzkt:
     kind: tezos.tzkt
     url: ${TZKT_URL:-https://api.tzkt.io}
 
 indexes:
   registry_dao:
-    kind: tezos.tzkt.operations
-    datasource: tzkt
+    kind: tezos.operations
+    datasources:
+      - tzkt
     types:
       - transaction
       - origination
     handlers:
       - callback: on_origination
         pattern:
           - type: origination
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_dao/handlers/on_propose.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dao/handlers/on_propose.py.j2`

 * *Files 24% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 import {{project.package}}.models as models
 from {{project.package}}.types.registry.tezos_parameters.propose import ProposeParameter
 from {{project.package}}.types.registry.tezos_storage import RegistryStorage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_propose(
     ctx: HandlerContext,
-    propose: TzktTransaction[ProposeParameter, RegistryStorage],
+    propose: TezosTransaction[ProposeParameter, RegistryStorage],
 ) -> None:
     dao = await models.DAO.get(address=propose.data.target_address)
     await models.Proposal(dao=dao).save()
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_dao/models/__init__.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dao/models/__init__.py.j2`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_dex/dipdup.yaml.j2` & `dipdup-8.0.0a1/src/demo_tezos_dex/dipdup.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-spec_version: 2.0
-package: {{ project.package }}
+spec_version: 3.0
+package: demo_tezos_dex
 
 contracts:
   kusd_dex_mainnet:
     kind: tezos
     address: KT1K4EwTpbvYN9agJdjpyJm4ZZdhpUNKB3F6
     typename: quipu_fa12
   kusd_token_mainnet:
@@ -22,16 +22,17 @@
 datasources:
   tzkt_mainnet:
     kind: tezos.tzkt
     url: https://api.tzkt.io
 
 templates:
   quipuswap_fa12:
-    kind: tezos.tzkt.operations
-    datasource: tzkt_mainnet
+    kind: tezos.operations
+    datasources:
+      - tzkt_mainnet
     contracts:
       - <dex_contract>
     types:
       - transaction
       - origination
     handlers:
       - callback: on_fa12_origination
@@ -85,16 +86,17 @@
             destination: <dex_contract>
             entrypoint: withdrawProfit
           - type: transaction
             source: <dex_contract>
             optional: True
 
   quipuswap_fa2:
-    kind: tezos.tzkt.operations
-    datasource: tzkt_mainnet
+    kind: tezos.operations
+    datasources:
+      - tzkt_mainnet
     contracts:
       - <dex_contract>
     types:
       - transaction
       - origination
     handlers:
       - callback: on_fa2_origination
@@ -162,8 +164,8 @@
 
   hdao_mainnet:
     template: quipuswap_fa2
     values:
       dex_contract: hdao_dex_mainnet
       token_contract: hdao_token_mainnet
       symbol: hDAO
-      decimals: 6
+      decimals: 6
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa12_divest_liquidity.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa12_divest_liquidity.py.j2`

 * *Files 6% similar despite different names*

```diff
@@ -2,23 +2,23 @@
 
 import {{project.package}}.models as models
 from {{project.package}}.types.fa12_token.tezos_parameters.transfer import TransferParameter
 from {{project.package}}.types.fa12_token.tezos_storage import Fa12TokenStorage
 from {{project.package}}.types.quipu_fa12.tezos_parameters.divest_liquidity import DivestLiquidityParameter
 from {{project.package}}.types.quipu_fa12.tezos_storage import QuipuFa12Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktOperationData
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosOperationData
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_fa12_divest_liquidity(
     ctx: HandlerContext,
-    divest_liquidity: TzktTransaction[DivestLiquidityParameter, QuipuFa12Storage],
-    transfer: TzktTransaction[TransferParameter, Fa12TokenStorage],
-    transaction_1: TzktOperationData,
+    divest_liquidity: TezosTransaction[DivestLiquidityParameter, QuipuFa12Storage],
+    transfer: TezosTransaction[TransferParameter, Fa12TokenStorage],
+    transaction_1: TezosOperationData,
 ) -> None:
     storage = divest_liquidity.storage
 
     decimals = int(ctx.template_values['decimals'])
     symbol = ctx.template_values['symbol']
     trader = divest_liquidity.data.sender_address
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa12_invest_liquidity.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa2_invest_liquidity.py.j2`

 * *Files 4% similar despite different names*

```diff
@@ -1,36 +1,36 @@
 from decimal import Decimal
 
 import {{project.package}}.models as models
-from {{project.package}}.types.fa12_token.tezos_parameters.transfer import TransferParameter
-from {{project.package}}.types.fa12_token.tezos_storage import Fa12TokenStorage
-from {{project.package}}.types.quipu_fa12.tezos_parameters.invest_liquidity import InvestLiquidityParameter
-from {{project.package}}.types.quipu_fa12.tezos_storage import QuipuFa12Storage
+from {{project.package}}.types.fa2_token.tezos_parameters.transfer import TransferParameter
+from {{project.package}}.types.fa2_token.tezos_storage import Fa2TokenStorage
+from {{project.package}}.types.quipu_fa2.tezos_parameters.invest_liquidity import InvestLiquidityParameter
+from {{project.package}}.types.quipu_fa2.tezos_storage import QuipuFa2Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
-async def on_fa12_invest_liquidity(
+async def on_fa2_invest_liquidity(
     ctx: HandlerContext,
-    invest_liquidity: TzktTransaction[InvestLiquidityParameter, QuipuFa12Storage],
-    transfer: TzktTransaction[TransferParameter, Fa12TokenStorage],
+    invest_liquidity: TezosTransaction[InvestLiquidityParameter, QuipuFa2Storage],
+    transfer: TezosTransaction[TransferParameter, Fa2TokenStorage],
 ) -> None:
     storage = invest_liquidity.storage
 
     decimals = int(ctx.template_values['decimals'])
     symbol = ctx.template_values['symbol']
     trader = invest_liquidity.data.sender_address
 
     assert trader is not None
 
     position, _ = await models.Position.get_or_create(trader=trader, symbol=symbol)
 
     assert invest_liquidity.data.amount is not None
     tez_qty = Decimal(invest_liquidity.data.amount) / (10**6)
-    token_qty = Decimal(transfer.parameter.value) / (10**decimals)
+    token_qty = sum(Decimal(tx.amount) for tx in transfer.parameter.root[0].txs) / (10**decimals)
     new_shares_qty = int(storage.storage.ledger[trader].balance) + int(storage.storage.ledger[trader].frozen_balance)
 
     price = (Decimal(storage.storage.tez_pool) / (10**6)) / (Decimal(storage.storage.token_pool) / (10**decimals))
     value = tez_qty + price * token_qty
     share_px = value / (new_shares_qty - position.shares_qty)
     assert share_px > 0, invest_liquidity.data.hash
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa12_origination.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa12_origination.py.j2`

 * *Files 21% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import {{project.package}}.models as models
 from {{project.package}}.types.quipu_fa12.tezos_storage import QuipuFa12Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktOrigination
+from dipdup.models.tezos import TezosOrigination
 
 
 async def on_fa12_origination(
     ctx: HandlerContext,
-    quipu_fa12_origination: TzktOrigination[QuipuFa12Storage],
+    quipu_fa12_origination: TezosOrigination[QuipuFa12Storage],
 ) -> None:
     symbol = ctx.template_values['symbol']
 
     for address, value in quipu_fa12_origination.storage.storage.ledger.items():
         shares_qty = value.balance
         await models.Position(trader=address, symbol=symbol, shares_qty=shares_qty).save()
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa12_tez_to_token.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa2_token_to_tez.py.j2`

 * *Files 24% similar despite different names*

```diff
@@ -1,37 +1,39 @@
 from decimal import Decimal
 
 import {{project.package}}.models as models
-from {{project.package}}.types.fa12_token.tezos_parameters.transfer import TransferParameter
-from {{project.package}}.types.fa12_token.tezos_storage import Fa12TokenStorage
-from {{project.package}}.types.quipu_fa12.tezos_parameters.tez_to_token_payment import TezToTokenPaymentParameter
-from {{project.package}}.types.quipu_fa12.tezos_storage import QuipuFa12Storage
+from {{project.package}}.types.fa2_token.tezos_parameters.transfer import TransferParameter
+from {{project.package}}.types.fa2_token.tezos_storage import Fa2TokenStorage
+from {{project.package}}.types.quipu_fa2.tezos_parameters.token_to_tez_payment import TokenToTezPaymentParameter
+from {{project.package}}.types.quipu_fa2.tezos_storage import QuipuFa2Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosOperationData
+from dipdup.models.tezos import TezosTransaction
 
 
-async def on_fa12_tez_to_token(
+async def on_fa2_token_to_tez(
     ctx: HandlerContext,
-    tez_to_token_payment: TzktTransaction[TezToTokenPaymentParameter, QuipuFa12Storage],
-    transfer: TzktTransaction[TransferParameter, Fa12TokenStorage],
+    token_to_tez_payment: TezosTransaction[TokenToTezPaymentParameter, QuipuFa2Storage],
+    transfer: TezosTransaction[TransferParameter, Fa2TokenStorage],
+    transaction_0: TezosOperationData,
 ) -> None:
     decimals = int(ctx.template_values['decimals'])
     symbol = ctx.template_values['symbol']
-    trader = tez_to_token_payment.data.sender_address
+    trader = token_to_tez_payment.data.sender_address
 
-    min_token_quantity = Decimal(tez_to_token_payment.parameter.min_out) / (10**decimals)
-    token_quantity = Decimal(transfer.parameter.value) / (10**decimals)
-    assert tez_to_token_payment.data.amount is not None
-    tez_quantity = Decimal(tez_to_token_payment.data.amount) / (10**6)
-    assert min_token_quantity <= token_quantity, tez_to_token_payment.data.hash
+    min_tez_quantity = Decimal(token_to_tez_payment.parameter.min_out) / (10**decimals)
+    token_quantity = Decimal(token_to_tez_payment.parameter.amount) / (10**decimals)
+    assert transaction_0.amount is not None
+    tez_quantity = Decimal(transaction_0.amount) / (10**6)
+    assert min_tez_quantity <= tez_quantity, token_to_tez_payment.data.hash
 
     trade = models.Trade(
         symbol=symbol,
         trader=trader,
-        side=models.TradeSide.BUY,
+        side=models.TradeSide.SELL,
         quantity=token_quantity,
         price=token_quantity / tez_quantity,
-        slippage=(1 - (min_token_quantity / token_quantity)).quantize(Decimal('0.000001')),
+        slippage=1 - (min_tez_quantity / tez_quantity),
         level=transfer.data.level,
         timestamp=transfer.data.timestamp,
     )
     await trade.save()
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa12_token_to_tez.py.j2` & `dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa2_tez_to_token.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,39 +1,37 @@
 from decimal import Decimal
 
-import {{project.package}}.models as models
-from {{project.package}}.types.fa12_token.tezos_parameters.transfer import TransferParameter
-from {{project.package}}.types.fa12_token.tezos_storage import Fa12TokenStorage
-from {{project.package}}.types.quipu_fa12.tezos_parameters.token_to_tez_payment import TokenToTezPaymentParameter
-from {{project.package}}.types.quipu_fa12.tezos_storage import QuipuFa12Storage
+import demo_tezos_dex.models as models
+from demo_tezos_dex.types.fa2_token.tezos_parameters.transfer import TransferParameter
+from demo_tezos_dex.types.fa2_token.tezos_storage import Fa2TokenStorage
+from demo_tezos_dex.types.quipu_fa2.tezos_parameters.tez_to_token_payment import TezToTokenPaymentParameter
+from demo_tezos_dex.types.quipu_fa2.tezos_storage import QuipuFa2Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktOperationData
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
-async def on_fa12_token_to_tez(
+async def on_fa2_tez_to_token(
     ctx: HandlerContext,
-    token_to_tez_payment: TzktTransaction[TokenToTezPaymentParameter, QuipuFa12Storage],
-    transfer: TzktTransaction[TransferParameter, Fa12TokenStorage],
-    transaction_0: TzktOperationData,
+    tez_to_token_payment: TezosTransaction[TezToTokenPaymentParameter, QuipuFa2Storage],
+    transfer: TezosTransaction[TransferParameter, Fa2TokenStorage],
 ) -> None:
     decimals = int(ctx.template_values['decimals'])
     symbol = ctx.template_values['symbol']
-    trader = token_to_tez_payment.data.sender_address
+    trader = tez_to_token_payment.data.sender_address
 
-    min_tez_quantity = Decimal(token_to_tez_payment.parameter.min_out) / (10**6)
-    token_quantity = Decimal(token_to_tez_payment.parameter.amount) / (10**decimals)
-    assert transaction_0.amount is not None
-    tez_quantity = Decimal(transaction_0.amount) / (10**6)
-    assert min_tez_quantity <= tez_quantity, token_to_tez_payment.data.hash
+    min_token_quantity = Decimal(tez_to_token_payment.parameter.min_out) / (10**decimals)
+    assert tez_to_token_payment.data.amount is not None
+    token_quantity = sum(Decimal(tx.amount) for tx in transfer.parameter.root[0].txs) / (10**decimals)
+    tez_quantity = Decimal(tez_to_token_payment.data.amount) / (10**6)
+    assert min_token_quantity <= token_quantity, tez_to_token_payment.data.hash
 
     trade = models.Trade(
         symbol=symbol,
         trader=trader,
-        side=models.TradeSide.SELL,
+        side=models.TradeSide.BUY,
         quantity=token_quantity,
         price=token_quantity / tez_quantity,
-        slippage=(1 - (min_tez_quantity / tez_quantity)).quantize(Decimal('0.000001')),
+        slippage=1 - (min_token_quantity / token_quantity),
         level=transfer.data.level,
         timestamp=transfer.data.timestamp,
     )
-    await trade.save()
+    await trade.save()
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa12_transfer.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa12_withdraw_profit.py.j2`

 * *Files 27% similar despite different names*

```diff
@@ -1,25 +1,25 @@
+from decimal import Decimal
+from typing import Optional
+
 import {{project.package}}.models as models
-from {{project.package}}.types.quipu_fa12.tezos_parameters.transfer import TransferParameter
+from {{project.package}}.types.quipu_fa12.tezos_parameters.withdraw_profit import WithdrawProfitParameter
 from {{project.package}}.types.quipu_fa12.tezos_storage import QuipuFa12Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosOperationData
+from dipdup.models.tezos import TezosTransaction
 
 
-async def on_fa12_transfer(
+async def on_fa12_withdraw_profit(
     ctx: HandlerContext,
-    transfer: TzktTransaction[TransferParameter, QuipuFa12Storage],
+    withdraw_profit: TezosTransaction[WithdrawProfitParameter, QuipuFa12Storage],
+    transaction_0: TezosOperationData | None = None,
 ) -> None:
     symbol = ctx.template_values['symbol']
-    from_address = transfer.parameter.from_
-    to_address = transfer.parameter.to
-    value = int(transfer.parameter.value)
+    trader = withdraw_profit.data.sender_address
 
-    from_position, _ = await models.Position.get_or_create(trader=from_address, symbol=symbol)
-    from_position.shares_qty -= value
-    assert from_position.shares_qty >= 0, transfer.data.hash
-    await from_position.save()
+    position, _ = await models.Position.get_or_create(trader=trader, symbol=symbol)
+    if transaction_0:
+        assert transaction_0.amount is not None
+        position.realized_pl += Decimal(transaction_0.amount) / (10**6)
 
-    to_position, _ = await models.Position.get_or_create(trader=to_address, symbol=symbol)
-    to_position.shares_qty += value
-    assert to_position.shares_qty >= 0, transfer.data.hash
-    await to_position.save()
+        await position.save()
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa12_withdraw_profit.py.j2` & `dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa2_withdraw_profit.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 from decimal import Decimal
-from typing import Optional
 
-import {{project.package}}.models as models
-from {{project.package}}.types.quipu_fa12.tezos_parameters.withdraw_profit import WithdrawProfitParameter
-from {{project.package}}.types.quipu_fa12.tezos_storage import QuipuFa12Storage
+import demo_tezos_dex.models as models
+from demo_tezos_dex.types.quipu_fa2.tezos_parameters.withdraw_profit import WithdrawProfitParameter
+from demo_tezos_dex.types.quipu_fa2.tezos_storage import QuipuFa2Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktOperationData
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosOperationData
+from dipdup.models.tezos import TezosTransaction
 
 
-async def on_fa12_withdraw_profit(
+async def on_fa2_withdraw_profit(
     ctx: HandlerContext,
-    withdraw_profit: TzktTransaction[WithdrawProfitParameter, QuipuFa12Storage],
-    transaction_0: TzktOperationData | None = None,
+    withdraw_profit: TezosTransaction[WithdrawProfitParameter, QuipuFa2Storage],
+    transaction_0: TezosOperationData | None = None,
 ) -> None:
     symbol = ctx.template_values['symbol']
     trader = withdraw_profit.data.sender_address
 
     position, _ = await models.Position.get_or_create(trader=trader, symbol=symbol)
+
     if transaction_0:
         assert transaction_0.amount is not None
         position.realized_pl += Decimal(transaction_0.amount) / (10**6)
 
-        await position.save()
+        await position.save()
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa2_divest_liquidity.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa2_divest_liquidity.py.j2`

 * *Files 4% similar despite different names*

```diff
@@ -2,35 +2,35 @@
 
 import {{project.package}}.models as models
 from {{project.package}}.types.fa2_token.tezos_parameters.transfer import TransferParameter
 from {{project.package}}.types.fa2_token.tezos_storage import Fa2TokenStorage
 from {{project.package}}.types.quipu_fa2.tezos_parameters.divest_liquidity import DivestLiquidityParameter
 from {{project.package}}.types.quipu_fa2.tezos_storage import QuipuFa2Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktOperationData
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosOperationData
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_fa2_divest_liquidity(
     ctx: HandlerContext,
-    divest_liquidity: TzktTransaction[DivestLiquidityParameter, QuipuFa2Storage],
-    transfer: TzktTransaction[TransferParameter, Fa2TokenStorage],
-    transaction_1: TzktOperationData,
+    divest_liquidity: TezosTransaction[DivestLiquidityParameter, QuipuFa2Storage],
+    transfer: TezosTransaction[TransferParameter, Fa2TokenStorage],
+    transaction_1: TezosOperationData,
 ) -> None:
     storage = divest_liquidity.storage
 
     decimals = int(ctx.template_values['decimals'])
     symbol = ctx.template_values['symbol']
     trader = divest_liquidity.data.sender_address
 
     position, _ = await models.Position.get_or_create(trader=trader, symbol=symbol)
 
     assert transaction_1.amount is not None
     tez_qty = Decimal(transaction_1.amount) / (10**6)
-    token_qty = sum(Decimal(tx.amount) for tx in transfer.parameter.__root__[0].txs) / (10**decimals)
+    token_qty = sum(Decimal(tx.amount) for tx in transfer.parameter.root[0].txs) / (10**decimals)
     shares_qty = int(divest_liquidity.parameter.shares)
 
     tez_pool = Decimal(storage.storage.tez_pool) / (10**6)
     token_pool = Decimal(storage.storage.token_pool) / (10**decimals)
 
     # NOTE: Empty pools mean exchange is not initialized yet
     if not tez_pool and not token_pool:
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa2_invest_liquidity.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/handlers/on_fa12_invest_liquidity.py.j2`

 * *Files 8% similar despite different names*

```diff
@@ -1,36 +1,36 @@
 from decimal import Decimal
 
 import {{project.package}}.models as models
-from {{project.package}}.types.fa2_token.tezos_parameters.transfer import TransferParameter
-from {{project.package}}.types.fa2_token.tezos_storage import Fa2TokenStorage
-from {{project.package}}.types.quipu_fa2.tezos_parameters.invest_liquidity import InvestLiquidityParameter
-from {{project.package}}.types.quipu_fa2.tezos_storage import QuipuFa2Storage
+from {{project.package}}.types.fa12_token.tezos_parameters.transfer import TransferParameter
+from {{project.package}}.types.fa12_token.tezos_storage import Fa12TokenStorage
+from {{project.package}}.types.quipu_fa12.tezos_parameters.invest_liquidity import InvestLiquidityParameter
+from {{project.package}}.types.quipu_fa12.tezos_storage import QuipuFa12Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
-async def on_fa2_invest_liquidity(
+async def on_fa12_invest_liquidity(
     ctx: HandlerContext,
-    invest_liquidity: TzktTransaction[InvestLiquidityParameter, QuipuFa2Storage],
-    transfer: TzktTransaction[TransferParameter, Fa2TokenStorage],
+    invest_liquidity: TezosTransaction[InvestLiquidityParameter, QuipuFa12Storage],
+    transfer: TezosTransaction[TransferParameter, Fa12TokenStorage],
 ) -> None:
     storage = invest_liquidity.storage
 
     decimals = int(ctx.template_values['decimals'])
     symbol = ctx.template_values['symbol']
     trader = invest_liquidity.data.sender_address
 
     assert trader is not None
 
     position, _ = await models.Position.get_or_create(trader=trader, symbol=symbol)
 
     assert invest_liquidity.data.amount is not None
     tez_qty = Decimal(invest_liquidity.data.amount) / (10**6)
-    token_qty = sum(Decimal(tx.amount) for tx in transfer.parameter.__root__[0].txs) / (10**decimals)
+    token_qty = Decimal(transfer.parameter.value) / (10**decimals)
     new_shares_qty = int(storage.storage.ledger[trader].balance) + int(storage.storage.ledger[trader].frozen_balance)
 
     price = (Decimal(storage.storage.tez_pool) / (10**6)) / (Decimal(storage.storage.token_pool) / (10**decimals))
     value = tez_qty + price * token_qty
     share_px = value / (new_shares_qty - position.shares_qty)
     assert share_px > 0, invest_liquidity.data.hash
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa2_transfer.py.j2` & `dipdup-8.0.0a1/src/demo_tezos_dex/handlers/on_fa2_transfer.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-import {{project.package}}.models as models
-from {{project.package}}.types.quipu_fa2.tezos_parameters.transfer import TransferParameter
-from {{project.package}}.types.quipu_fa2.tezos_storage import QuipuFa2Storage
+import demo_tezos_dex.models as models
+from demo_tezos_dex.types.quipu_fa2.tezos_parameters.transfer import TransferParameter
+from demo_tezos_dex.types.quipu_fa2.tezos_storage import QuipuFa2Storage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_fa2_transfer(
     ctx: HandlerContext,
-    transfer: TzktTransaction[TransferParameter, QuipuFa2Storage],
+    transfer: TezosTransaction[TransferParameter, QuipuFa2Storage],
 ) -> None:
-    transfer_parameter = transfer.parameter.__root__[0]
+    transfer_parameter = transfer.parameter.root[0]
 
     symbol = ctx.template_values['symbol']
     from_address = transfer_parameter.from_
     from_position, _ = await models.Position.get_or_create(trader=from_address, symbol=symbol)
 
     for transfer_tx in transfer_parameter.txs:
         to_address = transfer_tx.to_
@@ -23,8 +23,8 @@
         assert from_position.shares_qty >= 0, transfer.data.hash
 
         to_position, _ = await models.Position.get_or_create(trader=to_address, symbol=symbol)
         to_position.shares_qty += value
         assert to_position.shares_qty >= 0, transfer.data.hash
         await to_position.save()
 
-    await from_position.save()
+    await from_position.save()
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_dex/handlers/on_fa2_withdraw_profit.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_nft_marketplace/handlers/on_mint.py.j2`

 * *Files 26% similar despite different names*

```diff
@@ -1,26 +1,23 @@
-from decimal import Decimal
-from typing import Optional
-
 import {{project.package}}.models as models
-from {{project.package}}.types.quipu_fa2.tezos_parameters.withdraw_profit import WithdrawProfitParameter
-from {{project.package}}.types.quipu_fa2.tezos_storage import QuipuFa2Storage
+from {{project.package}}.types.hen_minter.tezos_parameters.mint_objkt import MintOBJKTParameter
+from {{project.package}}.types.hen_minter.tezos_storage import HenMinterStorage
+from {{project.package}}.types.hen_objkts.tezos_parameters.mint import MintParameter
+from {{project.package}}.types.hen_objkts.tezos_storage import HenObjktsStorage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktOperationData
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
-async def on_fa2_withdraw_profit(
+async def on_mint(
     ctx: HandlerContext,
-    withdraw_profit: TzktTransaction[WithdrawProfitParameter, QuipuFa2Storage],
-    transaction_0: TzktOperationData | None = None,
+    mint_objkt: TezosTransaction[MintOBJKTParameter, HenMinterStorage],
+    mint: TezosTransaction[MintParameter, HenObjktsStorage],
 ) -> None:
-    symbol = ctx.template_values['symbol']
-    trader = withdraw_profit.data.sender_address
-
-    position, _ = await models.Position.get_or_create(trader=trader, symbol=symbol)
-
-    if transaction_0:
-        assert transaction_0.amount is not None
-        position.realized_pl += Decimal(transaction_0.amount) / (10**6)
-
-        await position.save()
+    holder, _ = await models.Holder.get_or_create(address=mint.parameter.address)
+    token = models.Token(
+        id=mint.parameter.token_id,
+        creator=holder,
+        supply=mint.parameter.amount,
+        level=mint.data.level,
+        timestamp=mint.data.timestamp,
+    )
+    await token.save()
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_dex/models/__init__.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/models/__init__.py.j2`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_domains/dipdup.yaml.j2` & `dipdup-8.0.0a1/tests/configs/demo_tezos_domains.yml`

 * *Files 21% similar despite different names*

```diff
@@ -1,39 +1,42 @@
-spec_version: 2.0
-package: {{ project.package }}
+spec_version: 3.0
+package: demo_tezos_domains
 
 contracts:
   mainnet_name_registry:
     kind: tezos
     address: KT1GBZmSxmnKJXGMdMLbugPfLyUPmuLSMwKS
     typename: name_registry
 
 datasources:
   mainnet:
     kind: tezos.tzkt
     url: ${TZKT_URL:-https://api.tzkt.io}
 
 templates:
   tezos_domains_big_map:
-    kind: tezos.tzkt.big_maps
-    datasource: <datasource>
+    kind: tezos.big_maps
+    datasources:
+      - <datasource>
     handlers:
       - callback: on_update_records
         contract: <name_registry>
         path: store.records
       - callback: on_update_expiry_map
         contract: <name_registry>
         path: store.expiry_map
 
 indexes:
   tezos_domains_big_map_mainnet:
     template: tezos_domains_big_map
     values:
       datasource: mainnet
       name_registry: mainnet_name_registry
+    first_level: 1417329
+    last_level: 1417729
 
 hooks:
   check_expiration:
     callback: check_expiration
     atomic: False
 
 jobs:
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_domains/handlers/on_update_expiry_map.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_domains/handlers/on_update_expiry_map.py.j2`

 * *Files 5% similar despite different names*

```diff
@@ -1,32 +1,32 @@
 from datetime import datetime
 from typing import Any
 from typing import cast
 
 import strict_rfc3339  # type: ignore[import-untyped]
 from dipdup.context import HandlerContext
-from dipdup.datasources.tezos_tzkt import TzktDatasource
-from dipdup.models.tezos_tzkt import TzktBigMapDiff
+from dipdup.datasources.tezos_tzkt import TezosTzktDatasource
+from dipdup.models.tezos import TezosBigMapDiff
 
 from {{ project.package }} import models as models
 from {{ project.package }}.types.name_registry.tezos_big_maps.store_expiry_map_key import StoreExpiryMapKey
 from {{ project.package }}.types.name_registry.tezos_big_maps.store_expiry_map_value import StoreExpiryMapValue
 
 
 async def on_update_expiry_map(
     ctx: HandlerContext,
-    store_expiry_map: TzktBigMapDiff[StoreExpiryMapKey, StoreExpiryMapValue],
+    store_expiry_map: TezosBigMapDiff[StoreExpiryMapKey, StoreExpiryMapValue],
 ) -> None:
     if not store_expiry_map.action.has_value:
         return
     assert store_expiry_map.key
     assert store_expiry_map.value
 
-    expires_at = datetime.utcfromtimestamp(strict_rfc3339.rfc3339_to_timestamp(store_expiry_map.value.__root__))
-    record_name = bytes.fromhex(store_expiry_map.key.__root__).decode()
+    expires_at = datetime.utcfromtimestamp(strict_rfc3339.rfc3339_to_timestamp(store_expiry_map.value.root))
+    record_name = bytes.fromhex(store_expiry_map.key.root).decode()
     await models.Expiry.update_or_create(
         id=record_name,
         defaults={'expires_at': expires_at},
     )
 
     domain = await models.Domain.get_or_none(id=record_name).prefetch_related('records')
     if domain is None:
@@ -42,11 +42,11 @@
     for record in domain.records:
         record.expired = False
         await record.save()
         if record.address is not None:
             metadata = {} if record.metadata is None else cast(dict[str, Any], record.metadata)
             metadata.update(name=record.id)
             await ctx.update_contract_metadata(
-                network=cast(TzktDatasource, ctx.datasource).name,
+                network=ctx.handler_config.parent.datasources[0].name,  # type: ignore[union-attr]
                 address=record.address,
                 metadata=metadata,
             )
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_domains/handlers/on_update_records.py.j2` & `dipdup-8.0.0a1/src/demo_tezos_domains/handlers/on_update_records.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,39 +1,36 @@
 from contextlib import suppress
-from typing import cast
 
 import orjson
+from demo_tezos_domains import models as models
+from demo_tezos_domains.types.name_registry.tezos_big_maps.store_records_key import StoreRecordsKey
+from demo_tezos_domains.types.name_registry.tezos_big_maps.store_records_value import StoreRecordsValue
 from dipdup.context import HandlerContext
-from dipdup.datasources.tezos_tzkt import TzktDatasource
-from dipdup.models.tezos_tzkt import TzktBigMapDiff
-
-from {{ project.package }} import models as models
-from {{ project.package }}.types.name_registry.tezos_big_maps.store_records_key import StoreRecordsKey
-from {{ project.package }}.types.name_registry.tezos_big_maps.store_records_value import StoreRecordsValue
+from dipdup.models.tezos import TezosBigMapDiff
 
 
 def decode_domain_data(data: dict[str, str]) -> dict[str, str]:
     res = {}
     if isinstance(data, dict):
         for k, v in data.items():
             with suppress(ValueError, orjson.JSONDecodeError):
                 res[k] = orjson.loads(bytes.fromhex(v).decode())
     return res
 
 
 async def on_update_records(
     ctx: HandlerContext,
-    store_records: TzktBigMapDiff[StoreRecordsKey, StoreRecordsValue],
+    store_records: TezosBigMapDiff[StoreRecordsKey, StoreRecordsValue],
 ) -> None:
     if not store_records.action.has_value:
         return
     assert store_records.key
     assert store_records.value
 
-    record_name = bytes.fromhex(store_records.key.__root__).decode()
+    record_name = bytes.fromhex(store_records.key.root).decode()
     record_path = record_name.split('.')
     domain_data = decode_domain_data(store_records.value.data)
     ctx.logger.info('Processing `%s`', record_name)
 
     if len(record_path) != int(store_records.value.level):
         ctx.logger.warning(
             'Invalid record `%s`: expected %s chunks, got %s',
@@ -52,15 +49,15 @@
         )
         return
 
     if store_records.value.level == '2':
         token_id = store_records.value.tzip12_token_id
         if token_id:
             await ctx.update_token_metadata(
-                network=cast(TzktDatasource, ctx.datasource).name,
+                network=ctx.handler_config.parent.datasources[0].name,  # type: ignore[union-attr]
                 address=store_records.data.contract_address,
                 token_id=token_id,
                 metadata={
                     'name': record_name,
                     'symbol': 'TD',
                     'decimals': '0',
                     'isBooleanAmount': True,
@@ -89,11 +86,11 @@
             'expired': False,
             'metadata': domain_data,
         },
     )
 
     if store_records.value.address is not None:
         await ctx.update_contract_metadata(
-            network=cast(TzktDatasource, ctx.datasource).name,
+            network=ctx.handler_config.parent.datasources[0].name,  # type: ignore[union-attr]
             address=store_records.value.address,
             metadata={**domain_data, 'name': record_name},
         )
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_domains/hooks/check_expiration.py.j2` & `dipdup-8.0.0a1/src/demo_tezos_domains/hooks/check_expiration.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from datetime import datetime
 from typing import cast
 
-from {{ project.package }}.models import Record
+from demo_tezos_domains.models import Record
 from dipdup.context import HookContext
-from dipdup.datasources.tezos_tzkt import TzktDatasource
+from dipdup.datasources.tezos_tzkt import TezosTzktDatasource
 
 
 async def check_expiration(
     ctx: HookContext,
 ) -> None:
-    ds = cast(TzktDatasource, next(iter(ctx.datasources.values())))
+    ds = cast(TezosTzktDatasource, next(iter(ctx.datasources.values())))
     expiring_records = (
         await Record.filter(expired=False, domain__expires_at__lt=datetime.utcnow()).all().prefetch_related('domain')
     )
 
     for record in expiring_records:
         ctx.logger.info('Record %s expired at %s', record.id, record.domain.expires_at)
         record.expired = True
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_domains/models/__init__.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_domains/models/__init__.py.j2`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_etherlink/dipdup.yaml.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_etherlink/dipdup.yaml.j2`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-spec_version: 2.0
-package: demo_etherlink
+spec_version: 3.0
+package: demo_tezos_etherlink
 
 datasources:
   tzkt:
     kind: tezos.tzkt
     url: ${TZKT_URL:-https://api.nairobinet.tzkt.io}
 
 contracts:
@@ -18,16 +18,17 @@
   rollup:
     kind: tezos
     address: sr1QgYF6ARMSLcWyAX4wFDrWFaZTyy4twbqe
     typename: rollup
 
 indexes:
   rollup_operations:
-    kind: tezos.tzkt.operations
-    datasource: tzkt
+    kind: tezos.operations
+    datasources:
+      - tzkt
     contracts:
       - ticketer
       - ticket_helper
       - rollup
     types:
       - transaction
       - sr_execute
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_events/dipdup.yaml.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_events/dipdup.yaml.j2`

 * *Files 2% similar despite different names*

```diff
@@ -1,24 +1,25 @@
-spec_version: 2.0
+spec_version: 3.0
 package: {{ project.package }}
 
 datasources:
   tzkt:
     kind: tezos.tzkt
     url: https://api.ghostnet.tzkt.io
 
 contracts:
   events_contract:
     kind: tezos
     address: KT1Up6AMehze2VTdt3w85xaZPtrEWn1AeyR3
 
 indexes:
   events:
-    kind: tezos.tzkt.events
-    datasource: tzkt
+    kind: tezos.events
+    datasources:
+      - tzkt
     handlers:
       - callback: on_move_event
         contract: events_contract
         tag: move
       - callback: on_roll_event
         contract: events_contract
         tag: roll
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_evm_events/dipdup.yaml.j2` & `dipdup-8.0.0a1/src/demo_evm_events/dipdup.yaml`

 * *Files 6% similar despite different names*

```diff
@@ -1,15 +1,14 @@
-spec_version: 2.0
-package: {{ project.package }}
+spec_version: 3.0
+package: demo_evm_events
 
 datasources:
   subsquid:
     kind: evm.subsquid
     url: ${SUBSQUID_URL:-https://v2.archive.subsquid.io/network/ethereum-mainnet}
-    node: evm_node
   etherscan:
     kind: abi.etherscan
     url: ${ETHERSCAN_URL:-https://api.etherscan.io/api}
     api_key: ${ETHERSCAN_API_KEY:-''}
   evm_node:
     kind: evm.node
     url: ${NODE_URL:-https://eth-mainnet.g.alchemy.com/v2}/${NODE_API_KEY:-''}
@@ -19,13 +18,16 @@
   eth_usdt:
     kind: evm
     address: 0xdac17f958d2ee523a2206206994597c13d831ec7
     typename: eth_usdt
 
 indexes:
   eth_usdt_events:
-    kind: evm.subsquid.events
-    datasource: subsquid
+    kind: evm.events
+    datasources:
+      - subsquid
+      - etherscan
+      - evm_node
     handlers:
       - callback: on_transfer
         contract: eth_usdt
-        name: Transfer
+        name: Transfer
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_evm_events/handlers/on_transfer.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_events/handlers/on_transfer.py.j2`

 * *Files 10% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 from decimal import Decimal
 
 from tortoise.exceptions import DoesNotExist
 
 from {{ project.package }} import models as models
-from {{ project.package }}.types.eth_usdt.evm_events.transfer import Transfer
+from {{ project.package }}.types.eth_usdt.evm_events.transfer import TransferPayload
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidEvent
+from dipdup.models.evm import EvmEvent
 
 
 async def on_transfer(
     ctx: HandlerContext,
-    event: SubsquidEvent[Transfer],
+    event: EvmEvent[TransferPayload],
 ) -> None:
     amount = Decimal(event.payload.value) / (10**6)
     if not amount:
         return
 
     await on_balance_update(
         address=event.payload.from_,
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_evm_transactions/dipdup.yaml.j2` & `dipdup-8.0.0a1/tests/configs/demo_evm_events.yml`

 * *Files 13% similar despite different names*

```diff
@@ -1,32 +1,37 @@
-spec_version: 2.0
-package: {{ project.package }}
+spec_version: 3.0
+package: demo_evm_events
 
 datasources:
-  subsquid:
-    kind: evm.subsquid
-    url: ${SUBSQUID_URL:-https://v2.archive.subsquid.io/network/ethereum-mainnet}
-    node: evm_node
   etherscan:
     kind: abi.etherscan
-    url: ${ETHERSCAN_URL:-https://api.etherscan.io/api}
-    api_key: ${ETHERSCAN_API_KEY:-''}
+
   evm_node:
     kind: evm.node
     url: ${NODE_URL:-https://eth-mainnet.g.alchemy.com/v2}/${NODE_API_KEY:-''}
     ws_url: ${NODE_WS_URL:-wss://eth-mainnet.g.alchemy.com/v2}/${NODE_API_KEY:-''}
 
+  subsquid:
+    kind: evm.subsquid
+    url: ${SUBSQUID_URL:-https://v2.archive.subsquid.io/network/ethereum-mainnet}
+    http:
+      replay_path: ${DIPDUP_REPLAY_PATH:-}
+
 contracts:
   eth_usdt:
     kind: evm
     address: 0xdac17f958d2ee523a2206206994597c13d831ec7
     typename: eth_usdt
 
 indexes:
-  eth_usdt_transactions:
-    kind: evm.subsquid.transactions
-    datasource: subsquid
+  eth_usdt_events:
+    kind: evm.events
+    datasources:
+      - subsquid
+      - etherscan
+      - evm_node
     handlers:
       - callback: on_transfer
-        to: eth_usdt
-        method: transfer
-    first_level: 4634748
+        contract: eth_usdt
+        name: Transfer
+    first_level: 18077421
+    last_level: 18077421
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_evm_transactions/handlers/on_transfer.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_transactions/handlers/on_transfer.py.j2`

 * *Files 8% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from decimal import Decimal
 
 from {{ project.package }} import models as models
-from {{ project.package }}.types.eth_usdt.evm_methods.transfer import Transfer
+from {{ project.package }}.types.eth_usdt.evm_transactions.transfer import TransferInput
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidTransaction
+from dipdup.models.evm import EvmTransaction
 from tortoise.exceptions import DoesNotExist
 
 
 async def on_transfer(
     ctx: HandlerContext,
-    transaction: SubsquidTransaction[Transfer],
+    transaction: EvmTransaction[TransferInput],
 ) -> None:
     amount = Decimal(transaction.input.value) / (10**6)
     if not amount:
         return
 
     await on_balance_update(
         address=transaction.data.from_,
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_factories/dipdup.yaml.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_factories/dipdup.yaml.j2`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-spec_version: 2.0
+spec_version: 3.0
 package: {{ project.package }}
 
 contracts:
   factory:
     kind: tezos
     address: KT1PvEyN1xCFCgorN92QCfYjw3axS6jawCiJ
     typename: factory
@@ -14,16 +14,17 @@
 datasources:
   tzkt:
     kind: tezos.tzkt
     url: ${TZKT_URL:-https://api.tzkt.io}
 
 templates:
   dex:
-    kind: tezos.tzkt.operations
-    datasource: tzkt
+    kind: tezos.operations
+    datasources:
+      - tzkt
     types:
       - transaction
     contracts:
       - <dex>
       - <token>
     handlers:
       - callback: on_transfer
@@ -32,16 +33,17 @@
             destination: <token>
             entrypoint: transfer
     first_level: 2393103
     last_level: 2393103
 
 indexes:
   factory:
-    kind: tezos.tzkt.operations
-    datasource: tzkt
+    kind: tezos.operations
+    datasources:
+      - tzkt
     contracts:
       - factory
     types:
       - origination
       - transaction
     handlers:
       - callback: on_factory_origination
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_factories/handlers/on_factory_origination.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_factories/handlers/on_factory_origination.py.j2`

 * *Files 19% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from contextlib import suppress
 from typing import cast
 
 from dipdup.context import HandlerContext
 from dipdup.exceptions import ContractAlreadyExistsError
-from dipdup.models.tezos_tzkt import TzktOperationData
+from dipdup.models.tezos import TezosOperationData
 
 
 async def on_factory_origination(
     ctx: HandlerContext,
-    transaction_0: TzktOperationData,
-    origination_1: TzktOperationData,
+    transaction_0: TezosOperationData,
+    origination_1: TezosOperationData,
 ) -> None:
     assert transaction_0.parameter_json
     dex_contract = cast(str, origination_1.originated_contract_address)
     token_contract = cast(str, transaction_0.parameter_json['token']['address'])
 
     await ctx.add_contract(
         kind='tezos',
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_factories/handlers/on_transfer.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_factories/handlers/on_transfer.py.j2`

 * *Files 13% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 import {{ project.package }}.models as models
 from {{ project.package }}.types.token.tezos_parameters.transfer import TransferParameter
 from {{ project.package }}.types.token.tezos_storage import TokenStorage
 
 
 async def on_transfer(
     ctx: HandlerContext,
-    transfer: TzktTransaction[TransferParameter, TokenStorage],
+    transfer: TezosTransaction[TransferParameter, TokenStorage],
 ) -> None:
-    for transfer_item in transfer.parameter.__root__:
+    for transfer_item in transfer.parameter.root:
         for tx in transfer_item.txs:
             await models.Transfer.create(
                 from_=transfer_item.from_,
                 to=tx.to_,
                 amount=tx.amount,
             )
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_nft_marketplace/dipdup.yaml.j2` & `dipdup-8.0.0a1/tests/configs/demo_tezos_nft_marketplace.yml`

 * *Files 6% similar despite different names*

```diff
@@ -1,29 +1,32 @@
-spec_version: 2.0
-package: {{ project.package }}
-
-datasources:
-  tzkt_mainnet:
-    kind: tezos.tzkt
-    url: ${TZKT_URL:-https://api.tzkt.io}
+spec_version: 3.0
+package: demo_tezos_nft_marketplace
 
 contracts:
   HEN_objkts:
     kind: tezos
     address: ${HEN_OBJKTS:-KT1RJ6PbjHpwc3M5rw5s2Nbmefwbuwbdxton}
     typename: hen_objkts
   HEN_minter:
     kind: tezos
     address: ${HEN_MINTER:-KT1Hkg5qeNhfwpKW4fXvq7HGZB9z2EnmCCA9}
     typename: hen_minter
 
+datasources:
+  tzkt_mainnet:
+    kind: tezos.tzkt
+    url: ${TZKT_URL:-https://api.tzkt.io}
+    http:
+      replay_path: ${DIPDUP_REPLAY_PATH:-}
+
 indexes:
   hen_mainnet:
-    kind: tezos.tzkt.operations
-    datasource: tzkt_mainnet
+    kind: tezos.operations
+    datasources:
+      - tzkt_mainnet
     contracts:
       - HEN_minter
     handlers:
       - callback: on_mint
         pattern:
           - type: transaction
             destination: HEN_minter
@@ -42,7 +45,11 @@
             destination: HEN_minter
             entrypoint: cancel_swap
       - callback: on_collect
         pattern:
           - type: transaction
             destination: HEN_minter
             entrypoint: collect
+    first_level: 1365000
+    last_level: 1366000
+
+logging: WARN
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_nft_marketplace/handlers/on_cancel_swap.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_nft_marketplace/handlers/on_cancel_swap.py.j2`

 * *Files 4% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 import {{project.package}}.models as models
 from {{project.package}}.types.hen_minter.tezos_parameters.cancel_swap import CancelSwapParameter
 from {{project.package}}.types.hen_minter.tezos_storage import HenMinterStorage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_cancel_swap(
     ctx: HandlerContext,
-    cancel_swap: TzktTransaction[CancelSwapParameter, HenMinterStorage],
+    cancel_swap: TezosTransaction[CancelSwapParameter, HenMinterStorage],
 ) -> None:
-    swap = await models.Swap.filter(id=int(cancel_swap.parameter.__root__)).get()
+    swap = await models.Swap.filter(id=int(cancel_swap.parameter.root)).get()
     swap.status = models.SwapStatus.CANCELED
     await swap.save()
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_nft_marketplace/handlers/on_collect.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_nft_marketplace/handlers/on_collect.py.j2`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 import {{project.package}}.models as models
 from {{project.package}}.types.hen_minter.tezos_parameters.collect import CollectParameter
 from {{project.package}}.types.hen_minter.tezos_storage import HenMinterStorage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_collect(
     ctx: HandlerContext,
-    collect: TzktTransaction[CollectParameter, HenMinterStorage],
+    collect: TezosTransaction[CollectParameter, HenMinterStorage],
 ) -> None:
     swap = await models.Swap.filter(id=collect.parameter.swap_id).get()
     seller = await swap.creator
     buyer, _ = await models.Holder.get_or_create(address=collect.data.sender_address)
 
     trade = models.Trade(
         swap=swap,
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_nft_marketplace/handlers/on_mint.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_nft_marketplace/handlers/on_swap.py.j2`

 * *Files 22% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 import {{project.package}}.models as models
-from {{project.package}}.types.hen_minter.tezos_parameters.mint_objkt import MintOBJKTParameter
+from {{project.package}}.types.hen_minter.tezos_parameters.swap import SwapParameter
 from {{project.package}}.types.hen_minter.tezos_storage import HenMinterStorage
-from {{project.package}}.types.hen_objkts.tezos_parameters.mint import MintParameter
-from {{project.package}}.types.hen_objkts.tezos_storage import HenObjktsStorage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
-async def on_mint(
+async def on_swap(
     ctx: HandlerContext,
-    mint_objkt: TzktTransaction[MintOBJKTParameter, HenMinterStorage],
-    mint: TzktTransaction[MintParameter, HenObjktsStorage],
+    swap: TezosTransaction[SwapParameter, HenMinterStorage],
 ) -> None:
-    holder, _ = await models.Holder.get_or_create(address=mint.parameter.address)
-    token = models.Token(
-        id=mint.parameter.token_id,
+    holder, _ = await models.Holder.get_or_create(address=swap.data.sender_address)
+    swap_model = models.Swap(
+        id=int(swap.storage.swap_id) - 1,
         creator=holder,
-        supply=mint.parameter.amount,
-        level=mint.data.level,
-        timestamp=mint.data.timestamp,
+        price=swap.parameter.xtz_per_objkt,
+        amount=swap.parameter.objkt_amount,
+        amount_left=swap.parameter.objkt_amount,
+        status=models.SwapStatus.ACTIVE,
+        level=swap.data.level,
+        timestamp=swap.data.timestamp,
     )
-    await token.save()
+    await swap_model.save()
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_nft_marketplace/models/__init__.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_nft_marketplace/models/__init__.py.j2`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_token/dipdup.yaml.j2` & `dipdup-8.0.0a1/src/demo_tezos_token/dipdup.yaml`

 * *Files 17% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-spec_version: 2.0
-package: {{ project.package }}
+spec_version: 3.0
+package: demo_tezos_token
 
 contracts:
   tzbtc_mainnet:
     kind: tezos
     address: KT1PWx2mnDueood7fEmfbBDKx1D9BAnnXitn
     typename: tzbtc
 
@@ -17,20 +17,21 @@
     template: tzbtc_holders
     values:
       contract: tzbtc_mainnet
       datasource: tzkt_mainnet
 
 templates:
   tzbtc_holders:
-    kind: tezos.tzkt.operations
-    datasource: <datasource>
+    kind: tezos.operations
+    datasources:
+      - <datasource>
     contracts:
       - <contract>
     handlers:
       - callback: on_transfer
         pattern:
           - destination: <contract>
             entrypoint: transfer
       - callback: on_mint
         pattern:
           - destination: <contract>
-            entrypoint: mint
+            entrypoint: mint
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_token/handlers/on_mint.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_token/handlers/on_mint.py.j2`

 * *Files 4% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from decimal import Decimal
 
 from {{ project.package }}.handlers.on_balance_update import on_balance_update
 from {{ project.package }}.types.tzbtc.tezos_parameters.mint import MintParameter
 from {{ project.package }}.types.tzbtc.tezos_storage import TzbtcStorage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_mint(
     ctx: HandlerContext,
-    mint: TzktTransaction[MintParameter, TzbtcStorage],
+    mint: TezosTransaction[MintParameter, TzbtcStorage],
 ) -> None:
     amount = Decimal(mint.parameter.value) / (10**8)
     await on_balance_update(
         address=mint.parameter.to,
         balance_update=amount,
         timestamp=mint.data.timestamp,
     )
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_token/handlers/on_transfer.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_token/handlers/on_transfer.py.j2`

 * *Files 16% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from decimal import Decimal
 
 from {{ project.package }}.handlers.on_balance_update import on_balance_update
 from {{ project.package }}.types.tzbtc.tezos_parameters.transfer import TransferParameter
 from {{ project.package }}.types.tzbtc.tezos_storage import TzbtcStorage
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTransaction
+from dipdup.models.tezos import TezosTransaction
 
 
 async def on_transfer(
     ctx: HandlerContext,
-    transfer: TzktTransaction[TransferParameter, TzbtcStorage],
+    transfer: TezosTransaction[TransferParameter, TzbtcStorage],
 ) -> None:
     if transfer.parameter.from_ == transfer.parameter.to:
         # NOTE: Internal tzBTC transfer
         return
 
     amount = Decimal(transfer.parameter.value) / (10**8)
     await on_balance_update(
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_token_transfers/handlers/on_balance_update.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_token_transfers/handlers/on_balance_update.py.j2`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_token_transfers/handlers/on_token_transfer.py.j2` & `dipdup-8.0.0a1/src/demo_tezos_token_transfers/handlers/on_token_transfer.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 from decimal import Decimal
 from decimal import InvalidOperation
 
-from {{project.package}}.handlers.on_balance_update import on_balance_update
+from demo_tezos_token_transfers.handlers.on_balance_update import on_balance_update
 from dipdup.context import HandlerContext
-from dipdup.models.tezos_tzkt import TzktTokenTransferData
+from dipdup.models.tezos import TezosTokenTransferData
 
 
 async def on_token_transfer(
     ctx: HandlerContext,
-    token_transfer: TzktTokenTransferData,
+    token_transfer: TezosTokenTransferData,
 ) -> None:
     from_, to = token_transfer.from_address, token_transfer.to_address
     if not from_ or not to or from_ == to:
         return
     try:
         amount = Decimal(token_transfer.amount or 0) / (10**8)
     except InvalidOperation:
         return
     if not amount:
         return
 
     await on_balance_update(address=from_, balance_update=-amount, timestamp=token_transfer.timestamp)
-    await on_balance_update(address=to, balance_update=amount, timestamp=token_transfer.timestamp)
+    await on_balance_update(address=to, balance_update=amount, timestamp=token_transfer.timestamp)
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_uniswap/abi/erc20/ERC20.json.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/abi/erc20/ERC20.json.j2`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_uniswap/dipdup.yaml.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/dipdup.yaml.j2`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,14 @@
-spec_version: 2.0
+spec_version: 3.0
 package: {{ project.package }}
 
 datasources:
   subsquid:
     kind: evm.subsquid
     url: ${SUBSQUID_URL:-https://v2.archive.subsquid.io/network/ethereum-mainnet}
-    node: evm_node
   etherscan:
     kind: abi.etherscan
     url: ${ETHERSCAN_URL:-https://api.etherscan.io/api}
     api_key: ${ETHERSCAN_API_KEY:-''}
   evm_node:
     kind: evm.node
     url: ${NODE_URL:-https://eth-mainnet.g.alchemy.com/v2}/${NODE_API_KEY:-''}
@@ -27,16 +26,19 @@
   pool:
     kind: evm
     abi: 0x7668b2ea8490955f68f5c33e77fe150066c94fb9
     typename: pool
 
 templates:
   uniswap_v3_factory:
-    kind: evm.subsquid.events
-    datasource: <datasource>
+    kind: evm.events
+    datasources:
+      - <datasource>
+      - etherscan
+      - evm_node
     first_level: 12369521
     handlers:
       - callback: factory.pool_created
         contract: factory
         name: PoolCreated
       - callback: position_manager.increase_liquidity
         contract: position_manager
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_uniswap/handlers/factory/pool_created.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/handlers/factory/pool_created.py.j2`

 * *Files 9% similar despite different names*

```diff
@@ -2,18 +2,18 @@
 from typing import cast
 
 from tortoise.exceptions import OperationalError
 
 from {{ project.package }} import models as models
 from {{ project.package }}.models.token import WHITELIST_TOKENS
 from {{ project.package }}.models.token import ERC20Token
-from {{ project.package }}.types.factory.evm_events.pool_created import PoolCreated
+from {{ project.package }}.types.factory.evm_events.pool_created import PoolCreatedPayload
 from dipdup.config.evm import EvmContractConfig
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidEvent
+from dipdup.models.evm import EvmEvent
 
 POOL_BLACKLIST = {'0x8fe8d9bb8eeba3ed688069c3d6b556c9ca258248'}
 WETH_ADDRESS = '0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2'
 
 
 async def create_token(ctx: HandlerContext, address: str, pool_id: str) -> None:
     with suppress(Exception):
@@ -33,15 +33,15 @@
     )
     token.cache()
     await token.save()
 
 
 async def pool_created(
     ctx: HandlerContext,
-    event: SubsquidEvent[PoolCreated],
+    event: EvmEvent[PoolCreatedPayload],
 ) -> None:
     if event.payload.pool in POOL_BLACKLIST:
         ctx.logger.info('Pool %s is blacklisted', event.payload.pool)
         return
 
     factory_address = cast(EvmContractConfig, ctx.config.get_contract('factory')).address
     factory, _ = await models.Factory.get_or_create(id=factory_address)
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_uniswap/handlers/pool/burn.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/handlers/pool/burn.py.j2`

 * *Files 26% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 from {{ project.package }} import models
 from {{ project.package }}.models.pool import PoolUpdateSign
 from {{ project.package }}.models.pool import pool_update
-from {{ project.package }}.types.pool.evm_events.burn import Burn
+from {{ project.package }}.types.pool.evm_events.burn import BurnPayload
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidEvent
+from dipdup.models.evm import EvmEvent
 
 
 async def burn(
     ctx: HandlerContext,
-    event: SubsquidEvent[Burn],
+    event: EvmEvent[BurnPayload],
 ) -> None:
     pool = await models.Pool.cached_get_or_none(event.data.address)
     if not pool:
         return
     await pool_update(ctx, pool, event, PoolUpdateSign.BURN)
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_uniswap/handlers/pool/mint.py.j2` & `dipdup-8.0.0a1/src/demo_evm_uniswap/handlers/pool/mint.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,23 +1,22 @@
-from eth_utils.address import to_normalized_address
-
-from {{ project.package }} import models
-from {{ project.package }}.models.pool import PoolUpdateSign
-from {{ project.package }}.models.pool import pool_update
-from {{ project.package }}.models.repo import models_repo
-from {{ project.package }}.types.pool.evm_events.mint import Mint
+from demo_evm_uniswap import models
+from demo_evm_uniswap.models.pool import PoolUpdateSign
+from demo_evm_uniswap.models.pool import pool_update
+from demo_evm_uniswap.models.repo import models_repo
+from demo_evm_uniswap.types.pool.evm_events.mint import MintPayload
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidEvent
+from dipdup.models.evm import EvmEvent
+from eth_utils.address import to_normalized_address
 
 BLACKLISTED_POOLS = {'0x8fe8d9bb8eeba3ed688069c3d6b556c9ca258248'}
 
 
 async def mint(
     ctx: HandlerContext,
-    event: SubsquidEvent[Mint],
+    event: EvmEvent[MintPayload],
 ) -> None:
     pool = await models.Pool.cached_get_or_none(event.data.address)
     if not pool or pool.id in BLACKLISTED_POOLS:
         ctx.logger.debug('Pool.mint: skipping pool %s as it is blacklisted', event.data.address)
         return
 
     await pool_update(ctx, pool, event, PoolUpdateSign.MINT)
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_uniswap/handlers/pool/swap.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/handlers/pool/swap.py.j2`

 * *Files 5% similar despite different names*

```diff
@@ -3,17 +3,17 @@
 from {{ project.package }} import models as models
 from {{ project.package }}.models.repo import USDC_WETH_03_POOL
 from {{ project.package }}.models.repo import get_ctx_factory
 from {{ project.package }}.models.repo import models_repo
 from {{ project.package }}.models.token import WHITELIST_TOKENS
 from {{ project.package }}.models.token import convert_token_amount
 from {{ project.package }}.models.token import token_derive_eth
-from {{ project.package }}.types.pool.evm_events.swap import Swap
+from {{ project.package }}.types.pool.evm_events.swap import SwapPayload
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidEvent
+from dipdup.models.evm import EvmEvent
 
 POOL_BLACKLIST = {'0x9663f2ca0454accad3e094448ea6f77443880454'}
 Q192 = Decimal(2**192)
 
 
 def get_tracked_amount_usd(
     token0: models.Token, token1: models.Token, amount0: Decimal, amount1: Decimal, eth_usd: Decimal
@@ -44,15 +44,15 @@
     price1 = (num / Q192) * (Decimal(10) ** token0.decimals) / (Decimal(10) ** token1.decimals)
     price0 = Decimal(1) / price1
     return price0, price1
 
 
 async def swap(
     ctx: HandlerContext,
-    event: SubsquidEvent[Swap],
+    event: EvmEvent[SwapPayload],
 ) -> None:
     factory = await get_ctx_factory(ctx)
     pool = await models.Pool.cached_get_or_none(event.data.address)
     if not pool:
         return
     token0 = await models.Token.cached_get(pool.token0_id)
     token1 = await models.Token.cached_get(pool.token1_id)
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_uniswap/handlers/position_manager/collect.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/handlers/position_manager/increase_liquidity.py.j2`

 * *Files 17% similar despite different names*

```diff
@@ -1,33 +1,38 @@
 from {{ project.package }} import models
 from {{ project.package }}.models.position import save_position_snapshot
 from {{ project.package }}.models.token import convert_token_amount
-from {{ project.package }}.types.position_manager.evm_events.collect import Collect
+from {{ project.package }}.types.position_manager.evm_events.increase_liquidity import IncreaseLiquidityPayload
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidEvent
+from dipdup.models.evm import EvmEvent
 
 BLACKLISTED_BLOCKS = {14317993}
 
 
-async def collect(
+async def increase_liquidity(
     ctx: HandlerContext,
-    event: SubsquidEvent[Collect],
+    event: EvmEvent[IncreaseLiquidityPayload],
 ) -> None:
     if event.data.level in BLACKLISTED_BLOCKS:
         ctx.logger.warning('Blacklisted level %d', event.data.level)
         return
 
     position = await models.Position.get_or_none(id=event.payload.tokenId)
     if position is None:
         ctx.logger.warning('Skipping position %s (must be blacklisted pool)', event.payload.tokenId)
         return
 
+    # TODO: remove me
+    # await position_validate(ctx, event.data.address, event.payload.tokenId, position)
+
     token0 = await models.Token.cached_get(position.token0_id)
+    token1 = await models.Token.cached_get(position.token1_id)
+
     amount0 = convert_token_amount(event.payload.amount0, token0.decimals)
-    amount1 = convert_token_amount(event.payload.amount1, token0.decimals)  # Correct?
+    amount1 = convert_token_amount(event.payload.amount1, token1.decimals)
 
-    position.collected_fees_token0 += amount0
-    position.collected_fees_token1 += amount1
+    position.liquidity += event.payload.liquidity
+    position.deposited_token0 += amount0
+    position.deposited_token1 += amount1
 
     await position.save()
-    # position.cache()
     await save_position_snapshot(position, event.data.level, event.data.timestamp)
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_uniswap/handlers/position_manager/decrease_liquidity.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/handlers/position_manager/decrease_liquidity.py.j2`

 * *Files 6% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 from {{ project.package }} import models
 from {{ project.package }}.models.position import save_position_snapshot
 from {{ project.package }}.models.token import convert_token_amount
-from {{ project.package }}.types.position_manager.evm_events.decrease_liquidity import DecreaseLiquidity
+from {{ project.package }}.types.position_manager.evm_events.decrease_liquidity import DecreaseLiquidityPayload
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidEvent
+from dipdup.models.evm import EvmEvent
 
 BLACKLISTED_BLOCKS = {14317993}
 
 
 async def decrease_liquidity(
     ctx: HandlerContext,
-    event: SubsquidEvent[DecreaseLiquidity],
+    event: EvmEvent[DecreaseLiquidityPayload],
 ) -> None:
     if event.data.level in BLACKLISTED_BLOCKS:
         ctx.logger.warning('Blacklisted level %d', event.data.level)
         return
 
     position = await models.Position.get_or_none(id=event.payload.tokenId)
     if position is None:
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_uniswap/handlers/position_manager/transfer.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/handlers/position_manager/transfer.py.j2`

 * *Files 18% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 from eth_utils.address import to_normalized_address
 
 import {{ project.package }}.models as models
 from {{ project.package }}.models.position import save_position_snapshot
 from {{ project.package }}.models.repo import models_repo
-from {{ project.package }}.types.position_manager.evm_events.transfer import Transfer
+from {{ project.package }}.types.position_manager.evm_events.transfer import TransferPayload
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidEvent
+from dipdup.models.evm import EvmEvent
 
 
 async def transfer(
     ctx: HandlerContext,
-    event: SubsquidEvent[Transfer],
+    event: EvmEvent[TransferPayload],
 ) -> None:
     if event.payload.from_ == '0x0000000000000000000000000000000000000000':
         idx = f'{event.data.level}.{event.data.transaction_index}.{event.data.log_index}'
         pending_position = models_repo.get_pending_position(idx)
         if pending_position is None:
             ctx.logger.warning('Skipping position %s (must be blacklisted pool)', event.payload.tokenId)
             return
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_uniswap/models/__init__.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/models/__init__.py.j2`

 * *Files 0% similar despite different names*

```diff
@@ -169,15 +169,15 @@
     liquidity_provider_count = fields.BigIntField(default=0)  # used to detect new exchanges
     # vars needed for fee computation
     # TODO: require rpc calls
     # fee_growth_outside_0x128 = fields.BigIntField()
     # fee_growth_outside_1x128 = fields.BigIntField()
 
 
-# NOTE: Cached, but with custom logic; see `demo_uniswap.utils.position`
+# NOTE: Cached, but with custom logic; see `demo_evm_uniswap.utils.position`
 class Position(Model):
     id = fields.BigIntField(pk=True)
     # owner of the NFT
     owner = fields.CharField(max_length=42, default=ADDRESS_ZERO)
     # pool position is within
     pool: fields.ForeignKeyRelation[Pool] = fields.ForeignKeyField('models.Pool', related_name='positions')
     # allow indexing by tokens
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_uniswap/models/pool.py.j2` & `dipdup-8.0.0a1/src/demo_evm_uniswap/models/pool.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,27 +1,28 @@
-from {{ project.package }} import models
-from {{ project.package }}.models.repo import get_ctx_factory
-from {{ project.package }}.models.repo import models_repo
-from {{ project.package }}.models.tick import tick_get_or_create
-from {{ project.package }}.models.token import convert_token_amount
-from {{ project.package }}.types.pool.evm_events.burn import Burn
-from {{ project.package }}.types.pool.evm_events.mint import Mint
 from dipdup.context import HandlerContext
-from dipdup.models.evm_subsquid import SubsquidEvent
+from dipdup.models.evm import EvmEvent
+
+from demo_evm_uniswap import models
+from demo_evm_uniswap.models.repo import get_ctx_factory
+from demo_evm_uniswap.models.repo import models_repo
+from demo_evm_uniswap.models.tick import tick_get_or_create
+from demo_evm_uniswap.models.token import convert_token_amount
+from demo_evm_uniswap.types.pool.evm_events.burn import BurnPayload
+from demo_evm_uniswap.types.pool.evm_events.mint import MintPayload
 
 
 class PoolUpdateSign:
     MINT = 1
     BURN = -1
 
 
 async def pool_update(
     ctx: HandlerContext,
     pool: models.Pool,
-    event: SubsquidEvent[Burn] | SubsquidEvent[Mint],
+    event: EvmEvent[BurnPayload] | EvmEvent[MintPayload],
     sign: int,
 ) -> None:
     factory = await get_ctx_factory(ctx)
     token0 = await models.Token.cached_get(pool.token0_id)
     token1 = await models.Token.cached_get(pool.token1_id)
 
     amount0 = convert_token_amount(event.payload.amount0, token0.decimals)
@@ -76,19 +77,19 @@
         'amount_usd': amount_usd,
         'tick_lower': event.payload.tickLower,
         'tick_upper': event.payload.tickUpper,
         'log_index': event.data.log_index,
     }
 
     tx: models.Burn | models.Mint
-    if isinstance(event.payload, Mint) and sign == PoolUpdateSign.MINT:
-        if not isinstance(event.payload, Mint):
+    if isinstance(event.payload, MintPayload) and sign == PoolUpdateSign.MINT:
+        if not isinstance(event.payload, MintPayload):
             raise Exception('Invalid event type')
         tx = models.Mint(sender=event.payload.sender, **tx_defaults)
-    elif isinstance(event.payload, Burn) and sign == PoolUpdateSign.BURN:
+    elif isinstance(event.payload, BurnPayload) and sign == PoolUpdateSign.BURN:
         tx = models.Burn(**tx_defaults)
     else:
         raise Exception('Invalid event type')
     await tx.save()
 
     lower_tick = await tick_get_or_create(event.payload.tickLower, pool, event.data.level, event.data.timestamp)
     lower_tick.liquidity_gross = lower_tick.liquidity_gross + sign * event.payload.amount
```

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_uniswap/models/position.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/models/position.py.j2`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_uniswap/models/repo.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/models/repo.py.j2`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_uniswap/models/tick.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/models/tick.py.j2`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_uniswap/models/token.py.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/models/token.py.j2`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_uniswap/sql/on_reindex/20_create_ca_quotes_1m.sql.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/sql/on_reindex/20_create_ca_quotes_1m.sql.j2`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_uniswap/sql/on_reindex/21_create_ca_quotes_1h.sql.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/sql/on_reindex/21_create_ca_quotes_1h.sql.j2`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/projects/demo_uniswap/sql/on_reindex/22_create_ca_quotes_1d.sql.j2` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_uniswap/sql/on_reindex/22_create_ca_quotes_1d.sql.j2`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/prometheus.py` & `dipdup-8.0.0a1/src/dipdup/prometheus.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/pysignalr.py` & `dipdup-8.0.0a1/src/dipdup/pysignalr.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/report.py` & `dipdup-8.0.0a1/src/dipdup/report.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/scheduler.py` & `dipdup-8.0.0a1/src/dipdup/scheduler.py`

 * *Files 2% similar despite different names*

```diff
@@ -54,15 +54,15 @@
         self._scheduler = AsyncIOScheduler(config or DEFAULT_CONFIG)
         self._scheduler.add_listener(self._on_error, EVENT_JOB_ERROR)
         self._scheduler.add_listener(self._on_executed, EVENT_JOB_EXECUTED)
         self._exception: Exception | None = None
         self._exception_event: asyncio.Event = asyncio.Event()
         self._daemons: set[str] = set()
 
-    async def run(self, ctx: DipDupContext, event: asyncio.Event) -> None:
+    async def run(self, ctx: 'DipDupContext', event: asyncio.Event) -> None:
         if not event.is_set():
             self._logger.info('Job scheduler is waiting for an event')
         await event.wait()
 
         try:
             self._logger.info('Starting job scheduler')
             self._scheduler.start()
@@ -75,27 +75,27 @@
                 raise FrameworkException('Job has failed but exception is not set')
             raise self._exception
         except asyncio.CancelledError:
             pass
         finally:
             self._scheduler.shutdown()
 
-    def add_job(self, ctx: DipDupContext, job_config: JobConfig) -> Job:
+    def add_job(self, ctx: 'DipDupContext', job_config: JobConfig) -> Job:
         if job_config.daemon:
             self._daemons.add(job_config.name)
 
         hook_config = job_config.hook
 
         logger = FormattedLogger(
             name=f'dipdup.hooks.{hook_config.callback}',
             fmt=job_config.name + ': {}',
         )
 
         async def _job_wrapper(
-            ctx: DipDupContext,
+            ctx: 'DipDupContext',
             *args: Any,
             **kwargs: Any,
         ) -> None:
             nonlocal job_config, hook_config
             job_ctx = HookContext._wrap(
                 ctx=ctx,
                 logger=logger,
```

### Comparing `dipdup-7.5.7/src/dipdup/sentry.py` & `dipdup-8.0.0a1/src/dipdup/sentry.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/sql/dipdup_wipe.sql` & `dipdup-8.0.0a1/src/dipdup/sql/dipdup_wipe.sql`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/subscriptions.py` & `dipdup-8.0.0a1/src/dipdup/subscriptions.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/sys.py` & `dipdup-8.0.0a1/src/dipdup/sys.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/templates/models.py` & `dipdup-8.0.0a1/src/dipdup/templates/models.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/test.py` & `dipdup-8.0.0a1/src/dipdup/test.py`

 * *Files 4% similar despite different names*

```diff
@@ -140,25 +140,30 @@
     package: str,
     exists: bool,
     env: dict[str, str] | None = None,
 ) -> AsyncIterator[tuple[Path, dict[str, str]]]:
     """Create a temporary isolated DipDup project."""
     with tempfile.TemporaryDirectory() as tmp_package_path:
         # NOTE: Dump config
-        config, _ = DipDupYAMLConfig.load(config_paths, environment=False)
+        config, _ = DipDupYAMLConfig.load(
+            config_paths,
+            environment=False,
+            raw=True,
+            unsafe=False,
+        )
         tmp_config_path = Path(tmp_package_path) / 'dipdup.yaml'
         tmp_config_path.write_text(config.dump())
 
         # NOTE: Symlink packages and executables
         tmp_bin_path = Path(tmp_package_path) / 'bin'
         tmp_bin_path.mkdir()
-        for executable in ('dipdup', 'datamodel-codegen'):
-            if (executable_path := which(executable)) is None:
-                raise FrameworkException(f'Executable `{executable}` not found')  # pragma: no cover
-            os.symlink(executable_path, tmp_bin_path / executable)
+
+        if (dipdup_path := which('dipdup')) is None:
+            raise FrameworkException('Executable `dipdup` not found')
+        os.symlink(dipdup_path, tmp_bin_path / 'dipdup')
 
         os.symlink(
             Path(__file__).parent.parent / 'dipdup',
             Path(tmp_package_path) / 'dipdup',
         )
 
         # NOTE: Ensure that `run` uses existing package and `init` creates a new one
@@ -166,15 +171,14 @@
             os.symlink(
                 Path(__file__).parent.parent / package,
                 Path(tmp_package_path) / package,
             )
 
         # NOTE: Prepare environment
         env = {
-            **os.environ,
             **(env or {}),
             'PATH': str(tmp_bin_path),
             'PYTHONPATH': str(tmp_package_path),
             'DIPDUP_TEST': '1',
             'DIPDUP_DEBUG': '1',
         }
 
@@ -189,14 +193,17 @@
     """Run DipDup in existing temporary project."""
     tmp_config_path = Path(tmp_path) / 'dipdup.yaml'
 
     proc = await asyncio.subprocess.create_subprocess_shell(
         f'dipdup -c {tmp_config_path} {" ".join(args)}',
         cwd=tmp_path,
         shell=True,
-        env=env,
+        env={
+            **os.environ,
+            **env,
+        },
         stdout=asyncio.subprocess.PIPE,
         stderr=asyncio.subprocess.PIPE,
     )
     res = await proc.communicate()
     if proc.returncode != 0:
         raise Exception(f'`dipdup` failed: {res[0].decode()}\n{res[1].decode()}')
```

### Comparing `dipdup-7.5.7/src/dipdup/transactions.py` & `dipdup-8.0.0a1/src/dipdup/transactions.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/src/dipdup/utils.py` & `dipdup-8.0.0a1/src/dipdup/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -197,19 +197,18 @@
 def parse_object(
     type_: type[ObjectT],
     data: Mapping[str, Any] | Sequence[Any] | None,
     plain: bool = False,
 ) -> ObjectT:
     try:
         if plain is False or data is None:
-            return type_.parse_obj(data)
+            return type_.model_validate(data)
 
-        model_keys = tuple(field.alias for field in type_.__fields__.values())
+        model_keys = tuple(field.alias or key for key, field in type_.model_fields.items())
         return type_(**dict(zip(model_keys, data, strict=True)))
-
     except ValidationError as e:
         raise InvalidDataError(f'Failed to parse: {e.errors()}', type_, data) from e
     except ValueError as e:
         raise InvalidDataError(f'Failed to parse: {e}', type_, data) from e
 
 
 def _default_for_decimals(obj: Any) -> Any:
```

### Comparing `dipdup-7.5.7/src/dipdup/yaml.py` & `dipdup-8.0.0a1/src/dipdup/yaml.py`

 * *Files 10% similar despite different names*

```diff
@@ -19,27 +19,31 @@
 from io import StringIO
 from os import environ as env
 from typing import TYPE_CHECKING
 from typing import Any
 
 from ruamel.yaml import YAML
 
-from dipdup import __spec_version__
 from dipdup.exceptions import ConfigurationError
-from dipdup.utils import json_dumps
 
 if TYPE_CHECKING:
     from pathlib import Path
 
 # NOTE: ${VARIABLE:-default} | ${VARIABLE}
 ENV_VARIABLE_REGEX = r'\$\{(?P<var_name>[\w]+)(?:\:\-(?P<default_value>.*?))?\}'
 
 
 _logger = logging.getLogger(__name__)
 
+yaml_loader = YAML()
+
+yaml_dumper = YAML()
+yaml_dumper.default_flow_style = False
+yaml_dumper.indent(mapping=2, sequence=4, offset=2)
+
 
 def exclude_none(config_json: Any) -> Any:
     if isinstance(config_json, list | tuple):
         return [exclude_none(i) for i in config_json if i is not None]
     if isinstance(config_json, dict):
         return {k: exclude_none(v) for k, v in config_json.items() if v is not None}
     return config_json
@@ -69,54 +73,57 @@
     try:
         with path.open() as file:
             return ''.join(filter(filter_comments, file.readlines()))
     except OSError as e:
         raise ConfigurationError(f'Config file `{path}` is not readable: {e}') from e
 
 
-def dump(value: Any) -> str:
-    yaml = YAML(typ='unsafe', pure=True)
-    yaml.default_flow_style = False
-    yaml.indent = 2
-
-    config_json = json_dumps(value)
-    config_yaml = exclude_none(yaml.load(config_json))
+def dump(value: dict[str, Any]) -> str:
+    value = exclude_none(value)
     buffer = StringIO()
-    yaml.dump(config_yaml, buffer)
+    yaml_dumper.dump(value, buffer)
     return buffer.getvalue()
 
 
-def substitute_env_variables(config_yaml: str) -> tuple[str, dict[str, str]]:
+def substitute_env_variables(
+    config_yaml: str,
+    unsafe: bool,
+) -> tuple[str, dict[str, str]]:
     _logger.debug('Substituting environment variables')
     environment: dict[str, str] = {}
 
     for match in re.finditer(ENV_VARIABLE_REGEX, config_yaml):
         variable, default_value = match.group('var_name'), match.group('default_value')
-        value = env.get(variable, default_value)
-        # NOTE: Don't fail on ''
-        if value is None:
-            raise ConfigurationError(f'Environment variable `{variable}` is not set')
+
+        if unsafe:
+            value = env.get(variable, default_value)
+            # NOTE: Don't fail on ''
+            if value is None:
+                raise ConfigurationError(f'Environment variable `{variable}` is not set')
+        else:
+            value = default_value or ''
+
         environment[variable] = value
         placeholder = match.group(0)
-        config_yaml = config_yaml.replace(placeholder, value or default_value or '')
+        config_yaml = config_yaml.replace(placeholder, value)
 
     return config_yaml, environment
 
 
 def get_default_env_variables(config_yaml: str) -> dict[str, str]:
     environment: dict[str, str] = {}
 
     for match in re.finditer(ENV_VARIABLE_REGEX, config_yaml):
         variable, default_value = match.group('var_name'), match.group('default_value')
         environment[variable] = default_value or ''
 
     return environment
 
 
-# FIXME: Can't use `from_` field alias in dataclasses (fixed in `next` with Pydantic v2)
+# FIXME: Can't use `from_` field alias in dataclasses
 def fix_dataclass_field_aliases(config: dict[str, Any]) -> None:
     for k, v in copy(config).items():
         if 'callback' in config and k == 'from':
             config['from_'] = config.pop('from')
         elif isinstance(v, dict):
             fix_dataclass_field_aliases(v)
         elif isinstance(v, list):
@@ -127,43 +134,33 @@
 
 class DipDupYAMLConfig(dict[str, Any]):
     @classmethod
     def load(
         cls,
         paths: list[Path],
         environment: bool = True,
+        raw: bool = False,
+        unsafe: bool = False,
     ) -> tuple[DipDupYAMLConfig, dict[str, Any]]:
-        yaml = YAML(typ='base')
 
         config = cls()
         config_environment: dict[str, str] = {}
 
         for path in paths:
             path_yaml = read_config_yaml(path)
 
-            if environment:
-                path_yaml, path_environment = substitute_env_variables(path_yaml)
+            if raw:
+                pass
+            elif environment:
+                path_yaml, path_environment = substitute_env_variables(path_yaml, unsafe)
                 config_environment.update(path_environment)
-            else:
-                config_environment |= get_default_env_variables(path_yaml)
 
-            config.update(yaml.load(path_yaml))
+            config.update(yaml_loader.load(path_yaml))
 
-        config._post_load_hooks()
+        if not raw:
+            # FIXME: Can't use `from_` field alias in dataclasses
+            fix_dataclass_field_aliases(config)
 
         return config, config_environment
 
     def dump(self) -> str:
         return dump(self)
-
-    def validate_version(self) -> None:
-        config_spec_version = self['spec_version']
-        if config_spec_version != __spec_version__:
-            raise ConfigurationError(
-                f'Incompatible spec version: expected {__spec_version__}, got {config_spec_version}. See'
-                ' https://dipdup.io/docs/config/spec_version'
-            )
-
-    def _post_load_hooks(self) -> None:
-        self.validate_version()
-        # FIXME: Can't use `from_` field alias in dataclasses (fixed in `next` with Pydantic v2)
-        fix_dataclass_field_aliases(self)
```

### Comparing `dipdup-7.5.7/tests/__init__.py` & `dipdup-8.0.0a1/tests/__init__.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,33 +1,33 @@
 from collections.abc import AsyncIterator
 from contextlib import asynccontextmanager
 from pathlib import Path
 
 from dipdup import env
 from dipdup.config import HttpConfig
-from dipdup.config.tezos_tzkt import TzktDatasourceConfig
-from dipdup.datasources.tezos_tzkt import TzktDatasource
+from dipdup.config.tezos_tzkt import TezosTzktDatasourceConfig
+from dipdup.datasources.tezos_tzkt import TezosTzktDatasource
 
 env.set_test()
 
 
 TEST_CONFIGS = Path(__file__).parent / 'configs'
 
 
 @asynccontextmanager
 async def tzkt_replay(
     url: str = 'https://api.tzkt.io',
     batch_size: int | None = None,
-) -> AsyncIterator[TzktDatasource]:
+) -> AsyncIterator[TezosTzktDatasource]:
     http_config = HttpConfig(
         batch_size=batch_size,
         replay_path=str(Path(__file__).parent / 'replays'),
     )
-    config = TzktDatasourceConfig(
+    config = TezosTzktDatasourceConfig(
         kind='tezos.tzkt',
         url=url,
         http=http_config,
     )
     config._name = 'tzkt'
-    datasource = TzktDatasource(config)
+    datasource = TezosTzktDatasource(config)
     async with datasource:
         yield datasource
```

### Comparing `dipdup-7.5.7/tests/configs/demo_auction.yml` & `dipdup-8.0.0a1/src/demo_tezos_auction/dipdup.yaml`

 * *Files 24% similar despite different names*

```diff
@@ -1,32 +1,30 @@
-spec_version: 2.0
-package: demo_auction
-
-datasources:
-  tzkt:
-    kind: tezos.tzkt
-    url: ${TZKT_URL:-https://api.tzkt.io}
-    http:
-      replay_path: ${DIPDUP_REPLAY_PATH:-}
+spec_version: 3.0
+package: demo_tezos_auction
 
 contracts:
   tzcolors_minter:
     kind: tezos
     address: KT1FyaDqiMQWg7Exo7VUiXAgZbd2kCzo3d4s
     typename: tzcolors_minter
   tzcolors_auction:
     kind: tezos
     address: KT1CpeSQKdkhWi4pinYcseCFKmDhs5M74BkU
     typename: tzcolors_auction
 
+datasources:
+  tzkt:
+    kind: tezos.tzkt
+    url: ${TZKT_URL:-https://api.tzkt.io}
 
 templates:
-  tzcolors_auction:
-    kind: tezos.tzkt.operations
-    datasource: <datasource>
+  auction:
+    kind: tezos.operations
+    datasources:
+      - <datasource>
     contracts:
       - <auction>
     handlers:
       - callback: on_create_auction
         pattern:
           - type: transaction
             destination: <auction>
@@ -37,19 +35,15 @@
             destination: <auction>
             entrypoint: bid
       - callback: on_withdraw
         pattern:
           - type: transaction
             destination: <auction>
             entrypoint: withdraw
-    first_level: 1335654
-    last_level: 1340654
 
 indexes:
-  tzcolors_auction:
-    template: tzcolors_auction
+  tzcolors:
+    template: auction
     values:
       datasource: tzkt
       minter: tzcolors_minter
-      auction: tzcolors_auction
-
-logging: WARN
+      auction: tzcolors_auction
```

### Comparing `dipdup-7.5.7/tests/configs/demo_big_maps.yml` & `dipdup-8.0.0a1/tests/configs/demo_tezos_big_maps.yml`

 * *Files 18% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-spec_version: 2.0
-package: demo_big_maps
+spec_version: 3.0
+package: demo_tezos_big_maps
 
 contracts:
   name_registry:
     kind: tezos
     address: KT1GBZmSxmnKJXGMdMLbugPfLyUPmuLSMwKS
     typename: name_registry
 
@@ -12,16 +12,17 @@
     kind: tezos.tzkt
     url: ${TZKT_URL:-https://api.tzkt.io}
     http:
       replay_path: ${DIPDUP_REPLAY_PATH:-}
 
 templates:
   big_maps:
-    kind: tezos.tzkt.big_maps
-    datasource: <datasource>
+    kind: tezos.big_maps
+    datasources:
+      - <datasource>
     handlers:
       - callback: on_update_records
         contract: <name_registry>
         path: store.records
       - callback: on_update_expiry_map
         contract: <name_registry>
         path: store.expiry_map
```

### Comparing `dipdup-7.5.7/tests/configs/demo_dao.yml` & `dipdup-8.0.0a1/tests/configs/demo_tezos_dao.yml`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-spec_version: 2.0
-package: demo_dao
+spec_version: 3.0
+package: demo_tezos_dao
 
 contracts:
   registry:
     kind: tezos
     code_hash: KT1J2e6sDkgdTuB9hmE1AntzrghJem1wzT7a
     typename: registry
 
@@ -12,16 +12,17 @@
     kind: tezos.tzkt
     url: ${TZKT_URL:-https://api.tzkt.io}
     http:
       replay_path: ${DIPDUP_REPLAY_PATH:-}
 
 indexes:
   registry_dao:
-    kind: tezos.tzkt.operations
-    datasource: tzkt
+    kind: tezos.operations
+    datasources:
+      - tzkt
     types:
       - transaction
       - origination
     handlers:
       - callback: on_origination
         pattern:
           - type: origination
```

### Comparing `dipdup-7.5.7/tests/configs/demo_dex.yml` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_dex/dipdup.yaml.j2`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-spec_version: 2.0
-package: demo_dex
+spec_version: 3.0
+package: {{ project.package }}
 
 contracts:
   kusd_dex_mainnet:
     kind: tezos
     address: KT1K4EwTpbvYN9agJdjpyJm4ZZdhpUNKB3F6
     typename: quipu_fa12
   kusd_token_mainnet:
@@ -19,21 +19,20 @@
     address: KT1AFA2mwNUMNd4SsujE1YYp29vd8BZejyKW
     typename: fa2_token
 
 datasources:
   tzkt_mainnet:
     kind: tezos.tzkt
     url: https://api.tzkt.io
-    http:
-      replay_path: ${DIPDUP_REPLAY_PATH:-}
 
 templates:
   quipuswap_fa12:
-    kind: tezos.tzkt.operations
-    datasource: tzkt_mainnet
+    kind: tezos.operations
+    datasources:
+      - tzkt_mainnet
     contracts:
       - <dex_contract>
     types:
       - transaction
       - origination
     handlers:
       - callback: on_fa12_origination
@@ -87,16 +86,17 @@
             destination: <dex_contract>
             entrypoint: withdrawProfit
           - type: transaction
             source: <dex_contract>
             optional: True
 
   quipuswap_fa2:
-    kind: tezos.tzkt.operations
-    datasource: tzkt_mainnet
+    kind: tezos.operations
+    datasources:
+      - tzkt_mainnet
     contracts:
       - <dex_contract>
     types:
       - transaction
       - origination
     handlers:
       - callback: on_fa2_origination
@@ -157,21 +157,15 @@
   kusd_mainnet:
     template: quipuswap_fa12
     values:
       dex_contract: kusd_dex_mainnet
       token_contract: kusd_token_mainnet
       symbol: kUSD
       decimals: 18
-    first_level: 3032136
-    last_level: 3032136
 
   hdao_mainnet:
     template: quipuswap_fa2
     values:
       dex_contract: hdao_dex_mainnet
       token_contract: hdao_token_mainnet
       symbol: hDAO
       decimals: 6
-    first_level: 1443017
-    last_level: 1443370
-
-logging: WARN
```

### Comparing `dipdup-7.5.7/tests/configs/demo_domains.yml` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_domains/dipdup.yaml.j2`

 * *Files 6% similar despite different names*

```diff
@@ -1,41 +1,40 @@
-spec_version: 2.0
-package: demo_domains
+spec_version: 3.0
+package: {{ project.package }}
 
 contracts:
   mainnet_name_registry:
     kind: tezos
     address: KT1GBZmSxmnKJXGMdMLbugPfLyUPmuLSMwKS
     typename: name_registry
 
 datasources:
   mainnet:
     kind: tezos.tzkt
     url: ${TZKT_URL:-https://api.tzkt.io}
 
 templates:
   tezos_domains_big_map:
-    kind: tezos.tzkt.big_maps
-    datasource: <datasource>
+    kind: tezos.big_maps
+    datasources:
+      - <datasource>
     handlers:
       - callback: on_update_records
         contract: <name_registry>
         path: store.records
       - callback: on_update_expiry_map
         contract: <name_registry>
         path: store.expiry_map
 
 indexes:
   tezos_domains_big_map_mainnet:
     template: tezos_domains_big_map
     values:
       datasource: mainnet
       name_registry: mainnet_name_registry
-    first_level: 1417329
-    last_level: 1417729
 
 hooks:
   check_expiration:
     callback: check_expiration
     atomic: False
 
 jobs:
```

### Comparing `dipdup-7.5.7/tests/configs/demo_etherlink.yaml` & `dipdup-8.0.0a1/tests/configs/demo_tezos_etherlink.yaml`

 * *Files 11% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-spec_version: 2.0
-package: demo_etherlink
+spec_version: 3.0
+package: demo_tezos_etherlink
 
 datasources:
   tzkt:
     kind: tezos.tzkt
     url: ${TZKT_URL:-https://api.nairobinet.tzkt.io}
 
 contracts:
@@ -18,16 +18,17 @@
   rollup:
     kind: tezos
     address: sr1QgYF6ARMSLcWyAX4wFDrWFaZTyy4twbqe
     typename: rollup
 
 indexes:
   rollup_operations:
-    kind: tezos.tzkt.operations
-    datasource: tzkt
+    kind: tezos.operations
+    datasources:
+      - tzkt
     contracts:
       - ticketer
       - ticket_helper
       - rollup
     types:
       - transaction
       - sr_execute
```

### Comparing `dipdup-7.5.7/tests/configs/demo_events.yml` & `dipdup-8.0.0a1/tests/configs/demo_tezos_events.yml`

 * *Files 5% similar despite different names*

```diff
@@ -1,26 +1,27 @@
-spec_version: 2.0
-package: demo_events
+spec_version: 3.0
+package: demo_tezos_events
 
 datasources:
   tzkt:
     kind: tezos.tzkt
     url: https://api.ghostnet.tzkt.io
 
 contracts:
   events_contract:
     kind: tezos
     address: KT1Up6AMehze2VTdt3w85xaZPtrEWn1AeyR3
 
 indexes:
   events:
-    kind: tezos.tzkt.events
+    kind: tezos.events
     first_level: 1250000
     last_level: 1258176
-    datasource: tzkt
+    datasources:
+      - tzkt
     handlers:
       - callback: on_move_event
         contract: events_contract
         tag: move
       - callback: on_roll_event
         contract: events_contract
         tag: roll
```

### Comparing `dipdup-7.5.7/tests/configs/demo_evm_events.yml` & `dipdup-8.0.0a1/tests/configs/demo_evm_transactions_node.yml`

 * *Files 13% similar despite different names*

```diff
@@ -1,35 +1,33 @@
-spec_version: 2.0
-package: demo_evm_events
+spec_version: 3.0
+package: demo_evm_transactions
 
 datasources:
+  subsquid:
+    kind: evm.subsquid
+    url: ${SUBSQUID_URL:-https://v2.archive.subsquid.io/network/ethereum-mainnet}
   etherscan:
     kind: abi.etherscan
-
+    url: ${ETHERSCAN_URL:-https://api.etherscan.io/api}
+    api_key: ${ETHERSCAN_API_KEY:-''}
   evm_node:
     kind: evm.node
     url: ${NODE_URL:-https://eth-mainnet.g.alchemy.com/v2}/${NODE_API_KEY:-''}
     ws_url: ${NODE_WS_URL:-wss://eth-mainnet.g.alchemy.com/v2}/${NODE_API_KEY:-''}
 
-  subsquid:
-    kind: evm.subsquid
-    url: ${SUBSQUID_URL:-https://v2.archive.subsquid.io/network/ethereum-mainnet}
-    node: evm_node
-    http:
-      replay_path: ${DIPDUP_REPLAY_PATH:-}
-
 contracts:
   eth_usdt:
     kind: evm
     address: 0xdac17f958d2ee523a2206206994597c13d831ec7
     typename: eth_usdt
 
 indexes:
-  eth_usdt_events:
-    kind: evm.subsquid.events
-    datasource: subsquid
+  eth_usdt_transactions:
+    kind: evm.transactions
+    datasources:
+      - evm_node
     handlers:
       - callback: on_transfer
-        contract: eth_usdt
-        name: Transfer
+        to: eth_usdt
+        method: transfer
     first_level: 18077421
     last_level: 18077421
```

### Comparing `dipdup-7.5.7/tests/configs/demo_evm_events_node.yml` & `dipdup-8.0.0a1/tests/configs/demo_evm_events_node.yml`

 * *Files 8% similar despite different names*

```diff
@@ -1,35 +1,35 @@
-spec_version: 2.0
+spec_version: 3.0
 package: demo_evm_events
 
 datasources:
   etherscan:
     kind: abi.etherscan
 
   evm_node:
     kind: evm.node
     url: ${NODE_URL:-https://eth-mainnet.g.alchemy.com/v2}/${NODE_API_KEY:-''}
     ws_url: ${NODE_WS_URL:-wss://eth-mainnet.g.alchemy.com/v2}/${NODE_API_KEY:-''}
 
   subsquid:
     kind: evm.subsquid
     url: ${SUBSQUID_URL:-https://v2.archive.subsquid.io/network/ethereum-mainnet}
-    node: evm_node
     http:
       replay_path: ${DIPDUP_REPLAY_PATH:-}
 
 contracts:
   eth_usdt:
     kind: evm
     address: 0xdac17f958d2ee523a2206206994597c13d831ec7
     typename: eth_usdt
 
 indexes:
   eth_usdt_events:
-    kind: evm.subsquid.events
-    datasource: evm_node
+    kind: evm.events
+    datasources:
+      - evm_node
     handlers:
       - callback: on_transfer
         contract: eth_usdt
         name: Transfer
     first_level: 18077421
     last_level: 18077421
```

### Comparing `dipdup-7.5.7/tests/configs/demo_evm_transactions.yml` & `dipdup-8.0.0a1/src/demo_evm_transactions/dipdup.yaml`

 * *Files 7% similar despite different names*

```diff
@@ -1,15 +1,14 @@
-spec_version: 2.0
+spec_version: 3.0
 package: demo_evm_transactions
 
 datasources:
   subsquid:
     kind: evm.subsquid
     url: ${SUBSQUID_URL:-https://v2.archive.subsquid.io/network/ethereum-mainnet}
-    node: evm_node
   etherscan:
     kind: abi.etherscan
     url: ${ETHERSCAN_URL:-https://api.etherscan.io/api}
     api_key: ${ETHERSCAN_API_KEY:-''}
   evm_node:
     kind: evm.node
     url: ${NODE_URL:-https://eth-mainnet.g.alchemy.com/v2}/${NODE_API_KEY:-''}
@@ -19,15 +18,17 @@
   eth_usdt:
     kind: evm
     address: 0xdac17f958d2ee523a2206206994597c13d831ec7
     typename: eth_usdt
 
 indexes:
   eth_usdt_transactions:
-    kind: evm.subsquid.transactions
-    datasource: subsquid
+    kind: evm.transactions
+    datasources:
+      - subsquid
+      - etherscan
+      - evm_node
     handlers:
       - callback: on_transfer
         to: eth_usdt
         method: transfer
-    first_level: 18077421
-    last_level: 18077421
+    first_level: 4634748
```

### Comparing `dipdup-7.5.7/tests/configs/demo_evm_transactions_node.yml` & `dipdup-8.0.0a1/src/dipdup/projects/demo_evm_transactions/dipdup.yaml.j2`

 * *Files 7% similar despite different names*

```diff
@@ -1,15 +1,14 @@
-spec_version: 2.0
-package: demo_evm_transactions
+spec_version: 3.0
+package: {{ project.package }}
 
 datasources:
   subsquid:
     kind: evm.subsquid
     url: ${SUBSQUID_URL:-https://v2.archive.subsquid.io/network/ethereum-mainnet}
-    node: evm_node
   etherscan:
     kind: abi.etherscan
     url: ${ETHERSCAN_URL:-https://api.etherscan.io/api}
     api_key: ${ETHERSCAN_API_KEY:-''}
   evm_node:
     kind: evm.node
     url: ${NODE_URL:-https://eth-mainnet.g.alchemy.com/v2}/${NODE_API_KEY:-''}
@@ -19,15 +18,17 @@
   eth_usdt:
     kind: evm
     address: 0xdac17f958d2ee523a2206206994597c13d831ec7
     typename: eth_usdt
 
 indexes:
   eth_usdt_transactions:
-    kind: evm.subsquid.transactions
-    datasource: evm_node
+    kind: evm.transactions
+    datasources:
+      - subsquid
+      - etherscan
+      - evm_node
     handlers:
       - callback: on_transfer
         to: eth_usdt
         method: transfer
-    first_level: 18077421
-    last_level: 18077421
+    first_level: 4634748
```

### Comparing `dipdup-7.5.7/tests/configs/demo_factories.yml` & `dipdup-8.0.0a1/src/demo_tezos_factories/dipdup.yaml`

 * *Files 20% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-spec_version: 2.0
-package: demo_factories
+spec_version: 3.0
+package: demo_tezos_factories
 
 contracts:
   factory:
     kind: tezos
     address: KT1PvEyN1xCFCgorN92QCfYjw3axS6jawCiJ
     typename: factory
   token:
@@ -11,21 +11,20 @@
     address: KT1UsSfaXyqcjSVPeiD7U1bWgKy3taYN7NWY
     typename: token
 
 datasources:
   tzkt:
     kind: tezos.tzkt
     url: ${TZKT_URL:-https://api.tzkt.io}
-    http:
-      replay_path: ${DIPDUP_REPLAY_PATH:-}
 
 templates:
   dex:
-    kind: tezos.tzkt.operations
-    datasource: tzkt
+    kind: tezos.operations
+    datasources:
+      - tzkt
     types:
       - transaction
     contracts:
       - <dex>
       - <token>
     handlers:
       - callback: on_transfer
@@ -34,23 +33,24 @@
             destination: <token>
             entrypoint: transfer
     first_level: 2393103
     last_level: 2393103
 
 indexes:
   factory:
-    kind: tezos.tzkt.operations
-    datasource: tzkt
+    kind: tezos.operations
+    datasources:
+      - tzkt
     contracts:
       - factory
     types:
       - origination
       - transaction
     handlers:
       - callback: on_factory_origination
         pattern:
           - type: transaction
             entrypoint: launchExchange
           - type: origination
             source: factory
     first_level: 2428590
-    last_level: 2428590
+    last_level: 2428590
```

### Comparing `dipdup-7.5.7/tests/configs/demo_nft_marketplace.yml` & `dipdup-8.0.0a1/tests/configs/dipdup.yml`

 * *Files 25% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-spec_version: 2.0
-package: demo_nft_marketplace
+spec_version: 3.0
+package: demo_tezos_nft_marketplace
 
 contracts:
   HEN_objkts:
     kind: tezos
     address: ${HEN_OBJKTS:-KT1RJ6PbjHpwc3M5rw5s2Nbmefwbuwbdxton}
     typename: hen_objkts
   HEN_minter:
@@ -16,16 +16,17 @@
     kind: tezos.tzkt
     url: ${TZKT_URL:-https://api.tzkt.io}
     http:
       replay_path: ${DIPDUP_REPLAY_PATH:-}
 
 indexes:
   hen_mainnet:
-    kind: tezos.tzkt.operations
-    datasource: tzkt_mainnet
+    kind: tezos.operations
+    datasources:
+      - tzkt_mainnet
     contracts:
       - HEN_minter
     handlers:
       - callback: on_mint
         pattern:
           - type: transaction
             destination: HEN_minter
@@ -43,12 +44,8 @@
           - type: transaction
             destination: HEN_minter
             entrypoint: cancel_swap
       - callback: on_collect
         pattern:
           - type: transaction
             destination: HEN_minter
-            entrypoint: collect
-    first_level: 1365000
-    last_level: 1366000
-
-logging: WARN
+            entrypoint: collect
```

### Comparing `dipdup-7.5.7/tests/configs/demo_token.yml` & `dipdup-8.0.0a1/tests/configs/demo_tezos_token.yml`

 * *Files 13% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-spec_version: 2.0
-package: demo_token
+spec_version: 3.0
+package: demo_tezos_token
 
 contracts:
   tzbtc_mainnet:
     kind: tezos
     address: KT1PWx2mnDueood7fEmfbBDKx1D9BAnnXitn
     typename: tzbtc
 
@@ -12,16 +12,17 @@
     kind: tezos.tzkt
     url: https://api.tzkt.io
     http:
       replay_path: ${DIPDUP_REPLAY_PATH:-}
 
 indexes:
   tzbtc_holders_mainnet:
-    kind: tezos.tzkt.operations
-    datasource: tzkt
+    kind: tezos.operations
+    datasources:
+      - tzkt
     contracts:
       - tzbtc_mainnet
     handlers:
       - callback: on_transfer
         pattern:
           - destination: tzbtc_mainnet
             entrypoint: transfer
```

### Comparing `dipdup-7.5.7/tests/configs/demo_token_transfers.yml` & `dipdup-8.0.0a1/tests/configs/demo_tezos_token_transfers.yml`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-spec_version: 2.0
-package: demo_token_transfers
+spec_version: 3.0
+package: demo_tezos_token_transfers
 
 contracts:
   tzbtc_mainnet:
     kind: tezos
     address: KT1PWx2mnDueood7fEmfbBDKx1D9BAnnXitn
     typename: tzbtc
 
@@ -12,16 +12,17 @@
     kind: tezos.tzkt
     url: https://api.tzkt.io
     http:
       replay_path: ${DIPDUP_REPLAY_PATH:-}
 
 indexes:
   tzbtc_holders_mainnet:
-    kind: tezos.tzkt.token_transfers
-    datasource: tzkt
+    kind: tezos.token_transfers
+    datasources:
+      - tzkt
     handlers:
       - callback: on_token_transfer
         contract: tzbtc_mainnet
     first_level: 1364999
     last_level: 1366000
 
 logging: WARN
```

### Comparing `dipdup-7.5.7/tests/configs/demo_token_transfers_2.yml` & `dipdup-8.0.0a1/tests/configs/demo_tezos_token_transfers_4.yml`

 * *Files 19% similar despite different names*

```diff
@@ -1,27 +1,36 @@
-spec_version: 2.0
-package: demo_token_transfers
+spec_version: 3.0
+package: demo_tezos_token_transfers
 
 contracts:
   tzbtc_mainnet:
     kind: tezos
     address: KT1PWx2mnDueood7fEmfbBDKx1D9BAnnXitn
     typename: tzbtc
+  tzbtc_holder_mainnet:
+    kind: tezos
+    address: tz1Ub7v6eoec6KdB5VTCqtAEVrQsjj1ZTFTk
 
 datasources:
   tzkt:
     kind: tezos.tzkt
     url: https://api.tzkt.io
     http:
       replay_path: ${DIPDUP_REPLAY_PATH:-}
 
 indexes:
   tzbtc_holders_mainnet:
-    kind: tezos.tzkt.token_transfers
-    datasource: tzkt
+    kind: tezos.token_transfers
+    datasources:
+      - tzkt
     handlers:
       - callback: on_token_transfer
         contract: tzbtc_mainnet
-    first_level: 1366824
-    last_level: 1366999
+      - callback: on_token_transfer
+        from: tzbtc_mainnet
+      - callback: on_token_transfer
+        to: tzbtc_holder_mainnet
+    # see: https://api.tzkt.io/v1/tokens/transfers?id=125069119
+    first_level: 1366840
+    last_level: 1366840
 
 logging: WARN
```

### Comparing `dipdup-7.5.7/tests/configs/demo_token_transfers_3.yml` & `dipdup-8.0.0a1/tests/configs/demo_tezos_token_transfers_3.yml`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-spec_version: 2.0
-package: demo_token_transfers
+spec_version: 3.0
+package: demo_tezos_token_transfers
 
 contracts:
   tzbtc_mainnet:
     kind: tezos
     address: KT1PWx2mnDueood7fEmfbBDKx1D9BAnnXitn
     typename: tzbtc
 
@@ -12,16 +12,17 @@
     kind: tezos.tzkt
     url: https://api.tzkt.io
     http:
       replay_path: ${DIPDUP_REPLAY_PATH:-}
 
 indexes:
   tzbtc_holders_mainnet:
-    kind: tezos.tzkt.token_transfers
-    datasource: tzkt
+    kind: tezos.token_transfers
+    datasources:
+      - tzkt
     handlers:
       - callback: on_token_transfer
         contract: tzbtc_mainnet
     first_level: 2315000
     last_level: 2315100
 
 logging: WARN
```

### Comparing `dipdup-7.5.7/tests/configs/demo_token_transfers_4.yml` & `dipdup-8.0.0a1/tests/configs/demo_tezos_token_transfers_2.yml`

 * *Files 16% similar despite different names*

```diff
@@ -1,35 +1,28 @@
-spec_version: 2.0
-package: demo_token_transfers
+spec_version: 3.0
+package: demo_tezos_token_transfers
 
 contracts:
   tzbtc_mainnet:
     kind: tezos
     address: KT1PWx2mnDueood7fEmfbBDKx1D9BAnnXitn
     typename: tzbtc
-  tzbtc_holder_mainnet:
-    kind: tezos
-    address: tz1Ub7v6eoec6KdB5VTCqtAEVrQsjj1ZTFTk
 
 datasources:
   tzkt:
     kind: tezos.tzkt
     url: https://api.tzkt.io
     http:
       replay_path: ${DIPDUP_REPLAY_PATH:-}
 
 indexes:
   tzbtc_holders_mainnet:
-    kind: tezos.tzkt.token_transfers
-    datasource: tzkt
+    kind: tezos.token_transfers
+    datasources:
+      - tzkt
     handlers:
       - callback: on_token_transfer
         contract: tzbtc_mainnet
-      - callback: on_token_transfer
-        from: tzbtc_mainnet
-      - callback: on_token_transfer
-        to: tzbtc_holder_mainnet
-    # see: https://api.tzkt.io/v1/tokens/transfers?id=125069119
-    first_level: 1366840
-    last_level: 1366840
+    first_level: 1366824
+    last_level: 1366999
 
 logging: WARN
```

### Comparing `dipdup-7.5.7/tests/configs/dipdup.yml` & `dipdup-8.0.0a1/src/dipdup/projects/demo_tezos_nft_marketplace/dipdup.yaml.j2`

 * *Files 17% similar despite different names*

```diff
@@ -1,31 +1,30 @@
-spec_version: 2.0
-package: demo_nft_marketplace
+spec_version: 3.0
+package: {{ project.package }}
+
+datasources:
+  tzkt_mainnet:
+    kind: tezos.tzkt
+    url: ${TZKT_URL:-https://api.tzkt.io}
 
 contracts:
   HEN_objkts:
     kind: tezos
     address: ${HEN_OBJKTS:-KT1RJ6PbjHpwc3M5rw5s2Nbmefwbuwbdxton}
     typename: hen_objkts
   HEN_minter:
     kind: tezos
     address: ${HEN_MINTER:-KT1Hkg5qeNhfwpKW4fXvq7HGZB9z2EnmCCA9}
     typename: hen_minter
 
-datasources:
-  tzkt_mainnet:
-    kind: tezos.tzkt
-    url: ${TZKT_URL:-https://api.tzkt.io}
-    http:
-      replay_path: ${DIPDUP_REPLAY_PATH:-}
-
 indexes:
   hen_mainnet:
-    kind: tezos.tzkt.operations
-    datasource: tzkt_mainnet
+    kind: tezos.operations
+    datasources:
+      - tzkt_mainnet
     contracts:
       - HEN_minter
     handlers:
       - callback: on_mint
         pattern:
           - type: transaction
             destination: HEN_minter
@@ -43,8 +42,8 @@
           - type: transaction
             destination: HEN_minter
             entrypoint: cancel_swap
       - callback: on_collect
         pattern:
           - type: transaction
             destination: HEN_minter
-            entrypoint: collect
+            entrypoint: collect
```

### Comparing `dipdup-7.5.7/tests/configs/hen_subjkt.yml` & `dipdup-8.0.0a1/tests/configs/hen_subjkt.yml`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-spec_version: 2.0
+spec_version: 3.0
 package: hen_subjkt
 
 contracts:
   hen_subjkt:
     kind: tezos
     address: KT1My1wDZHDGweCrJnQJi3wcFaS67iksirvj
     typename: hen_subjkt
@@ -12,16 +12,17 @@
     kind: tezos.tzkt
     url: https://api.tzkt.io
     http:
       replay_path: ${DIPDUP_REPLAY_PATH:-}
 
 indexes:
   hen_subjkt:
-    kind: tezos.tzkt.operations
-    datasource: tzkt
+    kind: tezos.operations
+    datasources:
+      - tzkt
     contracts:
       - hen_subjkt
     handlers:
       - callback: on_registry
         pattern:
           - destination: hen_subjkt
             entrypoint: registry
```

### Comparing `dipdup-7.5.7/tests/configs/kolibri_ovens.yml` & `dipdup-8.0.0a1/tests/configs/kolibri_ovens.yml`

 * *Files 24% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-spec_version: 2.0
+spec_version: 3.0
 package: kolibri_ovens
 
 contracts:
   kolibri_ovens:
     kind: tezos
     address: KT1KV31DTzktr8t7edCLUzzgEN54cQtksJou
     typename: kolibri_ovens
@@ -12,16 +12,17 @@
     kind: tezos.tzkt
     url: https://api.tzkt.io
     http:
       replay_path: ${DIPDUP_REPLAY_PATH:-}
 
 indexes:
   kolibri_ovens:
-    kind: tezos.tzkt.operations
-    datasource: tzkt
+    kind: tezos.operations
+    datasources:
+      - tzkt
     contracts:
       - kolibri_ovens
     handlers:
       - callback: on_set_delegate
         pattern:
           - destination: kolibri_ovens
             entrypoint: setDelegate
```

### Comparing `dipdup-7.5.7/tests/configs/operation_filters.yml` & `dipdup-8.0.0a1/tests/configs/operation_filters.yml`

 * *Files 18% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-spec_version: 2.0
-package: demo_nft_marketplace
+spec_version: 3.0
+package: demo_tezos_nft_marketplace
 
 contracts:
   by_address:
     kind: tezos
     address: KT1RJ6PbjHpwc3M5rw5s2Nbmefwbuwbdxton
   by_code_hash:
     kind: tezos
@@ -17,16 +17,17 @@
     kind: tezos.tzkt
     url: ${TZKT_URL:-https://api.tzkt.io}
     http:
       replay_path: ${DIPDUP_REPLAY_PATH:-}
 
 indexes:
   test:
-    kind: tezos.tzkt.operations
-    datasource: tzkt_replay
+    kind: tezos.operations
+    datasources:
+      - tzkt_replay
     types:
       - origination
       - transaction
       - migration
     contracts:
       - by_address
       - by_code_hash
```

### Comparing `dipdup-7.5.7/tests/configs/yupana.yml` & `dipdup-8.0.0a1/tests/configs/yupana.yml`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-spec_version: 2.0
+spec_version: 3.0
 package: yupana
 
 contracts:
   yupana:
     kind: tezos
     address: KT1LTqpmGJ11EebMVWAzJ7DWd9msgExvHM94
     typename: yupana
@@ -12,16 +12,17 @@
     kind: tezos.tzkt
     url: https://api.hangzhou2net.tzkt.io/
     http:
       replay_path: ${DIPDUP_REPLAY_PATH:-}
 
 indexes:
   yupana:
-    kind: tezos.tzkt.operations
-    datasource: tzkt_testnet
+    kind: tezos.operations
+    datasources:
+      - tzkt_testnet
     contracts:
       - yupana
     handlers:
       - callback: on_enter_market
         pattern:
           - destination: yupana
             entrypoint: enterMarket
```

### Comparing `dipdup-7.5.7/tests/replays/0535b2dcc93076e6026fa48cc501adaed47b7b060e6483d8312f40c184d7287d` & `dipdup-8.0.0a1/tests/replays/0535b2dcc93076e6026fa48cc501adaed47b7b060e6483d8312f40c184d7287d`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/0eaaba2830dbdd3a80286fbc367084bce6e55c678e21da178a7eb16beef6c997` & `dipdup-8.0.0a1/tests/replays/0eaaba2830dbdd3a80286fbc367084bce6e55c678e21da178a7eb16beef6c997`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/1228b36594bb93d619170ad49373f1ceec52d10faafdd727b37f3cdeffd663db` & `dipdup-8.0.0a1/tests/replays/1228b36594bb93d619170ad49373f1ceec52d10faafdd727b37f3cdeffd663db`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/13afdf001ce3d6a0219c0f7f6d372d9b645770e5f4304576f7f7a37b45af96fc` & `dipdup-8.0.0a1/tests/replays/13afdf001ce3d6a0219c0f7f6d372d9b645770e5f4304576f7f7a37b45af96fc`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/27373c23411bf37b605c8d0ead9a0e6c6c1f1718ce7863b095b759811e44e155` & `dipdup-8.0.0a1/tests/replays/27373c23411bf37b605c8d0ead9a0e6c6c1f1718ce7863b095b759811e44e155`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/2a45ec6372b45e46199a6af24272cb93586777a0522cd1203b3eeef213ce4583` & `dipdup-8.0.0a1/tests/replays/2a45ec6372b45e46199a6af24272cb93586777a0522cd1203b3eeef213ce4583`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/383899084f79460e96fd311bb64e4925738c486b39d6281539456c5fcac41620` & `dipdup-8.0.0a1/tests/replays/383899084f79460e96fd311bb64e4925738c486b39d6281539456c5fcac41620`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/388fe9107380b6dd1e9ce3a87c23abd56ad39dfb6cb8a5a27b959e5b0434633b` & `dipdup-8.0.0a1/tests/replays/388fe9107380b6dd1e9ce3a87c23abd56ad39dfb6cb8a5a27b959e5b0434633b`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/39b8664d1bca5d374ff905c8a3a396b53d19ee469dc37545a8ca6b080bd0e9e0` & `dipdup-8.0.0a1/tests/replays/39b8664d1bca5d374ff905c8a3a396b53d19ee469dc37545a8ca6b080bd0e9e0`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/3a2bd8b6b72bf18152d2550c106789fa9b8abc98ea9d759a6597b7ebfbab0fc2` & `dipdup-8.0.0a1/tests/replays/3a2bd8b6b72bf18152d2550c106789fa9b8abc98ea9d759a6597b7ebfbab0fc2`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/3f5927db41422038d8e2cc203ef56a769c66b25835cdee42b17bc61e600be550` & `dipdup-8.0.0a1/tests/replays/3f5927db41422038d8e2cc203ef56a769c66b25835cdee42b17bc61e600be550`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/43cb0ab415d8b8b3f7addc3e82ea27d93b2c66ff55c117e1e0c7c64a0fcfc3f2` & `dipdup-8.0.0a1/tests/replays/43cb0ab415d8b8b3f7addc3e82ea27d93b2c66ff55c117e1e0c7c64a0fcfc3f2`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/4a57776d93475adfd9c49b6c3295a7cedfc23b73733a1fb5f0c985ee039dc5dc` & `dipdup-8.0.0a1/tests/replays/4a57776d93475adfd9c49b6c3295a7cedfc23b73733a1fb5f0c985ee039dc5dc`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/4aa7f9b0657be0c44baf2caed8c7cb08d02097a4095cf6417f78cba3a25e8423` & `dipdup-8.0.0a1/tests/replays/4aa7f9b0657be0c44baf2caed8c7cb08d02097a4095cf6417f78cba3a25e8423`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/5483a0e11009e0f186bf70c214e2597d267a75a1e19152a9e7ed1ec257ce88ca` & `dipdup-8.0.0a1/tests/replays/5483a0e11009e0f186bf70c214e2597d267a75a1e19152a9e7ed1ec257ce88ca`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/587613799ebfae42b1884016d1a44a452d68e70e3ed80641d90b8e7657ba8ee5` & `dipdup-8.0.0a1/tests/replays/587613799ebfae42b1884016d1a44a452d68e70e3ed80641d90b8e7657ba8ee5`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/5b99bc4beb6a9a33f7d2f118426458e4c788e0ab6d9e51949d3ccbf8b4003fc1` & `dipdup-8.0.0a1/tests/replays/5b99bc4beb6a9a33f7d2f118426458e4c788e0ab6d9e51949d3ccbf8b4003fc1`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/607ecfd3653eda82aac502ac370c6ad7144d30c1e3c525ed520d44f9edf5b7e9` & `dipdup-8.0.0a1/tests/replays/607ecfd3653eda82aac502ac370c6ad7144d30c1e3c525ed520d44f9edf5b7e9`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/6d76a3c3f427ff534c551de1793cb1d1dfbd22ccad97f5917a9f9b201a3f9804` & `dipdup-8.0.0a1/tests/replays/6d76a3c3f427ff534c551de1793cb1d1dfbd22ccad97f5917a9f9b201a3f9804`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/6fa41b68da742cc7cf8a0d68baef77ce8b2e9abf765767318d7ff4cf453ded4c` & `dipdup-8.0.0a1/tests/replays/6fa41b68da742cc7cf8a0d68baef77ce8b2e9abf765767318d7ff4cf453ded4c`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/7b6cf9b8c69712bf26ed09059352ec740606969bf20eab0dedda870273f4fde9` & `dipdup-8.0.0a1/tests/replays/7b6cf9b8c69712bf26ed09059352ec740606969bf20eab0dedda870273f4fde9`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/803e05a8d0bb9e7cfb49530271d43ea62111b6419e7cded2d221f7e0e0c92ece` & `dipdup-8.0.0a1/tests/replays/803e05a8d0bb9e7cfb49530271d43ea62111b6419e7cded2d221f7e0e0c92ece`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/8060a1f95213d470ee947a12242ef76cb7fb0c05bbaecc385eb6ec4a20d694c4` & `dipdup-8.0.0a1/tests/replays/8060a1f95213d470ee947a12242ef76cb7fb0c05bbaecc385eb6ec4a20d694c4`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/93516225810a23a6799f2f9a1dee055ca79a66ee2b8d0f32be820c9c385e936b` & `dipdup-8.0.0a1/tests/replays/93516225810a23a6799f2f9a1dee055ca79a66ee2b8d0f32be820c9c385e936b`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/9e6e907842da2cd494c558ea5ecc211fd12e56bfc547450978fb7dfe03853e58` & `dipdup-8.0.0a1/tests/replays/9e6e907842da2cd494c558ea5ecc211fd12e56bfc547450978fb7dfe03853e58`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/a3ce91a1b0d505cc221f0e201781466ba1e2d6dc7b624b9bc75a03ce3dbb0f92` & `dipdup-8.0.0a1/tests/replays/a3ce91a1b0d505cc221f0e201781466ba1e2d6dc7b624b9bc75a03ce3dbb0f92`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/aa8fe6037996b296bf9a3011e45cd9ecb92fb728592a843f91b03b2848cb1fb1` & `dipdup-8.0.0a1/tests/replays/aa8fe6037996b296bf9a3011e45cd9ecb92fb728592a843f91b03b2848cb1fb1`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/acaa57345850f3b76471a7b3a8fb76b7f83e824f1520a2e0ee8ec93cdd6cb1c3` & `dipdup-8.0.0a1/tests/replays/acaa57345850f3b76471a7b3a8fb76b7f83e824f1520a2e0ee8ec93cdd6cb1c3`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/acc952ba1905717315212f952ed689d7b8f683165b31c0a7a25199aed9fda27f` & `dipdup-8.0.0a1/tests/replays/acc952ba1905717315212f952ed689d7b8f683165b31c0a7a25199aed9fda27f`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/b3af887f7ad8172af75b94a09bedfb9ae1e14f8819a36d6ce9f709721068263b` & `dipdup-8.0.0a1/tests/replays/b3af887f7ad8172af75b94a09bedfb9ae1e14f8819a36d6ce9f709721068263b`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/b89b0ea704071e273d3c74a4dbb7b4f6c6fd9ea1848c69b452dce4f04872d3b5` & `dipdup-8.0.0a1/tests/replays/b89b0ea704071e273d3c74a4dbb7b4f6c6fd9ea1848c69b452dce4f04872d3b5`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/bec4433b4206f00c2310a7961cff7f539434b9161b45673793aa5a3b50234313` & `dipdup-8.0.0a1/tests/replays/bec4433b4206f00c2310a7961cff7f539434b9161b45673793aa5a3b50234313`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/c1c3eef91f7149d7aa2da072f71598f3ad5e29250cfa441bb6d4411acd70d657` & `dipdup-8.0.0a1/tests/replays/c1c3eef91f7149d7aa2da072f71598f3ad5e29250cfa441bb6d4411acd70d657`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/cc5d3d4a58d5cb6bc7270d38c797b7740b79f913590ef0164abd50e58fba9405` & `dipdup-8.0.0a1/tests/replays/cc5d3d4a58d5cb6bc7270d38c797b7740b79f913590ef0164abd50e58fba9405`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/d0a594d14bcb3fbf916092ec6707dfd3c9f48f53f0a1ad40a32023e7a87f8ef5` & `dipdup-8.0.0a1/tests/replays/d0a594d14bcb3fbf916092ec6707dfd3c9f48f53f0a1ad40a32023e7a87f8ef5`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/d62748a927a09395579b5790c8f871cc8653081cf4475abc93173989f950b92b` & `dipdup-8.0.0a1/tests/replays/d62748a927a09395579b5790c8f871cc8653081cf4475abc93173989f950b92b`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/d94397f6ecec8ce25f87177fe410f6498d7d30a04360506c0cd300d291c167e7` & `dipdup-8.0.0a1/tests/replays/d94397f6ecec8ce25f87177fe410f6498d7d30a04360506c0cd300d291c167e7`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/dca9cf4f9f27623f10975d369444899458ab9ea85c22af2da6ce6ce8c09c2b58` & `dipdup-8.0.0a1/tests/replays/dca9cf4f9f27623f10975d369444899458ab9ea85c22af2da6ce6ce8c09c2b58`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/dd5d267c6e8e943a637ede23d708587123b9184560358d294be7fbed0d4b587a` & `dipdup-8.0.0a1/tests/replays/dd5d267c6e8e943a637ede23d708587123b9184560358d294be7fbed0d4b587a`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/e10e6552f0dce5124e0d72b74c508541a8098c407c9a3b0d2e10a7408b4d7cfe` & `dipdup-8.0.0a1/tests/replays/e10e6552f0dce5124e0d72b74c508541a8098c407c9a3b0d2e10a7408b4d7cfe`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/e4a563a0b19379a44e9d2dc398131e9fd30d6039ff4ffacf1252db0bf8b433aa` & `dipdup-8.0.0a1/tests/replays/e4a563a0b19379a44e9d2dc398131e9fd30d6039ff4ffacf1252db0bf8b433aa`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/eb8b6b33cb2e165d1a3a73c09938d3083671a82ad73d4c0cff1fb2a5e5715f76` & `dipdup-8.0.0a1/tests/replays/eb8b6b33cb2e165d1a3a73c09938d3083671a82ad73d4c0cff1fb2a5e5715f76`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/eb8e2c3ce2fe7792d2c8e81c61d37821275b64021343103b0c955042ae802189` & `dipdup-8.0.0a1/tests/replays/eb8e2c3ce2fe7792d2c8e81c61d37821275b64021343103b0c955042ae802189`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/f3d608f99e6b92e28a064bb9c10c3c605c9c817383c1eebcc68f663d1d23d650` & `dipdup-8.0.0a1/tests/replays/f3d608f99e6b92e28a064bb9c10c3c605c9c817383c1eebcc68f663d1d23d650`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/f7d244938de3e3d153e4ef8172cab0f1e896b801904a54ac034d3d14352ee64a` & `dipdup-8.0.0a1/tests/replays/f7d244938de3e3d153e4ef8172cab0f1e896b801904a54ac034d3d14352ee64a`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/f9fa1571c3d850f4a19c286205291893d184a9d124390d0358034a8b8366556d` & `dipdup-8.0.0a1/tests/replays/f9fa1571c3d850f4a19c286205291893d184a9d124390d0358034a8b8366556d`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/fe80425d17f2467fccc527a99b5a11da144f63f9a3cab83989be0f8fed737264` & `dipdup-8.0.0a1/tests/replays/fe80425d17f2467fccc527a99b5a11da144f63f9a3cab83989be0f8fed737264`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/replays/ff51b3535acc2972090ecd5db3af8f827464c9d92f1aa661630976e5b4ed4cbe` & `dipdup-8.0.0a1/tests/replays/ff51b3535acc2972090ecd5db3af8f827464c9d92f1aa661630976e5b4ed4cbe`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/responses/asdf.json` & `dipdup-8.0.0a1/tests/responses/asdf.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/responses/ftzfun.json` & `dipdup-8.0.0a1/tests/responses/ftzfun.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/responses/hen_subjkt.json` & `dipdup-8.0.0a1/tests/responses/hen_subjkt.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/responses/hjkl.json` & `dipdup-8.0.0a1/tests/responses/hjkl.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/responses/kolibri_ovens.json` & `dipdup-8.0.0a1/tests/responses/kolibri_ovens.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/responses/ooQuCAKBHkmWy2VciDAV9c6CFTywuMLupLzVoKDwS1xvR4EdRng.json` & `dipdup-8.0.0a1/tests/responses/ooQuCAKBHkmWy2VciDAV9c6CFTywuMLupLzVoKDwS1xvR4EdRng.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/responses/origination_amount.json` & `dipdup-8.0.0a1/tests/responses/origination_amount.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/responses/qwer.json` & `dipdup-8.0.0a1/tests/responses/qwer.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/responses/rewq.json` & `dipdup-8.0.0a1/tests/responses/rewq.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/responses/yupana.json` & `dipdup-8.0.0a1/tests/responses/yupana.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/responses/zxcv.json` & `dipdup-8.0.0a1/tests/responses/zxcv.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/schemas/asdf/storage.json` & `dipdup-8.0.0a1/tests/schemas/asdf/storage.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/schemas/hen_subjkt/storage.json` & `dipdup-8.0.0a1/tests/schemas/hen_subjkt/storage.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/schemas/hjkl/storage.json` & `dipdup-8.0.0a1/tests/schemas/hjkl/storage.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/schemas/kolibri_ovens/storage.json` & `dipdup-8.0.0a1/tests/schemas/kolibri_ovens/storage.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/schemas/qwer/storage.json` & `dipdup-8.0.0a1/tests/schemas/qwer/storage.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/schemas/rewq/storage.json` & `dipdup-8.0.0a1/tests/schemas/rewq/storage.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/schemas/yupana/storage.json` & `dipdup-8.0.0a1/tests/schemas/yupana/storage.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/schemas/zxcv/storage.json` & `dipdup-8.0.0a1/tests/schemas/zxcv/storage.json`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/test_config/test_callbacks.py` & `dipdup-8.0.0a1/tests/test_config/test_callbacks.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,91 +1,91 @@
 import pytest
 
 from dipdup.config.tezos import TezosContractConfig
-from dipdup.config.tezos_tzkt_operations import OperationsHandlerOriginationPatternConfig
-from dipdup.config.tezos_tzkt_operations import OperationsHandlerTransactionPatternConfig
+from dipdup.config.tezos_operations import TezosOperationsHandlerOriginationPatternConfig
+from dipdup.config.tezos_operations import TezosOperationsHandlerTransactionPatternConfig
 
 
 @pytest.fixture
 def contract() -> TezosContractConfig:
     contract = TezosContractConfig(kind='tezos', address='KT1Hkg5qeCgJPwE6SDh8KKPDiun7j5G8r4ee')
     contract._name = 'dex_contract'
     return contract
 
 
 def test_transaction_callbacks(contract: TezosContractConfig) -> None:
     # NOTE: Typed `transaction`
-    pattern = OperationsHandlerTransactionPatternConfig(
+    pattern = TezosOperationsHandlerTransactionPatternConfig(
         destination=contract,
         entrypoint='fooBar',
     )
-    assert tuple(pattern.iter_arguments()) == (('foo_bar', 'TzktTransaction[FooBarParameter, DexContractStorage]'),)
+    assert tuple(pattern.iter_arguments()) == (('foo_bar', 'TezosTransaction[FooBarParameter, DexContractStorage]'),)
     assert tuple(pattern.iter_imports('test')) == (
-        ('dipdup.models.tezos_tzkt', 'TzktTransaction'),
+        ('dipdup.models.tezos', 'TezosTransaction'),
         ('test.types.dex_contract.tezos_parameters.foo_bar', 'FooBarParameter'),
         ('test.types.dex_contract.tezos_storage', 'DexContractStorage'),
     )
 
     # NOTE: With alias and optional
     pattern.alias = 'aliased'
     pattern.optional = True
 
     assert tuple(pattern.iter_arguments()) == (
-        ('aliased', 'TzktTransaction[AliasedParameter, DexContractStorage] | None'),
+        ('aliased', 'TezosTransaction[AliasedParameter, DexContractStorage] | None'),
     )
     assert tuple(pattern.iter_imports('test')) == (
-        ('dipdup.models.tezos_tzkt', 'TzktTransaction'),
+        ('dipdup.models.tezos', 'TezosTransaction'),
         ('test.types.dex_contract.tezos_parameters.foo_bar', 'FooBarParameter as AliasedParameter'),
         ('test.types.dex_contract.tezos_storage', 'DexContractStorage'),
     )
 
     # NOTE: Untyped `transaction`
-    pattern = OperationsHandlerTransactionPatternConfig(
+    pattern = TezosOperationsHandlerTransactionPatternConfig(
         destination=contract,
     )
     pattern.subgroup_index = 1
-    assert tuple(pattern.iter_arguments()) == (('transaction_1', 'TzktOperationData'),)
-    assert tuple(pattern.iter_imports('test')) == (('dipdup.models.tezos_tzkt', 'TzktOperationData'),)
+    assert tuple(pattern.iter_arguments()) == (('transaction_1', 'TezosOperationData'),)
+    assert tuple(pattern.iter_imports('test')) == (('dipdup.models.tezos', 'TezosOperationData'),)
 
     # NOTE: With alias and optional
     pattern.alias = 'aliased'
     pattern.optional = True
 
-    assert tuple(pattern.iter_arguments()) == (('aliased', 'TzktOperationData | None'),)
-    assert tuple(pattern.iter_imports('test')) == (('dipdup.models.tezos_tzkt', 'TzktOperationData'),)
+    assert tuple(pattern.iter_arguments()) == (('aliased', 'TezosOperationData | None'),)
+    assert tuple(pattern.iter_imports('test')) == (('dipdup.models.tezos', 'TezosOperationData'),)
 
 
 def test_origination_callbacks(contract: TezosContractConfig) -> None:
     # NOTE: Typed `origination`
-    pattern = OperationsHandlerOriginationPatternConfig(
+    pattern = TezosOperationsHandlerOriginationPatternConfig(
         originated_contract=contract,
     )
-    assert tuple(pattern.iter_arguments()) == (('dex_contract_origination', 'TzktOrigination[DexContractStorage]'),)
+    assert tuple(pattern.iter_arguments()) == (('dex_contract_origination', 'TezosOrigination[DexContractStorage]'),)
     assert tuple(pattern.iter_imports('test')) == (
-        ('dipdup.models.tezos_tzkt', 'TzktOrigination'),
+        ('dipdup.models.tezos', 'TezosOrigination'),
         ('test.types.dex_contract.tezos_storage', 'DexContractStorage'),
     )
 
     # NOTE: With alias and optional
     pattern.alias = 'aliased'
     pattern.optional = True
 
-    assert tuple(pattern.iter_arguments()) == (('aliased', 'TzktOrigination[DexContractStorage] | None'),)
+    assert tuple(pattern.iter_arguments()) == (('aliased', 'TezosOrigination[DexContractStorage] | None'),)
     assert tuple(pattern.iter_imports('test')) == (
-        ('dipdup.models.tezos_tzkt', 'TzktOrigination'),
+        ('dipdup.models.tezos', 'TezosOrigination'),
         ('test.types.dex_contract.tezos_storage', 'DexContractStorage'),
     )
 
     # NOTE: Untyped `origination`
-    pattern = OperationsHandlerOriginationPatternConfig(
+    pattern = TezosOperationsHandlerOriginationPatternConfig(
         source=contract,
     )
     pattern.subgroup_index = 1
-    assert tuple(pattern.iter_arguments()) == (('origination_1', 'TzktOperationData'),)
-    assert tuple(pattern.iter_imports('test')) == (('dipdup.models.tezos_tzkt', 'TzktOperationData'),)
+    assert tuple(pattern.iter_arguments()) == (('origination_1', 'TezosOperationData'),)
+    assert tuple(pattern.iter_imports('test')) == (('dipdup.models.tezos', 'TezosOperationData'),)
 
     # NOTE: With alias and optional
     pattern.alias = 'aliased'
     pattern.optional = True
 
-    assert tuple(pattern.iter_arguments()) == (('aliased', 'TzktOperationData | None'),)
-    assert tuple(pattern.iter_imports('test')) == (('dipdup.models.tezos_tzkt', 'TzktOperationData'),)
+    assert tuple(pattern.iter_arguments()) == (('aliased', 'TezosOperationData | None'),)
+    assert tuple(pattern.iter_imports('test')) == (('dipdup.models.tezos', 'TezosOperationData'),)
```

### Comparing `dipdup-7.5.7/tests/test_config/test_config.py` & `dipdup-8.0.0a1/tests/test_config/test_config.py`

 * *Files 10% similar despite different names*

```diff
@@ -5,102 +5,100 @@
 from pydantic import ValidationError
 
 from dipdup.config import DipDupConfig
 from dipdup.config import HasuraConfig
 from dipdup.config import HttpConfig
 from dipdup.config import PostgresDatabaseConfig
 from dipdup.config import ResolvedHttpConfig
-from dipdup.config.evm_subsquid_transactions import SubsquidTransactionsHandlerConfig
+from dipdup.config.evm_transactions import EvmTransactionsHandlerConfig
 from dipdup.config.tezos import TezosContractConfig
-from dipdup.config.tezos_tzkt import TzktDatasourceConfig
-from dipdup.config.tezos_tzkt_operations import TzktOperationsIndexConfig
-from dipdup.exceptions import ConfigurationError
+from dipdup.config.tezos_operations import TezosOperationsIndexConfig
+from dipdup.config.tezos_tzkt import TezosTzktDatasourceConfig
+from dipdup.models.tezos import TezosOperationType
 from dipdup.models.tezos_tzkt import HeadSubscription
 from dipdup.models.tezos_tzkt import OriginationSubscription
 from dipdup.models.tezos_tzkt import TransactionSubscription
-from dipdup.models.tezos_tzkt import TzktOperationType
 from dipdup.yaml import DipDupYAMLConfig
 
 
 def create_config(merge_subs: bool = False, origs: bool = False) -> DipDupConfig:
     path = Path(__file__).parent.parent / 'configs' / 'dipdup.yaml'
     config = DipDupConfig.load([path])
     if origs:
-        config.indexes['hen_mainnet'].types += (TzktOperationType.origination,)  # type: ignore
+        config.indexes['hen_mainnet'].types += (TezosOperationType.origination,)  # type: ignore
     config.datasources['tzkt_mainnet'].merge_subscriptions = merge_subs  # type: ignore
     config.initialize()
     return config
 
 
 async def test_load_initialize() -> None:
     config = create_config()
     index_config = config.indexes['hen_mainnet']
-    assert isinstance(index_config, TzktOperationsIndexConfig)
+    assert isinstance(index_config, TezosOperationsIndexConfig)
 
     assert isinstance(config, DipDupConfig)
     destination = index_config.handlers[0].pattern[0].destination  # type: ignore[union-attr]
     assert destination == config.contracts['HEN_minter']
 
 
 async def test_operation_subscriptions() -> None:
     index_config = create_config(False, False).indexes['hen_mainnet']
-    assert isinstance(index_config, TzktOperationsIndexConfig)
+    assert isinstance(index_config, TezosOperationsIndexConfig)
     assert index_config.get_subscriptions() == {
         TransactionSubscription(address='KT1Hkg5qeNhfwpKW4fXvq7HGZB9z2EnmCCA9'),
         HeadSubscription(),
     }
 
     index_config = create_config(True, False).indexes['hen_mainnet']
-    assert isinstance(index_config, TzktOperationsIndexConfig)
+    assert isinstance(index_config, TezosOperationsIndexConfig)
     assert index_config.get_subscriptions() == {TransactionSubscription(), HeadSubscription()}
 
     index_config = create_config(False, True).indexes['hen_mainnet']
-    assert isinstance(index_config, TzktOperationsIndexConfig)
+    assert isinstance(index_config, TezosOperationsIndexConfig)
     assert index_config.get_subscriptions() == {
         TransactionSubscription(address='KT1Hkg5qeNhfwpKW4fXvq7HGZB9z2EnmCCA9'),
         OriginationSubscription(),
         HeadSubscription(),
     }
 
     index_config = create_config(True, True).indexes['hen_mainnet']
-    assert isinstance(index_config, TzktOperationsIndexConfig)
+    assert isinstance(index_config, TezosOperationsIndexConfig)
     assert index_config.get_subscriptions() == {
         TransactionSubscription(),
         OriginationSubscription(),
         HeadSubscription(),
     }
 
 
 async def test_validators() -> None:
-    # NOTE: @validator wrapped with `ConfigurationError` in `DipDupConfig.load`
     with pytest.raises(ValidationError):
         TezosContractConfig(kind='tezos', address='KT1lalala')
     with pytest.raises(ValidationError):
         TezosContractConfig(kind='tezos', address='lalalalalalalalalalalalalalalalalala')
-    with pytest.raises(ConfigurationError):
-        TzktDatasourceConfig(kind='tezos.tzkt', url='not_an_url')
+    with pytest.raises(ValidationError):
+        TezosTzktDatasourceConfig(kind='tezos.tzkt', url='not_an_url')
 
 
 async def test_reserved_keywords() -> None:
     assert (
-        SubsquidTransactionsHandlerConfig(  # type: ignore[comparison-overlap]
+        EvmTransactionsHandlerConfig(  # type: ignore[comparison-overlap]
             callback='test',
             from_='from',  # type: ignore[arg-type]
         ).from_
         == 'from'
     )
 
-    # FIXME: Can't use `from_` field alias in dataclasses (fixed in `next` with Pydantic v2)
+    # FIXME: Can't use `from_` field alias in dataclasses
     raw_config, _ = DipDupYAMLConfig.load(
-        paths=[Path(__file__).parent.parent / 'configs' / 'demo_token_transfers_4.yml']
+        paths=[Path(__file__).parent.parent / 'configs' / 'demo_tezos_token_transfers_4.yml']
     )
     assert raw_config['indexes']['tzbtc_holders_mainnet']['handlers'][1]['from_'] == 'tzbtc_mainnet'
 
-    config = DipDupConfig.load([Path(__file__).parent.parent / 'configs' / 'demo_token_transfers_4.yml'])
-    assert config.indexes['tzbtc_holders_mainnet'].handlers[1].from_ == 'tzbtc_mainnet'  # type: ignore[union-attr]
+    config = DipDupConfig.load([Path(__file__).parent.parent / 'configs' / 'demo_tezos_token_transfers_4.yml'])
+    assert config.indexes['tzbtc_holders_mainnet'].handlers[1].from_ == 'tzbtc_mainnet'  # type: ignore[misc,union-attr]
 
 
 async def test_dump() -> None:
     config = create_config()
 
     tmp_path = Path(tempfile.mkstemp(suffix='yaml')[1])
     tmp_path.write_text(config.dump())
```

### Comparing `dipdup-7.5.7/tests/test_config/test_custom_config.py` & `dipdup-8.0.0a1/tests/test_config/test_custom_config.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,25 @@
 import os
+from functools import partial
 from pathlib import Path
 from typing import Any
 
 import pytest
 from _pytest.tmpdir import TempPathFactory
 
 from dipdup.config import DipDupConfig
 from dipdup.exceptions import ConfigurationError
 
+load_config = partial(
+    DipDupConfig.load,
+    environment=True,
+    raw=False,
+    unsafe=True,
+)
+
 
 class TestCustomConfig:
     @pytest.fixture(scope='session')
     def dummy_config_path(self) -> Path:
         return Path(__file__).parent.parent / 'configs' / 'dipdup.yml'
 
     @staticmethod
@@ -40,22 +48,22 @@
     def config_with_custom_section_path(
         self, dummy_config_path: str, tmp_path_factory: TempPathFactory, request: Any
     ) -> str:
         return self.appended_config_path(dummy_config_path, tmp_path_factory, request.param)
 
     @staticmethod
     def test_empty_custom_section(dummy_config_path: str) -> None:
-        config = DipDupConfig.load([Path(dummy_config_path)], False)
+        config = load_config([Path(dummy_config_path)])
         config.initialize()
         assert hasattr(config, 'custom')
         assert config.custom == {}
 
     @staticmethod
     def test_custom_section_items(config_with_custom_section_path: str) -> None:
-        config = DipDupConfig.load([Path(config_with_custom_section_path)], False)
+        config = load_config([Path(config_with_custom_section_path)])
         config.initialize()
 
         assert hasattr(config, 'custom')
         assert isinstance(config.custom, dict)
 
         assert config.custom['foo'] == 'bar'
 
@@ -78,15 +86,15 @@
         self, value: str, expected: str, dummy_config_path: str, tmp_path_factory: TempPathFactory
     ) -> None:
         append_raw = f"""
 custom:
     var_from_env: {value}
 """
         config_path = self.appended_config_path(dummy_config_path, tmp_path_factory, append_raw)
-        config = DipDupConfig.load([Path(config_path)], True)
+        config = load_config([Path(config_path)])
         config.initialize()
 
         assert hasattr(config, 'custom')
         assert isinstance(config.custom, dict)
 
         assert config.custom['var_from_env'] == expected
 
@@ -98,17 +106,17 @@
         append_raw = f"""
 custom:
     var_from_env: {value}
 """
         config_path = self.appended_config_path(dummy_config_path, tmp_path_factory, append_raw)
 
         try:
-            DipDupConfig.load([Path(config_path)], True)
+            load_config([Path(config_path)])
         except ConfigurationError as exc:
-            assert str(exc) == f'DipDup YAML config is invalid -> {exc.args[0]}'
+            assert str(exc) == 'DipDup YAML config is invalid -> ' + exc.args[0].split('\n')[0]
             assert exc.args[0] == 'Environment variable `DEFINITELY_NOT_DEFINED` is not set'
         else:
             raise AssertionError('ConfigurationError not raised')
 
     @pytest.mark.parametrize(
         'value',
         (
@@ -119,8 +127,8 @@
     def test_skip_commented_variables(
         self, value: str, dummy_config_path: str, tmp_path_factory: TempPathFactory
     ) -> None:
         append_raw = f"""
   #  some commented line corresponding to ENV_VARIABLE_REGEX with {value}
 """
         config_path = self.appended_config_path(dummy_config_path, tmp_path_factory, append_raw)
-        DipDupConfig.load([Path(config_path)], True)
+        load_config([Path(config_path)])
```

### Comparing `dipdup-7.5.7/tests/test_datasources/test_ipfs.py` & `dipdup-8.0.0a1/tests/test_datasources/test_ipfs.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/test_datasources/test_metadata.py` & `dipdup-8.0.0a1/tests/test_datasources/test_metadata.py`

 * *Files identical despite different names*

### Comparing `dipdup-7.5.7/tests/test_datasources/test_tzkt.py` & `dipdup-8.0.0a1/tests/test_datasources/test_tzkt.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,17 +6,17 @@
 import orjson as json
 import pysignalr.exceptions
 import pytest
 
 from dipdup.exceptions import DatasourceError
 from dipdup.exceptions import FrameworkException
 from dipdup.exceptions import InvalidRequestError
+from dipdup.models.tezos import TezosOperationData
 from dipdup.models.tezos_tzkt import HeadSubscription
-from dipdup.models.tezos_tzkt import TzktMessageType
-from dipdup.models.tezos_tzkt import TzktOperationData
+from dipdup.models.tezos_tzkt import TezosTzktMessageType
 from tests import tzkt_replay
 
 T = TypeVar('T')
 
 
 async def take_two(iterable: AsyncIterator[tuple[T, ...]]) -> tuple[T, ...]:
     result: tuple[T, ...] = ()
@@ -198,22 +198,22 @@
     message = {'type': 1, 'state': 2, 'data': operations_json}
     async with tzkt_replay(batch_size=1) as tzkt:
         emit_mock = AsyncMock()
         tzkt.call_on_operations(emit_mock)
         tzkt._subscriptions.add(HeadSubscription())
         tzkt.set_sync_level(HeadSubscription(), 1)
 
-        level = tzkt.get_channel_level(TzktMessageType.operation)
+        level = tzkt.get_channel_level(TezosTzktMessageType.operation)
         assert level == 1
 
-        await tzkt._on_message(TzktMessageType.operation, [message])
+        await tzkt._on_message(TezosTzktMessageType.operation, [message])
 
-        level = tzkt.get_channel_level(TzktMessageType.operation)
+        level = tzkt.get_channel_level(TezosTzktMessageType.operation)
         assert level == 2
-        assert isinstance(emit_mock.await_args_list[0][0][1][0], TzktOperationData)
+        assert isinstance(emit_mock.await_args_list[0][0][1][0], TezosOperationData)
 
 
 # FIXME: Hangs without internet
 async def test_no_content() -> None:
     async with tzkt_replay('https://api.ghostnet.tzkt.io', batch_size=1) as tzkt:
         with pytest.raises(InvalidRequestError):
             await tzkt.get_jsonschemas('KT1EHdK9asB6BtPLvt1ipKRuxsrKoQhDoKgs')
```

### Comparing `dipdup-7.5.7/tests/test_datasources/test_tzkt_blocks.py` & `dipdup-8.0.0a1/tests/test_datasources/test_tzkt_blocks.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 import json
 
 import pytest
 
-from dipdup.models.tezos_tzkt import TzktBlockData
+from dipdup.models.tezos import TezosBlockData
 
 
 @pytest.mark.parametrize(
     'tzkt_block_json',
     [
         '{"cycle":524,"level":2706800,"hash":"BLNtxuniowUUtyx4UtWDZCckQsp9rF89MRk3BZZvMWoXNDSqsLx","timestamp":"2022-09-13T14:10:59Z","proto":13,"payloadRound":0,"blockRound":0,"validations":6969,"deposit":0,"reward":10000000,"bonus":9866372,"fees":213751,"nonceRevealed":false,"proposer":{"address":"tz1Nf6tsK4G6bBqgSQERy4nUtkHNKUVdh7q1"},"producer":{"address":"tz1Nf6tsK4G6bBqgSQERy4nUtkHNKUVdh7q1"},"software":{"version":"v13.0","date":"2022-05-05T12:55:26Z"},"lbToggle":true,"lbToggleEma":376475923,"priority":0,"baker":{"address":"tz1Nf6tsK4G6bBqgSQERy4nUtkHNKUVdh7q1"},"lbEscapeVote":false,"lbEscapeEma":376475923}',
     ],
 )
 async def test_deprecated_priority(tzkt_block_json: str) -> None:
     tzkt_block_dict = json.loads(tzkt_block_json)
-    block = TzktBlockData.from_json(tzkt_block_dict)
+    block = TezosBlockData.from_json(tzkt_block_dict)
     assert block
-    assert isinstance(block, TzktBlockData)
+    assert isinstance(block, TezosBlockData)
     assert block.priority == 0
 
     del tzkt_block_dict['priority']
 
-    block = TzktBlockData.from_json(tzkt_block_dict)
+    block = TezosBlockData.from_json(tzkt_block_dict)
     assert block
-    assert isinstance(block, TzktBlockData)
+    assert isinstance(block, TezosBlockData)
     assert block.priority is None
```

### Comparing `dipdup-7.5.7/tests/test_datasources/test_tzkt_buffer.py` & `dipdup-8.0.0a1/tests/test_datasources/test_tzkt_buffer.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,59 +1,59 @@
 import pytest
 
 from dipdup.datasources.tezos_tzkt import BufferedMessage
 from dipdup.datasources.tezos_tzkt import MessageBuffer
-from dipdup.models.tezos_tzkt import TzktMessageType
+from dipdup.models.tezos_tzkt import TezosTzktMessageType
 
 
 @pytest.fixture
 def buffer() -> MessageBuffer:
     return MessageBuffer(2)
 
 
 async def test_add(buffer: MessageBuffer) -> None:
     assert len(buffer) == 0
 
-    buffer.add(TzktMessageType.head, 1, {})
+    buffer.add(TezosTzktMessageType.head, 1, {})
     assert len(buffer) == 1
 
-    buffer.add(TzktMessageType.operation, 1, [{}])
+    buffer.add(TezosTzktMessageType.operation, 1, [{}])
     assert len(buffer) == 1
 
-    buffer.add(TzktMessageType.operation, 2, [{}])
+    buffer.add(TezosTzktMessageType.operation, 2, [{}])
     assert len(buffer) == 2
 
 
 async def test_yield_from(buffer: MessageBuffer) -> None:
-    buffer.add(TzktMessageType.head, 1, {})
-    buffer.add(TzktMessageType.operation, 1, [{}])
-    buffer.add(TzktMessageType.head, 2, {})
-    buffer.add(TzktMessageType.operation, 2, [{}])
-    buffer.add(TzktMessageType.head, 3, {})
-    buffer.add(TzktMessageType.operation, 3, [{}])
+    buffer.add(TezosTzktMessageType.head, 1, {})
+    buffer.add(TezosTzktMessageType.operation, 1, [{}])
+    buffer.add(TezosTzktMessageType.head, 2, {})
+    buffer.add(TezosTzktMessageType.operation, 2, [{}])
+    buffer.add(TezosTzktMessageType.head, 3, {})
+    buffer.add(TezosTzktMessageType.operation, 3, [{}])
 
     assert len(buffer) == 3
 
     messages = list(buffer.yield_from())
 
     assert len(buffer) == 2
 
     assert isinstance(messages[0], BufferedMessage)
-    assert messages[0].type == TzktMessageType.head
+    assert messages[0].type == TezosTzktMessageType.head
     assert isinstance(messages[1], BufferedMessage)
-    assert messages[1].type == TzktMessageType.operation
+    assert messages[1].type == TezosTzktMessageType.operation
 
 
 async def test_rollback(buffer: MessageBuffer) -> None:
-    buffer.add(TzktMessageType.head, 2, {})
-    buffer.add(TzktMessageType.operation, 2, [{}])
-    buffer.add(TzktMessageType.head, 3, {})
-    buffer.add(TzktMessageType.operation, 3, [{}])
-    buffer.add(TzktMessageType.head, 4, {})
-    buffer.add(TzktMessageType.operation, 4, [{}])
-
-    assert buffer.rollback(TzktMessageType.head, 4, 3) is True
-    assert buffer.rollback(TzktMessageType.operation, 4, 3) is True
-    assert buffer.rollback(TzktMessageType.operation, 3, 1) is True
-    assert buffer.rollback(TzktMessageType.head, 3, 1) is True
-    assert buffer.rollback(TzktMessageType.operation, 1, 0) is False
-    assert buffer.rollback(TzktMessageType.head, 1, 0) is False
+    buffer.add(TezosTzktMessageType.head, 2, {})
+    buffer.add(TezosTzktMessageType.operation, 2, [{}])
+    buffer.add(TezosTzktMessageType.head, 3, {})
+    buffer.add(TezosTzktMessageType.operation, 3, [{}])
+    buffer.add(TezosTzktMessageType.head, 4, {})
+    buffer.add(TezosTzktMessageType.operation, 4, [{}])
+
+    assert buffer.rollback(TezosTzktMessageType.head, 4, 3) is True
+    assert buffer.rollback(TezosTzktMessageType.operation, 4, 3) is True
+    assert buffer.rollback(TezosTzktMessageType.operation, 3, 1) is True
+    assert buffer.rollback(TezosTzktMessageType.head, 3, 1) is True
+    assert buffer.rollback(TezosTzktMessageType.operation, 1, 0) is False
+    assert buffer.rollback(TezosTzktMessageType.head, 1, 0) is False
```

### Comparing `dipdup-7.5.7/tests/test_datasources/test_tzkt_quotes.py` & `dipdup-8.0.0a1/tests/test_datasources/test_tzkt_quotes.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 import json
 from decimal import Decimal
 
 import pytest
 
-from dipdup.models.tezos_tzkt import TzktQuoteData
+from dipdup.models.tezos import TezosQuoteData
 
 
 @pytest.mark.parametrize(
     'tzkt_quote_json, expected_fields',
     [
         [
             '{"level":2706800,"timestamp":"2022-09-13T14:10:59Z","btc":7.430321914172931E-05,"eur":1.5702972861340734,"usd":1.5734678237990354,"cny":10.896894066937795,"jpy":226.8776313310482,"krw":2192.5289432740697,"eth":0.000982514979977172,"gbp":1.3628685963904752}',
@@ -23,14 +23,14 @@
                 'gbp': Decimal('1.362868596390475'),
             },
         ]
     ],
 )
 async def test_convert_quote(tzkt_quote_json: str, expected_fields: dict[str, object]) -> None:
     tzkt_quote_dict = json.loads(tzkt_quote_json)
-    quote = TzktQuoteData.from_json(tzkt_quote_dict)
+    quote = TezosQuoteData.from_json(tzkt_quote_dict)
     assert quote
-    assert isinstance(quote, TzktQuoteData)
+    assert isinstance(quote, TezosQuoteData)
     for field, expected_value in expected_fields.items():
         assert hasattr(quote, field)
         value = getattr(quote, field)
         assert str(value).startswith(str(expected_value))
```

### Comparing `dipdup-7.5.7/tests/test_demos.py` & `dipdup-8.0.0a1/tests/test_demos.py`

 * *Files 20% similar despite different names*

```diff
@@ -3,143 +3,143 @@
 from contextlib import AsyncExitStack
 from decimal import Decimal
 from functools import partial
 
 import pytest
 
 from dipdup.database import tortoise_wrapper
-from dipdup.models.tezos_tzkt import TzktOperationType
+from dipdup.models.tezos import TezosOperationType
 from dipdup.test import run_in_tmp
 from dipdup.test import tmp_project
 from tests import TEST_CONFIGS
 
 
 async def assert_run_token() -> None:
-    import demo_token.models
+    import demo_tezos_token.models
 
-    holders = await demo_token.models.Holder.filter().count()
-    holder = await demo_token.models.Holder.first()
+    holders = await demo_tezos_token.models.Holder.filter().count()
+    holder = await demo_tezos_token.models.Holder.first()
     assert holder
     random_balance = holder.balance
 
     assert holders == 4
     assert random_balance == Decimal('-0.01912431')
 
 
 async def assert_run_nft_marketplace() -> None:
-    import demo_nft_marketplace.models
+    import demo_tezos_nft_marketplace.models
 
-    holders = await demo_nft_marketplace.models.Holder.filter().count()
-    tokens = await demo_nft_marketplace.models.Token.filter().count()
-    swaps = await demo_nft_marketplace.models.Swap.filter().count()
-    trades = await demo_nft_marketplace.models.Trade.filter().count()
+    holders = await demo_tezos_nft_marketplace.models.Holder.filter().count()
+    tokens = await demo_tezos_nft_marketplace.models.Token.filter().count()
+    swaps = await demo_tezos_nft_marketplace.models.Swap.filter().count()
+    trades = await demo_tezos_nft_marketplace.models.Trade.filter().count()
 
     assert holders == 22
     assert tokens == 29
     assert swaps == 20
     assert trades == 24
 
 
 async def assert_run_auction() -> None:
-    import demo_auction.models
+    import demo_tezos_auction.models
 
-    users = await demo_auction.models.User.filter().count()
-    tokens = await demo_auction.models.Token.filter().count()
-    auctions = await demo_auction.models.Auction.filter().count()
-    bids = await demo_auction.models.Bid.filter().count()
+    users = await demo_tezos_auction.models.User.filter().count()
+    tokens = await demo_tezos_auction.models.Token.filter().count()
+    auctions = await demo_tezos_auction.models.Auction.filter().count()
+    bids = await demo_tezos_auction.models.Bid.filter().count()
 
     assert users == 9
     assert tokens == 14
     assert auctions == 14
     assert bids == 44
 
 
 async def assert_run_token_transfers(expected_holders: int, expected_balance: str) -> None:
-    import demo_token_transfers.models
+    import demo_tezos_token_transfers.models
 
-    holders = await demo_token_transfers.models.Holder.filter().count()
-    holder = await demo_token_transfers.models.Holder.first()
+    holders = await demo_tezos_token_transfers.models.Holder.filter().count()
+    holder = await demo_tezos_token_transfers.models.Holder.first()
     assert holder
     random_balance = holder.balance
 
     assert holders == expected_holders
     assert f'{random_balance:f}' == expected_balance
 
 
 async def assert_run_balances() -> None:
-    import demo_token_balances.models
+    import demo_tezos_token_balances.models
 
-    holders = await demo_token_balances.models.Holder.filter().count()
-    holder = await demo_token_balances.models.Holder.first()
+    holders = await demo_tezos_token_balances.models.Holder.filter().count()
+    holder = await demo_tezos_token_balances.models.Holder.first()
     assert holder
     random_balance = holder.balance
 
     assert holders == 1
     assert random_balance == 0
 
 
 async def assert_run_big_maps() -> None:
-    import demo_big_maps.models
+    import demo_tezos_big_maps.models
 
-    tlds = await demo_big_maps.models.TLD.filter().count()
-    domains = await demo_big_maps.models.Domain.filter().count()
+    tlds = await demo_tezos_big_maps.models.TLD.filter().count()
+    domains = await demo_tezos_big_maps.models.Domain.filter().count()
 
     assert tlds == 1
     assert domains == 1
 
 
 async def assert_init(package: str) -> None:
     pass
 
 
 async def assert_run_dex() -> None:
-    import demo_dex.models
+    import demo_tezos_dex.models
     from tortoise.transactions import in_transaction
 
-    trades = await demo_dex.models.Trade.filter().count()
-    positions = await demo_dex.models.Position.filter().count()
+    trades = await demo_tezos_dex.models.Trade.filter().count()
+    positions = await demo_tezos_dex.models.Position.filter().count()
     async with in_transaction() as conn:
         symbols = (await conn.execute_query('select count(distinct(symbol)) from trade group by symbol;'))[0]
     assert symbols == 2
     assert trades == 55
     assert positions == 125
 
 
 async def assert_run_domains() -> None:
-    import demo_domains.models
+    import demo_tezos_domains.models
 
-    tlds = await demo_domains.models.TLD.filter().count()
-    domains = await demo_domains.models.Domain.filter().count()
+    tlds = await demo_tezos_domains.models.TLD.filter().count()
+    domains = await demo_tezos_domains.models.Domain.filter().count()
 
     assert tlds == 1
     assert domains == 1
 
 
 async def assert_run_events() -> None:
     pass
 
 
 async def assert_run_factories() -> None:
-    import demo_factories.models
+    import demo_tezos_factories.models
 
     from dipdup import models
 
     indexes = await models.Index.filter().count()
-    transfers = await demo_factories.models.Transfer.filter().count()
+    transfers = await demo_tezos_factories.models.Transfer.filter().count()
 
     assert indexes == 2
     assert transfers == 1
 
 
 async def assert_run_raw() -> None:
-    import demo_raw.models
+    import demo_tezos_raw.models
 
-    transactions = await demo_raw.models.Operation.filter(type=TzktOperationType.transaction).count()
-    originations = await demo_raw.models.Operation.filter(type=TzktOperationType.origination).count()
-    migrations = await demo_raw.models.Operation.filter(type=TzktOperationType.migration).count()
+    transactions = await demo_tezos_raw.models.Operation.filter(type=TezosOperationType.transaction).count()
+    originations = await demo_tezos_raw.models.Operation.filter(type=TezosOperationType.origination).count()
+    migrations = await demo_tezos_raw.models.Operation.filter(type=TezosOperationType.migration).count()
 
     assert transactions == 167
     assert originations == 1
     assert migrations == 2
 
 
 async def assert_run_evm_events() -> None:
@@ -154,80 +154,90 @@
 
     holders = await demo_evm_transactions.models.Holder.filter().count()
     # NOTE: Another 4 holders covered by `demo_evm_events` index are from non-`Transfer` calls.
     assert holders == 22
 
 
 async def assert_run_dao() -> None:
-    import demo_dao.models
+    import demo_tezos_dao.models
 
-    proposals = await demo_dao.models.DAO.filter().count()
-    votes = await demo_dao.models.Proposal.filter().count()
+    proposals = await demo_tezos_dao.models.DAO.filter().count()
+    votes = await demo_tezos_dao.models.Proposal.filter().count()
 
     assert proposals == 1
     assert votes == 1
 
 
 test_args = ('config', 'package', 'cmd', 'assert_fn')
 test_params = (
-    ('demo_token.yml', 'demo_token', 'run', assert_run_token),
-    ('demo_token.yml', 'demo_token', 'init', None),
-    ('demo_nft_marketplace.yml', 'demo_nft_marketplace', 'run', assert_run_nft_marketplace),
-    ('demo_nft_marketplace.yml', 'demo_nft_marketplace', 'init', None),
-    ('demo_auction.yml', 'demo_auction', 'run', assert_run_auction),
-    ('demo_auction.yml', 'demo_auction', 'init', None),
-    ('demo_token_transfers.yml', 'demo_token_transfers', 'run', partial(assert_run_token_transfers, 4, '-0.01912431')),
+    ('demo_tezos_token.yml', 'demo_tezos_token', 'run', assert_run_token),
+    ('demo_tezos_token.yml', 'demo_tezos_token', 'init', None),
+    ('demo_tezos_nft_marketplace.yml', 'demo_tezos_nft_marketplace', 'run', assert_run_nft_marketplace),
+    ('demo_tezos_nft_marketplace.yml', 'demo_tezos_nft_marketplace', 'init', None),
+    ('demo_tezos_auction.yml', 'demo_tezos_auction', 'run', assert_run_auction),
+    ('demo_tezos_auction.yml', 'demo_tezos_auction', 'init', None),
+    (
+        'demo_tezos_token_transfers.yml',
+        'demo_tezos_token_transfers',
+        'run',
+        partial(assert_run_token_transfers, 4, '-0.01912431'),
+    ),
     # TODO: Too many token transfer runs
-    ('demo_token_transfers.yml', 'demo_token_transfers', 'init', None),
+    ('demo_tezos_token_transfers.yml', 'demo_tezos_token_transfers', 'init', None),
     (
-        'demo_token_transfers_2.yml',
-        'demo_token_transfers',
+        'demo_tezos_token_transfers_2.yml',
+        'demo_tezos_token_transfers',
         'run',
         partial(assert_run_token_transfers, 12, '0.26554711'),
     ),
-    ('demo_token_transfers_3.yml', 'demo_token_transfers', 'run', partial(assert_run_token_transfers, 9, '0.15579888')),
+    (
+        'demo_tezos_token_transfers_3.yml',
+        'demo_tezos_token_transfers',
+        'run',
+        partial(assert_run_token_transfers, 9, '0.15579888'),
+    ),
     # FIXME: Reenable after fixing fetcher
     # (
-    #     'demo_token_transfers_4.yml',
-    #     'demo_token_transfers',
+    #     'demo_tezos_token_transfers_4.yml',
+    #     'demo_tezos_token_transfers',
     #     'run',
     #     partial(assert_run_token_transfers, 2, '-0.02302128'),
     # ),
-    ('demo_token_balances.yml', 'demo_token_balances', 'run', assert_run_balances),
-    ('demo_token_balances.yml', 'demo_token_balances', 'init', None),
-    ('demo_big_maps.yml', 'demo_big_maps', 'run', assert_run_big_maps),
-    ('demo_big_maps.yml', 'demo_big_maps', 'init', None),
-    ('demo_domains.yml', 'demo_domains', 'run', assert_run_domains),
-    ('demo_domains.yml', 'demo_domains', 'init', None),
-    ('demo_dex.yml', 'demo_dex', 'run', assert_run_dex),
-    ('demo_dex.yml', 'demo_dex', 'init', None),
-    ('demo_dao.yml', 'demo_dao', 'run', assert_run_dao),
-    ('demo_dao.yml', 'demo_dao', 'init', None),
-    ('demo_factories.yml', 'demo_factories', 'run', assert_run_factories),
-    ('demo_factories.yml', 'demo_factories', 'init', None),
-    ('demo_events.yml', 'demo_events', 'run', assert_run_events),
-    ('demo_events.yml', 'demo_events', 'init', None),
-    ('demo_raw.yml', 'demo_raw', 'run', assert_run_raw),
-    ('demo_raw.yml', 'demo_raw', 'init', None),
+    ('demo_tezos_token_balances.yml', 'demo_tezos_token_balances', 'run', assert_run_balances),
+    ('demo_tezos_token_balances.yml', 'demo_tezos_token_balances', 'init', None),
+    ('demo_tezos_big_maps.yml', 'demo_tezos_big_maps', 'run', assert_run_big_maps),
+    ('demo_tezos_big_maps.yml', 'demo_tezos_big_maps', 'init', None),
+    ('demo_tezos_domains.yml', 'demo_tezos_domains', 'run', assert_run_domains),
+    ('demo_tezos_domains.yml', 'demo_tezos_domains', 'init', None),
+    ('demo_tezos_dex.yml', 'demo_tezos_dex', 'run', assert_run_dex),
+    ('demo_tezos_dex.yml', 'demo_tezos_dex', 'init', None),
+    ('demo_tezos_dao.yml', 'demo_tezos_dao', 'run', assert_run_dao),
+    ('demo_tezos_dao.yml', 'demo_tezos_dao', 'init', None),
+    ('demo_tezos_factories.yml', 'demo_tezos_factories', 'run', assert_run_factories),
+    ('demo_tezos_factories.yml', 'demo_tezos_factories', 'init', None),
+    ('demo_tezos_events.yml', 'demo_tezos_events', 'run', assert_run_events),
+    ('demo_tezos_events.yml', 'demo_tezos_events', 'init', None),
+    ('demo_tezos_raw.yml', 'demo_tezos_raw', 'run', assert_run_raw),
+    ('demo_tezos_raw.yml', 'demo_tezos_raw', 'init', None),
     ('demo_evm_events.yml', 'demo_evm_events', 'run', assert_run_evm_events),
     ('demo_evm_events.yml', 'demo_evm_events', 'init', None),
     ('demo_evm_transactions.yml', 'demo_evm_transactions', 'run', assert_run_evm_transactions),
     ('demo_evm_transactions.yml', 'demo_evm_transactions', 'init', None),
-    ('demo_etherlink.yml', 'demo_etherlink', 'run', None),
-    ('demo_etherlink.yml', 'demo_etherlink', 'init', None),
-    # NOTE: EVM indexes with `node_only`
+    ('demo_tezos_etherlink.yml', 'demo_tezos_etherlink', 'run', None),
+    ('demo_tezos_etherlink.yml', 'demo_tezos_etherlink', 'init', None),
+    # NOTE: Indexes with `evm.node` as index datasource
     ('demo_evm_events_node.yml', 'demo_evm_events', 'run', assert_run_evm_events),
     ('demo_evm_transactions_node.yml', 'demo_evm_transactions', 'run', assert_run_evm_transactions),
     # NOTE: Smoke tests for small tools.
-    ('demo_dex.yml', 'demo_dex', ('config', 'env', '--compose', '--internal'), None),
-    ('demo_dex.yml', 'demo_dex', ('config', 'export', '--full'), None),
-    ('demo_dex.yml', 'demo_dex', ('package', 'tree'), None),
-    ('demo_dex.yml', 'demo_dex', ('report', 'ls'), None),
-    ('demo_dex.yml', 'demo_dex', ('self', 'env'), None),
-    ('demo_dex.yml', 'demo_dex', ('schema', 'export'), None),
+    ('demo_tezos_dex.yml', 'demo_tezos_dex', ('config', 'env', '--compose', '--internal'), None),
+    ('demo_tezos_dex.yml', 'demo_tezos_dex', ('config', 'export', '--full'), None),
+    ('demo_tezos_dex.yml', 'demo_tezos_dex', ('package', 'tree'), None),
+    ('demo_tezos_dex.yml', 'demo_tezos_dex', ('report', 'ls'), None),
+    ('demo_tezos_dex.yml', 'demo_tezos_dex', ('self', 'env'), None),
+    ('demo_tezos_dex.yml', 'demo_tezos_dex', ('schema', 'export'), None),
 )
 
 
 @pytest.mark.parametrize(test_args, test_params)
 async def test_run_init(
     config: str,
     package: str,
```

### Comparing `dipdup-7.5.7/tests/test_dipdup.py` & `dipdup-8.0.0a1/tests/test_dipdup.py`

 * *Files 2% similar despite different names*

```diff
@@ -21,21 +21,21 @@
         name='hen_mainnet',
         template=None,
         config_hash=hash_,
         created_at=datetime(2021, 10, 8, 18, 43, 35, 744412, tzinfo=UTC),
         template_values={},
         status=IndexStatus.new,
         updated_at=datetime(2021, 10, 8, 18, 43, 35, 744449, tzinfo=UTC),
-        type=IndexType.tezos_tzkt_operations,
+        type=IndexType.tezos_operations,
     )
 
 
 class IndexStateTest:
     def __init__(self) -> None:
-        name = 'demo_nft_marketplace.yml'
+        name = 'demo_tezos_nft_marketplace.yml'
         config_path = Path(__file__).parent / 'configs' / name
         self.config = DipDupConfig.load([config_path])
         self.config.database = SqliteDatabaseConfig(kind='sqlite')
         self.config.advanced.rollback_depth = 2
         self.config.initialize()
 
         self.new_hash = '98858ec743f2c84ef9505ccefa2235fc6bb9e9b209b14b2028dd4650eaf96756'
```

### Comparing `dipdup-7.5.7/tests/test_hasura.py` & `dipdup-8.0.0a1/tests/test_hasura.py`

 * *Files 2% similar despite different names*

```diff
@@ -25,15 +25,15 @@
     from aiohttp.test_utils import TestClient
 
 
 async def test_configure_hasura() -> None:
     if os.uname().sysname != 'Linux' or 'microsoft' in os.uname().release:  # check for WSL, Windows, mac and else
         pytest.skip('Test is not supported for os archetecture', allow_module_level=True)
 
-    config_path = Path(__file__).parent / 'configs' / 'demo_nft_marketplace.yml'
+    config_path = Path(__file__).parent / 'configs' / 'demo_tezos_nft_marketplace.yml'
 
     config = DipDupConfig.load([config_path])
     config.database = await run_postgres_container()
     config.hasura = await run_hasura_container(config.database.host)
     config.advanced.reindex[ReindexingReason.schema_modified] = ReindexingAction.ignore
     config.initialize()
 
@@ -66,14 +66,14 @@
     fake_api.router.add_get('/v1/version', version_response)
     fake_client: TestClient = await aiohttp_client(fake_api)
 
     fake_client_url = f'http://{fake_client.server.host}:{fake_client.server.port}'
     hasura_config = HasuraConfig(url=fake_client_url)
     postgres_config = PostgresDatabaseConfig(kind='postgres', host='localhost')
 
-    hasura_gateway = HasuraGateway('demo_nft_marketplace', hasura_config, postgres_config)
+    hasura_gateway = HasuraGateway('demo_tezos_nft_marketplace', hasura_config, postgres_config)
 
     with pytest.raises(UnsupportedAPIError):
         async with hasura_gateway:
-            async with tortoise_wrapper('sqlite://:memory:', 'demo_nft_marketplace.models'):
+            async with tortoise_wrapper('sqlite://:memory:', 'demo_tezos_nft_marketplace.models'):
                 await Tortoise.generate_schemas()
                 await hasura_gateway.configure()
```

### Comparing `dipdup-7.5.7/tests/test_index/test_tzkt_operations.py` & `dipdup-8.0.0a1/tests/test_index/test_tzkt_operations.py`

 * *Files 7% similar despite different names*

```diff
@@ -2,179 +2,181 @@
 from contextlib import AsyncExitStack
 from decimal import Decimal
 from typing import cast
 
 import pytest
 
 from dipdup.config import DipDupConfig
-from dipdup.config.tezos_tzkt_operations import OperationsHandlerOriginationPatternConfig
-from dipdup.config.tezos_tzkt_operations import TzktOperationsHandlerConfig
-from dipdup.config.tezos_tzkt_operations import TzktOperationsIndexConfig
-from dipdup.datasources.tezos_tzkt import TzktDatasource
+from dipdup.config.tezos_operations import TezosOperationsHandlerConfig
+from dipdup.config.tezos_operations import TezosOperationsHandlerOriginationPatternConfig
+from dipdup.config.tezos_operations import TezosOperationsIndexConfig
+from dipdup.datasources.tezos_tzkt import TezosTzktDatasource
 from dipdup.exceptions import FrameworkException
-from dipdup.indexes.tezos_tzkt_operations.fetcher import get_origination_filters
-from dipdup.indexes.tezos_tzkt_operations.fetcher import get_transaction_filters
-from dipdup.indexes.tezos_tzkt_operations.index import TzktOperationsIndex
+from dipdup.indexes.tezos_operations.fetcher import get_origination_filters
+from dipdup.indexes.tezos_operations.fetcher import get_transaction_filters
+from dipdup.indexes.tezos_operations.index import TezosOperationsIndex
+from dipdup.models.tezos import TezosOperationType
 from dipdup.models.tezos_tzkt import HeadSubscription
 from dipdup.models.tezos_tzkt import TransactionSubscription
-from dipdup.models.tezos_tzkt import TzktOperationType
 from dipdup.test import create_dummy_dipdup
 from dipdup.test import spawn_index
 from tests import TEST_CONFIGS
 from tests import tzkt_replay
 
 
 @pytest.fixture
-async def tzkt() -> AsyncIterator[TzktDatasource]:
+async def tzkt() -> AsyncIterator[TezosTzktDatasource]:
     async with tzkt_replay() as tzkt:
         yield tzkt
 
 
 @pytest.fixture
-def index_config() -> TzktOperationsIndexConfig:
+def index_config() -> TezosOperationsIndexConfig:
     config = DipDupConfig.load([TEST_CONFIGS / 'operation_filters.yml'], True)
     config.initialize()
-    return cast(TzktOperationsIndexConfig, config.indexes['test'])
+    return cast(TezosOperationsIndexConfig, config.indexes['test'])
 
 
 async def test_ignored_type_filter(
-    tzkt: TzktDatasource,
-    index_config: TzktOperationsIndexConfig,
+    tzkt: TezosTzktDatasource,
+    index_config: TezosOperationsIndexConfig,
 ) -> None:
     index_config.types = ()
-    addresses, hashes = await get_origination_filters(index_config, tzkt)
+    addresses, hashes = await get_origination_filters(index_config, (tzkt,))
     assert not addresses
     assert not hashes
 
-    addresses, hashes = await get_transaction_filters(index_config, tzkt)
+    addresses, hashes = await get_transaction_filters(index_config)
     assert not addresses
     assert not hashes
 
 
+@pytest.mark.skip('FIXME: Pydantic 2 migration mystery')
 async def test_get_origination_filters(
-    tzkt: TzktDatasource,
-    index_config: TzktOperationsIndexConfig,
+    tzkt: TezosTzktDatasource,
+    index_config: TezosOperationsIndexConfig,
 ) -> None:
     index_config.handlers = (
-        TzktOperationsHandlerConfig(
+        TezosOperationsHandlerConfig(
             callback='address_origination',
             pattern=(
-                OperationsHandlerOriginationPatternConfig(
+                TezosOperationsHandlerOriginationPatternConfig(
                     originated_contract=index_config.contracts[0],
                 ),
             ),
         ),
     )
-    addresses, hashes = await get_origination_filters(index_config, tzkt)
+    addresses, hashes = await get_origination_filters(index_config, (tzkt,))
     assert addresses == {'KT1RJ6PbjHpwc3M5rw5s2Nbmefwbuwbdxton'}
     assert not hashes
 
     index_config.handlers = (
-        TzktOperationsHandlerConfig(
+        TezosOperationsHandlerConfig(
             callback='hash_origination',
             pattern=(
-                OperationsHandlerOriginationPatternConfig(
+                TezosOperationsHandlerOriginationPatternConfig(
                     originated_contract=index_config.contracts[1],
                 ),
             ),
         ),
     )
-    addresses, hashes = await get_origination_filters(index_config, tzkt)
+    addresses, hashes = await get_origination_filters(index_config, (tzkt,))
     assert not addresses
     assert hashes == {-1585533315}
 
     index_config.handlers = (
-        TzktOperationsHandlerConfig(
+        TezosOperationsHandlerConfig(
             callback='hash_address_origination',
             pattern=(
-                OperationsHandlerOriginationPatternConfig(
+                TezosOperationsHandlerOriginationPatternConfig(
                     originated_contract=index_config.contracts[2],
                 ),
             ),
         ),
     )
     # NOTE: Resolved earlier
     with pytest.raises(FrameworkException):
-        await get_origination_filters(index_config, tzkt)
+        await get_origination_filters(index_config, (tzkt,))
 
     index_config.handlers = (
-        TzktOperationsHandlerConfig(
+        TezosOperationsHandlerConfig(
             callback='address_source',
             pattern=(
-                OperationsHandlerOriginationPatternConfig(
+                TezosOperationsHandlerOriginationPatternConfig(
                     source=index_config.contracts[0],
                 ),
             ),
         ),
     )
-    addresses, hashes = await get_origination_filters(index_config, tzkt)
+    addresses, hashes = await get_origination_filters(index_config, (tzkt,))
     assert not addresses
     assert hashes == set()
 
 
-async def test_get_transaction_filters(tzkt: TzktDatasource, index_config: TzktOperationsIndexConfig) -> None:
-    index_config.types = (TzktOperationType.transaction,)
+@pytest.mark.skip('FIXME: Pydantic 2 migration mystery')
+async def test_get_transaction_filters(tzkt: TezosTzktDatasource, index_config: TezosOperationsIndexConfig) -> None:
+    index_config.types = (TezosOperationType.transaction,)
     index_config.contracts[2].code_hash = -680664524
 
-    filters = await get_transaction_filters(index_config, tzkt)
+    filters = await get_transaction_filters(index_config)
     assert filters == ({'KT1RJ6PbjHpwc3M5rw5s2Nbmefwbuwbdxton'}, {-680664524, -1585533315})
 
     index_config.types = ()
-    filters = await get_transaction_filters(index_config, tzkt)
+    filters = await get_transaction_filters(index_config)
     assert filters == (set(), set())
 
 
 async def test_get_sync_level() -> None:
-    config = DipDupConfig.load([TEST_CONFIGS / 'demo_token.yml'], True)
+    config = DipDupConfig.load([TEST_CONFIGS / 'demo_tezos_token.yml'], True)
     async with AsyncExitStack() as stack:
         dipdup = await create_dummy_dipdup(config, stack)
         index = await spawn_index(dipdup, 'tzbtc_holders_mainnet')
 
         with pytest.raises(FrameworkException):
             index.get_sync_level()
 
-        index.datasource.set_sync_level(None, 0)
+        index.datasources[0].set_sync_level(None, 0)
         assert index.get_sync_level() == 0
 
         subs = index._config.get_subscriptions()
         assert subs == {
             HeadSubscription(),
             TransactionSubscription(address='KT1PWx2mnDueood7fEmfbBDKx1D9BAnnXitn'),
         }
 
         for i, sub in enumerate(subs):
-            index.datasource.set_sync_level(sub, i + 1)
+            index.datasources[0].set_sync_level(sub, i + 1)
             assert index.get_sync_level() == i + 1
 
 
 async def test_realtime() -> None:
-    from demo_token import models
+    from demo_tezos_token import models
 
-    config = DipDupConfig.load([TEST_CONFIGS / 'demo_token.yml'], True)
+    config = DipDupConfig.load([TEST_CONFIGS / 'demo_tezos_token.yml'], True)
     async with AsyncExitStack() as stack:
         dipdup = await create_dummy_dipdup(config, stack)
         await dipdup._set_up_datasources(stack)
 
         dispatcher = dipdup._index_dispatcher
-        index = cast(TzktOperationsIndex, await spawn_index(dipdup, 'tzbtc_holders_mainnet'))
+        index = cast(TezosOperationsIndex, await spawn_index(dipdup, 'tzbtc_holders_mainnet'))
 
         # NOTE: Start sync and realtime connection simultaneously.
         first_level = 1365000
         last_level = first_level + 500
         realtime_level = first_level + 1000
 
         fetcher = await index._create_fetcher(first_level, realtime_level)
         all_operations = {level: ops async for level, ops in fetcher.fetch_by_level()}
 
         assert len(all_operations) == 4
 
         # NOTE: Fill the queue while index is IndexStatus.new
         for _, operations in all_operations.items():
             await dispatcher._on_tzkt_operations(
-                datasource=index.datasource,
+                datasource=index.datasources[0],
                 operations=operations,
             )
 
         assert len(index._queue) == 4
         assert await models.Holder.filter().count() == 0
 
         # NOTE: We don't want index with `last_level` to be disabled
```

### Comparing `dipdup-7.5.7/tests/test_introspection.py` & `dipdup-8.0.0a1/tests/test_introspection.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,16 +1,19 @@
+from typing import Any
+
 import pytest
 from pydantic import BaseModel
+from pydantic import RootModel
 
-from dipdup.indexes.tezos_tzkt_operations.parser import IntrospectionError
-from dipdup.indexes.tezos_tzkt_operations.parser import extract_root_outer_type
-from dipdup.indexes.tezos_tzkt_operations.parser import get_dict_value_type
-from dipdup.indexes.tezos_tzkt_operations.parser import get_list_elt_type
-from dipdup.indexes.tezos_tzkt_operations.parser import is_array_type
-from dipdup.indexes.tezos_tzkt_operations.parser import unwrap_union_type
+from dipdup.indexes.tezos_operations.parser import IntrospectionError
+from dipdup.indexes.tezos_operations.parser import extract_root_outer_type
+from dipdup.indexes.tezos_operations.parser import get_dict_value_type
+from dipdup.indexes.tezos_operations.parser import get_list_elt_type
+from dipdup.indexes.tezos_operations.parser import is_array_type
+from dipdup.indexes.tezos_operations.parser import unwrap_union_type
 
 NoneType = type(None)
 
 
 def test_list_simple_args() -> None:
     assert get_list_elt_type(list[str]) == str
     assert get_list_elt_type(list[int]) == int
@@ -31,21 +34,21 @@
     assert get_list_elt_type(list[tuple[Class]]) == tuple[Class]
     assert get_list_elt_type(list[list[Class]]) == list[Class]
     assert get_list_elt_type(list[dict[str, Class]]) == dict[str, Class]
 
 
 def test_pydantic_list_arg() -> None:
     class ListOfMapsStorage(BaseModel):
-        __root__: list[int | dict[str, str]]
+        root: list[int | dict[str, str]]
 
     class SomethingElse(BaseModel):
-        __root__: dict[str, str]
+        root: dict[str, str]
 
     class OptionalList(BaseModel):
-        __root__: list[str] | None
+        root: list[str] | None
 
     assert get_list_elt_type(ListOfMapsStorage) == int | dict[str, str]
 
     with pytest.raises(IntrospectionError):
         get_list_elt_type(OptionalList)
 
     with pytest.raises(IntrospectionError):
@@ -71,22 +74,22 @@
     assert get_dict_value_type(dict[str, Class | int]) == Class | int
     assert get_dict_value_type(dict[str, tuple[Class]]) == tuple[Class]
     assert get_dict_value_type(dict[str, list[Class]]) == list[Class]
     assert get_dict_value_type(dict[str, dict[str, Class]]) == dict[str, Class]
 
 
 def test_pydantic_dict_arg() -> None:
-    class DictOfMapsStorage(BaseModel):
-        __root__: dict[str, int | dict[str, str]]
+    class DictOfMapsStorage(RootModel[Any]):
+        root: dict[str, int | dict[str, str]]
 
-    class SomethingElse(BaseModel):
-        __root__: list[str]
+    class SomethingElse(RootModel[Any]):
+        root: list[str]
 
-    class OptionalDict(BaseModel):
-        __root__: dict[str, str] | None
+    class OptionalDict(RootModel[Any]):
+        root: dict[str, str] | None
 
     assert get_dict_value_type(DictOfMapsStorage) == int | dict[str, str]
     with pytest.raises(IntrospectionError):
         get_dict_value_type(OptionalDict)
 
     with pytest.raises(IntrospectionError):
         get_dict_value_type(SomethingElse)
@@ -104,44 +107,44 @@
     assert get_dict_value_type(Storage, 'list_str') == list[str]
     assert get_dict_value_type(Storage, 'dict_of_lists') == dict[str, list[str]]
     assert get_dict_value_type(Storage, 'optional_str') == str | None
     assert get_dict_value_type(Storage, 'union_arg') == str | int
 
 
 def test_is_array() -> None:
-    class ListOfMapsStorage(BaseModel):
-        __root__: list[int | dict[str, str]]
+    class ListOfMapsStorage(RootModel[Any]):
+        root: list[int | dict[str, str]]
 
-    class OptionalList(BaseModel):
-        __root__: list[str] | None
+    class OptionalList(RootModel[Any]):
+        root: list[str] | None
 
     assert is_array_type(list[str]) is True
     assert is_array_type(ListOfMapsStorage) is True
     assert is_array_type(OptionalList) is False
 
 
 def test_simple_union_unwrap() -> None:
     assert unwrap_union_type(str | None) == (True, (str, NoneType))  # type: ignore[arg-type]
     assert unwrap_union_type(int | str) == (True, (int, str))  # type: ignore[arg-type]
 
 
 def test_pydantic_optional_unwrap() -> None:
-    class UnionIntStr(BaseModel):
-        __root__: int | str
+    class UnionIntStr(RootModel[Any]):
+        root: int | str
 
-    class OptionalStr(BaseModel):
-        __root__: str | None
+    class OptionalStr(RootModel[Any]):
+        root: str | None
 
     assert unwrap_union_type(OptionalStr) == (True, (str, NoneType))
     assert unwrap_union_type(UnionIntStr) == (True, (int, str))
 
 
 def test_root_type_extraction() -> None:
-    class OptionalStr(BaseModel):
-        __root__: str | None
+    class OptionalStr(RootModel[Any]):
+        root: str | None
 
-    class ListOfMapsStorage(BaseModel):
-        __root__: list[int | dict[str, str]]
+    class ListOfMapsStorage(RootModel[Any]):
+        root: list[int | dict[str, str]]
 
     assert extract_root_outer_type(OptionalStr) == str | None
-    # FIXME: left operand type: "Type[BaseModel]", right operand type: "Type[List[Any]]"
+    # FIXME: left operand type: "Type[BaseModel]", right operand type: "Type[list[Any]]"
     assert extract_root_outer_type(ListOfMapsStorage) == list[int | dict[str, str]]  # type: ignore[comparison-overlap]
```

### Comparing `dipdup-7.5.7/tests/test_models.py` & `dipdup-8.0.0a1/tests/test_models.py`

 * *Files 7% similar despite different names*

```diff
@@ -2,16 +2,16 @@
 
 from datetime import datetime
 from pathlib import Path
 from typing import Any
 
 import orjson as json
 
-from dipdup.indexes.tezos_tzkt_operations.parser import deserialize_storage
-from dipdup.models.tezos_tzkt import TzktOperationData
+from dipdup.indexes.tezos_operations.parser import deserialize_storage
+from dipdup.models.tezos import TezosOperationData
 from tests.types.asdf.storage import AsdfStorage
 from tests.types.bazaar.storage import BazaarMarketPlaceStorage
 from tests.types.ftzfun.storage import FtzFunStorage
 from tests.types.hen_subjkt.storage import HenSubjktStorage
 from tests.types.hjkl.storage import HjklStorage
 from tests.types.kolibri_ovens.set_delegate import SetDelegateParameter
 from tests.types.kolibri_ovens.storage import KolibriOvensStorage
@@ -19,16 +19,16 @@
 from tests.types.qwer.storage import QwerStorage
 from tests.types.rewq.storage import RewqStorage
 from tests.types.tezotop.storage import ResourceCollectorStorage
 from tests.types.yupana.storage import YupanaStorage
 from tests.types.zxcv.storage import ZxcvStorage
 
 
-def get_operation_data(storage: Any, diffs: tuple[dict[str, Any], ...]) -> TzktOperationData:
-    return TzktOperationData(
+def get_operation_data(storage: Any, diffs: tuple[dict[str, Any], ...]) -> TezosOperationData:
+    return TezosOperationData(
         storage=storage,
         diffs=diffs,
         type='transaction',
         id=0,
         level=0,
         timestamp=datetime.now(),
         hash='',
@@ -97,16 +97,16 @@
     operation_data = get_operation_data(storage, diffs)
 
     # Act
     _, storage_obj = deserialize_storage(operation_data, BazaarMarketPlaceStorage)
 
     # Assert
     assert isinstance(storage_obj, BazaarMarketPlaceStorage)
-    assert isinstance(storage_obj.__root__, list)
-    assert storage_obj.__root__[0].key.sale_seller == 'tz1QX6eLPYbRcakYbiUy7i8krXEgc5XL3Lhb'
+    assert isinstance(storage_obj.root, list)
+    assert storage_obj.root[0].key.sale_seller == 'tz1QX6eLPYbRcakYbiUy7i8krXEgc5XL3Lhb'
 
 
 def test_deserialize_storage_list_of_maps() -> None:
     # Arrange
     storage = [164576, 164577, 164578]
     diffs = (
         {'bigmap': 164578, 'path': '2', 'action': 'allocate'},
@@ -146,99 +146,99 @@
     operation_data = get_operation_data(storage, diffs)
 
     # Act
     _, storage_obj = deserialize_storage(operation_data, ListOfMapsStorage)
 
     # Assert
     assert isinstance(storage_obj, ListOfMapsStorage)
-    assert isinstance(storage_obj.__root__, list)
-    assert storage_obj.__root__[1]['test'] == '123'
+    assert isinstance(storage_obj.root, list)
+    assert storage_obj.root[1]['test'] == '123'
 
 
 def test_convert_operation_with_default_entrypoint() -> None:
     # Arrange
     json_path = Path(__file__).parent / 'responses' / 'ooQuCAKBHkmWy2VciDAV9c6CFTywuMLupLzVoKDwS1xvR4EdRng.json'
     operations_json = json.loads(json_path.read_bytes())
 
     # Act
-    operations = [TzktOperationData.from_json(op) for op in operations_json]
+    operations = [TezosOperationData.from_json(op) for op in operations_json]
 
     # Assert
     assert operations[0].entrypoint == 'default'
     assert operations[0].parameter_json == {}
     assert operations[1].entrypoint == 'deposit'
     assert operations[1].parameter_json != {}
 
 
 def test_deserialize_storage_dict_key() -> None:
     # Arrange
     json_path = Path(__file__).parent / 'responses' / 'ftzfun.json'
     operations_json = json.loads(json_path.read_bytes())
 
     # Act
-    operations = [TzktOperationData.from_json(op) for op in operations_json]
+    operations = [TezosOperationData.from_json(op) for op in operations_json]
     _, storage_obj = deserialize_storage(operations[0], FtzFunStorage)
 
     # Assert
     assert isinstance(storage_obj, FtzFunStorage)
     assert isinstance(storage_obj.assets.operators, list)
     assert storage_obj.assets.operators[0].key.address_0 == 'tz1fMia93yL7vndY2fZ5rGAQPgex7RQHXV1m'
     assert storage_obj.assets.operators[0].value == {}
 
 
 def test_qwer() -> None:
     json_path = Path(__file__).parent / 'responses' / 'qwer.json'
     operations_json = json.loads(json_path.read_bytes())
 
     # Act
-    operations = [TzktOperationData.from_json(op) for op in operations_json]
+    operations = [TezosOperationData.from_json(op) for op in operations_json]
     _, storage_obj = deserialize_storage(operations[0], QwerStorage)
 
     # Assert
     assert isinstance(storage_obj, QwerStorage)
-    assert isinstance(storage_obj.__root__, list)
-    assert storage_obj.__root__[0][1].R['1'] == '1'  # type: ignore[union-attr]
-    assert storage_obj.__root__[0][1].R['2'] == '2'  # type: ignore[union-attr]
+    assert isinstance(storage_obj.root, list)
+    assert storage_obj.root[0][1].R['1'] == '1'  # type: ignore[union-attr]
+    assert storage_obj.root[0][1].R['2'] == '2'  # type: ignore[union-attr]
 
 
 def test_asdf() -> None:
     json_path = Path(__file__).parent / 'responses' / 'asdf.json'
     operations_json = json.loads(json_path.read_bytes())
 
     # Act
-    operations = [TzktOperationData.from_json(op) for op in operations_json]
+    operations = [TezosOperationData.from_json(op) for op in operations_json]
     _, storage_obj = deserialize_storage(operations[0], AsdfStorage)
 
     # Assert
     assert isinstance(storage_obj, AsdfStorage)
-    assert isinstance(storage_obj.__root__, list)
-    assert isinstance(storage_obj.__root__[0]['pupa'], list)
+    assert isinstance(storage_obj.root, list)
+    assert isinstance(storage_obj.root[0]['pupa'], list)
 
 
 def test_hjkl() -> None:
     json_path = Path(__file__).parent / 'responses' / 'hjkl.json'
     operations_json = json.loads(json_path.read_bytes())
 
     # Act
-    operations = [TzktOperationData.from_json(op) for op in operations_json]
+    operations = [TezosOperationData.from_json(op) for op in operations_json]
     _, storage_obj = deserialize_storage(operations[0], HjklStorage)
 
     # Assert
     assert isinstance(storage_obj, HjklStorage)
-    assert isinstance(storage_obj.__root__, list)
-    assert isinstance(storage_obj.__root__[0].value.mr, dict)
-    assert storage_obj.__root__[0].value.mr['111'] is True
+    assert isinstance(storage_obj.root, list)
+    assert isinstance(storage_obj.root[0].value.mr, dict)
+    assert storage_obj.root[0].value.mr['111'] is True
 
 
 def test_zxcv() -> None:
     json_path = Path(__file__).parent / 'responses' / 'zxcv.json'
     operations_json = json.loads(json_path.read_bytes())
 
     # Act
-    operations = [TzktOperationData.from_json(op) for op in operations_json]
+    operations = [TezosOperationData.from_json(op) for op in operations_json]
     _, storage_obj = deserialize_storage(operations[0], ZxcvStorage)
 
     # Assert
     assert isinstance(storage_obj, ZxcvStorage)
     assert isinstance(storage_obj.big_map, dict)
     assert storage_obj.big_map['111'].L == '222'  # type: ignore[union-attr]
     assert storage_obj.map['happy'].R == 'new year'  # type: ignore[union-attr]
@@ -248,15 +248,15 @@
 
 
 def test_rewq() -> None:
     json_path = Path(__file__).parent / 'responses' / 'rewq.json'
     operations_json = json.loads(json_path.read_bytes())
 
     # Act
-    operations = [TzktOperationData.from_json(op) for op in operations_json]
+    operations = [TezosOperationData.from_json(op) for op in operations_json]
     _, storage_obj = deserialize_storage(operations[0], RewqStorage)
 
     # Assert
     assert isinstance(storage_obj, RewqStorage)
     assert isinstance(storage_obj.map, dict)
     assert isinstance(storage_obj.map['try'].L, dict)  # type: ignore[union-attr]
     assert storage_obj.map['try'].L['111'] == '222'  # type: ignore[union-attr]
@@ -265,44 +265,44 @@
 
 
 def test_hen_subjkt() -> None:
     json_path = Path(__file__).parent / 'responses' / 'hen_subjkt.json'
     operations_json = json.loads(json_path.read_bytes())
 
     # Act
-    operations = [TzktOperationData.from_json(op) for op in operations_json]
+    operations = [TezosOperationData.from_json(op) for op in operations_json]
     _, storage_obj = deserialize_storage(operations[0], HenSubjktStorage)
 
     # Assert
     assert isinstance(storage_obj, HenSubjktStorage)
     assert isinstance(storage_obj.entries, dict)
     assert storage_obj.entries['tz1Y1j7FK1X9Rrv2VdPz5bXoU7SszF8W1RnK'] is True
 
 
 def test_kolibri_ovens() -> None:
     json_path = Path(__file__).parent / 'responses' / 'kolibri_ovens.json'
     operations_json = json.loads(json_path.read_bytes())
 
     # Act
-    operations = [TzktOperationData.from_json(op) for op in operations_json]
+    operations = [TezosOperationData.from_json(op) for op in operations_json]
     _, storage_obj = deserialize_storage(operations[0], KolibriOvensStorage)
-    parameter_obj = SetDelegateParameter.parse_obj(operations[0].parameter_json)
+    parameter_obj = SetDelegateParameter.model_validate(operations[0].parameter_json)
 
     # Assert
     assert isinstance(storage_obj, KolibriOvensStorage)
     assert isinstance(parameter_obj, SetDelegateParameter)
-    assert parameter_obj.__root__ is None
+    assert parameter_obj.root is None
 
 
 def test_yupana() -> None:
     json_path = Path(__file__).parent / 'responses' / 'yupana.json'
     operations_json = json.loads(json_path.read_bytes())
 
     # Act
-    operations = [TzktOperationData.from_json(op) for op in operations_json]
+    operations = [TezosOperationData.from_json(op) for op in operations_json]
     _, storage_obj = deserialize_storage(operations[0], YupanaStorage)
 
     # Assert
     assert isinstance(storage_obj, YupanaStorage)
     assert isinstance(storage_obj.storage.markets, dict)
     assert storage_obj.storage.markets['tz1MDhGTfMQjtMYFXeasKzRWzkQKPtXEkSEw'] == ['0']
 
@@ -310,10 +310,10 @@
 def _load_response(name: str) -> Any:
     path = Path(__file__).parent / 'responses' / name
     return json.loads(path.read_bytes())
 
 
 def test_origination_amount() -> None:
     operations_json = _load_response('origination_amount.json')
-    operation = TzktOperationData.from_json(operations_json[0])
+    operation = TezosOperationData.from_json(operations_json[0])
 
     assert operation.amount == 31000000
```

### Comparing `dipdup-7.5.7/tests/test_rollback.py` & `dipdup-8.0.0a1/tests/test_rollback.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 from contextlib import AsyncExitStack
 from datetime import datetime
 
-import demo_domains.models as domains_models
-import demo_nft_marketplace.models as hen_models
+import demo_tezos_domains.models as domains_models
+import demo_tezos_nft_marketplace.models as hen_models
 from tortoise.expressions import F
 
 from dipdup.config import DipDupConfig
 from dipdup.context import HookContext
 from dipdup.models import Index
 from dipdup.models import IndexType
 from dipdup.models import ModelUpdate
 from dipdup.models import ModelUpdateAction
 from dipdup.test import create_dummy_dipdup
 
 
 async def test_model_updates() -> None:
-    config = DipDupConfig(spec_version='2.0', package='demo_nft_marketplace')
+    config = DipDupConfig(spec_version='3.0', package='demo_tezos_nft_marketplace')
     config.advanced.rollback_depth = 2
 
     async with AsyncExitStack() as stack:
         dipdup = await create_dummy_dipdup(config, stack)
         in_transaction = dipdup._transactions.in_transaction
 
         # NOTE: INSERT
@@ -124,15 +124,15 @@
         swaps = await hen_models.Swap.filter().count()
         assert swaps == 0
         model_updates = await ModelUpdate.filter().count()
         assert model_updates == 0
 
 
 async def test_cleanup_and_filtering() -> None:
-    config = DipDupConfig(spec_version='2.0', package='demo_nft_marketplace')
+    config = DipDupConfig(spec_version='3.0', package='demo_tezos_nft_marketplace')
     config.advanced.rollback_depth = 2
 
     async with AsyncExitStack() as stack:
         dipdup = await create_dummy_dipdup(config, stack)
         in_transaction = dipdup._transactions.in_transaction
 
         # NOTE: Filter less than `rollback_depth` (which is 2 by default)
@@ -144,27 +144,27 @@
 
         model_update_levels = await ModelUpdate.filter().values_list('level', flat=True)
         assert model_update_levels == [998, 999, 1000, 1001, 1002, 1003, 1004]  # type: ignore[comparison-overlap]
 
         # NOTE: Cleanup
         index = Index(
             name='test',
-            type=IndexType.tezos_tzkt_operations,
+            type=IndexType.tezos_operations,
             config_hash='',
             level=1005,
         )
         await index.save()
         await dipdup._transactions.cleanup()
 
         model_update_levels = await ModelUpdate.filter().values_list('level', flat=True)
         assert model_update_levels == [1003, 1004]  # type: ignore[comparison-overlap]
 
 
 async def test_optionals() -> None:
-    config = DipDupConfig(spec_version='2.0', package='demo_domains')
+    config = DipDupConfig(spec_version='3.0', package='demo_tezos_domains')
     config.advanced.rollback_depth = 2
 
     async with AsyncExitStack() as stack:
         dipdup = await create_dummy_dipdup(config, stack)
         in_transaction = dipdup._transactions.in_transaction
 
         # NOTE: INSERT and DELETE model with optionals
@@ -197,15 +197,15 @@
         # assert domain.tld_id == tld.id
         # assert domain.expiry is None
         assert domain.owner == 'test'
         assert domain.token_id is None
 
 
 async def test_bulk_create_update() -> None:
-    config = DipDupConfig(spec_version='2.0', package='demo_domains')
+    config = DipDupConfig(spec_version='3.0', package='demo_tezos_domains')
     config.advanced.rollback_depth = 2
 
     async with AsyncExitStack() as stack:
         dipdup = await create_dummy_dipdup(config, stack)
         in_transaction = dipdup._transactions.in_transaction
 
         tlds: list[domains_models.TLD] = []
@@ -280,15 +280,15 @@
         assert token_ids == []
 
         model_updates = await ModelUpdate.filter().count()
         assert model_updates == 0
 
 
 async def test_update_prefetch() -> None:
-    config = DipDupConfig(spec_version='2.0', package='demo_domains')
+    config = DipDupConfig(spec_version='3.0', package='demo_tezos_domains')
     config.advanced.rollback_depth = 2
 
     async with AsyncExitStack() as stack:
         dipdup = await create_dummy_dipdup(config, stack)
         in_transaction = dipdup._transactions.in_transaction
 
         # NOTE: INSERT
@@ -331,15 +331,15 @@
         assert owners == ['test'] * 3  # type: ignore[comparison-overlap]
 
         model_updates = await ModelUpdate.filter().count()
         assert model_updates == 3
 
 
 async def test_update_arithmetics() -> None:
-    config = DipDupConfig(spec_version='2.0', package='demo_nft_marketplace')
+    config = DipDupConfig(spec_version='3.0', package='demo_tezos_nft_marketplace')
     config.advanced.rollback_depth = 2
 
     async with AsyncExitStack() as stack:
         dipdup = await create_dummy_dipdup(config, stack)
         in_transaction = dipdup._transactions.in_transaction
 
         # NOTE: INSERT
```

### Comparing `dipdup-7.5.7/tests/test_schema.py` & `dipdup-8.0.0a1/tests/test_schema.py`

 * *Files 5% similar despite different names*

```diff
@@ -18,15 +18,15 @@
     'dipdup_head',
     'dipdup_index',
     'dipdup_meta',
 }
 
 
 async def test_schema_sqlite() -> None:
-    package = 'demo_domains'
+    package = 'demo_tezos_domains'
     config_path = TEST_CONFIGS / f'{package}.yml'
     env_config_path = TEST_CONFIGS / 'test_sqlite.yaml'
 
     async with AsyncExitStack() as stack:
         tmp_package_path, env = await stack.enter_async_context(
             tmp_project(
                 [config_path, env_config_path],
@@ -64,15 +64,15 @@
 
         async with tortoise():
             conn = get_connection()
             assert await get_tables() == set()
 
 
 async def test_schema_sqlite_immune() -> None:
-    package = 'demo_domains'
+    package = 'demo_tezos_domains'
     config_path = TEST_CONFIGS / f'{package}.yml'
     env_config_path = TEST_CONFIGS / 'test_sqlite_immune.yaml'
 
     async with AsyncExitStack() as stack:
         tmp_package_path, env = await stack.enter_async_context(
             tmp_project(
                 [config_path, env_config_path],
@@ -110,30 +110,29 @@
 
         async with tortoise():
             conn = get_connection()
             assert await get_tables() == {'dipdup_meta', 'test', 'domain', 'tld'}
 
 
 async def test_schema_postgres() -> None:
-    package = 'demo_domains'
+    package = 'demo_tezos_domains'
     config_path = TEST_CONFIGS / f'{package}.yml'
     env_config_path = TEST_CONFIGS / 'test_postgres.yaml'
 
     async with AsyncExitStack() as stack:
+        database_config = await run_postgres_container()
         tmp_package_path, env = await stack.enter_async_context(
             tmp_project(
                 [config_path, env_config_path],
                 package,
                 exists=True,
+                env={'POSTGRES_HOST': database_config.host},
             ),
         )
 
-        database_config = await run_postgres_container()
-        env['POSTGRES_HOST'] = database_config.host
-
         def tortoise() -> AbstractAsyncContextManager[None]:
             return tortoise_wrapper(
                 database_config.connection_string,
                 f'{package}.models',
             )
 
         async with tortoise():
@@ -152,30 +151,29 @@
 
         async with tortoise():
             conn = get_connection()
             assert await get_tables() == {'dipdup_meta'}
 
 
 async def test_schema_postgres_immune() -> None:
-    package = 'demo_domains'
+    package = 'demo_tezos_domains'
     config_path = TEST_CONFIGS / f'{package}.yml'
     env_config_path = TEST_CONFIGS / 'test_postgres_immune.yaml'
 
     async with AsyncExitStack() as stack:
+        database_config = await run_postgres_container()
         tmp_package_path, env = await stack.enter_async_context(
             tmp_project(
                 [config_path, env_config_path],
                 package,
                 exists=True,
+                env={'POSTGRES_HOST': database_config.host},
             ),
         )
 
-        database_config = await run_postgres_container()
-        env['POSTGRES_HOST'] = database_config.host
-
         def tortoise() -> AbstractAsyncContextManager[None]:
             return tortoise_wrapper(
                 database_config.connection_string,
                 f'{package}.models',
             )
 
         async with tortoise():
```

### Comparing `dipdup-7.5.7/tests/test_utils.py` & `dipdup-8.0.0a1/tests/test_utils.py`

 * *Files 18% similar despite different names*

```diff
@@ -23,35 +23,35 @@
 
 async def test_in_global_transaction() -> None:
     transactions = TransactionManager()
     async with tortoise_wrapper('sqlite://:memory:'):
         await Tortoise.generate_schemas()
 
         # 1. Success query without transaction
-        await Index(name='1', type=IndexType.tezos_tzkt_operations, config_hash='').save()
+        await Index(name='1', type=IndexType.tezos_operations, config_hash='').save()
         count = await Index.filter().count()
         assert count == 1
 
         # 2. Success query within transaction
         async with transactions.in_transaction():
-            await Index(name='2', type=IndexType.tezos_tzkt_operations, config_hash='').save()
+            await Index(name='2', type=IndexType.tezos_operations, config_hash='').save()
         count = await Index.filter().count()
         assert count == 2
 
         # 3. Not rolled back query without transaction
         with suppress(SomeException):
-            await Index(name='3', type=IndexType.tezos_tzkt_operations, config_hash='').save()
+            await Index(name='3', type=IndexType.tezos_operations, config_hash='').save()
             raise SomeException
         count = await Index.filter().count()
         assert count == 3
 
         # 4. Rolled back query within transaction
         with suppress(SomeException):
             async with transactions.in_transaction():
-                await Index(name='4', type=IndexType.tezos_tzkt_operations, config_hash='').save()
+                await Index(name='4', type=IndexType.tezos_operations, config_hash='').save()
                 raise SomeException
         count = await Index.filter().count()
         assert count == 3
 
 
 async def test_humps_helpers() -> None:
     assert pascal_to_snake('foo_bar', True) == 'foo_bar'
@@ -68,32 +68,32 @@
     assert snake_to_pascal('FooBar') == 'FooBar'
     assert snake_to_pascal('foobar') == 'Foobar'
     assert snake_to_pascal('foo__bar') == 'FooBar'
     assert snake_to_pascal('FOOBAR') == 'Foobar'
 
 
 async def test_iter_models() -> None:
-    models = list(iter_models('demo_token'))
+    models = list(iter_models('demo_tezos_token'))
     assert len(models) == 9
     assert models[0][0] == 'int_models'
     assert models[-1][0] == 'models'
 
 
 async def test_import_submodules() -> None:
     with raises(FrameworkException):
-        import_submodules('demo_token')
+        import_submodules('demo_tezos_token')
 
-    submodules = import_submodules('demo_token.handlers')
+    submodules = import_submodules('demo_tezos_token.handlers')
     assert len(submodules) == 3
 
 
 async def test_parse_object() -> None:
     # empty
     empty = parse_object(SetDelegateParameter, None)
-    assert empty.__root__ is None
+    assert empty.root is None
     # string only
     str_ = parse_object(SetDelegateParameter, 'some')
-    assert str_.__root__ == 'some'
+    assert str_.root == 'some'
     # map
     map_ = parse_object(QwerStorage, [[{'R': {'a': 'b'}}, {'R': {}}], [{'L': 'test'}]])
-    assert isinstance(map_.__root__[0][0], QwerStorageItem1)
-    assert map_.__root__[0][0].R['a'] == 'b'
+    assert isinstance(map_.root[0][0], QwerStorageItem1)
+    assert map_.root[0][0].R['a'] == 'b'
```

### Comparing `dipdup-7.5.7/tests/types/tezotop/storage.py` & `dipdup-8.0.0a1/tests/types/tezotop/storage.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,27 +1,25 @@
 # generated by datamodel-codegen:
 #   filename:  storage.json
 
 from __future__ import annotations
 
 from pydantic import BaseModel
-from pydantic import Extra
+from pydantic import ConfigDict
 
 
 class ResourceMap(BaseModel):
-    class Config:
-        extra = Extra.forbid
+    model_config = ConfigDict(extra='forbid')
 
     id: str
     rate: str
 
 
 class ResourceCollectorStorage(BaseModel):
-    class Config:
-        extra = Extra.forbid
+    model_config = ConfigDict(extra='forbid')
 
     administrator: str
     current_user: str | None
     default_start_time: str
     generation_rate: str
     managers: list[str]
     metadata: dict[str, str]
```

### Comparing `dipdup-7.5.7/PKG-INFO` & `dipdup-8.0.0a1/PKG-INFO`

 * *Files 7% similar despite different names*

```diff
@@ -1,62 +1,60 @@
 Metadata-Version: 2.1
 Name: dipdup
-Version: 7.5.7
+Version: 8.0.0a1
 Summary: Modular framework for creating selective indexers and featureful backends for dapps
 Keywords: api,backend,blockchain,crypto,cryptocurrencies,dapp,declarative,ethereum,evm,framework,indexer,indexers,michelson,scheduler,sdk,smart-contracts,tezos,tzkt,web3
 Author-Email: Lev Gorodetskii <dipdup@drsr.io>, Vladimir Bobrikov <vladimir_bobrikov@pm.me>, Michael Zaikin <mz@baking-bad.org>
 Maintainer-Email: Lev Gorodetskii <dipdup@drsr.io>, Vladimir Bobrikov <vladimir_bobrikov@pm.me>
 License: MIT
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Environment :: Console
 Classifier: Intended Audience :: Developers
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Operating System :: OS Independent
 Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.11
+Classifier: Programming Language :: Python :: 3.12
 Classifier: Programming Language :: Python :: Implementation :: CPython
 Classifier: Topic :: Software Development :: Libraries :: Application Frameworks
 Classifier: Typing :: Typed
 Project-URL: Homepage, https://dipdup.io/
 Project-URL: Documentation, https://dipdup.io/docs
 Project-URL: Repository, https://github.com/dipdup-io/dipdup
-Requires-Python: <3.12,>=3.11
-Requires-Dist: asyncpg~=0.29.0
+Requires-Python: <3.13,>=3.12
 Requires-Dist: datamodel-code-generator~=0.25.0
-Requires-Dist: pydantic~=1.10.11
-Requires-Dist: tortoise-orm==0.19.3
-Requires-Dist: aiohttp~=3.8
+Requires-Dist: pyarrow~=16.0
+Requires-Dist: pydantic~=2.2
+Requires-Dist: sentry-sdk~=2.0
+Requires-Dist: tortoise-orm==0.20.1
+Requires-Dist: web3~=6.18
+Requires-Dist: aiohttp~=3.9
 Requires-Dist: aiolimiter~=1.0
 Requires-Dist: anyio>=4.1.0
 Requires-Dist: APScheduler~=3.8
 Requires-Dist: async-lru~=2.0
 Requires-Dist: asyncclick~=8.0
+Requires-Dist: asyncpg~=0.29
 Requires-Dist: eth-abi<6,>=5.0.1
-Requires-Dist: lru-dict~=1.3.0
 Requires-Dist: orjson~=3.9
 Requires-Dist: prometheus-client~=0.17
-Requires-Dist: pyarrow<15,>=14.0.1
 Requires-Dist: pycryptodome~=3.17
 Requires-Dist: pyhumps~=3.0
 Requires-Dist: pysignalr~=1.0
 Requires-Dist: python-dotenv~=1.0
 Requires-Dist: ruamel.yaml~=0.17
-Requires-Dist: sentry-sdk~=1.29
-Requires-Dist: setuptools>=68.1.2
 Requires-Dist: sqlparse~=0.4
 Requires-Dist: strict-rfc3339~=0.7
-Requires-Dist: survey~=4.4
+Requires-Dist: survey~=5.3
 Requires-Dist: tabulate~=0.9
-Requires-Dist: web3~=6.2
 Description-Content-Type: text/markdown
 
 [![Twitter](https://badgen.net/badge/icon/dipdup_io?icon=twitter&label=)](https://twitter.com/dipdup_io)
+[![Monthly downloads](https://static.pepy.tech/badge/dipdup/month)](https://pepy.tech/project/dipdup)
 [![GitHub stars](https://img.shields.io/github/stars/dipdup-io/dipdup?color=2c2c2c&style=plain)](https://github.com/dipdup-io/dipdup)
-[![PyPI monthly downloads](https://img.shields.io/pypi/dm/dipdup?color=2c2c2c)](https://pypi.org/project/dipdup/)
-[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/dipdup?color=2c2c2c)](https://www.python.org)
+[![Python Version](https://img.shields.io/pypi/pyversions/dipdup?color=2c2c2c)](https://www.python.org)
 [![License: MIT](https://img.shields.io/github/license/dipdup-io/dipdup?color=2c2c2c)](https://github.com/dipdup-io/dipdup/blob/next/LICENSE)
 <br>
 [![Latest stable release](https://img.shields.io/github/v/release/dipdup-io/dipdup?label=stable%20release&color=2c2c2c)](https://github.com/dipdup-io/dipdup/releases)
 [![Latest pre-release](https://img.shields.io/github/v/release/dipdup-io/dipdup?include_prereleases&label=latest%20release&color=2c2c2c)](https://github.com/dipdup-io/dipdup/releases)
 [![GitHub issues](https://img.shields.io/github/issues/dipdup-io/dipdup?color=2c2c2c)](https://github.com/dipdup-io/dipdup/issues)
 [![GitHub pull requests](https://img.shields.io/github/issues-pr/dipdup-io/dipdup?color=2c2c2c)](https://github.com/dipdup-io/dipdup/pulls)
```

