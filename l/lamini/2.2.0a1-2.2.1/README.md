# Comparing `tmp/lamini-2.2.0a1-124-py3-none-any.whl.zip` & `tmp/lamini-2.2.1-126-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,59 +1,59 @@
-Zip file size: 690663 bytes, number of entries: 57
--rw-r--r--  2.0 unx     1420 b- defN 24-May-16 22:24 lamini/__init__.py
--rw-r--r--  2.0 unx     2200 b- defN 24-May-16 22:24 lamini/api/classifier.py
--rw-r--r--  2.0 unx     1129 b- defN 24-May-16 22:24 lamini/api/embedding.py
--rw-r--r--  2.0 unx    13018 b- defN 24-May-16 22:24 lamini/api/lamini.py
--rw-r--r--  2.0 unx     2369 b- defN 24-May-16 22:24 lamini/api/lamini_config.py
--rw-r--r--  2.0 unx     2404 b- defN 24-May-16 22:24 lamini/api/precise_trainer.py
--rw-r--r--  2.0 unx     6208 b- defN 24-May-16 22:24 lamini/api/rest_requests.py
--rw-r--r--  2.0 unx     6827 b- defN 24-May-16 22:24 lamini/api/streaming_completion.py
--rw-r--r--  2.0 unx     1547 b- defN 24-May-16 22:24 lamini/api/synchronize.py
--rw-r--r--  2.0 unx     6999 b- defN 24-May-16 22:24 lamini/api/train.py
--rw-r--r--  2.0 unx     4605 b- defN 24-May-16 22:24 lamini/api/utils/async_inference_queue.py
--rw-r--r--  2.0 unx     5930 b- defN 24-May-16 22:24 lamini/api/utils/async_inference_queue_3_10.py
--rw-r--r--  2.0 unx     1494 b- defN 24-May-16 22:24 lamini/api/utils/base_async_inference_queue.py
--rw-r--r--  2.0 unx     1343 b- defN 24-May-16 22:24 lamini/api/utils/completion.py
--rw-r--r--  2.0 unx     2865 b- defN 24-May-16 22:24 lamini/api/utils/process_batch.py
--rw-r--r--  2.0 unx     5959 b- defN 24-May-16 22:24 lamini/api/utils/reservations.py
--rw-r--r--  2.0 unx      413 b- defN 24-May-16 22:24 lamini/api/utils/shutdown.py
--rw-r--r--  2.0 unx     1394 b- defN 24-May-16 22:24 lamini/api/utils/upload_client.py
--rw-r--r--  2.0 unx    24599 b- defN 24-May-16 22:24 lamini/classify/lamini_classifier.py
--rw-r--r--  2.0 unx      896 b- defN 24-May-16 22:24 lamini/error/error.py
--rw-r--r--  2.0 unx     2906 b- defN 24-May-16 22:24 lamini/evaluators/benchmark.py
--rw-r--r--  2.0 unx     2820 b- defN 24-May-16 22:24 lamini/evaluators/custom/custom_evaluator.py
--rw-r--r--  2.0 unx     9671 b- defN 24-May-16 22:24 lamini/evaluators/custom/earnings_call_evaluator.py
--rw-r--r--  2.0 unx     9770 b- defN 24-May-16 22:24 lamini/evaluators/custom/ecommerce_evaluator.py
--rw-r--r--  2.0 unx     9121 b- defN 24-May-16 22:24 lamini/evaluators/custom/icd_evaluator.py
--rw-r--r--  2.0 unx  1298418 b- defN 24-May-16 22:24 lamini/evaluators/custom/datasets/earnings_calls.jsonl
--rw-r--r--  2.0 unx  5527615 b- defN 24-May-16 22:24 lamini/evaluators/custom/datasets/icd11.jsonl
--rw-r--r--  2.0 unx   732222 b- defN 24-May-16 22:24 lamini/evaluators/custom/datasets/shopping.jsonl
--rw-r--r--  2.0 unx     5413 b- defN 24-May-16 22:24 lamini/evaluators/helm/harness_evaluator.py
--rw-r--r--  2.0 unx      775 b- defN 24-May-16 22:24 lamini/evaluators/helm/mmlu_evaluator.py
--rw-r--r--  2.0 unx      861 b- defN 24-May-16 22:24 lamini/evaluators/helm/truthfulqa_evaluator.py
--rw-r--r--  2.0 unx     2441 b- defN 24-May-16 22:24 lamini/evaluators/utils/utils.py
--rw-r--r--  2.0 unx     1273 b- defN 24-May-16 22:24 lamini/generation/base_generation_queue.py
--rw-r--r--  2.0 unx      594 b- defN 24-May-16 22:24 lamini/generation/base_node_object.py
--rw-r--r--  2.0 unx      797 b- defN 24-May-16 22:24 lamini/generation/base_prompt_object.py
--rw-r--r--  2.0 unx     2154 b- defN 24-May-16 22:24 lamini/generation/classifier_node.py
--rw-r--r--  2.0 unx     1418 b- defN 24-May-16 22:24 lamini/generation/embedding_node.py
--rw-r--r--  2.0 unx     5104 b- defN 24-May-16 22:24 lamini/generation/generation_node.py
--rw-r--r--  2.0 unx     3868 b- defN 24-May-16 22:24 lamini/generation/generation_pipeline.py
--rw-r--r--  2.0 unx     6615 b- defN 24-May-16 22:24 lamini/generation/generation_queue_3_10.py
--rw-r--r--  2.0 unx     2014 b- defN 24-May-16 22:24 lamini/generation/index_node.py
--rw-r--r--  2.0 unx      965 b- defN 24-May-16 22:24 lamini/generation/modify_node.py
--rw-r--r--  2.0 unx     3454 b- defN 24-May-16 22:24 lamini/generation/process_generation_batch.py
--rw-r--r--  2.0 unx     1390 b- defN 24-May-16 22:24 lamini/generation/split_response_node.py
--rw-r--r--  2.0 unx      557 b- defN 24-May-16 22:24 lamini/generation/token_optimizer.py
--rw-r--r--  2.0 unx     3413 b- defN 24-May-16 22:24 lamini/index/lamini_index.py
--rw-r--r--  2.0 unx     9354 b- defN 24-May-16 22:24 lamini/runners/base_runner.py
--rw-r--r--  2.0 unx      720 b- defN 24-May-16 22:24 lamini/runners/basic_model_runner.py
--rw-r--r--  2.0 unx     3068 b- defN 24-May-16 22:24 lamini/runners/llama_v2_runner.py
--rw-r--r--  2.0 unx     3203 b- defN 24-May-16 22:24 lamini/runners/llama_v3_runner.py
--rw-r--r--  2.0 unx     2625 b- defN 24-May-16 22:24 lamini/runners/mistral_runner.py
--rw-r--r--  2.0 unx       21 b- defN 24-May-16 22:24 llama/__init__.py
--rw-r--r--  2.0 unx    11340 b- defN 24-May-16 22:24 lamini-2.2.0a1.dist-info/LICENSE
--rw-r--r--  2.0 unx     1509 b- defN 24-May-16 22:24 lamini-2.2.0a1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-May-16 22:24 lamini-2.2.0a1.dist-info/WHEEL
--rw-r--r--  2.0 unx       13 b- defN 24-May-16 22:24 lamini-2.2.0a1.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     5167 b- defN 24-May-16 22:24 lamini-2.2.0a1.dist-info/RECORD
-57 files, 7766380 bytes uncompressed, 682357 bytes compressed:  91.2%
+Zip file size: 690896 bytes, number of entries: 57
+-rw-r--r--  2.0 unx     1420 b- defN 24-May-31 03:44 lamini/__init__.py
+-rw-r--r--  2.0 unx     2200 b- defN 24-May-31 03:43 lamini/api/classifier.py
+-rw-r--r--  2.0 unx     1129 b- defN 24-May-31 03:43 lamini/api/embedding.py
+-rw-r--r--  2.0 unx    13018 b- defN 24-May-31 03:43 lamini/api/lamini.py
+-rw-r--r--  2.0 unx     2369 b- defN 24-May-31 03:43 lamini/api/lamini_config.py
+-rw-r--r--  2.0 unx     2403 b- defN 24-May-31 03:43 lamini/api/memory_trainer.py
+-rw-r--r--  2.0 unx     6208 b- defN 24-May-31 03:43 lamini/api/rest_requests.py
+-rw-r--r--  2.0 unx     7672 b- defN 24-May-31 03:43 lamini/api/streaming_completion.py
+-rw-r--r--  2.0 unx     1547 b- defN 24-May-31 03:43 lamini/api/synchronize.py
+-rw-r--r--  2.0 unx     6999 b- defN 24-May-31 03:43 lamini/api/train.py
+-rw-r--r--  2.0 unx     4605 b- defN 24-May-31 03:43 lamini/api/utils/async_inference_queue.py
+-rw-r--r--  2.0 unx     6197 b- defN 24-May-31 03:43 lamini/api/utils/async_inference_queue_3_10.py
+-rw-r--r--  2.0 unx     1494 b- defN 24-May-31 03:43 lamini/api/utils/base_async_inference_queue.py
+-rw-r--r--  2.0 unx     1343 b- defN 24-May-31 03:43 lamini/api/utils/completion.py
+-rw-r--r--  2.0 unx     2865 b- defN 24-May-31 03:43 lamini/api/utils/process_batch.py
+-rw-r--r--  2.0 unx     6531 b- defN 24-May-31 03:43 lamini/api/utils/reservations.py
+-rw-r--r--  2.0 unx      413 b- defN 24-May-31 03:43 lamini/api/utils/shutdown.py
+-rw-r--r--  2.0 unx     1394 b- defN 24-May-31 03:43 lamini/api/utils/upload_client.py
+-rw-r--r--  2.0 unx    24599 b- defN 24-May-31 03:43 lamini/classify/lamini_classifier.py
+-rw-r--r--  2.0 unx      896 b- defN 24-May-31 03:43 lamini/error/error.py
+-rw-r--r--  2.0 unx     2906 b- defN 24-May-31 03:43 lamini/evaluators/benchmark.py
+-rw-r--r--  2.0 unx     2820 b- defN 24-May-31 03:43 lamini/evaluators/custom/custom_evaluator.py
+-rw-r--r--  2.0 unx     9671 b- defN 24-May-31 03:43 lamini/evaluators/custom/earnings_call_evaluator.py
+-rw-r--r--  2.0 unx     9770 b- defN 24-May-31 03:43 lamini/evaluators/custom/ecommerce_evaluator.py
+-rw-r--r--  2.0 unx     9121 b- defN 24-May-31 03:43 lamini/evaluators/custom/icd_evaluator.py
+-rw-r--r--  2.0 unx  1298418 b- defN 24-May-31 03:43 lamini/evaluators/custom/datasets/earnings_calls.jsonl
+-rw-r--r--  2.0 unx  5527615 b- defN 24-May-31 03:43 lamini/evaluators/custom/datasets/icd11.jsonl
+-rw-r--r--  2.0 unx   732222 b- defN 24-May-31 03:43 lamini/evaluators/custom/datasets/shopping.jsonl
+-rw-r--r--  2.0 unx     5413 b- defN 24-May-31 03:43 lamini/evaluators/helm/harness_evaluator.py
+-rw-r--r--  2.0 unx      775 b- defN 24-May-31 03:43 lamini/evaluators/helm/mmlu_evaluator.py
+-rw-r--r--  2.0 unx      861 b- defN 24-May-31 03:43 lamini/evaluators/helm/truthfulqa_evaluator.py
+-rw-r--r--  2.0 unx     2441 b- defN 24-May-31 03:43 lamini/evaluators/utils/utils.py
+-rw-r--r--  2.0 unx     1273 b- defN 24-May-31 03:43 lamini/generation/base_generation_queue.py
+-rw-r--r--  2.0 unx      594 b- defN 24-May-31 03:43 lamini/generation/base_node_object.py
+-rw-r--r--  2.0 unx      797 b- defN 24-May-31 03:43 lamini/generation/base_prompt_object.py
+-rw-r--r--  2.0 unx     2154 b- defN 24-May-31 03:43 lamini/generation/classifier_node.py
+-rw-r--r--  2.0 unx     1418 b- defN 24-May-31 03:43 lamini/generation/embedding_node.py
+-rw-r--r--  2.0 unx     5104 b- defN 24-May-31 03:43 lamini/generation/generation_node.py
+-rw-r--r--  2.0 unx     3868 b- defN 24-May-31 03:43 lamini/generation/generation_pipeline.py
+-rw-r--r--  2.0 unx     6615 b- defN 24-May-31 03:43 lamini/generation/generation_queue_3_10.py
+-rw-r--r--  2.0 unx     2014 b- defN 24-May-31 03:43 lamini/generation/index_node.py
+-rw-r--r--  2.0 unx      965 b- defN 24-May-31 03:43 lamini/generation/modify_node.py
+-rw-r--r--  2.0 unx     3454 b- defN 24-May-31 03:43 lamini/generation/process_generation_batch.py
+-rw-r--r--  2.0 unx     1390 b- defN 24-May-31 03:43 lamini/generation/split_response_node.py
+-rw-r--r--  2.0 unx      557 b- defN 24-May-31 03:43 lamini/generation/token_optimizer.py
+-rw-r--r--  2.0 unx     3413 b- defN 24-May-31 03:43 lamini/index/lamini_index.py
+-rw-r--r--  2.0 unx     9354 b- defN 24-May-31 03:43 lamini/runners/base_runner.py
+-rw-r--r--  2.0 unx      720 b- defN 24-May-31 03:43 lamini/runners/basic_model_runner.py
+-rw-r--r--  2.0 unx     3068 b- defN 24-May-31 03:43 lamini/runners/llama_v2_runner.py
+-rw-r--r--  2.0 unx     3203 b- defN 24-May-31 03:43 lamini/runners/llama_v3_runner.py
+-rw-r--r--  2.0 unx     2625 b- defN 24-May-31 03:43 lamini/runners/mistral_runner.py
+-rw-r--r--  2.0 unx       21 b- defN 24-May-31 03:43 llama/__init__.py
+-rw-r--r--  2.0 unx    11340 b- defN 24-May-31 03:44 lamini-2.2.1.dist-info/LICENSE
+-rw-r--r--  2.0 unx     1507 b- defN 24-May-31 03:44 lamini-2.2.1.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-May-31 03:44 lamini-2.2.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx       13 b- defN 24-May-31 03:44 lamini-2.2.1.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     5156 b- defN 24-May-31 03:44 lamini-2.2.1.dist-info/RECORD
+57 files, 7768050 bytes uncompressed, 682612 bytes compressed:  91.2%
```

## zipnote {}

```diff
@@ -9,15 +9,15 @@
 
 Filename: lamini/api/lamini.py
 Comment: 
 
 Filename: lamini/api/lamini_config.py
 Comment: 
 
-Filename: lamini/api/precise_trainer.py
+Filename: lamini/api/memory_trainer.py
 Comment: 
 
 Filename: lamini/api/rest_requests.py
 Comment: 
 
 Filename: lamini/api/streaming_completion.py
 Comment: 
@@ -150,23 +150,23 @@
 
 Filename: lamini/runners/mistral_runner.py
 Comment: 
 
 Filename: llama/__init__.py
 Comment: 
 
-Filename: lamini-2.2.0a1.dist-info/LICENSE
+Filename: lamini-2.2.1.dist-info/LICENSE
 Comment: 
 
-Filename: lamini-2.2.0a1.dist-info/METADATA
+Filename: lamini-2.2.1.dist-info/METADATA
 Comment: 
 
-Filename: lamini-2.2.0a1.dist-info/WHEEL
+Filename: lamini-2.2.1.dist-info/WHEEL
 Comment: 
 
-Filename: lamini-2.2.0a1.dist-info/top_level.txt
+Filename: lamini-2.2.1.dist-info/top_level.txt
 Comment: 
 
-Filename: lamini-2.2.0a1.dist-info/RECORD
+Filename: lamini-2.2.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## lamini/api/streaming_completion.py

```diff
@@ -5,77 +5,102 @@
 import aiohttp
 import lamini
 from lamini.api.lamini_config import get_config, get_configured_key, get_configured_url
 from lamini.api.rest_requests import make_async_web_request, make_web_request
 
 
 class StreamingCompletionObject:
-    def __init__(self, request_params, api_url, api_key, polling_interval):
+    def __init__(
+        self, request_params, api_url, api_key, polling_interval, max_errors=0
+    ):
         self.request_params = request_params
         self.api_url = api_url
         self.api_key = api_key
         self.done_streaming = False
         self.server = None
         self.polling_interval = polling_interval
+        self.current_result = None
+        self.error_count = 0
+        self.max_errors = max_errors
 
     def __iter__(self):
         return self
 
     def __next__(self):
         return self.next()
 
     def next(self):
         if self.done_streaming:
             raise StopIteration()
         time.sleep(self.polling_interval)
         if self.server is not None:
             self.request_params["server"] = self.server
-        resp = make_web_request(
-            self.api_key,
-            self.api_url,
-            "post",
-            self.request_params,
-        )
-        self.server = resp["server"]
-        if resp["status"][0]:
-            self.done_streaming = True
-        return resp["data"][0]
+        try:
+            resp = make_web_request(
+                self.api_key,
+                self.api_url,
+                "post",
+                self.request_params,
+            )
+
+            self.server = resp["server"]
+            if resp["status"][0]:
+                self.done_streaming = True
+            self.current_result = resp["data"][0]
+        except Exception as e:
+            self.error_count += 1
+            if self.error_count > self.max_errors:
+                raise e
+        return self.current_result
 
 
 class AsyncStreamingCompletionObject:
-    def __init__(self, request_params, api_url, api_key, polling_interval):
+    def __init__(
+        self, request_params, api_url, api_key, polling_interval, max_errors=5
+    ):
         self.request_params = request_params
         self.api_url = api_url
         self.api_key = api_key
         self.done_streaming = False
         self.server = None
         self.polling_interval = polling_interval
+        self.current_result = None
+        self.error_count = 0
+        self.max_errors = max_errors
 
     def __aiter__(self):
         return self
 
     async def __anext__(self):
         return await self.next()
 
     async def next(self):
         if self.done_streaming:
             raise StopAsyncIteration()
         await asyncio.sleep(self.polling_interval)
-        async with aiohttp.ClientSession() as client:
-            resp = await make_async_web_request(
-                client,
-                self.api_key,
-                self.api_url,
-                "post",
-                self.request_params,
-            )
-        self.server = resp["server"]
-        if resp["status"][0]:
-            self.done_streaming = True
-        return resp["data"][0]
+        if self.server is not None:
+            self.request_params["server"] = self.server
+        try:
+            async with aiohttp.ClientSession() as client:
+                resp = await make_async_web_request(
+                    client,
+                    self.api_key,
+                    self.api_url,
+                    "post",
+                    self.request_params,
+                )
+            self.server = resp["server"]
+            if resp["status"][0]:
+                self.done_streaming = True
+            self.current_result = resp["data"][0]
+        except Exception as e:
+            self.error_count += 1
+            if self.error_count > self.max_errors:
+                raise e
+        return self.current_result
 
 
 class StreamingCompletion:
     def __init__(
         self,
         api_key: str = None,
         api_url: str = None,
```

## lamini/api/utils/async_inference_queue_3_10.py

```diff
@@ -96,17 +96,17 @@
         key,
         api_prefix,
         local_cache_file,
         local_cache,
         callback,
         metadata,
     ):
-        batch_size = self.get_batch_size()
         assert isinstance(request["prompt"], list)
-        async for i in arange(0, len(request["prompt"]), batch_size):
+        batch_size_func = self.reservation_api.get_dynamic_max_batch_size
+        async for i, batch_size in arange_w_step_func(0, len(request["prompt"]), batch_size_func):
             batch = request.copy()
             end = min(i + batch_size, len(request["prompt"]))
             batch["prompt"] = request["prompt"][i:end]
             metadata_batch = None
             if metadata is not None:
                 metadata_batch = metadata[i:end]
             yield {
@@ -174,7 +174,15 @@
     if stop:
         range_ = range(start, stop, step)
     else:
         range_ = range(start)
     for i in range_:
         yield i
         await asyncio.sleep(0)
+
+async def arange_w_step_func(start, stop, step_func):
+    i = start
+    while i < stop:
+        batch_size = step_func()
+        yield (i, batch_size)
+        i += batch_size
+        await asyncio.sleep(0)
```

## lamini/api/utils/reservations.py

```diff
@@ -31,14 +31,15 @@
         self.config = get_config(config)
         self.api_key = api_key or lamini.api_key or get_configured_key(self.config)
         self.api_url = api_url or lamini.api_url or get_configured_url(self.config)
         self.api_prefix = self.api_url + "/v1/reservation"
         self.current_reservation = None
         self.capacity_remaining = 0
         self.capacity_needed = 0
+        self.dynamic_max_batch_size = 0
         self.condition = asyncio.Condition()
         self.is_working = False
         self.polling_task = None
         self.poll_for_reservation = asyncio.Event()
         self.is_polling = False
 
     def initialize_reservation(
@@ -60,25 +61,29 @@
                     "capacity": max(capacity, batch_size),
                     "model_name": model_name,
                     "max_tokens": max_tokens,
                     "batch_size": batch_size,
                 },
             )
             logger.info("Made reservation " + str(reservation))
+            if "dynamic_max_batch_size" not in reservation:
+                reservation["dynamic_max_batch_size"] = batch_size
             self.current_reservation = reservation
             self.capacity_needed = capacity
             self.model_name = model_name
             self.max_tokens = max_tokens
             self.capacity_remaining = reservation["capacity_remaining"]
+            self.dynamic_max_batch_size = reservation["dynamic_max_batch_size"]
             self.is_working = True
             self.batch_size = batch_size
         except Exception as e:
             logger.warning(f"Error making reservation, continuing without one. {e}")
             self.current_reservation = None
             self.capacity_remaining = 0
+            self.dynamic_max_batch_size = 0
             self.capacity_needed = 0
             self.model_name = model_name
             self.max_tokens = None
 
     def pause_for_reservation_start(self):
         if self.current_reservation is None:
             return
@@ -103,16 +108,19 @@
                 "capacity": max(self.capacity_needed, self.batch_size),
                 "model_name": self.model_name,
                 "max_tokens": self.max_tokens,
                 "batch_size": self.batch_size,
             },
         )
         logger.info("Made reservation " + str(reservation))
+        if "dynamic_max_batch_size" not in reservation:
+            reservation["dynamic_max_batch_size"] = batch_size
         self.current_reservation = reservation
         self.capacity_remaining = reservation["capacity_remaining"]
+        self.dynamic_max_batch_size = reservation["dynamic_max_batch_size"]
         async with self.condition:
             self.condition.notify(len(self.condition._waiters))
         self.is_polling = False
         if self.is_working:
             self.polling_task = asyncio.create_task(
                 self.kickoff_reservation_polling(client)
             )
@@ -158,7 +166,10 @@
         if self.current_reservation is None:
             return
         self.capacity_needed -= queries
 
     def __del__(self):
         if self.polling_task is not None:
             self.polling_task.cancel()
+
+    def get_dynamic_max_batch_size(self):
+        return self.dynamic_max_batch_size
```

## Comparing `lamini/api/precise_trainer.py` & `lamini/api/memory_trainer.py`

 * *Files 1% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 from lamini.api.lamini import Lamini
 from lamini.api.lamini_config import get_config
 from lamini.api.train import Train
 
 logger = logging.getLogger(__name__)
 
 
-class PreciseTrainer:
+class MemoryTrainer:
     def __init__(
         self,
         model_name: str,
         api_key: Optional[str] = None,
         api_url: Optional[str] = None,
         local_cache_file: Optional[str] = None,
         config: dict = {},
```

## Comparing `lamini-2.2.0a1.dist-info/LICENSE` & `lamini-2.2.1.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `lamini-2.2.0a1.dist-info/METADATA` & `lamini-2.2.1.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: lamini
-Version: 2.2.0a1
+Version: 2.2.1
 Summary: Build on large language models faster
 Author-email: PowerML <info@powerml.co>
 Classifier: Programming Language :: Python :: 3
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Operating System :: OS Independent
 Requires-Python: >=3.7
 Description-Content-Type: text/markdown
```

## Comparing `lamini-2.2.0a1.dist-info/RECORD` & `lamini-2.2.1.dist-info/RECORD`

 * *Files 6% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 lamini/__init__.py,sha256=Sx_94ell5ny8qL40VBM22omxf5u49-YjGR_eMAt3d8Y,1420
 lamini/api/classifier.py,sha256=Xv8EwtyLD4n5M5N7tW33wmKFBhXI5OV6uMT7DYqxBX4,2200
 lamini/api/embedding.py,sha256=jbfbNmS7jyBYO_Nylp3kw7L-Zb0GrZa1owoRAtgFmNY,1129
 lamini/api/lamini.py,sha256=o7BcUXF1zgWgx62IsimKxxG0ryUqhx3GmwYGmaMb3ik,13018
 lamini/api/lamini_config.py,sha256=LcPqdlaMAdoahFNlH1ig1NYfMK_z0nQMneafhcZWuu4,2369
-lamini/api/precise_trainer.py,sha256=-30qzyw7AAcnU8QhQo1iaU8YQrGDuFdWXGhBHhT3ffc,2404
+lamini/api/memory_trainer.py,sha256=2cwPQCxPOmepoHKHMxWc9u4KM3V8NUJfldmEZ0MjdLU,2403
 lamini/api/rest_requests.py,sha256=i1nIcAOrtE4zvs0le4mPz37NUq1_Hrty4f5zl0D446w,6208
-lamini/api/streaming_completion.py,sha256=cSiU80XgOj1p9nOPh6j_N-z8T9Zp1CM6yZN4R7hncCA,6827
+lamini/api/streaming_completion.py,sha256=iwRsZ1VC6eEjlPbbC1-_S-P8Dt7Z8A_MBuU-NIBi0lU,7672
 lamini/api/synchronize.py,sha256=Uo6-lQToa-42zVdQ4Qlefvf0Mi3i2He_W1S9yciMMNk,1547
 lamini/api/train.py,sha256=t6tN7pC88iWQIc_lPwsrBTAgnsmHigo-DtyvFiaJz-U,6999
 lamini/api/utils/async_inference_queue.py,sha256=M-7RMyMIFcMS47Z2l9-8W05SafuJnnYiQvLUTgWWfdw,4605
-lamini/api/utils/async_inference_queue_3_10.py,sha256=Itmn1E9bfotiVmnO-k1dznAP87sY-EKRUC-zuZkkLtQ,5930
+lamini/api/utils/async_inference_queue_3_10.py,sha256=ZTp5IpJLIbwld9r0hVeRBfs1GP0M0LAZ299V62qkxn0,6197
 lamini/api/utils/base_async_inference_queue.py,sha256=4JvyjGSQfxcSAvV5hQ2-VqbN_1diqLW_nJzNUsEXXnU,1494
 lamini/api/utils/completion.py,sha256=37vn81fvpGR7HMuGQy1Cwz2ozIj0aZQTcxHzXl-cVpI,1343
 lamini/api/utils/process_batch.py,sha256=nNWu80NSeYig_MoO1GQs_JOiJMQgpts0F5Y-xQMDmG8,2865
-lamini/api/utils/reservations.py,sha256=yXnGPM1eQXgzRdQ1rjtoHMSxn4DhDPetxJfPl5221_4,5959
+lamini/api/utils/reservations.py,sha256=zixkqFAR8v8h3OA7x5uXcHjhvLQ_XgVBzg743WmvT4s,6531
 lamini/api/utils/shutdown.py,sha256=oznFdh3JsE3CDH4Fx30c8_pVGBlIF0iPlFCFpoTE4iU,413
 lamini/api/utils/upload_client.py,sha256=nTossvV58LSVvdny1iuTO6PPomE3HlPxjt2_xkmw0V8,1394
 lamini/classify/lamini_classifier.py,sha256=HW6yRQxjcApX2DeG4EAgZSR1t3ucgbXd1tlb65qYV18,24599
 lamini/error/error.py,sha256=C4SbfG3obNYGH8onkUkhUc61XRTwejCBlsG1QBNaEQI,896
 lamini/evaluators/benchmark.py,sha256=sXEmTgEKMvKng-4FjEZZB_AFKd5__KQSalKvdB_qFQs,2906
 lamini/evaluators/custom/custom_evaluator.py,sha256=XvNSIznP_3gNN7sbXOryOCWor7I7tO3Tsy6bOgJRpGA,2820
 lamini/evaluators/custom/earnings_call_evaluator.py,sha256=S_mE6X5UgpXKm97DnfhcnYkmVA3BfmVqDBAgsfnAq-w,9671
@@ -46,12 +46,12 @@
 lamini/index/lamini_index.py,sha256=Hdc3pNxdGHwz10hUlR9frBluDBOe9l45_nS9UnIR6vk,3413
 lamini/runners/base_runner.py,sha256=VYPlMdx2sR9BLXrO_jsyp-p0_3IQUXwPkVta8g6xFPE,9354
 lamini/runners/basic_model_runner.py,sha256=7e4xTotKGdmC0PH-ynAlOtXxHDvhH8HInqWCggG5DOA,720
 lamini/runners/llama_v2_runner.py,sha256=UWzd4P2zV0qSC9Id72CqH68vGF9w69y48ldx0-mJSFY,3068
 lamini/runners/llama_v3_runner.py,sha256=negM9Eiv6qnrWH_knEf6FHVWW6HF6eWED2eBqNp21Hc,3203
 lamini/runners/mistral_runner.py,sha256=q-MhkotBc1Y9y57Uym9k4ONBkGn9mRBLhJue3M9uMd8,2625
 llama/__init__.py,sha256=E77xncFEWyRrg-MsjkiLrCkNJBIYIxr111hLd7WpgjY,21
-lamini-2.2.0a1.dist-info/LICENSE,sha256=-alRIf0b5B1SavU0njHUTAanPUn6GHxH9a2Q_ACz1HM,11340
-lamini-2.2.0a1.dist-info/METADATA,sha256=SdsCJcgYg4ohrtif_8YDTeZb36yzDbbE1fD-p38MjFo,1509
-lamini-2.2.0a1.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-lamini-2.2.0a1.dist-info/top_level.txt,sha256=5h0-n2aeXxQUxmNPPJ0AnsKIBAZV_qWqU0JIpA6Q2zo,13
-lamini-2.2.0a1.dist-info/RECORD,,
+lamini-2.2.1.dist-info/LICENSE,sha256=-alRIf0b5B1SavU0njHUTAanPUn6GHxH9a2Q_ACz1HM,11340
+lamini-2.2.1.dist-info/METADATA,sha256=i_qbkBOscDCZHFCxPmfHPT16vq4RUOXZgddCB_6Z9iE,1507
+lamini-2.2.1.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+lamini-2.2.1.dist-info/top_level.txt,sha256=5h0-n2aeXxQUxmNPPJ0AnsKIBAZV_qWqU0JIpA6Q2zo,13
+lamini-2.2.1.dist-info/RECORD,,
```

