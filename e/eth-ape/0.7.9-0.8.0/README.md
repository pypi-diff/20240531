# Comparing `tmp/eth-ape-0.7.9.tar.gz` & `tmp/eth-ape-0.8.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "eth-ape-0.7.9.tar", last modified: Fri Feb 16 18:36:13 2024, max compression
+gzip compressed data, was "eth-ape-0.8.0.tar", last modified: Fri May 31 16:37:47 2024, max compression
```

## Comparing `eth-ape-0.7.9.tar` & `eth-ape-0.8.0.tar`

### file list

```diff
@@ -1,505 +1,526 @@
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.702334 eth-ape-0.7.9/
--rw-r--r--   0 runner    (1001) docker     (127)       25 2024-02-16 18:35:07.000000 eth-ape-0.7.9/.dockerignore
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.634333 eth-ape-0.7.9/.github/
--rw-r--r--   0 runner    (1001) docker     (127)       16 2024-02-16 18:35:07.000000 eth-ape-0.7.9/.github/FUNDING.yml
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.638333 eth-ape-0.7.9/.github/ISSUE_TEMPLATE/
--rw-r--r--   0 runner    (1001) docker     (127)      907 2024-02-16 18:35:07.000000 eth-ape-0.7.9/.github/ISSUE_TEMPLATE/bug.md
--rw-r--r--   0 runner    (1001) docker     (127)      676 2024-02-16 18:35:07.000000 eth-ape-0.7.9/.github/ISSUE_TEMPLATE/feature.md
--rw-r--r--   0 runner    (1001) docker     (127)     1254 2024-02-16 18:35:07.000000 eth-ape-0.7.9/.github/ISSUE_TEMPLATE/work-item.md
--rw-r--r--   0 runner    (1001) docker     (127)      526 2024-02-16 18:35:07.000000 eth-ape-0.7.9/.github/PULL_REQUEST_TEMPLATE.md
--rw-r--r--   0 runner    (1001) docker     (127)      677 2024-02-16 18:35:07.000000 eth-ape-0.7.9/.github/release-drafter.yml
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.638333 eth-ape-0.7.9/.github/workflows/
--rw-r--r--   0 runner    (1001) docker     (127)      618 2024-02-16 18:35:07.000000 eth-ape-0.7.9/.github/workflows/codeql.yml
--rw-r--r--   0 runner    (1001) docker     (127)      703 2024-02-16 18:35:07.000000 eth-ape-0.7.9/.github/workflows/commitlint.yaml
--rw-r--r--   0 runner    (1001) docker     (127)     1709 2024-02-16 18:35:07.000000 eth-ape-0.7.9/.github/workflows/docs.yaml
--rw-r--r--   0 runner    (1001) docker     (127)      366 2024-02-16 18:35:07.000000 eth-ape-0.7.9/.github/workflows/draft.yaml
--rw-r--r--   0 runner    (1001) docker     (127)      630 2024-02-16 18:35:07.000000 eth-ape-0.7.9/.github/workflows/prtitle.yaml
--rw-r--r--   0 runner    (1001) docker     (127)      605 2024-02-16 18:35:07.000000 eth-ape-0.7.9/.github/workflows/publish.yaml
--rw-r--r--   0 runner    (1001) docker     (127)      709 2024-02-16 18:35:07.000000 eth-ape-0.7.9/.github/workflows/stale-prs.yml
--rw-r--r--   0 runner    (1001) docker     (127)     2869 2024-02-16 18:35:07.000000 eth-ape-0.7.9/.github/workflows/test.yaml
--rw-r--r--   0 runner    (1001) docker     (127)     2121 2024-02-16 18:35:07.000000 eth-ape-0.7.9/.gitignore
--rw-r--r--   0 runner    (1001) docker     (127)      976 2024-02-16 18:35:07.000000 eth-ape-0.7.9/.pre-commit-config.yaml
--rw-r--r--   0 runner    (1001) docker     (127)     2807 2024-02-16 18:35:07.000000 eth-ape-0.7.9/CONTRIBUTING.md
--rw-r--r--   0 runner    (1001) docker     (127)     1761 2024-02-16 18:35:07.000000 eth-ape-0.7.9/Dockerfile
--rw-r--r--   0 runner    (1001) docker     (127)    11342 2024-02-16 18:35:07.000000 eth-ape-0.7.9/LICENSE
--rw-r--r--   0 runner    (1001) docker     (127)     6562 2024-02-16 18:36:13.702334 eth-ape-0.7.9/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (127)     5312 2024-02-16 18:35:07.000000 eth-ape-0.7.9/README.md
--rw-r--r--   0 runner    (1001) docker     (127)     3807 2024-02-16 18:35:07.000000 eth-ape-0.7.9/SECURITY.md
--rw-r--r--   0 runner    (1001) docker     (127)     2515 2024-02-16 18:35:07.000000 eth-ape-0.7.9/build_docs.py
--rw-r--r--   0 runner    (1001) docker     (127)       83 2024-02-16 18:35:07.000000 eth-ape-0.7.9/codeql-config.yml
--rw-r--r--   0 runner    (1001) docker     (127)       23 2024-02-16 18:35:07.000000 eth-ape-0.7.9/cz-requirement.txt
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.638333 eth-ape-0.7.9/docs/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.638333 eth-ape-0.7.9/docs/_static/
--rw-r--r--   0 runner    (1001) docker     (127)     5434 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/_static/custom.css
--rw-r--r--   0 runner    (1001) docker     (127)     1032 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/_static/custom.js
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.638333 eth-ape-0.7.9/docs/_templates/
--rw-r--r--   0 runner    (1001) docker     (127)    10136 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/_templates/layout.html
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.638333 eth-ape-0.7.9/docs/commands/
--rw-r--r--   0 runner    (1001) docker     (127)       67 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/commands/accounts.rst
--rw-r--r--   0 runner    (1001) docker     (127)       65 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/commands/compile.rst
--rw-r--r--   0 runner    (1001) docker     (127)       82 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/commands/console.rst
--rw-r--r--   0 runner    (1001) docker     (127)       59 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/commands/init.rst
--rw-r--r--   0 runner    (1001) docker     (127)       67 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/commands/networks.rst
--rw-r--r--   0 runner    (1001) docker     (127)       65 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/commands/plugins.rst
--rw-r--r--   0 runner    (1001) docker     (127)       55 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/commands/pm.rst
--rw-r--r--   0 runner    (1001) docker     (127)       66 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/commands/run.rst
--rw-r--r--   0 runner    (1001) docker     (127)       59 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/commands/test.rst
--rw-r--r--   0 runner    (1001) docker     (127)     4063 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/conf.py
--rw-r--r--   0 runner    (1001) docker     (127)    20915 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/favicon.ico
--rw-r--r--   0 runner    (1001) docker     (127)     1171 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/index.md
--rw-r--r--   0 runner    (1001) docker     (127)    11889 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/logo.gif
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.642333 eth-ape-0.7.9/docs/methoddocs/
--rw-r--r--   0 runner    (1001) docker     (127)       59 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/methoddocs/ape.md
--rw-r--r--   0 runner    (1001) docker     (127)       77 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/methoddocs/ape_accounts.md
--rw-r--r--   0 runner    (1001) docker     (127)     1335 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/methoddocs/api.md
--rw-r--r--   0 runner    (1001) docker     (127)      775 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/methoddocs/cli.md
--rw-r--r--   0 runner    (1001) docker     (127)      533 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/methoddocs/contracts.md
--rw-r--r--   0 runner    (1001) docker     (127)      104 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/methoddocs/exceptions.md
--rw-r--r--   0 runner    (1001) docker     (127)     1656 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/methoddocs/managers.md
--rw-r--r--   0 runner    (1001) docker     (127)      933 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/methoddocs/plugins.md
--rw-r--r--   0 runner    (1001) docker     (127)      767 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/methoddocs/types.md
--rw-r--r--   0 runner    (1001) docker     (127)      152 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/methoddocs/utils.md
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.642333 eth-ape-0.7.9/docs/userguides/
--rw-r--r--   0 runner    (1001) docker     (127)    13356 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/userguides/accounts.md
--rw-r--r--   0 runner    (1001) docker     (127)     7891 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/userguides/clis.md
--rw-r--r--   0 runner    (1001) docker     (127)     3957 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/userguides/compile.md
--rw-r--r--   0 runner    (1001) docker     (127)     4670 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/userguides/config.md
--rw-r--r--   0 runner    (1001) docker     (127)     5938 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/userguides/console.md
--rw-r--r--   0 runner    (1001) docker     (127)    15143 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/userguides/contracts.md
--rw-r--r--   0 runner    (1001) docker     (127)     2579 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/userguides/data.md
--rw-r--r--   0 runner    (1001) docker     (127)     8606 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/userguides/dependencies.md
--rw-r--r--   0 runner    (1001) docker     (127)     6944 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/userguides/developing_plugins.md
--rw-r--r--   0 runner    (1001) docker     (127)     2156 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/userguides/forking_networks.md
--rw-r--r--   0 runner    (1001) docker     (127)     2845 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/userguides/installing_plugins.md
--rw-r--r--   0 runner    (1001) docker     (127)     1791 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/userguides/logging.md
--rw-r--r--   0 runner    (1001) docker     (127)    21467 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/userguides/networks.md
--rw-r--r--   0 runner    (1001) docker     (127)     2988 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/userguides/projects.md
--rw-r--r--   0 runner    (1001) docker     (127)     1740 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/userguides/proxy.md
--rw-r--r--   0 runner    (1001) docker     (127)     2131 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/userguides/publishing.md
--rw-r--r--   0 runner    (1001) docker     (127)       33 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/userguides/quickstart.md
--rw-r--r--   0 runner    (1001) docker     (127)     5273 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/userguides/scripts.md
--rw-r--r--   0 runner    (1001) docker     (127)    24402 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/userguides/testing.md
--rw-r--r--   0 runner    (1001) docker     (127)    20438 2024-02-16 18:35:07.000000 eth-ape-0.7.9/docs/userguides/transactions.md
--rw-r--r--   0 runner    (1001) docker     (127)     1482 2024-02-16 18:35:07.000000 eth-ape-0.7.9/pyproject.toml
--rw-r--r--   0 runner    (1001) docker     (127)      116 2024-02-16 18:35:07.000000 eth-ape-0.7.9/recommended-plugins.txt
--rw-r--r--   0 runner    (1001) docker     (127)      284 2024-02-16 18:36:13.702334 eth-ape-0.7.9/setup.cfg
--rw-r--r--   0 runner    (1001) docker     (127)     6648 2024-02-16 18:35:07.000000 eth-ape-0.7.9/setup.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.626333 eth-ape-0.7.9/src/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.646334 eth-ape-0.7.9/src/ape/
--rw-r--r--   0 runner    (1001) docker     (127)     1902 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      240 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/__modules__.py
--rw-r--r--   0 runner    (1001) docker     (127)     5084 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/_cli.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.646334 eth-ape-0.7.9/src/ape/api/
--rw-r--r--   0 runner    (1001) docker     (127)     1313 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/api/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    21114 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/api/accounts.py
--rw-r--r--   0 runner    (1001) docker     (127)     6436 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/api/address.py
--rw-r--r--   0 runner    (1001) docker     (127)     9832 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/api/compiler.py
--rw-r--r--   0 runner    (1001) docker     (127)     2515 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/api/config.py
--rw-r--r--   0 runner    (1001) docker     (127)      904 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/api/convert.py
--rw-r--r--   0 runner    (1001) docker     (127)     1668 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/api/explorers.py
--rw-r--r--   0 runner    (1001) docker     (127)    42700 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/api/networks.py
--rw-r--r--   0 runner    (1001) docker     (127)    24000 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/api/projects.py
--rw-r--r--   0 runner    (1001) docker     (127)    37100 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/api/providers.py
--rw-r--r--   0 runner    (1001) docker     (127)     7327 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/api/query.py
--rw-r--r--   0 runner    (1001) docker     (127)    18509 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/api/transactions.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.646334 eth-ape-0.7.9/src/ape/cli/
--rw-r--r--   0 runner    (1001) docker     (127)     1362 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/cli/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     2151 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/cli/arguments.py
--rw-r--r--   0 runner    (1001) docker     (127)    14037 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/cli/choices.py
--rw-r--r--   0 runner    (1001) docker     (127)     5292 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/cli/commands.py
--rw-r--r--   0 runner    (1001) docker     (127)    15315 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/cli/options.py
--rw-r--r--   0 runner    (1001) docker     (127)      967 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/cli/paramtype.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.650334 eth-ape-0.7.9/src/ape/contracts/
--rw-r--r--   0 runner    (1001) docker     (127)      230 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/contracts/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    54839 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/contracts/base.py
--rw-r--r--   0 runner    (1001) docker     (127)    24678 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/exceptions.py
--rw-r--r--   0 runner    (1001) docker     (127)       79 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/harambe.py
--rw-r--r--   0 runner    (1001) docker     (127)     9177 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/logging.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.650334 eth-ape-0.7.9/src/ape/managers/
--rw-r--r--   0 runner    (1001) docker     (127)     1417 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/managers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    13084 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/managers/accounts.py
--rw-r--r--   0 runner    (1001) docker     (127)      590 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/managers/base.py
--rw-r--r--   0 runner    (1001) docker     (127)    60131 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/managers/chain.py
--rw-r--r--   0 runner    (1001) docker     (127)    15063 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/managers/compilers.py
--rw-r--r--   0 runner    (1001) docker     (127)    14225 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/managers/config.py
--rw-r--r--   0 runner    (1001) docker     (127)    13523 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/managers/converters.py
--rw-r--r--   0 runner    (1001) docker     (127)    24833 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/managers/networks.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.650334 eth-ape-0.7.9/src/ape/managers/project/
--rw-r--r--   0 runner    (1001) docker     (127)      400 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/managers/project/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    16071 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/managers/project/dependency.py
--rw-r--r--   0 runner    (1001) docker     (127)    30887 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/managers/project/manager.py
--rw-r--r--   0 runner    (1001) docker     (127)    14298 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/managers/project/types.py
--rw-r--r--   0 runner    (1001) docker     (127)     8136 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/managers/query.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.650334 eth-ape-0.7.9/src/ape/plugins/
--rw-r--r--   0 runner    (1001) docker     (127)     8694 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/plugins/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    21574 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/plugins/_utils.py
--rw-r--r--   0 runner    (1001) docker     (127)     1000 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/plugins/account.py
--rw-r--r--   0 runner    (1001) docker     (127)      916 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/plugins/compiler.py
--rw-r--r--   0 runner    (1001) docker     (127)     1035 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/plugins/config.py
--rw-r--r--   0 runner    (1001) docker     (127)      816 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/plugins/converter.py
--rw-r--r--   0 runner    (1001) docker     (127)     3512 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/plugins/network.py
--rw-r--r--   0 runner    (1001) docker     (127)      752 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/plugins/pluggy_patch.py
--rw-r--r--   0 runner    (1001) docker     (127)     1542 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/plugins/project.py
--rw-r--r--   0 runner    (1001) docker     (127)      662 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/plugins/query.py
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/py.typed
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.654333 eth-ape-0.7.9/src/ape/pytest/
--rw-r--r--   0 runner    (1001) docker     (127)      550 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/pytest/README.md
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/pytest/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     3253 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/pytest/config.py
--rw-r--r--   0 runner    (1001) docker     (127)     6913 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/pytest/contextmanagers.py
--rw-r--r--   0 runner    (1001) docker     (127)    11959 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/pytest/coverage.py
--rw-r--r--   0 runner    (1001) docker     (127)     8150 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/pytest/fixtures.py
--rw-r--r--   0 runner    (1001) docker     (127)     2075 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/pytest/gas.py
--rw-r--r--   0 runner    (1001) docker     (127)     4691 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/pytest/plugin.py
--rw-r--r--   0 runner    (1001) docker     (127)    10701 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/pytest/runners.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.654333 eth-ape-0.7.9/src/ape/types/
--rw-r--r--   0 runner    (1001) docker     (127)    15819 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/types/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     1431 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/types/address.py
--rw-r--r--   0 runner    (1001) docker     (127)    36424 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/types/coverage.py
--rw-r--r--   0 runner    (1001) docker     (127)     3656 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/types/signatures.py
--rw-r--r--   0 runner    (1001) docker     (127)    23239 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/types/trace.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.654333 eth-ape-0.7.9/src/ape/utils/
--rw-r--r--   0 runner    (1001) docker     (127)     3051 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    17895 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/utils/abi.py
--rw-r--r--   0 runner    (1001) docker     (127)    13223 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/utils/basemodel.py
--rw-r--r--   0 runner    (1001) docker     (127)     7971 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/utils/github.py
--rw-r--r--   0 runner    (1001) docker     (127)    15158 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/utils/misc.py
--rw-r--r--   0 runner    (1001) docker     (127)     4173 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/utils/os.py
--rw-r--r--   0 runner    (1001) docker     (127)     1198 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/utils/process.py
--rw-r--r--   0 runner    (1001) docker     (127)     2244 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/utils/testing.py
--rw-r--r--   0 runner    (1001) docker     (127)    14564 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/utils/trace.py
--rw-r--r--   0 runner    (1001) docker     (127)     1648 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape/utils/validators.py
--rw-r--r--   0 runner    (1001) docker     (127)      411 2024-02-16 18:36:13.000000 eth-ape-0.7.9/src/ape/version.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.654333 eth-ape-0.7.9/src/ape_accounts/
--rw-r--r--   0 runner    (1001) docker     (127)      455 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_accounts/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     6975 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_accounts/_cli.py
--rw-r--r--   0 runner    (1001) docker     (127)    12470 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_accounts/accounts.py
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_accounts/py.typed
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.658334 eth-ape-0.7.9/src/ape_cache/
--rw-r--r--   0 runner    (1001) docker     (127)      333 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_cache/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     2266 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_cache/_cli.py
--rw-r--r--   0 runner    (1001) docker     (127)      348 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_cache/base.py
--rw-r--r--   0 runner    (1001) docker     (127)     2745 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_cache/models.py
--rw-r--r--   0 runner    (1001) docker     (127)    17961 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_cache/query.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.658334 eth-ape-0.7.9/src/ape_compile/
--rw-r--r--   0 runner    (1001) docker     (127)     1048 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_compile/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     4540 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_compile/_cli.py
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_compile/py.typed
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.658334 eth-ape-0.7.9/src/ape_console/
--rw-r--r--   0 runner    (1001) docker     (127)      150 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_console/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     5170 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_console/_cli.py
--rw-r--r--   0 runner    (1001) docker     (127)      188 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_console/config.py
--rw-r--r--   0 runner    (1001) docker     (127)     2521 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_console/plugin.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.658334 eth-ape-0.7.9/src/ape_ethereum/
--rw-r--r--   0 runner    (1001) docker     (127)      895 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_ethereum/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      905 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_ethereum/_converters.py
--rw-r--r--   0 runner    (1001) docker     (127)    45099 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_ethereum/ecosystem.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.658334 eth-ape-0.7.9/src/ape_ethereum/multicall/
--rw-r--r--   0 runner    (1001) docker     (127)       86 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_ethereum/multicall/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    10277 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_ethereum/multicall/constants.py
--rw-r--r--   0 runner    (1001) docker     (127)      681 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_ethereum/multicall/exceptions.py
--rw-r--r--   0 runner    (1001) docker     (127)    10194 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_ethereum/multicall/handlers.py
--rw-r--r--   0 runner    (1001) docker     (127)    53222 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_ethereum/provider.py
--rw-r--r--   0 runner    (1001) docker     (127)     3721 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_ethereum/proxies.py
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_ethereum/py.typed
--rw-r--r--   0 runner    (1001) docker     (127)    16208 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_ethereum/transactions.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.658334 eth-ape-0.7.9/src/ape_geth/
--rw-r--r--   0 runner    (1001) docker     (127)      686 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_geth/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    18270 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_geth/provider.py
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_geth/py.typed
--rw-r--r--   0 runner    (1001) docker     (127)     1450 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_geth/query.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.658334 eth-ape-0.7.9/src/ape_init/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_init/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     1787 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_init/_cli.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.662334 eth-ape-0.7.9/src/ape_networks/
--rw-r--r--   0 runner    (1001) docker     (127)      834 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_networks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     5062 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_networks/_cli.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.662334 eth-ape-0.7.9/src/ape_plugins/
--rw-r--r--   0 runner    (1001) docker     (127)      133 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_plugins/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     8541 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_plugins/_cli.py
--rw-r--r--   0 runner    (1001) docker     (127)      654 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_plugins/exceptions.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.662334 eth-ape-0.7.9/src/ape_pm/
--rw-r--r--   0 runner    (1001) docker     (127)      175 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_pm/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    12251 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_pm/_cli.py
--rw-r--r--   0 runner    (1001) docker     (127)     4874 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_pm/compiler.py
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_pm/py.typed
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.662334 eth-ape-0.7.9/src/ape_run/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_run/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     9821 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_run/_cli.py
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_run/py.typed
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.662334 eth-ape-0.7.9/src/ape_test/
--rw-r--r--   0 runner    (1001) docker     (127)     3844 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_test/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     3644 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_test/_cli.py
--rw-r--r--   0 runner    (1001) docker     (127)     4542 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_test/accounts.py
--rw-r--r--   0 runner    (1001) docker     (127)    11325 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_test/provider.py
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/src/ape_test/py.typed
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.662334 eth-ape-0.7.9/src/eth_ape.egg-info/
--rw-r--r--   0 runner    (1001) docker     (127)     6562 2024-02-16 18:36:13.000000 eth-ape-0.7.9/src/eth_ape.egg-info/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (127)    15813 2024-02-16 18:36:13.000000 eth-ape-0.7.9/src/eth_ape.egg-info/SOURCES.txt
--rw-r--r--   0 runner    (1001) docker     (127)        1 2024-02-16 18:36:13.000000 eth-ape-0.7.9/src/eth_ape.egg-info/dependency_links.txt
--rw-r--r--   0 runner    (1001) docker     (127)      421 2024-02-16 18:36:13.000000 eth-ape-0.7.9/src/eth_ape.egg-info/entry_points.txt
--rw-r--r--   0 runner    (1001) docker     (127)        1 2024-02-16 18:36:13.000000 eth-ape-0.7.9/src/eth_ape.egg-info/not-zip-safe
--rw-r--r--   0 runner    (1001) docker     (127)     2117 2024-02-16 18:36:13.000000 eth-ape-0.7.9/src/eth_ape.egg-info/requires.txt
--rw-r--r--   0 runner    (1001) docker     (127)      131 2024-02-16 18:36:13.000000 eth-ape-0.7.9/src/eth_ape.egg-info/top_level.txt
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.662334 eth-ape-0.7.9/tests/
--rw-r--r--   0 runner    (1001) docker     (127)     3258 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/README.md
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    15988 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/conftest.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.670334 eth-ape-0.7.9/tests/functional/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    26353 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/conftest.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.670334 eth-ape-0.7.9/tests/functional/conversion/
--rw-r--r--   0 runner    (1001) docker     (127)      603 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/conversion/test_address.py
--rw-r--r--   0 runner    (1001) docker     (127)     3175 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/conversion/test_encode_structs.py
--rw-r--r--   0 runner    (1001) docker     (127)     1141 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/conversion/test_ether.py
--rw-r--r--   0 runner    (1001) docker     (127)      773 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/conversion/test_hex.py
--rw-r--r--   0 runner    (1001) docker     (127)      910 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/conversion/test_timestamp.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.670334 eth-ape-0.7.9/tests/functional/data/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.626333 eth-ape-0.7.9/tests/functional/data/contracts/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.626333 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.670334 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/abi/
--rw-r--r--   0 runner    (1001) docker     (127)    13727 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/abi/contract_abi.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.674334 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/
--rw-r--r--   0 runner    (1001) docker     (127)    26703 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/BeaconProxy.json
--rw-r--r--   0 runner    (1001) docker     (127)    77599 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/ContractA.json
--rw-r--r--   0 runner    (1001) docker     (127)    75147 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/ContractB.json
--rw-r--r--   0 runner    (1001) docker     (127)    32313 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/ContractC.json
--rw-r--r--   0 runner    (1001) docker     (127)     6348 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/DsNoteTest.json
--rw-r--r--   0 runner    (1001) docker     (127)    16463 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/HasError.json
--rw-r--r--   0 runner    (1001) docker     (127)      346 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/Interface.json
--rw-r--r--   0 runner    (1001) docker     (127)      982 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/InterfaceImplementation.json
--rw-r--r--   0 runner    (1001) docker     (127)    46986 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/RevertsContract.json
--rw-r--r--   0 runner    (1001) docker     (127)     5312 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/SolFallbackAndReceive.json
--rw-r--r--   0 runner    (1001) docker     (127)   240439 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/SolidityContract.json
--rw-r--r--   0 runner    (1001) docker     (127)     3735 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/SubReverts.json
--rw-r--r--   0 runner    (1001) docker     (127)     4848 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/VyDefault.json
--rw-r--r--   0 runner    (1001) docker     (127)   251475 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/VyperContract.json
--rw-r--r--   0 runner    (1001) docker     (127)     7393 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/VyperFactory.json
--rw-r--r--   0 runner    (1001) docker     (127)     6716 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/beacon.json
--rw-r--r--   0 runner    (1001) docker     (127)    19007 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/eip1967.json
--rw-r--r--   0 runner    (1001) docker     (127)     8101 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/proxy.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.626333 eth-ape-0.7.9/tests/functional/data/manifests/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.626333 eth-ape-0.7.9/tests/functional/data/manifests/OpenZeppelin/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.674334 eth-ape-0.7.9/tests/functional/data/manifests/OpenZeppelin/v3.1.0/
--rw-r--r--   0 runner    (1001) docker     (127)  1689272 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/manifests/OpenZeppelin/v3.1.0/OpenZeppelin.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.678334 eth-ape-0.7.9/tests/functional/data/manifests/OpenZeppelin/v4.4.2/
--rw-r--r--   0 runner    (1001) docker     (127)  3230874 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/manifests/OpenZeppelin/v4.4.2/OpenZeppelin.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.630333 eth-ape-0.7.9/tests/functional/data/projects/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.682334 eth-ape-0.7.9/tests/functional/data/projects/ApeProject/
--rw-r--r--   0 runner    (1001) docker     (127)       30 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/projects/ApeProject/ape-config.yaml
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.682334 eth-ape-0.7.9/tests/functional/data/projects/ApeProject/contracts/
--rw-r--r--   0 runner    (1001) docker     (127)       81 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/projects/ApeProject/contracts/ApeContract0.json
--rw-r--r--   0 runner    (1001) docker     (127)       81 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/projects/ApeProject/contracts/ApeContract1.json
--rw-r--r--   0 runner    (1001) docker     (127)     2725 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/projects/ApeProject/contracts/Contract.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.682334 eth-ape-0.7.9/tests/functional/data/projects/BrownieProject/
--rw-r--r--   0 runner    (1001) docker     (127)      181 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/projects/BrownieProject/brownie-config.yaml
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.682334 eth-ape-0.7.9/tests/functional/data/projects/BrownieProject/contracts/
--rw-r--r--   0 runner    (1001) docker     (127)       73 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/projects/BrownieProject/contracts/brownie.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.630333 eth-ape-0.7.9/tests/functional/data/projects/LongContractsFolder/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.630333 eth-ape-0.7.9/tests/functional/data/projects/LongContractsFolder/source/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.682334 eth-ape-0.7.9/tests/functional/data/projects/LongContractsFolder/source/v0.1/
--rw-r--r--   0 runner    (1001) docker     (127)       73 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/projects/LongContractsFolder/source/v0.1/long_contracts_folder.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.682334 eth-ape-0.7.9/tests/functional/data/python/
--rw-r--r--   0 runner    (1001) docker     (127)    37472 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/python/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.686334 eth-ape-0.7.9/tests/functional/data/sources/
--rw-r--r--   0 runner    (1001) docker     (127)     2687 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/sources/ContractA.sol
--rw-r--r--   0 runner    (1001) docker     (127)     2359 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/sources/ContractB.sol
--rw-r--r--   0 runner    (1001) docker     (127)     1128 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/sources/ContractC.sol
--rw-r--r--   0 runner    (1001) docker     (127)      582 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/sources/HasError.sol
--rw-r--r--   0 runner    (1001) docker     (127)      298 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/sources/Proxy.sol
--rw-r--r--   0 runner    (1001) docker     (127)     1454 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/sources/RevertsContract.vy
--rw-r--r--   0 runner    (1001) docker     (127)      252 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/sources/SolFallbackAndReceive.sol
--rw-r--r--   0 runner    (1001) docker     (127)     8822 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/sources/SolidityContract.sol
--rw-r--r--   0 runner    (1001) docker     (127)      100 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/sources/SubRevertsVy.vy
--rw-r--r--   0 runner    (1001) docker     (127)      142 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/sources/VyDefault.vy
--rw-r--r--   0 runner    (1001) docker     (127)     7053 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/sources/VyperContract.vy
--rw-r--r--   0 runner    (1001) docker     (127)      232 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/sources/VyperFactory.vy
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.686334 eth-ape-0.7.9/tests/functional/data/sources/interfaces/
--rw-r--r--   0 runner    (1001) docker     (127)       58 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/data/sources/interfaces/ISubReverts.vy
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.686334 eth-ape-0.7.9/tests/functional/geth/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/geth/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     3165 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/geth/conftest.py
--rw-r--r--   0 runner    (1001) docker     (127)     2941 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/geth/test_contract.py
--rw-r--r--   0 runner    (1001) docker     (127)      300 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/geth/test_ecosystem.py
--rw-r--r--   0 runner    (1001) docker     (127)    15561 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/geth/test_provider.py
--rw-r--r--   0 runner    (1001) docker     (127)     1196 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/geth/test_query.py
--rw-r--r--   0 runner    (1001) docker     (127)     6310 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/geth/test_trace.py
--rw-r--r--   0 runner    (1001) docker     (127)      888 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/geth/text_proxy.py
--rw-r--r--   0 runner    (1001) docker     (127)    31931 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_accounts.py
--rw-r--r--   0 runner    (1001) docker     (127)      797 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_address.py
--rw-r--r--   0 runner    (1001) docker     (127)     1015 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_block.py
--rw-r--r--   0 runner    (1001) docker     (127)     6688 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_block_container.py
--rw-r--r--   0 runner    (1001) docker     (127)     4957 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_chain.py
--rw-r--r--   0 runner    (1001) docker     (127)    22203 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_cli.py
--rw-r--r--   0 runner    (1001) docker     (127)     5691 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_compilers.py
--rw-r--r--   0 runner    (1001) docker     (127)    10909 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_config.py
--rw-r--r--   0 runner    (1001) docker     (127)     1100 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_console.py
--rw-r--r--   0 runner    (1001) docker     (127)     2727 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_contract.py
--rw-r--r--   0 runner    (1001) docker     (127)      247 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_contract_call_handler.py
--rw-r--r--   0 runner    (1001) docker     (127)     5989 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_contract_container.py
--rw-r--r--   0 runner    (1001) docker     (127)    13390 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_contract_event.py
--rw-r--r--   0 runner    (1001) docker     (127)    33167 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_contract_instance.py
--rw-r--r--   0 runner    (1001) docker     (127)     1460 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_contract_method_handler.py
--rw-r--r--   0 runner    (1001) docker     (127)    14949 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_contracts_cache.py
--rw-r--r--   0 runner    (1001) docker     (127)     4528 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_coverage.py
--rw-r--r--   0 runner    (1001) docker     (127)     2774 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_default_sender_context_manager.py
--rw-r--r--   0 runner    (1001) docker     (127)     7107 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_dependencies.py
--rw-r--r--   0 runner    (1001) docker     (127)    57926 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_ecosystem.py
--rw-r--r--   0 runner    (1001) docker     (127)      924 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_exceptions.py
--rw-r--r--   0 runner    (1001) docker     (127)      753 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_fixtures.py
--rw-r--r--   0 runner    (1001) docker     (127)     2361 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_history.py
--rw-r--r--   0 runner    (1001) docker     (127)     2752 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_logging.py
--rw-r--r--   0 runner    (1001) docker     (127)     2254 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_multicall.py
--rw-r--r--   0 runner    (1001) docker     (127)     5630 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_network_api.py
--rw-r--r--   0 runner    (1001) docker     (127)    13463 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_network_manager.py
--rw-r--r--   0 runner    (1001) docker     (127)    11764 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_plugins.py
--rw-r--r--   0 runner    (1001) docker     (127)    23943 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_project.py
--rw-r--r--   0 runner    (1001) docker     (127)    14617 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_provider.py
--rw-r--r--   0 runner    (1001) docker     (127)      403 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_proxy.py
--rw-r--r--   0 runner    (1001) docker     (127)     3263 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_query.py
--rw-r--r--   0 runner    (1001) docker     (127)     6709 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_receipt.py
--rw-r--r--   0 runner    (1001) docker     (127)      510 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_receipt_capture.py
--rw-r--r--   0 runner    (1001) docker     (127)     4786 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_reverts_context_manager.py
--rw-r--r--   0 runner    (1001) docker     (127)    14818 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_transaction.py
--rw-r--r--   0 runner    (1001) docker     (127)     5344 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/test_types.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.686334 eth-ape-0.7.9/tests/functional/utils/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     2562 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/utils/test_abi.py
--rw-r--r--   0 runner    (1001) docker     (127)      688 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/utils/test_basemodel.py
--rw-r--r--   0 runner    (1001) docker     (127)     3415 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/utils/test_github.py
--rw-r--r--   0 runner    (1001) docker     (127)     4530 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/utils/test_misc.py
--rw-r--r--   0 runner    (1001) docker     (127)     2441 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/utils/test_os.py
--rw-r--r--   0 runner    (1001) docker     (127)      621 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/functional/utils/test_trace.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.686334 eth-ape-0.7.9/tests/integration/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.690334 eth-ape-0.7.9/tests/integration/cli/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     5880 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/conftest.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.634333 eth-ape-0.7.9/tests/integration/cli/projects/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.630333 eth-ape-0.7.9/tests/integration/cli/projects/bad-contracts/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.690334 eth-ape-0.7.9/tests/integration/cli/projects/bad-contracts/contracts/
--rw-r--r--   0 runner    (1001) docker     (127)       28 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/bad-contracts/contracts/Contract.test
--rw-r--r--   0 runner    (1001) docker     (127)       27 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/bad-contracts/contracts/Contract2.foo
--rw-r--r--   0 runner    (1001) docker     (127)       92 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/bad-contracts/contracts/doc.md
--rw-r--r--   0 runner    (1001) docker     (127)       81 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/bad-contracts/contracts/file_without_ext
--rw-r--r--   0 runner    (1001) docker     (127)      171 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/bad-contracts/contracts/package.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.690334 eth-ape-0.7.9/tests/integration/cli/projects/bad-contracts/contracts/subdir/
--rw-r--r--   0 runner    (1001) docker     (127)        4 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/bad-contracts/contracts/subdir/tsconfig.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.690334 eth-ape-0.7.9/tests/integration/cli/projects/bad-contracts/contracts/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/bad-contracts/contracts/tests/TestContract.foobar
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.690334 eth-ape-0.7.9/tests/integration/cli/projects/empty-config/
--rw-r--r--   0 runner    (1001) docker     (127)       15 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/empty-config/ape-config.yaml
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.690334 eth-ape-0.7.9/tests/integration/cli/projects/geth/
--rw-r--r--   0 runner    (1001) docker     (127)      869 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/geth/ape-config.yaml
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.690334 eth-ape-0.7.9/tests/integration/cli/projects/geth/contracts/
--rw-r--r--   0 runner    (1001) docker     (127)     6444 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/geth/contracts/TokenA.json
--rw-r--r--   0 runner    (1001) docker     (127)     6444 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/geth/contracts/TokenB.json
--rw-r--r--   0 runner    (1001) docker     (127)    28131 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/geth/contracts/VyperContract.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.690334 eth-ape-0.7.9/tests/integration/cli/projects/geth/tests/
--rw-r--r--   0 runner    (1001) docker     (127)      354 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/geth/tests/conftest.py
--rw-r--r--   0 runner    (1001) docker     (127)     2800 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/geth/tests/test_using_local_geth.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.630333 eth-ape-0.7.9/tests/integration/cli/projects/multiple-interfaces/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.694334 eth-ape-0.7.9/tests/integration/cli/projects/multiple-interfaces/contracts/
--rw-r--r--   0 runner    (1001) docker     (127)       73 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/multiple-interfaces/contracts/Interface-with-hyphens.json
--rw-r--r--   0 runner    (1001) docker     (127)        5 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/multiple-interfaces/contracts/Interface.exclude.json
--rw-r--r--   0 runner    (1001) docker     (127)       73 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/multiple-interfaces/contracts/Interface.json
--rw-r--r--   0 runner    (1001) docker     (127)       73 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/multiple-interfaces/contracts/InterfaceWithNumber123.json
--rw-r--r--   0 runner    (1001) docker     (127)       73 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/multiple-interfaces/contracts/Interface_with_underscores.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.694334 eth-ape-0.7.9/tests/integration/cli/projects/no-config/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/no-config/.gitkeep
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.694334 eth-ape-0.7.9/tests/integration/cli/projects/only-dependencies/
--rw-r--r--   0 runner    (1001) docker     (127)      281 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/only-dependencies/ape-config.yaml
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.694334 eth-ape-0.7.9/tests/integration/cli/projects/only-dependencies/dependency_in_project_only/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/only-dependencies/dependency_in_project_only/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)       75 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/only-dependencies/dependency_in_project_only/importme.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.694334 eth-ape-0.7.9/tests/integration/cli/projects/only-dependencies/dependency_in_project_only/sources/
--rw-r--r--   0 runner    (1001) docker     (127)       73 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/only-dependencies/dependency_in_project_only/sources/DependencyInProjectOnly.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.630333 eth-ape-0.7.9/tests/integration/cli/projects/only-script-subdirs/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.630333 eth-ape-0.7.9/tests/integration/cli/projects/only-script-subdirs/scripts/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.694334 eth-ape-0.7.9/tests/integration/cli/projects/only-script-subdirs/scripts/subdirectory/
--rw-r--r--   0 runner    (1001) docker     (127)      102 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/only-script-subdirs/scripts/subdirectory/subdirectory_click_print.py
--rw-r--r--   0 runner    (1001) docker     (127)       66 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/only-script-subdirs/scripts/subdirectory/subdirectory_main_print.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.630333 eth-ape-0.7.9/tests/integration/cli/projects/script/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.694334 eth-ape-0.7.9/tests/integration/cli/projects/script/contracts/
--rw-r--r--   0 runner    (1001) docker     (127)    28131 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/script/contracts/VyperContract.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.694334 eth-ape-0.7.9/tests/integration/cli/projects/script/scripts/
--rw-r--r--   0 runner    (1001) docker     (127)       79 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/script/scripts/_utils.py
--rw-r--r--   0 runner    (1001) docker     (127)      126 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/script/scripts/click.py
--rw-r--r--   0 runner    (1001) docker     (127)      274 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/script/scripts/deploy.py
--rw-r--r--   0 runner    (1001) docker     (127)      271 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/script/scripts/error_cli.py
--rw-r--r--   0 runner    (1001) docker     (127)      283 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/script/scripts/error_forgot_click.py
--rw-r--r--   0 runner    (1001) docker     (127)      198 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/script/scripts/error_main.py
--rw-r--r--   0 runner    (1001) docker     (127)      169 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/script/scripts/error_no_def.py
--rw-r--r--   0 runner    (1001) docker     (127)      357 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/script/scripts/output_contract_view_methods.py
--rw-r--r--   0 runner    (1001) docker     (127)      240 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/script/scripts/site.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.694334 eth-ape-0.7.9/tests/integration/cli/projects/script/scripts/subdirectory/
--rw-r--r--   0 runner    (1001) docker     (127)      102 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/script/scripts/subdirectory/subdirectory_click_print.py
--rw-r--r--   0 runner    (1001) docker     (127)       66 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/script/scripts/subdirectory/subdirectory_main_print.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.694334 eth-ape-0.7.9/tests/integration/cli/projects/test/
--rw-r--r--   0 runner    (1001) docker     (127)       92 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/test/ape-config.yaml
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.698334 eth-ape-0.7.9/tests/integration/cli/projects/test/tests/
--rw-r--r--   0 runner    (1001) docker     (127)      955 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/test/tests/test_fixture_isolation.py
--rw-r--r--   0 runner    (1001) docker     (127)      852 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/test/tests/test_fixtures.py
--rw-r--r--   0 runner    (1001) docker     (127)      747 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/test/tests/test_networks.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.698334 eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/
--rw-r--r--   0 runner    (1001) docker     (127)      220 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/ape-config.yaml
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.698334 eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/contracts/
--rw-r--r--   0 runner    (1001) docker     (127)     2727 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/contracts/ContractA.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.698334 eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/contracts/DirectoryWithJSONExtension.json/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/contracts/DirectoryWithJSONExtension.json/.gitkeep
--rw-r--r--   0 runner    (1001) docker     (127)       16 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/contracts/Exclude.json
--rw-r--r--   0 runner    (1001) docker     (127)    41634 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/contracts/RawSolidityOutput.json
--rw-r--r--   0 runner    (1001) docker     (127)    64327 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/contracts/RawVyperOutput.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.698334 eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/contracts/exclude_dir/
--rw-r--r--   0 runner    (1001) docker     (127)       16 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/contracts/exclude_dir/UnwantedContract.json
--rw-r--r--   0 runner    (1001) docker     (127)      103 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/contracts/hyphen-Contract.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.630333 eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/dep/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.698334 eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/dep/contracts/
--rw-r--r--   0 runner    (1001) docker     (127)    64326 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/dep/contracts/RawVyperOutputDep.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.698334 eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/scripts/
--rw-r--r--   0 runner    (1001) docker     (127)      263 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/scripts/txerr.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.698334 eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/tests/
--rw-r--r--   0 runner    (1001) docker     (127)      212 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/tests/conftest.py
--rw-r--r--   0 runner    (1001) docker     (127)      578 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/tests/test_contract.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.698334 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/
--rw-r--r--   0 runner    (1001) docker     (127)      551 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/ape-config.yaml
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.698334 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/containing_sub_dependencies/
--rw-r--r--   0 runner    (1001) docker     (127)       67 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/containing_sub_dependencies/ape-config.yaml
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.698334 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/containing_sub_dependencies/contracts/
--rw-r--r--   0 runner    (1001) docker     (127)       73 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/containing_sub_dependencies/contracts/containing_sub_dependencies.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.634333 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/containing_sub_dependencies/sub_dependency/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.698334 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/containing_sub_dependencies/sub_dependency/contracts/
--rw-r--r--   0 runner    (1001) docker     (127)       73 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/containing_sub_dependencies/sub_dependency/contracts/sub-dependency.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.698334 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/contracts/
--rw-r--r--   0 runner    (1001) docker     (127)       73 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/contracts/Other.json
--rw-r--r--   0 runner    (1001) docker     (127)       73 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/contracts/Project.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.634333 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/default/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.698334 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/default/contracts/
--rw-r--r--   0 runner    (1001) docker     (127)       73 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/default/contracts/default.json
--rw-r--r--   0 runner    (1001) docker     (127)      113 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/default/contracts/hyphen-DependencyContract.json
--rw-r--r--   0 runner    (1001) docker     (127)      455 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/manifest_dependency.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.634333 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/renamed_complex_contracts_folder/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.634333 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/renamed_complex_contracts_folder/contracts/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.634333 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/renamed_complex_contracts_folder/contracts/src/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.698334 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/renamed_complex_contracts_folder/contracts/src/v0.1/
--rw-r--r--   0 runner    (1001) docker     (127)       73 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/renamed_complex_contracts_folder/contracts/src/v0.1/renamed_complex_contracts_folder.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.634333 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/renamed_contracts_folder/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.698334 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/renamed_contracts_folder/sources/
--rw-r--r--   0 runner    (1001) docker     (127)       73 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/renamed_contracts_folder/sources/renamed_contracts_folder.json
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.702334 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/renamed_contracts_folder_specified_in_config/
--rw-r--r--   0 runner    (1001) docker     (127)       31 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/renamed_contracts_folder_specified_in_config/ape-config.yaml
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-02-16 18:36:13.702334 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/renamed_contracts_folder_specified_in_config/my_contracts/
--rw-r--r--   0 runner    (1001) docker     (127)       73 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/projects/with-dependencies/renamed_contracts_folder_specified_in_config/my_contracts/renamed_contracts_folder_specified_in_config.json
--rw-r--r--   0 runner    (1001) docker     (127)    12564 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/test_accounts.py
--rw-r--r--   0 runner    (1001) docker     (127)      410 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/test_cache.py
--rw-r--r--   0 runner    (1001) docker     (127)    14034 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/test_compile.py
--rw-r--r--   0 runner    (1001) docker     (127)     7254 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/test_console.py
--rw-r--r--   0 runner    (1001) docker     (127)     2258 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/test_init.py
--rw-r--r--   0 runner    (1001) docker     (127)      730 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/test_misc.py
--rw-r--r--   0 runner    (1001) docker     (127)     6085 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/test_networks.py
--rw-r--r--   0 runner    (1001) docker     (127)     5795 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/test_plugins.py
--rw-r--r--   0 runner    (1001) docker     (127)     7671 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/test_pm.py
--rw-r--r--   0 runner    (1001) docker     (127)     7042 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/test_run.py
--rw-r--r--   0 runner    (1001) docker     (127)    11471 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/test_test.py
--rw-r--r--   0 runner    (1001) docker     (127)     4227 2024-02-16 18:35:07.000000 eth-ape-0.7.9/tests/integration/cli/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.775256 eth-ape-0.8.0/
+-rw-r--r--   0 runner    (1001) docker     (127)       25 2024-05-31 16:36:56.000000 eth-ape-0.8.0/.dockerignore
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.703256 eth-ape-0.8.0/.github/
+-rw-r--r--   0 runner    (1001) docker     (127)       16 2024-05-31 16:36:56.000000 eth-ape-0.8.0/.github/FUNDING.yml
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.707256 eth-ape-0.8.0/.github/ISSUE_TEMPLATE/
+-rw-r--r--   0 runner    (1001) docker     (127)      907 2024-05-31 16:36:56.000000 eth-ape-0.8.0/.github/ISSUE_TEMPLATE/bug.md
+-rw-r--r--   0 runner    (1001) docker     (127)      676 2024-05-31 16:36:56.000000 eth-ape-0.8.0/.github/ISSUE_TEMPLATE/feature.md
+-rw-r--r--   0 runner    (1001) docker     (127)     1254 2024-05-31 16:36:56.000000 eth-ape-0.8.0/.github/ISSUE_TEMPLATE/work-item.md
+-rw-r--r--   0 runner    (1001) docker     (127)      526 2024-05-31 16:36:56.000000 eth-ape-0.8.0/.github/PULL_REQUEST_TEMPLATE.md
+-rw-r--r--   0 runner    (1001) docker     (127)      677 2024-05-31 16:36:56.000000 eth-ape-0.8.0/.github/release-drafter.yml
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.707256 eth-ape-0.8.0/.github/workflows/
+-rw-r--r--   0 runner    (1001) docker     (127)      618 2024-05-31 16:36:56.000000 eth-ape-0.8.0/.github/workflows/codeql.yml
+-rw-r--r--   0 runner    (1001) docker     (127)      703 2024-05-31 16:36:56.000000 eth-ape-0.8.0/.github/workflows/commitlint.yaml
+-rw-r--r--   0 runner    (1001) docker     (127)     2152 2024-05-31 16:36:56.000000 eth-ape-0.8.0/.github/workflows/docs.yaml
+-rw-r--r--   0 runner    (1001) docker     (127)      405 2024-05-31 16:36:56.000000 eth-ape-0.8.0/.github/workflows/draft.yaml
+-rw-r--r--   0 runner    (1001) docker     (127)      630 2024-05-31 16:36:56.000000 eth-ape-0.8.0/.github/workflows/prtitle.yaml
+-rw-r--r--   0 runner    (1001) docker     (127)      605 2024-05-31 16:36:56.000000 eth-ape-0.8.0/.github/workflows/publish.yaml
+-rw-r--r--   0 runner    (1001) docker     (127)      709 2024-05-31 16:36:56.000000 eth-ape-0.8.0/.github/workflows/stale-prs.yml
+-rw-r--r--   0 runner    (1001) docker     (127)     3007 2024-05-31 16:36:56.000000 eth-ape-0.8.0/.github/workflows/test.yaml
+-rw-r--r--   0 runner    (1001) docker     (127)     2121 2024-05-31 16:36:56.000000 eth-ape-0.8.0/.gitignore
+-rw-r--r--   0 runner    (1001) docker     (127)     1002 2024-05-31 16:36:56.000000 eth-ape-0.8.0/.pre-commit-config.yaml
+-rw-r--r--   0 runner    (1001) docker     (127)     2807 2024-05-31 16:36:56.000000 eth-ape-0.8.0/CONTRIBUTING.md
+-rw-r--r--   0 runner    (1001) docker     (127)     1761 2024-05-31 16:36:56.000000 eth-ape-0.8.0/Dockerfile
+-rw-r--r--   0 runner    (1001) docker     (127)    11342 2024-05-31 16:36:56.000000 eth-ape-0.8.0/LICENSE
+-rw-r--r--   0 runner    (1001) docker     (127)     6563 2024-05-31 16:37:47.775256 eth-ape-0.8.0/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (127)     5312 2024-05-31 16:36:56.000000 eth-ape-0.8.0/README.md
+-rw-r--r--   0 runner    (1001) docker     (127)     3807 2024-05-31 16:36:56.000000 eth-ape-0.8.0/SECURITY.md
+-rw-r--r--   0 runner    (1001) docker     (127)     2515 2024-05-31 16:36:56.000000 eth-ape-0.8.0/build_docs.py
+-rw-r--r--   0 runner    (1001) docker     (127)       83 2024-05-31 16:36:56.000000 eth-ape-0.8.0/codeql-config.yml
+-rw-r--r--   0 runner    (1001) docker     (127)       23 2024-05-31 16:36:56.000000 eth-ape-0.8.0/cz-requirement.txt
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.707256 eth-ape-0.8.0/docs/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.707256 eth-ape-0.8.0/docs/_static/
+-rw-r--r--   0 runner    (1001) docker     (127)     5434 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/_static/custom.css
+-rw-r--r--   0 runner    (1001) docker     (127)     1032 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/_static/custom.js
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.707256 eth-ape-0.8.0/docs/_templates/
+-rw-r--r--   0 runner    (1001) docker     (127)    10136 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/_templates/layout.html
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.707256 eth-ape-0.8.0/docs/commands/
+-rw-r--r--   0 runner    (1001) docker     (127)       67 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/commands/accounts.rst
+-rw-r--r--   0 runner    (1001) docker     (127)       65 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/commands/compile.rst
+-rw-r--r--   0 runner    (1001) docker     (127)       82 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/commands/console.rst
+-rw-r--r--   0 runner    (1001) docker     (127)       59 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/commands/init.rst
+-rw-r--r--   0 runner    (1001) docker     (127)       67 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/commands/networks.rst
+-rw-r--r--   0 runner    (1001) docker     (127)       65 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/commands/plugins.rst
+-rw-r--r--   0 runner    (1001) docker     (127)       55 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/commands/pm.rst
+-rw-r--r--   0 runner    (1001) docker     (127)       66 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/commands/run.rst
+-rw-r--r--   0 runner    (1001) docker     (127)       59 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/commands/test.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     4376 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/conf.py
+-rw-r--r--   0 runner    (1001) docker     (127)    20915 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/favicon.ico
+-rw-r--r--   0 runner    (1001) docker     (127)     1335 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/index.md
+-rw-r--r--   0 runner    (1001) docker     (127)    11889 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/logo.gif
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.711256 eth-ape-0.8.0/docs/methoddocs/
+-rw-r--r--   0 runner    (1001) docker     (127)       59 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/methoddocs/ape.md
+-rw-r--r--   0 runner    (1001) docker     (127)       77 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/methoddocs/ape_accounts.md
+-rw-r--r--   0 runner    (1001) docker     (127)       75 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/methoddocs/ape_compile.md
+-rw-r--r--   0 runner    (1001) docker     (127)       65 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/methoddocs/ape_pm.md
+-rw-r--r--   0 runner    (1001) docker     (127)     1335 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/methoddocs/api.md
+-rw-r--r--   0 runner    (1001) docker     (127)      775 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/methoddocs/cli.md
+-rw-r--r--   0 runner    (1001) docker     (127)      533 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/methoddocs/contracts.md
+-rw-r--r--   0 runner    (1001) docker     (127)      104 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/methoddocs/exceptions.md
+-rw-r--r--   0 runner    (1001) docker     (127)     1216 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/methoddocs/managers.md
+-rw-r--r--   0 runner    (1001) docker     (127)      933 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/methoddocs/plugins.md
+-rw-r--r--   0 runner    (1001) docker     (127)      767 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/methoddocs/types.md
+-rw-r--r--   0 runner    (1001) docker     (127)      152 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/methoddocs/utils.md
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.715256 eth-ape-0.8.0/docs/userguides/
+-rw-r--r--   0 runner    (1001) docker     (127)    13411 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/accounts.md
+-rw-r--r--   0 runner    (1001) docker     (127)     8866 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/clis.md
+-rw-r--r--   0 runner    (1001) docker     (127)     4957 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/compile.md
+-rw-r--r--   0 runner    (1001) docker     (127)     4671 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/config.md
+-rw-r--r--   0 runner    (1001) docker     (127)     5938 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/console.md
+-rw-r--r--   0 runner    (1001) docker     (127)    16302 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/contracts.md
+-rw-r--r--   0 runner    (1001) docker     (127)     2592 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/data.md
+-rw-r--r--   0 runner    (1001) docker     (127)    10220 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/dependencies.md
+-rw-r--r--   0 runner    (1001) docker     (127)     6944 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/developing_plugins.md
+-rw-r--r--   0 runner    (1001) docker     (127)     2156 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/forking_networks.md
+-rw-r--r--   0 runner    (1001) docker     (127)     2845 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/installing_plugins.md
+-rw-r--r--   0 runner    (1001) docker     (127)     1791 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/logging.md
+-rw-r--r--   0 runner    (1001) docker     (127)    21459 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/networks.md
+-rw-r--r--   0 runner    (1001) docker     (127)     3052 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/projects.md
+-rw-r--r--   0 runner    (1001) docker     (127)     1740 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/proxy.md
+-rw-r--r--   0 runner    (1001) docker     (127)     2132 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/publishing.md
+-rw-r--r--   0 runner    (1001) docker     (127)       33 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/quickstart.md
+-rw-r--r--   0 runner    (1001) docker     (127)     5251 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/scripts.md
+-rw-r--r--   0 runner    (1001) docker     (127)    25002 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/testing.md
+-rw-r--r--   0 runner    (1001) docker     (127)     4548 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/trace.md
+-rw-r--r--   0 runner    (1001) docker     (127)     8086 2024-05-31 16:36:56.000000 eth-ape-0.8.0/docs/userguides/transactions.md
+-rw-r--r--   0 runner    (1001) docker     (127)     1500 2024-05-31 16:36:56.000000 eth-ape-0.8.0/pyproject.toml
+-rw-r--r--   0 runner    (1001) docker     (127)      116 2024-05-31 16:36:56.000000 eth-ape-0.8.0/recommended-plugins.txt
+-rw-r--r--   0 runner    (1001) docker     (127)      291 2024-05-31 16:37:47.775256 eth-ape-0.8.0/setup.cfg
+-rw-r--r--   0 runner    (1001) docker     (127)     6772 2024-05-31 16:36:56.000000 eth-ape-0.8.0/setup.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.695256 eth-ape-0.8.0/src/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.715256 eth-ape-0.8.0/src/ape/
+-rw-r--r--   0 runner    (1001) docker     (127)     2052 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5640 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/_cli.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.719256 eth-ape-0.8.0/src/ape/api/
+-rw-r--r--   0 runner    (1001) docker     (127)     1357 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/api/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    23416 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/api/accounts.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6501 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/api/address.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10519 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/api/compiler.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15543 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/api/config.py
+-rw-r--r--   0 runner    (1001) docker     (127)      904 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/api/convert.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1668 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/api/explorers.py
+-rw-r--r--   0 runner    (1001) docker     (127)    43420 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/api/networks.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3558 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/api/projects.py
+-rw-r--r--   0 runner    (1001) docker     (127)    39205 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/api/providers.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8089 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/api/query.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1478 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/api/trace.py
+-rw-r--r--   0 runner    (1001) docker     (127)    19353 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/api/transactions.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.719256 eth-ape-0.8.0/src/ape/cli/
+-rw-r--r--   0 runner    (1001) docker     (127)     1334 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/cli/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6107 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/cli/arguments.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13618 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/cli/choices.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5014 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/cli/commands.py
+-rw-r--r--   0 runner    (1001) docker     (127)    16844 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/cli/options.py
+-rw-r--r--   0 runner    (1001) docker     (127)      823 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/cli/paramtype.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.719256 eth-ape-0.8.0/src/ape/contracts/
+-rw-r--r--   0 runner    (1001) docker     (127)      230 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/contracts/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    55095 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/contracts/base.py
+-rw-r--r--   0 runner    (1001) docker     (127)    26911 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/exceptions.py
+-rw-r--r--   0 runner    (1001) docker     (127)       79 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/harambe.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9254 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/logging.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.719256 eth-ape-0.8.0/src/ape/managers/
+-rw-r--r--   0 runner    (1001) docker     (127)      987 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/managers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13025 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/managers/accounts.py
+-rw-r--r--   0 runner    (1001) docker     (127)      516 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/managers/base.py
+-rw-r--r--   0 runner    (1001) docker     (127)    61607 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/managers/chain.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14025 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/managers/compilers.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5130 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/managers/config.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15741 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/managers/converters.py
+-rw-r--r--   0 runner    (1001) docker     (127)    23385 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/managers/networks.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5745 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/managers/plugins.py
+-rw-r--r--   0 runner    (1001) docker     (127)    81435 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/managers/project.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7596 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/managers/query.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.723256 eth-ape-0.8.0/src/ape/plugins/
+-rw-r--r--   0 runner    (1001) docker     (127)     2486 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/plugins/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    20654 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/plugins/_utils.py
+-rw-r--r--   0 runner    (1001) docker     (127)      968 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/plugins/account.py
+-rw-r--r--   0 runner    (1001) docker     (127)      884 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/plugins/compiler.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1010 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/plugins/config.py
+-rw-r--r--   0 runner    (1001) docker     (127)      812 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/plugins/converter.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3508 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/plugins/network.py
+-rw-r--r--   0 runner    (1001) docker     (127)      779 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/plugins/pluggy_patch.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1539 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/plugins/project.py
+-rw-r--r--   0 runner    (1001) docker     (127)      683 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/plugins/query.py
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/py.typed
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.723256 eth-ape-0.8.0/src/ape/pytest/
+-rw-r--r--   0 runner    (1001) docker     (127)      550 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/pytest/README.md
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/pytest/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3244 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/pytest/config.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6907 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/pytest/contextmanagers.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12038 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/pytest/coverage.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8163 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/pytest/fixtures.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2035 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/pytest/gas.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4586 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/pytest/plugin.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10697 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/pytest/runners.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.723256 eth-ape-0.8.0/src/ape/types/
+-rw-r--r--   0 runner    (1001) docker     (127)    15857 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/types/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1301 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/types/address.py
+-rw-r--r--   0 runner    (1001) docker     (127)    36405 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/types/coverage.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4015 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/types/signatures.py
+-rw-r--r--   0 runner    (1001) docker     (127)    17389 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/types/trace.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.727256 eth-ape-0.8.0/src/ape/utils/
+-rw-r--r--   0 runner    (1001) docker     (127)     3367 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7947 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/utils/_github.py
+-rw-r--r--   0 runner    (1001) docker     (127)    18563 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/utils/abi.py
+-rw-r--r--   0 runner    (1001) docker     (127)    16143 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/utils/basemodel.py
+-rw-r--r--   0 runner    (1001) docker     (127)    16057 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/utils/misc.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8645 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/utils/os.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1198 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/utils/process.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2220 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/utils/testing.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8187 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/utils/trace.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1648 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape/utils/validators.py
+-rw-r--r--   0 runner    (1001) docker     (127)      411 2024-05-31 16:37:47.000000 eth-ape-0.8.0/src/ape/version.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.727256 eth-ape-0.8.0/src/ape_accounts/
+-rw-r--r--   0 runner    (1001) docker     (127)      455 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_accounts/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6975 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_accounts/_cli.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13258 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_accounts/accounts.py
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_accounts/py.typed
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.727256 eth-ape-0.8.0/src/ape_cache/
+-rw-r--r--   0 runner    (1001) docker     (127)      333 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_cache/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2266 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_cache/_cli.py
+-rw-r--r--   0 runner    (1001) docker     (127)      348 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_cache/base.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2745 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_cache/models.py
+-rw-r--r--   0 runner    (1001) docker     (127)    17976 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_cache/query.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.727256 eth-ape-0.8.0/src/ape_compile/
+-rw-r--r--   0 runner    (1001) docker     (127)     1658 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_compile/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3914 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_compile/_cli.py
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_compile/py.typed
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.727256 eth-ape-0.8.0/src/ape_console/
+-rw-r--r--   0 runner    (1001) docker     (127)      150 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_console/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5515 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_console/_cli.py
+-rw-r--r--   0 runner    (1001) docker     (127)      163 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_console/config.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3189 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_console/plugin.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.731256 eth-ape-0.8.0/src/ape_ethereum/
+-rw-r--r--   0 runner    (1001) docker     (127)     1030 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_ethereum/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)   152476 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_ethereum/_console_log_abi.py
+-rw-r--r--   0 runner    (1001) docker     (127)      905 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_ethereum/_converters.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3917 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_ethereum/_print.py
+-rw-r--r--   0 runner    (1001) docker     (127)    51501 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_ethereum/ecosystem.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.731256 eth-ape-0.8.0/src/ape_ethereum/multicall/
+-rw-r--r--   0 runner    (1001) docker     (127)       86 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_ethereum/multicall/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10277 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_ethereum/multicall/constants.py
+-rw-r--r--   0 runner    (1001) docker     (127)      681 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_ethereum/multicall/exceptions.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10396 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_ethereum/multicall/handlers.py
+-rw-r--r--   0 runner    (1001) docker     (127)    51957 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_ethereum/provider.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3721 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_ethereum/proxies.py
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_ethereum/py.typed
+-rw-r--r--   0 runner    (1001) docker     (127)     5347 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_ethereum/query.py
+-rw-r--r--   0 runner    (1001) docker     (127)    23875 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_ethereum/trace.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15635 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_ethereum/transactions.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.731256 eth-ape-0.8.0/src/ape_init/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_init/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2350 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_init/_cli.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.731256 eth-ape-0.8.0/src/ape_networks/
+-rw-r--r--   0 runner    (1001) docker     (127)      822 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_networks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5065 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_networks/_cli.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.731256 eth-ape-0.8.0/src/ape_node/
+-rw-r--r--   0 runner    (1001) docker     (127)      666 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_node/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13436 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_node/provider.py
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_node/py.typed
+-rw-r--r--   0 runner    (1001) docker     (127)     1781 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_node/query.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.735256 eth-ape-0.8.0/src/ape_plugins/
+-rw-r--r--   0 runner    (1001) docker     (127)      133 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_plugins/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9446 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_plugins/_cli.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.735256 eth-ape-0.8.0/src/ape_pm/
+-rw-r--r--   0 runner    (1001) docker     (127)      669 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_pm/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10087 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_pm/_cli.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5639 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_pm/compiler.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10239 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_pm/dependency.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3861 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_pm/projects.py
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_pm/py.typed
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.735256 eth-ape-0.8.0/src/ape_run/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_run/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9853 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_run/_cli.py
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_run/py.typed
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.735256 eth-ape-0.8.0/src/ape_test/
+-rw-r--r--   0 runner    (1001) docker     (127)     4355 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_test/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3647 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_test/_cli.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5194 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_test/accounts.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13273 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_test/provider.py
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/src/ape_test/py.typed
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.735256 eth-ape-0.8.0/src/eth_ape.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (127)     6563 2024-05-31 16:37:47.000000 eth-ape-0.8.0/src/eth_ape.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (127)    16727 2024-05-31 16:37:47.000000 eth-ape-0.8.0/src/eth_ape.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (127)        1 2024-05-31 16:37:47.000000 eth-ape-0.8.0/src/eth_ape.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (127)      421 2024-05-31 16:37:47.000000 eth-ape-0.8.0/src/eth_ape.egg-info/entry_points.txt
+-rw-r--r--   0 runner    (1001) docker     (127)        1 2024-05-31 16:37:47.000000 eth-ape-0.8.0/src/eth_ape.egg-info/not-zip-safe
+-rw-r--r--   0 runner    (1001) docker     (127)     2168 2024-05-31 16:37:47.000000 eth-ape-0.8.0/src/eth_ape.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (127)      131 2024-05-31 16:37:47.000000 eth-ape-0.8.0/src/eth_ape.egg-info/top_level.txt
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.735256 eth-ape-0.8.0/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)     3258 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/README.md
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    17283 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/conftest.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.743256 eth-ape-0.8.0/tests/functional/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    28183 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/conftest.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.743256 eth-ape-0.8.0/tests/functional/conversion/
+-rw-r--r--   0 runner    (1001) docker     (127)     2058 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/conversion/test_address.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2067 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/conversion/test_decimal.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3162 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/conversion/test_encode_structs.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1108 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/conversion/test_ether.py
+-rw-r--r--   0 runner    (1001) docker     (127)      701 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/conversion/test_hex.py
+-rw-r--r--   0 runner    (1001) docker     (127)      987 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/conversion/test_misc.py
+-rw-r--r--   0 runner    (1001) docker     (127)      910 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/conversion/test_timestamp.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.743256 eth-ape-0.8.0/tests/functional/data/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.695256 eth-ape-0.8.0/tests/functional/data/contracts/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.695256 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.747256 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/abi/
+-rw-r--r--   0 runner    (1001) docker     (127)    13727 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/abi/contract_abi.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.751256 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/
+-rw-r--r--   0 runner    (1001) docker     (127)    26703 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/BeaconProxy.json
+-rw-r--r--   0 runner    (1001) docker     (127)    77599 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/ContractA.json
+-rw-r--r--   0 runner    (1001) docker     (127)    75147 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/ContractB.json
+-rw-r--r--   0 runner    (1001) docker     (127)    32313 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/ContractC.json
+-rw-r--r--   0 runner    (1001) docker     (127)     6348 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/DsNoteTest.json
+-rw-r--r--   0 runner    (1001) docker     (127)    16463 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/HasError.json
+-rw-r--r--   0 runner    (1001) docker     (127)      346 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/Interface.json
+-rw-r--r--   0 runner    (1001) docker     (127)      982 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/InterfaceImplementation.json
+-rw-r--r--   0 runner    (1001) docker     (127)    46986 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/RevertsContract.json
+-rw-r--r--   0 runner    (1001) docker     (127)     5312 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/SolFallbackAndReceive.json
+-rw-r--r--   0 runner    (1001) docker     (127)   240439 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/SolidityContract.json
+-rw-r--r--   0 runner    (1001) docker     (127)     3735 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/SubReverts.json
+-rw-r--r--   0 runner    (1001) docker     (127)     4848 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/VyDefault.json
+-rw-r--r--   0 runner    (1001) docker     (127)   251475 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/VyperContract.json
+-rw-r--r--   0 runner    (1001) docker     (127)     7393 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/VyperFactory.json
+-rw-r--r--   0 runner    (1001) docker     (127)     6716 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/beacon.json
+-rw-r--r--   0 runner    (1001) docker     (127)    19007 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/eip1967.json
+-rw-r--r--   0 runner    (1001) docker     (127)    13901 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/printing.json
+-rw-r--r--   0 runner    (1001) docker     (127)     8101 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/proxy.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.695256 eth-ape-0.8.0/tests/functional/data/manifests/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.695256 eth-ape-0.8.0/tests/functional/data/manifests/openzeppelin/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.751256 eth-ape-0.8.0/tests/functional/data/manifests/openzeppelin/3.1.0/
+-rw-r--r--   0 runner    (1001) docker     (127)  1733602 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/manifests/openzeppelin/3.1.0/openzeppelin.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.751256 eth-ape-0.8.0/tests/functional/data/manifests/openzeppelin/4.4.2/
+-rw-r--r--   0 runner    (1001) docker     (127)  1733602 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/manifests/openzeppelin/4.4.2/openzeppelin.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.695256 eth-ape-0.8.0/tests/functional/data/projects/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.755256 eth-ape-0.8.0/tests/functional/data/projects/ApeProject/
+-rw-r--r--   0 runner    (1001) docker     (127)       66 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/projects/ApeProject/ape-config.yaml
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.755256 eth-ape-0.8.0/tests/functional/data/projects/ApeProject/contracts/
+-rw-r--r--   0 runner    (1001) docker     (127)       81 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/projects/ApeProject/contracts/ApeContract0.json
+-rw-r--r--   0 runner    (1001) docker     (127)       81 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/projects/ApeProject/contracts/ApeContract1.json
+-rw-r--r--   0 runner    (1001) docker     (127)     2725 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/projects/ApeProject/contracts/Contract.json
+-rw-r--r--   0 runner    (1001) docker     (127)       81 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/projects/ApeProject/contracts/Exclude.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.755256 eth-ape-0.8.0/tests/functional/data/projects/ApeProject/contracts/subdir/
+-rw-r--r--   0 runner    (1001) docker     (127)       81 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/projects/ApeProject/contracts/subdir/ApeContractNested.json
+-rw-r--r--   0 runner    (1001) docker     (127)       81 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/projects/ApeProject/contracts/subdir/ExcludeNested.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.755256 eth-ape-0.8.0/tests/functional/data/projects/BrownieProject/
+-rw-r--r--   0 runner    (1001) docker     (127)      217 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/projects/BrownieProject/brownie-config.yaml
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.755256 eth-ape-0.8.0/tests/functional/data/projects/BrownieProject/contractsrenamed/
+-rw-r--r--   0 runner    (1001) docker     (127)       73 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/projects/BrownieProject/contractsrenamed/brownie.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.695256 eth-ape-0.8.0/tests/functional/data/projects/LongContractsFolder/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.699256 eth-ape-0.8.0/tests/functional/data/projects/LongContractsFolder/source/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.755256 eth-ape-0.8.0/tests/functional/data/projects/LongContractsFolder/source/v0.1/
+-rw-r--r--   0 runner    (1001) docker     (127)       73 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/projects/LongContractsFolder/source/v0.1/long_contracts_folder.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.755256 eth-ape-0.8.0/tests/functional/data/python/
+-rw-r--r--   0 runner    (1001) docker     (127)    22650 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/python/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.759256 eth-ape-0.8.0/tests/functional/data/sources/
+-rw-r--r--   0 runner    (1001) docker     (127)     2687 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/sources/ContractA.sol
+-rw-r--r--   0 runner    (1001) docker     (127)     2359 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/sources/ContractB.sol
+-rw-r--r--   0 runner    (1001) docker     (127)     1128 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/sources/ContractC.sol
+-rw-r--r--   0 runner    (1001) docker     (127)      582 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/sources/HasError.sol
+-rw-r--r--   0 runner    (1001) docker     (127)      298 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/sources/Proxy.sol
+-rw-r--r--   0 runner    (1001) docker     (127)     1454 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/sources/RevertsContract.vy
+-rw-r--r--   0 runner    (1001) docker     (127)      252 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/sources/SolFallbackAndReceive.sol
+-rw-r--r--   0 runner    (1001) docker     (127)     8822 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/sources/SolidityContract.sol
+-rw-r--r--   0 runner    (1001) docker     (127)      100 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/sources/SubRevertsVy.vy
+-rw-r--r--   0 runner    (1001) docker     (127)      142 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/sources/VyDefault.vy
+-rw-r--r--   0 runner    (1001) docker     (127)     7053 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/sources/VyperContract.vy
+-rw-r--r--   0 runner    (1001) docker     (127)      232 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/sources/VyperFactory.vy
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.759256 eth-ape-0.8.0/tests/functional/data/sources/interfaces/
+-rw-r--r--   0 runner    (1001) docker     (127)       58 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/data/sources/interfaces/ISubReverts.vy
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.759256 eth-ape-0.8.0/tests/functional/geth/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/geth/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3057 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/geth/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3327 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/geth/test_contract.py
+-rw-r--r--   0 runner    (1001) docker     (127)      382 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/geth/test_contract_event.py
+-rw-r--r--   0 runner    (1001) docker     (127)      300 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/geth/test_ecosystem.py
+-rw-r--r--   0 runner    (1001) docker     (127)      863 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/geth/test_gas_tracker.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1281 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/geth/test_network_manager.py
+-rw-r--r--   0 runner    (1001) docker     (127)    18683 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/geth/test_provider.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1291 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/geth/test_query.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1801 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/geth/test_receipt.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10931 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/geth/test_trace.py
+-rw-r--r--   0 runner    (1001) docker     (127)      888 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/geth/text_proxy.py
+-rw-r--r--   0 runner    (1001) docker     (127)    32503 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_accounts.py
+-rw-r--r--   0 runner    (1001) docker     (127)      797 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_address.py
+-rw-r--r--   0 runner    (1001) docker     (127)      751 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_base_manager.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2240 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_block.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6664 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_block_container.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4957 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_chain.py
+-rw-r--r--   0 runner    (1001) docker     (127)    27423 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_cli.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6201 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_compilers.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10216 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_config.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2544 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_console.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2627 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_contract.py
+-rw-r--r--   0 runner    (1001) docker     (127)      247 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_contract_call_handler.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6183 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_contract_container.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13366 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_contract_event.py
+-rw-r--r--   0 runner    (1001) docker     (127)    32749 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_contract_instance.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1460 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_contract_method_handler.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14951 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_contracts_cache.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5738 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_coverage.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2774 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_default_sender_context_manager.py
+-rw-r--r--   0 runner    (1001) docker     (127)    17404 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_dependencies.py
+-rw-r--r--   0 runner    (1001) docker     (127)    65316 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_ecosystem.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2919 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_exceptions.py
+-rw-r--r--   0 runner    (1001) docker     (127)      753 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_fixtures.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1232 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_gas_tracker.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2361 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_history.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2746 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_logging.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2253 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_multicall.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6815 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_network_api.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13659 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_network_manager.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13972 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_plugins.py
+-rw-r--r--   0 runner    (1001) docker     (127)    28114 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_project.py
+-rw-r--r--   0 runner    (1001) docker     (127)    17323 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_provider.py
+-rw-r--r--   0 runner    (1001) docker     (127)      403 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_proxy.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3265 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_query.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8257 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_receipt.py
+-rw-r--r--   0 runner    (1001) docker     (127)      510 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_receipt_capture.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4786 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_reverts_context_manager.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6987 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_trace.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15166 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_transaction.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5275 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/test_types.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.763256 eth-ape-0.8.0/tests/functional/utils/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4285 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/utils/test_abi.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1437 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/utils/test_basemodel.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3080 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/utils/test_github.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4738 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/utils/test_misc.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6141 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/functional/utils/test_os.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.763256 eth-ape-0.8.0/tests/integration/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.763256 eth-ape-0.8.0/tests/integration/cli/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4835 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/conftest.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.699256 eth-ape-0.8.0/tests/integration/cli/projects/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.699256 eth-ape-0.8.0/tests/integration/cli/projects/bad-contracts/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.763256 eth-ape-0.8.0/tests/integration/cli/projects/bad-contracts/contracts/
+-rw-r--r--   0 runner    (1001) docker     (127)       28 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/bad-contracts/contracts/Contract.test
+-rw-r--r--   0 runner    (1001) docker     (127)       27 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/bad-contracts/contracts/Contract2.foo
+-rw-r--r--   0 runner    (1001) docker     (127)       92 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/bad-contracts/contracts/doc.md
+-rw-r--r--   0 runner    (1001) docker     (127)       81 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/bad-contracts/contracts/file_without_ext
+-rw-r--r--   0 runner    (1001) docker     (127)      171 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/bad-contracts/contracts/package.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.763256 eth-ape-0.8.0/tests/integration/cli/projects/bad-contracts/contracts/subdir/
+-rw-r--r--   0 runner    (1001) docker     (127)        4 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/bad-contracts/contracts/subdir/tsconfig.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.763256 eth-ape-0.8.0/tests/integration/cli/projects/bad-contracts/contracts/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/bad-contracts/contracts/tests/TestContract.foobar
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.763256 eth-ape-0.8.0/tests/integration/cli/projects/empty-config/
+-rw-r--r--   0 runner    (1001) docker     (127)       15 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/empty-config/ape-config.yaml
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.763256 eth-ape-0.8.0/tests/integration/cli/projects/geth/
+-rw-r--r--   0 runner    (1001) docker     (127)      869 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/geth/ape-config.yaml
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.767256 eth-ape-0.8.0/tests/integration/cli/projects/geth/contracts/
+-rw-r--r--   0 runner    (1001) docker     (127)     6444 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/geth/contracts/TokenA.json
+-rw-r--r--   0 runner    (1001) docker     (127)     6444 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/geth/contracts/TokenB.json
+-rw-r--r--   0 runner    (1001) docker     (127)    28131 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/geth/contracts/VyperContract.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.767256 eth-ape-0.8.0/tests/integration/cli/projects/geth/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)      354 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/geth/tests/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2800 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/geth/tests/test_using_local_geth.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.699256 eth-ape-0.8.0/tests/integration/cli/projects/multiple-interfaces/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.767256 eth-ape-0.8.0/tests/integration/cli/projects/multiple-interfaces/contracts/
+-rw-r--r--   0 runner    (1001) docker     (127)       73 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/multiple-interfaces/contracts/Interface-with-hyphens.json
+-rw-r--r--   0 runner    (1001) docker     (127)       53 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/multiple-interfaces/contracts/Interface.exclude.json
+-rw-r--r--   0 runner    (1001) docker     (127)       73 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/multiple-interfaces/contracts/Interface.json
+-rw-r--r--   0 runner    (1001) docker     (127)       73 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/multiple-interfaces/contracts/InterfaceWithNumber123.json
+-rw-r--r--   0 runner    (1001) docker     (127)       73 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/multiple-interfaces/contracts/Interface_with_underscores.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.767256 eth-ape-0.8.0/tests/integration/cli/projects/no-config/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/no-config/.gitkeep
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.767256 eth-ape-0.8.0/tests/integration/cli/projects/only-dependencies/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/only-dependencies/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)      394 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/only-dependencies/ape-config.yaml
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.767256 eth-ape-0.8.0/tests/integration/cli/projects/only-dependencies/dependency_in_project_only/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/only-dependencies/dependency_in_project_only/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)       75 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/only-dependencies/dependency_in_project_only/importme.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.767256 eth-ape-0.8.0/tests/integration/cli/projects/only-dependencies/dependency_in_project_only/sources/
+-rw-r--r--   0 runner    (1001) docker     (127)       73 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/only-dependencies/dependency_in_project_only/sources/DependencyInProjectOnly.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.699256 eth-ape-0.8.0/tests/integration/cli/projects/only-script-subdirs/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.699256 eth-ape-0.8.0/tests/integration/cli/projects/only-script-subdirs/scripts/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.767256 eth-ape-0.8.0/tests/integration/cli/projects/only-script-subdirs/scripts/subdirectory/
+-rw-r--r--   0 runner    (1001) docker     (127)      102 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/only-script-subdirs/scripts/subdirectory/subdirectory_click_print.py
+-rw-r--r--   0 runner    (1001) docker     (127)       66 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/only-script-subdirs/scripts/subdirectory/subdirectory_main_print.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.699256 eth-ape-0.8.0/tests/integration/cli/projects/script/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.767256 eth-ape-0.8.0/tests/integration/cli/projects/script/contracts/
+-rw-r--r--   0 runner    (1001) docker     (127)    28131 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/script/contracts/VyperContract.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.771256 eth-ape-0.8.0/tests/integration/cli/projects/script/scripts/
+-rw-r--r--   0 runner    (1001) docker     (127)       79 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/script/scripts/_utils.py
+-rw-r--r--   0 runner    (1001) docker     (127)      126 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/script/scripts/click.py
+-rw-r--r--   0 runner    (1001) docker     (127)      274 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/script/scripts/deploy.py
+-rw-r--r--   0 runner    (1001) docker     (127)      190 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/script/scripts/error_cli.py
+-rw-r--r--   0 runner    (1001) docker     (127)      283 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/script/scripts/error_forgot_click.py
+-rw-r--r--   0 runner    (1001) docker     (127)      198 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/script/scripts/error_main.py
+-rw-r--r--   0 runner    (1001) docker     (127)      169 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/script/scripts/error_no_def.py
+-rw-r--r--   0 runner    (1001) docker     (127)      357 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/script/scripts/output_contract_view_methods.py
+-rw-r--r--   0 runner    (1001) docker     (127)      240 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/script/scripts/site.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.771256 eth-ape-0.8.0/tests/integration/cli/projects/script/scripts/subdirectory/
+-rw-r--r--   0 runner    (1001) docker     (127)      102 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/script/scripts/subdirectory/subdirectory_click_print.py
+-rw-r--r--   0 runner    (1001) docker     (127)       66 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/script/scripts/subdirectory/subdirectory_main_print.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.771256 eth-ape-0.8.0/tests/integration/cli/projects/test/
+-rw-r--r--   0 runner    (1001) docker     (127)       92 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/test/ape-config.yaml
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.771256 eth-ape-0.8.0/tests/integration/cli/projects/test/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)      955 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/test/tests/test_fixture_isolation.py
+-rw-r--r--   0 runner    (1001) docker     (127)      852 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/test/tests/test_fixtures.py
+-rw-r--r--   0 runner    (1001) docker     (127)      747 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/test/tests/test_networks.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.771256 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/
+-rw-r--r--   0 runner    (1001) docker     (127)      485 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/ape-config.yaml
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.771256 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/contracts/
+-rw-r--r--   0 runner    (1001) docker     (127)     2727 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/contracts/ContractA.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.771256 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/contracts/DirectoryWithJSONExtension.json/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/contracts/DirectoryWithJSONExtension.json/.gitkeep
+-rw-r--r--   0 runner    (1001) docker     (127)       16 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/contracts/Exclude.json
+-rw-r--r--   0 runner    (1001) docker     (127)    41634 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/contracts/RawSolidityOutput.json
+-rw-r--r--   0 runner    (1001) docker     (127)    64327 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/contracts/RawVyperOutput.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.771256 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/contracts/exclude_dir/
+-rw-r--r--   0 runner    (1001) docker     (127)       16 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/contracts/exclude_dir/UnwantedContract.json
+-rw-r--r--   0 runner    (1001) docker     (127)      103 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/contracts/hyphen-Contract.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.699256 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/dep/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.771256 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/dep/contracts/
+-rw-r--r--   0 runner    (1001) docker     (127)    64326 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/dep/contracts/RawVyperOutputDep.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.771256 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/dep_contracts_folder_root/
+-rw-r--r--   0 runner    (1001) docker     (127)    64326 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/dep_contracts_folder_root/RawVyperOutputDepNoContractsFolder.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.771256 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/scripts/
+-rw-r--r--   0 runner    (1001) docker     (127)      263 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/scripts/txerr.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.771256 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)      212 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/tests/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (127)      578 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/tests/test_contract.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.771256 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/
+-rw-r--r--   0 runner    (1001) docker     (127)      596 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/ape-config.yaml
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.771256 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/containing_sub_dependencies/
+-rw-r--r--   0 runner    (1001) docker     (127)       67 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/containing_sub_dependencies/ape-config.yaml
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.775256 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/containing_sub_dependencies/contracts/
+-rw-r--r--   0 runner    (1001) docker     (127)       73 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/containing_sub_dependencies/contracts/containing_sub_dependencies.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.703256 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/containing_sub_dependencies/sub_dependency/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.775256 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/containing_sub_dependencies/sub_dependency/contracts/
+-rw-r--r--   0 runner    (1001) docker     (127)       73 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/containing_sub_dependencies/sub_dependency/contracts/sub-dependency.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.775256 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/contracts/
+-rw-r--r--   0 runner    (1001) docker     (127)       73 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/contracts/Other.json
+-rw-r--r--   0 runner    (1001) docker     (127)       73 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/contracts/Project.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.703256 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/default/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.775256 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/default/contracts/
+-rw-r--r--   0 runner    (1001) docker     (127)       73 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/default/contracts/default.json
+-rw-r--r--   0 runner    (1001) docker     (127)      113 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/default/contracts/hyphen-DependencyContract.json
+-rw-r--r--   0 runner    (1001) docker     (127)      455 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/manifest_dependency.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.703256 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/renamed_complex_contracts_folder/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.703256 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/renamed_complex_contracts_folder/contracts/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.703256 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/renamed_complex_contracts_folder/contracts/src/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.775256 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/renamed_complex_contracts_folder/contracts/src/v0.1/
+-rw-r--r--   0 runner    (1001) docker     (127)       73 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/renamed_complex_contracts_folder/contracts/src/v0.1/renamed_complex_contracts_folder.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.703256 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/renamed_contracts_folder/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.775256 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/renamed_contracts_folder/sources/
+-rw-r--r--   0 runner    (1001) docker     (127)       73 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/renamed_contracts_folder/sources/renamed_contracts_folder.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.775256 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/renamed_contracts_folder_specified_in_config/
+-rw-r--r--   0 runner    (1001) docker     (127)       31 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/renamed_contracts_folder_specified_in_config/ape-config.yaml
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-31 16:37:47.775256 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/renamed_contracts_folder_specified_in_config/my_contracts/
+-rw-r--r--   0 runner    (1001) docker     (127)       73 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/projects/with-dependencies/renamed_contracts_folder_specified_in_config/my_contracts/renamed_contracts_folder_specified_in_config.json
+-rw-r--r--   0 runner    (1001) docker     (127)    12497 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/test_accounts.py
+-rw-r--r--   0 runner    (1001) docker     (127)      475 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/test_cache.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13398 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/test_compile.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8233 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/test_console.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2225 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/test_init.py
+-rw-r--r--   0 runner    (1001) docker     (127)      733 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/test_misc.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6374 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/test_networks.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5849 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/test_plugins.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8501 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/test_pm.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7734 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/test_run.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13531 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/test_test.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4230 2024-05-31 16:36:56.000000 eth-ape-0.8.0/tests/integration/cli/utils.py
```

### Comparing `eth-ape-0.7.9/.github/ISSUE_TEMPLATE/bug.md` & `eth-ape-0.8.0/.github/ISSUE_TEMPLATE/bug.md`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/.github/ISSUE_TEMPLATE/feature.md` & `eth-ape-0.8.0/.github/ISSUE_TEMPLATE/feature.md`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/.github/ISSUE_TEMPLATE/work-item.md` & `eth-ape-0.8.0/.github/ISSUE_TEMPLATE/work-item.md`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/.github/PULL_REQUEST_TEMPLATE.md` & `eth-ape-0.8.0/.github/PULL_REQUEST_TEMPLATE.md`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/.github/release-drafter.yml` & `eth-ape-0.8.0/.github/release-drafter.yml`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/.github/workflows/codeql.yml` & `eth-ape-0.8.0/.github/workflows/codeql.yml`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/.github/workflows/commitlint.yaml` & `eth-ape-0.8.0/.github/workflows/commitlint.yaml`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/.github/workflows/docs.yaml` & `eth-ape-0.8.0/.github/workflows/docs.yaml`

 * *Files 26% similar despite different names*

```diff
@@ -8,14 +8,17 @@
     pull_request:
         types: [opened, synchronize]
 
 jobs:
     docs:
         runs-on: ubuntu-latest
 
+        permissions:
+          contents: write
+
         steps:
         - uses: actions/checkout@v4
 
         - name: Setup Python
           uses: actions/setup-python@v5
           with:
               python-version: "3.10"
@@ -30,14 +33,25 @@
 
         - name: Upload HTML artifact
           uses: actions/upload-artifact@v4
           with:
               name: DocumentationHTML
               path: docs/_build/ape
 
+        - name: Doctesting
+          run: |
+            sphinx-build -b doctest docs docs/_build/doctest
+            if grep -q '0 failed' docs/_build/doctest/output.txt; then
+              echo "All doctests passed!"
+            else
+              echo "Some doctests failed. See the output below."
+              cat docs/_build/doctest/output.txt
+              exit 1
+            fi
+
         - name: Commit and publish documentation changes to gh-pages branch
           run: |
               if [[ "${GITHUB_EVENT_NAME}" =~ "pull_request" ]]; then
                 echo "skipping 'git commit' step for PR"
               else
                 git clone https://github.com/${GITHUB_REPOSITORY} --branch gh-pages --single-branch gh-pages
                 cp -r docs/_build/ape/* gh-pages/
@@ -51,7 +65,8 @@
         - name: Push changes
           uses: ad-m/github-push-action@master
           if: ${{ github.event_name != 'pull_request' }}
           with:
               branch: gh-pages
               directory: gh-pages
               github_token: ${{ secrets.GITHUB_TOKEN }}
+
```

### Comparing `eth-ape-0.7.9/.github/workflows/prtitle.yaml` & `eth-ape-0.8.0/.github/workflows/prtitle.yaml`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/.github/workflows/publish.yaml` & `eth-ape-0.8.0/.github/workflows/publish.yaml`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/.github/workflows/stale-prs.yml` & `eth-ape-0.8.0/.github/workflows/stale-prs.yml`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/.github/workflows/test.yaml` & `eth-ape-0.8.0/.github/workflows/test.yaml`

 * *Files 5% similar despite different names*

```diff
@@ -58,16 +58,18 @@
           run: mypy .
 
     functional:
         runs-on: ${{ matrix.os }}
 
         strategy:
             matrix:
-                os: [ubuntu-latest, macos-latest]   # eventually add `windows-latest`
-                python-version: [3.8, 3.9, "3.10", "3.11"]
+                # TODO: Replace with macos-latest when works again.
+                #   https://github.com/actions/setup-python/issues/808
+                os: [ubuntu-latest, macos-12]   # eventually add `windows-latest`
+                python-version: [3.9, "3.10", "3.11", "3.12"]
 
         env:
           GITHUB_ACCESS_TOKEN: ${{ secrets.GITHUB_TOKEN }}
 
         steps:
         - uses: actions/checkout@v4
           with:
```

### Comparing `eth-ape-0.7.9/.gitignore` & `eth-ape-0.8.0/.gitignore`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/.pre-commit-config.yaml` & `eth-ape-0.8.0/.pre-commit-config.yaml`

 * *Files 14% similar despite different names*

```diff
@@ -1,35 +1,36 @@
 repos:
 -   repo: https://github.com/pre-commit/pre-commit-hooks
-    rev: v4.5.0
+    rev: v4.6.0
     hooks:
     -   id: check-yaml
 
--   repo: https://github.com/pre-commit/mirrors-isort
-    rev: v5.10.1
+-   repo: https://github.com/PyCQA/isort
+    rev: 5.13.2
     hooks:
       - id: isort
 
 -   repo: https://github.com/psf/black
-    rev: 24.1.1
+    rev: 24.4.2
     hooks:
       - id: black
         name: black
 
 -   repo: https://github.com/pycqa/flake8
     rev: 7.0.0
     hooks:
     -   id: flake8
 
 -   repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.8.0
+    rev: v1.10.0
     hooks:
     -   id: mypy
         additional_dependencies: [
                 types-PyYAML,
+                types-python-dateutil,
                 types-requests,
                 types-setuptools,
                 pydantic,
                 pandas-stubs,
                 types-SQLAlchemy
         ]
```

### Comparing `eth-ape-0.7.9/CONTRIBUTING.md` & `eth-ape-0.8.0/CONTRIBUTING.md`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/Dockerfile` & `eth-ape-0.8.0/Dockerfile`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 #---------------------------------------------------------------------------------------------
 # See LICENSE in the project root for license information.
 #---------------------------------------------------------------------------------------------
 
-ARG PYTHON_VERSION="3.10"
+ARG PYTHON_VERSION="3.11"
 ARG PLUGINS_FILE="./recommended-plugins.txt"
 
 FROM python:${PYTHON_VERSION} as builder
 
 WORKDIR /wheels
 
 COPY ./recommended-plugins.txt ./recommended-plugins.txt
```

### Comparing `eth-ape-0.7.9/LICENSE` & `eth-ape-0.8.0/LICENSE`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/PKG-INFO` & `eth-ape-0.8.0/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: eth-ape
-Version: 0.7.9
+Version: 0.8.0
 Summary: Ape Ethereum Framework
 Home-page: https://apeworx.io
 Author: ApeWorX Ltd.
 Author-email: admin@apeworx.io
 License: Apache-2.0
 Project-URL: Documentation, https://docs.apeworx.io/ape/
 Project-URL: Funding, https://gitcoin.co/grants/5958/ape-maintenance-fund
@@ -15,19 +15,19 @@
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Developers
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Natural Language :: English
 Classifier: Operating System :: MacOS
 Classifier: Operating System :: POSIX
 Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
-Requires-Python: >=3.8,<4
+Classifier: Programming Language :: Python :: 3.12
+Requires-Python: >=3.9,<4
 Description-Content-Type: text/markdown
 Provides-Extra: test
 Provides-Extra: lint
 Provides-Extra: doc
 Provides-Extra: release
 Provides-Extra: dev
 Provides-Extra: recommended-plugins
@@ -58,15 +58,15 @@
 Read our [academic platform](https://academy.apeworx.io/) will help you master Ape Framework with tutorials and challenges.
 
 ## Prerequisite
 
 In the latest release, Ape requires:
 
 - Linux or macOS
-- Python 3.8 up to 3.11
+- Python 3.9 up to 3.12
 - **Windows**: Install Windows Subsystem Linux [(WSL)](https://docs.microsoft.com/en-us/windows/wsl/install)
 
 Check your python version in a terminal with `python3 --version`.
 
 ## Installation
 
 There are three ways to install ape: `pipx`, `pip`, or `Docker`.
```

### Comparing `eth-ape-0.7.9/README.md` & `eth-ape-0.8.0/README.md`

 * *Files 0% similar despite different names*

```diff
@@ -23,15 +23,15 @@
 Read our [academic platform](https://academy.apeworx.io/) will help you master Ape Framework with tutorials and challenges.
 
 ## Prerequisite
 
 In the latest release, Ape requires:
 
 - Linux or macOS
-- Python 3.8 up to 3.11
+- Python 3.9 up to 3.12
 - **Windows**: Install Windows Subsystem Linux [(WSL)](https://docs.microsoft.com/en-us/windows/wsl/install)
 
 Check your python version in a terminal with `python3 --version`.
 
 ## Installation
 
 There are three ways to install ape: `pipx`, `pip`, or `Docker`.
```

### Comparing `eth-ape-0.7.9/SECURITY.md` & `eth-ape-0.8.0/SECURITY.md`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/build_docs.py` & `eth-ape-0.8.0/build_docs.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/docs/_static/custom.css` & `eth-ape-0.8.0/docs/_static/custom.css`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/docs/_static/custom.js` & `eth-ape-0.8.0/docs/_static/custom.js`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/docs/_templates/layout.html` & `eth-ape-0.8.0/docs/_templates/layout.html`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/docs/conf.py` & `eth-ape-0.8.0/docs/conf.py`

 * *Files 10% similar despite different names*

```diff
@@ -5,20 +5,20 @@
 # full list see the documentation:
 # https://www.sphinx-doc.org/en/master/config
 # -- Path setup --------------------------------------------------------------
 # If extensions (or modules to document with autodoc) are in another directory,
 # add these directories to sys.path here. If the directory is relative to the
 # documentation root, use os.path.abspath to make it absolute, like shown here.
 #
+import doctest
 import os
 import re
 import sys
 from functools import lru_cache
 from pathlib import Path
-from typing import List
 
 import requests
 from packaging.version import Version
 
 sys.path.insert(0, os.path.abspath(".."))
 
 # -- Project information -----------------------------------------------------
@@ -27,27 +27,28 @@
 copyright = "2023, ApeWorX LTD"
 author = "ApeWorX Team"
 extensions = [
     "myst_parser",
     "sphinx_click",
     "sphinx.ext.autodoc",
     "sphinx.ext.autosummary",
+    "sphinx.ext.doctest",
     "sphinx.ext.napoleon",
     "sphinx_rtd_theme",
     "sphinx_plausible",
 ]
 autosummary_generate = True
 
 # Add any paths that contain templates here, relative to this directory.
 templates_path = ["_templates"]
 
 # List of patterns, relative to source directory, that match files and
 # directories to ignore when looking for source files.
 # This pattern also affects html_static_path and html_extra_path.
-exclude_patterns: List[str] = ["_build", ".DS_Store"]
+exclude_patterns: list[str] = ["_build", ".DS_Store"]
 
 
 # The suffix(es) of source filenames.
 # You can specify multiple suffix as a list of string:
 source_suffix = [".rst", ".md"]
 
 # The master toctree document.
@@ -80,14 +81,28 @@
 myst_all_links_external = True
 
 # Set some default to avoid unnecessary repetitious directives.
 autodoc_default_options = {
     "exclude-members": "__repr__,__weakref__,__metaclass__,__init__,model_config,model_fields,model_post_init"
 }
 
+# -- Doctest configuration -------------------------------------------------
+
+doctest_default_flags = (
+    0
+    | doctest.DONT_ACCEPT_TRUE_FOR_1
+    | doctest.ELLIPSIS
+    | doctest.IGNORE_EXCEPTION_DETAIL
+    | doctest.NORMALIZE_WHITESPACE
+)
+
+doctest_global_setup = """
+from ape import *
+"""
+
 
 def fixpath(path: str) -> str:
     """
     Change paths to reference the resources from 'latest/' to save room.
     """
     suffix = path.split("_static")[1]
     new = f"/{project}/latest/_static"
@@ -95,15 +110,15 @@
     if suffix:
         new = str(Path(new) / suffix.lstrip("/"))
 
     return new
 
 
 @lru_cache(maxsize=None)
-def get_versions() -> List[str]:
+def get_versions() -> list[str]:
     """
     Get all the versions from the Web.
     """
     api_url = "https://api.github.com/repos/ApeWorx/ape/git/trees/gh-pages?recursive=1"
     response = requests.get(api_url)
     response.raise_for_status()
     pattern = re.compile(r"v\d+.?\d+.?\d+$")
```

### Comparing `eth-ape-0.7.9/docs/favicon.ico` & `eth-ape-0.8.0/docs/favicon.ico`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/docs/index.md` & `eth-ape-0.8.0/docs/index.md`

 * *Files 24% similar despite different names*

```diff
@@ -21,14 +21,15 @@
    userguides/console
    userguides/contracts
    userguides/proxy
    userguides/testing
    userguides/scripts
    userguides/publishing
    userguides/logging
+   userguides/trace
 ```
 
 ```{eval-rst}
 .. toctree::
    :caption: CLI Reference
    :maxdepth: 1
 
@@ -41,21 +42,30 @@
    commands/plugins.rst
    commands/run.rst
    commands/test.rst
 ```
 
 ```{eval-rst}
 .. toctree::
-   :caption: Python Reference
+   :caption: Core Python Reference
    :maxdepth: 1
 
    methoddocs/ape.md
-   methoddocs/ape_accounts.md
    methoddocs/api.md
    methoddocs/cli.md
    methoddocs/contracts.md
    methoddocs/exceptions.md
    methoddocs/managers.md
    methoddocs/plugins.md
    methoddocs/types.md
    methoddocs/utils.md
 ```
+
+```{eval-rst}
+.. toctree::
+   :caption: Plugin Python Reference
+   :maxdepth: 1
+
+   methoddocs/ape_accounts.md
+   methoddocs/ape_compile.md
+   methoddocs/ape_pm.md
+```
```

### Comparing `eth-ape-0.7.9/docs/logo.gif` & `eth-ape-0.8.0/docs/logo.gif`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/docs/methoddocs/api.md` & `eth-ape-0.8.0/docs/methoddocs/api.md`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/docs/methoddocs/cli.md` & `eth-ape-0.8.0/docs/methoddocs/cli.md`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/docs/methoddocs/contracts.md` & `eth-ape-0.8.0/docs/methoddocs/contracts.md`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/docs/methoddocs/managers.md` & `eth-ape-0.8.0/docs/methoddocs/managers.md`

 * *Files 22% similar despite different names*

```diff
@@ -68,39 +68,15 @@
 .. automodule:: ape.managers.networks
     :members:
 ```
 
 ## Project
 
 ```{eval-rst}
-.. automodule:: ape.managers.project.manager
-    :members:
-    :special-members:
-```
-
-```{eval-rst}
-.. automodule:: ape.managers.project.dependency
-    :members:
-    :special-members:
-```
-
-```{eval-rst}
-.. autoclass:: ape.managers.project.types.BaseProject
-    :members:
-    :special-members:
-```
-
-```{eval-rst}
-.. autoclass:: ape.managers.project.types.ApeProject
-    :members:
-    :special-members:
-```
-
-```{eval-rst}
-.. autoclass:: ape.managers.project.types.BrownieProject
+.. automodule:: ape.managers.project
     :members:
     :special-members:
 ```
 
 ## Query
 
 ```{eval-rst}
```

### Comparing `eth-ape-0.7.9/docs/methoddocs/plugins.md` & `eth-ape-0.8.0/docs/methoddocs/plugins.md`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/docs/methoddocs/types.md` & `eth-ape-0.8.0/docs/methoddocs/types.md`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/docs/userguides/accounts.md` & `eth-ape-0.8.0/docs/userguides/accounts.md`

 * *Files 2% similar despite different names*

```diff
@@ -25,18 +25,21 @@
     ...
 ```
 
 ### Use test accounts outside of tests
 
 To access the same prefunded accounts in your scripts or console, use the root `accounts` object and the [test_accounts](../methoddocs/managers.html#ape.managers.accounts.AccountManager.test_accounts) property:
 
-```python
-from ape import accounts
+```{eval-rst}
+
+.. doctest::
+
+>>> from ape import accounts
 
-sender = accounts.test_accounts[0]
+>>> sender = accounts.test_accounts[0]
 ```
 
 You can configure your test accounts using your `ape-config.yaml` file:
 
 ```yaml
 test:
   mnemonic: test test test test test test test test test test test junk
@@ -46,18 +49,21 @@
 **WARN**: NEVER put a seed phrase with real funds here.
 The accounts generated from this seed are solely for testing and debugging purposes.
 
 ### Creating new test accounts
 
 You can create a new test account by doing the following:
 
-```python
-from ape import accounts
+```{eval-rst}
+
+.. doctest::
+
+>>> from ape import accounts
 
-account = accounts.test_accounts.generate_test_account()
+>>> account = accounts.test_accounts.generate_test_account()
 ```
 
 **NOTE**: Creating a new test account means it will be unfunded by default.
 
 Learn more about test accounts from the [testing guide](./testing.html#accounts-fixture).
 
 If your testing provider supports this feature, it is possible to directly set the balances of any address by performing the following action:
@@ -177,30 +183,30 @@
 
 If you use the `--hd-path` option, you will need to pass the [HDPath](https://help.myetherwallet.com/en/articles/5867305-hd-wallets-and-derivation-paths) you'd like to use as an argument in the command.
 If you do not use the `--hd-path` option, Ape will use the default HDPath of (Ethereum network, first account).
 
 You can import an account programatically using a seed phrase [using `import_account_from_mnemonic()`](../methoddocs/ape_accounts.html#ape_accounts.import_account_from_mnemonic):
 
 ```python
-from ape_acounts import import_account_from_mnemonic
+from ape_accounts import import_account_from_mnemonic
 
 alias = "my-account"
 passphrase = "my$ecurePassphrase"
 mnemonic = "test test test test test test test test test test test junk"
 
 account = import_account_from_mnemonic(alias, passphrase, mnemonic)
 
 print(f'Your imported account address is: {account.address}')
 ```
 
 Or using a raw private key [using `import_account_from_private_key()`](../methoddocs/ape_accounts.html#ape_accounts.import_account_from_private_key):
 
 ```python
 import os
-from ape_acounts import import_account_from_private_key
+from ape_accounts import import_account_from_private_key
 
 alias = "my-account"
 passphrase = "my SecurePassphrase"
 private_key = os.urandom(32).hex()
 
 account = import_account_from_private_key(alias, passphrase, private_key)
 
@@ -288,15 +294,15 @@
     _name_: "string" = "Ether Mail"
     _verifyingContract_: "address" = "0xCcCCccccCCCCcCCCCCCcCcCccCcCCCcCcccccccC"
     _version_: "string" = "1"
 
     sender: Person
     receiver: Person
 
-alice = Person(name="Alice", wallet="0xCD2a3d9F938E13CD947Ec05AbC7FE734Df8DD826") 
+alice = Person(name="Alice", wallet="0xCD2a3d9F938E13CD947Ec05AbC7FE734Df8DD826")
 bob = Person("Bob", "0xB0B0b0b0b0b0B000000000000000000000000000")
 message = Mail(sender=alice, receiver=bob)
 
 account = accounts.load("<ALIAS>")
 account.sign_message(message)
 ```
```

### Comparing `eth-ape-0.7.9/docs/userguides/clis.md` & `eth-ape-0.8.0/docs/userguides/clis.md`

 * *Files 12% similar despite different names*

```diff
@@ -40,16 +40,16 @@
 from ape.cli import ApeCliContextObject, ape_cli_context
 import click
 
 class MyManager:
    """My custom manager."""
 
 class CustomContext(ApeCliContextObject):
-   """Add new managers to your custom context"""
    my_manager: MyManager = MyManager()
+   """Add new managers to your custom context"""
    
    @property
    def signer(self):
       """Utilize existing managers in your custom context."""
       return self.account_manager.load("my_account")
 
 @click.command()
@@ -203,18 +203,43 @@
 # NOTE: This is just an example and not anything specific or recommended.
 APPLICATION_PREFIX = "<FOO_BAR>"
 
 @click.command()
 @existing_alias_argument(account_type=KeyfileAccount)
 def cli_0(alias):
    pass
-   
+
 @click.command()
 @existing_alias_argument(account_type=lambda a: a.alias.startswith(APPLICATION_PREFIX))
 def cli_1(alias):
    pass
-    
-   
+
 # Select from the given accounts directly.
 my_accounts = [accounts.load("me"), accounts.load("me2")]
 selected_account = get_user_selected_account(account_type=my_accounts)
 ```
+
+## Contract File Paths
+
+Does your CLI interact with contract source files?
+(Think `ape compile`).
+
+If so, use the `@contract_file_paths_argument()` decorator in your CLI.
+
+```python
+from pathlib import Path
+import click
+
+from ape.cli import contract_file_paths_argument
+
+@click.command()
+@contract_file_paths_argument()
+def cli(file_paths: set[Path]):
+   # Loop through all source files given (or all source files in the project).
+    for path in file_paths:
+        click.echo(f"Source found: {path}")
+```
+
+When using the `@contract_file_paths_argument()` decorator, you can pass any number of source files as arguments.
+When not passing any source file(s), `@contract_file_paths_argument()` defaults to all sources in the local project.
+That is why `ape compile` compiles the full project and `ape compile MySource.vy` only compiles `MySource.vy` (and whatever else it needs / imports).
+Use `@contract_file_paths_argument()` for any similar use-case involving contract source files.
```

### Comparing `eth-ape-0.7.9/docs/userguides/compile.md` & `eth-ape-0.8.0/docs/userguides/compile.md`

 * *Files 15% similar despite different names*

```diff
@@ -43,30 +43,32 @@
 
 ## Other Compiler Plugins
 
 If your project includes Solidity (`.sol`) or Vyper (`.vy`) files, you will have to install additional compilers.
 To include additional compilers in your project, you can add the plugins to the `plugins` list in your `ape-config.yaml` or install them using the CLI.
 For information on how to configure plugins in your project, follow [this guide](./installing_plugins.html).
 
-## Ignore Files
+## Exclude Files
 
-You can configure files to be ignored from compilation.
-By default, Ape ignores files `package.json`, `package-lock.json`, `tsconfig.json`.
-To override this list, edit your `ape-config.yaml` similarly:
+You can configure files to be excluded from compilation.
+By default, Ape excludes known non-contract files such as `package.json`, `package-lock.json`, `tsconfig.json`, or `.DS_Store`.
+To append file-globs to the exclusions list, edit your `compile:exclude` config like this:
 
 ```yaml
 compile:
   exclude:
-    - "*package.json"
-    - "*package-lock.json"
-    - "*tsconfig.json"
-    - "*custom.json"  # Append a custom ignore
+    - "examples"  # Exclude all files in the examples/ directory
+    - "*Mock.sol"  # Exclude all files ending in Mock.sol
 ```
 
-**NOTE**: You must include the defaults in the list when overriding if you wish to retain them.
+You can also exclude files using the `--config-override` CLI option:
+
+```shell
+ape compile --config-override '{"compile": {"exclude": ["*Mock.sol"]}}'
+```
 
 ## Dependencies
 
 In Ape, compiler plugins typically let you have dependencies.
 See [this guide](./dependencies.html) to learn more about configuring dependencies in Ape.
 
 To always compile dependencies in Ape during the `ape compile` command, use the CLI flag `--include-dependencies`:
@@ -81,22 +83,30 @@
 compile:
   use_dependencies: true
 ```
 
 ## Settings
 
 Generally, configure compiler plugins using your `ape-config.yaml` file.
+
 For example, when using the `vyper` plugin, you can configure settings under the `vyper` key:
 
 ```yaml
 vyper:
   version: 0.3.10
 ```
 
-You can also configure adhoc settings in Python code:
+When using the CLI, you can also specify settings using the `--config-override`.
+This is not limited to compiler settings; you can include other settings, such as `"contracts_folder"`, which affects compiling.
+
+```shell
+ape compile --config-override '{"contracts_folder": "other_contracts", "vyper": {"evm_version": "paris"}, "solidity": {"evm_version": "paris"}}'
+```
+
+Finally, you can also configure settings in Python code:
 
 ```python
 from pathlib import Path
 from ape import compilers
 
 settings = {"vyper": {"version": "0.3.7"}, "solidity": {"version": "0.8.0"}}
 compilers.compile(
@@ -129,7 +139,23 @@
    contractName="MyContract",
 )
 
 owner = accounts.test_accounts[0]
 
 instance = container.deploy(sender=owner)
 ```
+
+## Output Extra
+
+Sometimes, there are extra output styles you may want.
+For example, to output minified ABI JSONs, use the following config:
+
+```yaml
+compile:
+  output_extra:
+     - ABI
+```
+
+Then, after compiling, you should notice minified ABI json files in your `.build/abi` folder.
+This is useful if hosting these files on a web-server.
+
+To see the full list of supported output-extra, see [the OutpuExtra enum documentation](../methoddocs/ape_compile.html#ape_compile.OutputExtras).
```

### Comparing `eth-ape-0.7.9/docs/userguides/config.md` & `eth-ape-0.8.0/docs/userguides/config.md`

 * *Files 2% similar despite different names*

```diff
@@ -68,15 +68,15 @@
 
 ```yaml
 deployments:
   ethereum:
     mainnet:
       - contract_type: MyContract
         address: 0x5FbDB2315678afecb367f032d93F642f64180aa3
-    goerli:
+    sepolia:
       - contract_type: MyContract
         address: 0xe7f1725E7734CE288F8367e1Bb143E90bb3F0512
 ```
 
 When connected to Ethereum mainnet, reference the deployment by doing:
 
 ```python
@@ -95,17 +95,17 @@
 ```yaml
 geth:
   ethereum:
     mainnet:
       uri: http://localhost:5030
 ```
 
-Now, the `ape-geth` core plugin will use the URL `http://localhost:5030` to connect and make requests.
+Now, the `ape-node` core plugin will use the URL `http://localhost:5030` to connect and make requests.
 
-**WARN**: Instead of using `ape-geth` to connect to an Infura or Alchemy node, use the [ape-infura](https://github.com/ApeWorX/ape-infura) or [ape-alchemy](https://github.com/ApeWorX/ape-alchemy) provider plugins instead, which have their own way of managing API keys via environment variables.
+**WARN**: Instead of using `ape-node` to connect to an Infura or Alchemy node, use the [ape-infura](https://github.com/ApeWorX/ape-infura) or [ape-alchemy](https://github.com/ApeWorX/ape-alchemy) provider plugins instead, which have their own way of managing API keys via environment variables.
 
 For more information on networking as a whole, see [this guide](./networks.html).
 
 ## Networks
 
 Set default network and network providers:
```

### Comparing `eth-ape-0.7.9/docs/userguides/console.md` & `eth-ape-0.8.0/docs/userguides/console.md`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/docs/userguides/contracts.md` & `eth-ape-0.8.0/docs/userguides/contracts.md`

 * *Files 5% similar despite different names*

```diff
@@ -174,38 +174,53 @@
 
 ## Contract Interaction
 
 Then, after you have a contract instance, you can call methods on the contract.
 For example, let's say you have a Vyper contract containing some functions:
 
 ```python
+wdAmount: public(uint256)
+
 @pure
 @external
 def get_static_list() -> DynArray[uint256, 3]:
     return [1, 2, 3]
 
 @external
 def set_number(num: uint256):
     assert msg.sender == self.owner, "!authorized"
     self.prevNumber = self.myNumber
     self.myNumber = num
+
+@external
+@payable
+def withdraw():
+    self.wdAmount = msg.value
 ```
 
-Notice the contract has both an external pure method and an external method that modifies state.
+Notice the contract has an external pure method, an external method that modifies state, and an external payable method that also modifies state using the given `msg.value`.
 In EVM languages, methods that modify state require a transaction to execute because they cost money.
 Modifying the storage of a contract requires gas and thus requires a sender with enough funding.
+Methods that accept value are `payable` (e.g. `msg.value` in Vyper); provide additional value (e.g. Ether) to these methods.
 Contract calls, on the other hand, are read-operations and do not cost anything.
+Calls are never payable.
 Thus, calls do not require specifying a `sender=` in Ape.
 
 At the RPC level, Ethereum calls are performed using the `eth_call` RPC and transactions are performed using the `eth_sendTransaction` or `eth_sendRawTransaction` RPCs.
 
+The following sub-sections show how, using Ape, we can invoke or call the methods defined above.
+
 ### Transactions
 
 The following example demonstrates invoking a contract's method in Ape as a transaction.
-However, take note that there is a [separate guide](./transactions.html) which fully covers transactions in Ape.
+Remember: transactions cost money, whether they are payable or not.
+Payable transactions cost more money, because the contract-logic requires additional value (e.g. Ether) to be forwarded with the call.
+
+Before continuing, take note that there is a [separate guide](./transactions.html) which fully covers transactions in Ape at a more granular level.
+For this guide, assume we are using the default transaction type in Ape for Ethereum-based networks.
 
 ```python
 from ape import accounts, Contract
 
 account = accounts.load("<ALIAS>")
 contract = Contract("0x...")  # Assume is deployed version of code above
 
@@ -213,17 +228,29 @@
 receipt = contract.set_number(sender=account)
 assert not receipt.failed
 
 # The receipt contains data such as `gas_used`.
 print(receipt.gas_used)
 ```
 
+To provider additional value to a payable method, use the `value=` kwarg:
+
+```python
+receipt = contract.withdraw(sender=account, value=123)
+print(receipt.gas_used)
+
+# NOTE: You can also use "smart" values such as `"0.1 ether"` or `"100 gwei"`:
+_ = contract.withdraw(sender=account, value="0.1 ether")
+_ = contract.withdraw(sender=account, value="100 gwei")
+_ = contract.withdraw(sender=account, value="1 wei")
+```
+
 Notice that transacting returns a [ReceiptAPI](../methoddocs/api.html#ape.api.transactions.ReceiptAPI) object which contains all the receipt data, such as `gas_used`.
 
-**NOTE**: If you need the `return_value` from a transaction, you have to either treat transaction as a call (see the section below!) or use a provider with tracing-features enabled (such as `ape-foundry` or `ape-geth`) and access the [return_value](../methoddocs/api.html#ape.api.transactions.ReceiptAPI.return_value) property on the receipt.
+**NOTE**: If you need the `return_value` from a transaction, you have to either treat transaction as a call (see the section below!) or use a provider with tracing-features enabled (such as `ape-foundry` or `ape-node`) and access the [return_value](../methoddocs/api.html#ape.api.transactions.ReceiptAPI.return_value) property on the receipt.
 
 ```python
 assert receipt.return_value == 123
 ```
 
 For more general information on transactions in the Ape framework, see [this guide](./transactions.html).
 
@@ -395,29 +422,27 @@
 
 Here is an example of how you can use the multicall module:
 
 ```python
 import ape
 from ape_ethereum import multicall
 
-
 ADDRESSES = ("0xF4b8A02D4e8D76070bD7092B54D2cBbe90fa72e9", "0x80067013d7F7aF4e86b3890489AcAFe79F31a4Cb")
 POOLS = [ape.project.IPool.at(a) for a in ADDRESSES]
 
-
 def main():
     # Use multi-call.
     call = multicall.Call()
     for pool in POOLS:
         call.add(pool.getReserves)
-    
+
     print(list(call()))
-    
+
     # Use multi-transaction.
     tx = multicall.Transaction()
     for pool in POOLS:
         tx.add(pool.ApplyDiscount, 123)
-    
+
     acct = ape.accounts.load("signer")
     for result in tx(sender=acct):
         print(result)
 ```
```

### Comparing `eth-ape-0.7.9/docs/userguides/data.md` & `eth-ape-0.8.0/docs/userguides/data.md`

 * *Files 4% similar despite different names*

```diff
@@ -22,17 +22,20 @@
 
 ## Getting Account Transaction Data
 
 Each account within ape will also fetch and store transactional data that you can query.
 To work with an account's transaction data, you can do stuff like this:
 
 ```python
-In [1]: chain.history["example.eth"].query("value").sum()  # All value sent by this address
-In [2]: acct = accounts.load("my-acct"); acct.history[-1]  # Last txn `acct` made
-In [3]: acct.history.query("total_fees_paid").sum()  # Sum of ether paid for fees by `acct`
+from ape import accounts, chain
+
+chain.history["example.eth"].query("value").sum()  # All value sent by this address
+acct = accounts.load("my-acct")
+tx = acct.history[-1]  # Last txn `acct` made
+acct.history.query("total_fees_paid").sum()  # Sum of ether paid for fees by `acct`
 ```
 
 ## Getting Contract Event Data
 
 On a deployed contract, you can query event history.
 
 For example, we have a contract with a `FooHappened` event that you want to query from.
```

### Comparing `eth-ape-0.7.9/docs/userguides/dependencies.md` & `eth-ape-0.8.0/docs/userguides/dependencies.md`

 * *Files 10% similar despite different names*

```diff
@@ -1,14 +1,21 @@
 # Dependencies
 
-Ape downloads and caches dependencies in the `.ape/packages/<name>/<version-id>` directory where `<name>` refers to the name of the dependency and `<version-id>` refers to the version or branch of the package.
-When first downloading dependencies, Ape only places the source contents in the `sources` field of the `PackageManifest` and leaves the `contract_types` field untouched.
-This is because dependencies may not compile by Ape's standard out-of-the-box but their contract types can still be used in projects that do.
+Ape downloads and caches dependencies in the `.ape/packages` folder.
+There are three sub-folders in `.ape/packages` for dependencies:
 
-To use dependencies in your projects, you must configure them in your `ape-config.yaml` file.
+1. `projects/` - contains the raw project files for each dependency in subsequent `/<name>/<version-id>` directories (where `<name>` refers to the path-ified full-name of the dependency, e.g. `"OpenZeppelin_openzeppelin-contracts"`, and `<version-id>` refers to the version or branch of the package).
+   This location is where local project compilation looks for additional sources from import statements.
+2. `manifests/` - much like your local projects' `.build/__local__.json`, this is where dependencies cache their manifests.
+   When you compile a dependency, the contract types are stored in the dependency manifest's JSON file.
+3. `api/` - for caching the API data placed in `dependencies:` config or `ape pm install` commands, allowing dependency usage and management from anywhere in the file system.
+
+*NOTE*: You can install dependencies that don't compile out-of-the-box.
+Sometimes, dependencies are only collections of source files not meant to compile on their own but instead be used in projects via import statements.
+You can change the settings of a dependency using `config_override:` to compile dependencies after installed, if needed, and the `api/` cache always refers to the latest used during installation or compilation.
 
 ## Types of Dependencies
 
 There are few dependency types that come with Ape.
 The following section highlights how to use each of them and what their differences are.
 
 ### GitHub
@@ -49,15 +56,14 @@
 
 You can use already-downloaded projects as dependencies by referencing them as local dependencies.
 
 ```yaml
 dependencies:
   - name: MyDependency
     local: local/path/to/MyDependency
-    contracts_folder: src/contracts
 ```
 
 This is helpful when:
 
 - Working on multiple packages at once.
 - When there is not a suitable `DependencyAPI` implementation available for downloading your dependency.
 - Testing the framework.
@@ -90,34 +96,25 @@
 
 ## Package Management CLI
 
 You can also install and / or compile dependencies using the `pm` CLI.
 
 ### list
 
-To list information about the dependencies in your local project, run:
+To list information about installed dependencies, run:
 
 ```shell
 ape pm list
 ```
 
-To list information about all installed dependencies across all projects, run:
-
-```shell
-ape pm list --all
-```
-
 You should see information like:
 
 ```shell
-Packages:
-  OpenZeppelin v4.6.0, compiled!
-  vault master
-  vault v0.4.5
-  gnosis v1.3.0
+NAME          VERSION  COMPILED
+openzeppelin  4.9.3    -
 ```
 
 ### install
 
 To install all dependencies in your project, run:
 
 ```shell
@@ -137,33 +134,52 @@
 ```
 
 **NOTE**: The `gh:` prefix is used because this dependency is from GitHub.
 For `npm` dependencies, you use an `npm:` prefix.
 For local dependencies, you give it a path to the local dependency.
 `--version` is not required when using a local dependency.
 
-### remove
+To change the config of a dependency when installing, use the `--config-override` CLI option:
+
+```shell
+ape pm install gh:OpenZeppelin/openzeppelin-contracts \
+  --name openzeppelin \
+  --version "4.6.0" \
+  --config-override '{"solidity": {"version": "0.8.12"}}'
+```
+
+You can also use Python to install dependencies, using `**kwargs` as the same fields you put in your `dependencies:` config:
+
+```python
+from ape import project
+
+project.dependencies.install(
+   github="OpenZeppelin/openzeppelin-contracts", name="openzeppelin", version="4.4.2"
+)
+```
+
+### uninstall
 
-Remove previously installed packages using the `remove` command:
+Remove previously installed packages using the `uninstall` command:
 
 ```shell
-ape pm remove OpenZeppelin
+ape pm uninstall OpenZeppelin
 ```
 
 If there is a single version installed, the command will remove the single version.
 If multiple versions are installed, pass additional arguments specifying the version(s) to be removed:
 
 ```shell
-ape pm remove OpenZeppelin 4.5.0 4.6.0
+ape pm uninstall OpenZeppelin 4.5.0 4.6.0
 ```
 
 To skip the confirmation prompts, use the `--yes` flag (abbreviated as `-y`):
 
 ```shell
-ape pm remove OpenZeppelin all --yes
+ape pm uninstall OpenZeppelin all --yes
 ```
 
 **NOTE**: Additionally, use the `all` special version key to delete all versions.
 
 ### compile
 
 Dependencies are not compiled when they are installed.
@@ -193,50 +209,61 @@
 ape compile --include-dependencies
 ```
 
 ## Misc
 
 The following guidelines are applicable to **ALL** dependency types.
 
-### Custom Contracts Folder
+### Config Override
 
-You can set the name of the dependency's contracts folder, e.g.:
+To use any extra config item for a dependency, such as configurations for compilers needed during compiling, use the `config_override` setting:
 
 ```yaml
 dependencies:
-  - name: DappToolsERC20
-    github: dapphub/erc20
-    ref: dappnix
-    contracts_folder: src
+  - name: dependency
+    github: org-name/dependency-project-name
+    config_override:
+       solidity:
+         evm_version: paris
 ```
 
-### File Exclusions
+This is the same as if these values were in an `ape-config.yaml` file in the project directly.
 
-To ignore files from a dependency project, use the `exclude` setting to specify glob patterns:
+You can also specify `--config-override` in the `ape pm install` command to try different settings more adhoc:
+
+```shell
+ape pm install --config-override '{"solidity": {"evm_version": "paris"}}'
+```
+
+### Custom Contracts Folder
+
+You can set the name of the dependency's contracts folder using the `config_override` key, e.g.:
 
 ```yaml
 dependencies:
-  - name: dependency-project-name
-    github: org-name/dependency-project-name
-    exclude:
-      - package.json    # Ignore package.json files.
-      - mocks/**/*      # Ignore all files in the 'mocks' directory
+  - name: DappToolsERC20
+    github: dapphub/erc20
+    ref: dappnix
+    config_override:
+      contracts_folder: src
 ```
 
-### Config Override
+### File Exclusions
 
-To use any extra config item for a dependency, such as configurations for compilers needed during compiling, use the `config_override` setting:
+To ignore files from a dependency project, use the `exclude` setting in the `config_override:compile` section to specify glob patterns:
 
 ```yaml
 dependencies:
-  - name: dependency
+  - name: dependency-project-name
     github: org-name/dependency-project-name
     config_override:
-       solidity:
-         evm_version: paris
+      compile:
+        exclude:
+          - package.json    # Ignore package.json files.
+          - mocks/**/*      # Ignore all files in the 'mocks' directory
 ```
 
 ### Solidity Remappings
 
 A common use-case for dependencies involves the Solidity plugin.
 To use your dependencies in the `ape-solidity` plugin, configure `import_remappings` to refer to them:
 
@@ -262,15 +289,16 @@
 Sometimes, you may need to access types (such as contract types) from dependencies.
 You can achieve this using the project manager:
 
 ```python
 from ape import accounts, project
 
 # NOTE: This will compile the dependency
-dependency_contract = project.dependencies["my_dependency"]["1.0.0"].DependencyContractType
+dependency_project = project.dependencies["my_dependency"]["1.0.0"]
+dependency_contract = dependency_project.DependencyContractType 
 my_account = accounts.load("alias")
 deployed_contract = my_account.deploy(dependency_contract, "argument")
 print(deployed_contract.address)
 ```
 
 If you would like to always compile dependencies during `ape compile` rather than only have them get compiled upon asking for contract types, you can use the config option `include_dependencies` from the `compile` config:
```

### Comparing `eth-ape-0.7.9/docs/userguides/developing_plugins.md` & `eth-ape-0.8.0/docs/userguides/developing_plugins.md`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/docs/userguides/forking_networks.md` & `eth-ape-0.8.0/docs/userguides/forking_networks.md`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/docs/userguides/installing_plugins.md` & `eth-ape-0.8.0/docs/userguides/installing_plugins.md`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/docs/userguides/logging.md` & `eth-ape-0.8.0/docs/userguides/logging.md`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/docs/userguides/networks.md` & `eth-ape-0.8.0/docs/userguides/networks.md`

 * *Files 2% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 # Networks
 
-When interacting with a blockchain, you will have to select an ecosystem (e.g. Ethereum, Arbitrum, or Fantom), a network (e.g. Mainnet or Goerli) and a provider (e.g. Eth-Tester, Geth, or Alchemy).
+When interacting with a blockchain, you will have to select an ecosystem (e.g. Ethereum, Arbitrum, or Fantom), a network (e.g. Mainnet or Sepolia) and a provider (e.g. Eth-Tester, Node (Geth), or Alchemy).
 Networks are part of ecosystems and typically defined in plugins.
 For example, the `ape-ethereum` plugin comes with Ape and can be used for handling EVM-like behavior.
 
 ## Selecting a Network
 
 Before discussing how to add custom networks or install L2 network plugins, you need to know how to specify the network choice.
 No matter what type of network you are using in Ape, you specify the network using a "network choice" triplet value:
 
 ```python
 "<ecosystem-name>:<network-name>:<provider-name>"
 ```
 
 Where `ecosystem-name` refers to the ecosystem, e.g. `ethereum`, `polygon`, `fantom`, or any valid ecosystem plugin name.
 The `network-name` refers to a network such as `mainnet`, `local`, or something else defined by your ecosystem or custom network config.
-And `provider-name` refers to the provider plugin in Ape, such as `geth` for a generic node or `foundry` if the network is more Anvil-based, or a different plugin altogether.
+And `provider-name` refers to the provider plugin in Ape, such as `node` for a generic node or `foundry` if the network is more Anvil-based, or a different plugin altogether.
 
 Commonly, the network triplet value is specified via the `--network` option in Ape CLI commands.
 The following is a list of common Ape commands that can use the `--network` option:
 
 ```bash
 ape test --network ethereum:local:foundry
 ape console --network arbitrum:testnet:alchemy # NOTICE: All networks, even from other ecosystems, use this.
@@ -75,18 +75,18 @@
 | ape-fantom        | [ApeWorX/ape-fantom](https://github.com/ApeWorX/ape-fantom)               |
 | ape-optmism       | [ApeWorX/ape-optimism](https://github.com/ApeWorX/ape-optimism)           |
 | ape-polygon       | [ApeWorX/ape-polygon](https://github.com/ApeWorX/ape-polygon)             |
 | ape-polygon-zkevm | [ApeWorX/ape-polygon-zkevm](https://github.com/ApeWorX/ape-polygon-zkevm) |
 
 **NOTE**: If you are connecting an L2 network or any other network that does not have a plugin, you can use the custom network support, which is described in the [next section](#custom-network-connection).
 
-Once you have the L2 network plugin installed, you can configure its node's URI by setting the values in the `geth` (default node) core plugin via your `ape-config.yaml` file:
+Once you have the L2 network plugin installed, you can configure its node's URI by setting the values in the `node` core plugin via your `ape-config.yaml` file:
 
 ```yaml
-geth:
+node:
   <ecosystem-name>:
     <network-name>:
       uri: https://path.to.node.example.com
 ```
 
 To see proper ecosystem and network names needed for configuration, run the command:
 
@@ -116,15 +116,15 @@
 ```yaml
 networks:
   custom:
      - name: mainnet                   # Required
        chain_id: 109                   # Required
        ecosystem: shibarium            # The ecosystem name, can either be new or an existing
        base_ecosystem_plugin: polygon  # The ecosystem base-class, defaults to the default ecosystem
-       default_provider: geth          # Default is the generic node provider
+       default_provider: node          # Default is the generic node provider
 ```
 
 The following paragraphs explain the different parameters of the custom network config.
 
 **name**: The `name` of the network is the same identifier you use in the network triplet for the "network" (second) section.
 Read more on the network option [here](#selecting-a-network).
 
@@ -164,42 +164,42 @@
 networks:
   custom:
     - name: mainnet
       ecosystem: shibarium
       base_ecosystem_plugin: polygon  # Closest base class.
       chain_id: 109  # This must be correct or txns will fail.
 
-geth:
+node:
   shibarium:
     mainnet:
       uri: https://www.shibrpc.com
 ```
 
-Now, when using `ethereum:apenet:geth`, it will connect to the RPC URL `https://apenet.example.com/rpc`.
+Now, when using `ethereum:apenet:node`, it will connect to the RPC URL `https://apenet.example.com/rpc`.
 
 #### Explorer URL
 
 To configure explorer URLs for your custom network, use the explorer's plugin config.
 For example, let's say you added the following network:
 
 ```yaml
 networks:
   custom:
     - name: customnetwork
       chain_id: 31337
-      default_provider: geth
+      default_provider: node
 ```
 
 To add a corresponding entry in `ape-etherscan` (assuming you are using `ape-etherscan` as your explorer plugin), add the following to your `ape-config.yaml` file:
 
 ```yaml
 etherscan:
   ethereum:
     rate_limit: 15  # Configure a rate limit that makes sense for retry logic.
-    
+
     # The name of the entry is the same as your custom network!
     customnetwork:
       uri: https://custom.scan              # URL used for showing transactions
       api_uri: https://api.custom.scan/api  # URL used for making API requests.
 ```
 
 **NOTE**: Every explorer plugin may be different in how you configure custom networks.
@@ -310,32 +310,32 @@
 ## Local Network
 
 The default network in Ape is the local network (keyword `"local"`).
 It is meant for running tests and debugging contracts.
 Out-of-the-box, Ape ships with two development providers you can use for the `local` network:
 
 - [EthTester](https://github.com/ethereum/eth-tester)
-- An Ephemeral Geth process
+- An Ephemeral Node (defaults to Geth) process
 
 ```bash
 ape test --network ::test
-ape test --network ::geth  # Launch a local development geth process
+ape test --network ::node  # Launch a local development node (geth) process
 ```
 
 To learn more about testing in ape, follow [this guide](./testing.html).
 
 ## Live Networks
 
-Use the core plugin `ape-geth` to connect to local or remote nodes via URI.
-The geth plugin is abstract in that it represents any node, not just geth nodes.
+Use the core plugin `ape-node` to connect to local or remote nodes via URI.
+The node plugin is abstract in that it represents any node.
 However, it will work best when connected to a geth node.
-To configure network URIs in geth, you can use the `ape-config.yaml` file:
+To configure network URIs in `node`, you can use the `ape-config.yaml` file:
 
 ```yaml
-geth:
+node:
   ethereum:
     mainnet:
       uri: https://foo.node.bar
 ```
 
 ## Network Config
 
@@ -356,46 +356,46 @@
     default_transaction_type: 0
 
     # The amount of time to wait for a transaction to be
     # accepted after sending it before raising an error.
     # Most networks use 120 seconds (2 minutes).
     transaction_acceptance_timeout: 60
 
-    # The amount of times to retry fetching a receipt. This is useful 
-    # because decentralized systems may show the transaction accepted 
-    # on some nodes but not on others, and potentially RPC requests 
+    # The amount of times to retry fetching a receipt. This is useful
+    # because decentralized systems may show the transaction accepted
+    # on some nodes but not on others, and potentially RPC requests
     # won't return a receipt immediately after sending its transaction.
     # This config accounts for such delay. The default is `20`.
     max_receipt_retries: 10
 
     # Set a gas limit here, or use the default of "auto" which
     # estimates gas. Note: local networks tend to use "max" here
     # by default.
     gas_limit: auto
-    
+
     # Base-fee multipliers are useful for times when the base fee changes
     # before a transaction is sent but after the base fee was derived,
     # thus causing rejection. A multiplier reduces the chance of
     # rejection. The default for live networks is `1.4` times the base fee.
     base_fee_multiplier: 1.2
-    
+
     # The block time helps Ape make decisions about
     # polling chain data.
     block_time: 10
 ```
 
 ## Running a Network Process
 
 To run a network with a process, use the `ape networks run` command:
 
 ```shell
 ape networks run
 ```
 
-By default, `ape networks run` runs a development Geth process.
+By default, `ape networks run` runs a development Node (geth) process.
 To use a different network, such as `hardhat` or Anvil nodes, use the `--network` flag:
 
 ```shell
 ape networks run --network ethereum:local:foundry
 ```
 
 ## Provider Interaction
@@ -419,30 +419,30 @@
 For example, if you are using a script with a default network connection, you can change connection in the middle of the script by using the provider context manager:
 
 ```python
 from ape import chain, networks
 
 def main():
     start_provider = chain.provider.name
-    with networks.ethereum.mainnet.use_provider("geth") as provider:
+    with networks.ethereum.mainnet.use_provider("node") as provider:
         # We are using a different provider than the one we started with.
         assert start_provider != provider.name
 ```
 
 Jump between networks to simulate multi-chain behavior.
 
 ```python
 import click
 from ape import networks
 
 @click.command()
 def cli():
-    with networks.polygon.mainnet.use_provider("geth"):
+    with networks.polygon.mainnet.use_provider("node"):
         ...
-    with networks.ethereum.mainnet.use_provider("geth"):
+    with networks.ethereum.mainnet.use_provider("node"):
         ...
 ```
 
 The argument to [use_provider()](../methoddocs/api.html#ape.api.networks.NetworkAPI.use_provider) is the name of the provider you want to use.
 You can also tell Ape to use the default provider by calling method [use_default_provider()](../methoddocs/api.html#ape.api.networks.NetworkAPI.use_default_provider) instead.
 This will use whatever provider is set as default for your ecosystem / network combination (via one of your `ape-config.yaml` files).
```

### Comparing `eth-ape-0.7.9/docs/userguides/projects.md` & `eth-ape-0.8.0/docs/userguides/projects.md`

 * *Files 17% similar despite different names*

```diff
@@ -13,68 +13,60 @@
     deploy.py                   # Sample script to automate a deployment of an ape project
  ape-config.yaml                 # The ape project configuration file
 ```
 
 Notice that you can configure you ape project using the `ape-config.yaml` file.
 See the [configuration guide](./config.html) for a more detailed explanation of settings you can adjust.
 
-## Adding Plugins
+## The Local Project
 
-Your project may require plugins.
-To install plugins, use the `ape plugins install .` command.
-Learn more about configuring your project's required plugins by following [this guide](./installing_plugins.html).
-
-## Compiling Contracts
-
-The project manager object is a representation of your current project.
-Access it from the root `ape` namespace:
+After you have a local project and you are in the directory of that project, the global `project` reference in Ape will refer to this project.
+You can see this by typing `project` in the `ape console`:
 
 ```python
-from ape import project
-```
-
-Your `project` contains all the "relevant" files, such as source files in the `contracts/` directory.
-Use the following command to compile all contracts in the `contracts/` directory:
-
-```bash
-ape compile
+In [1]: project
+Out[1]: <ProjectManager ~/ApeProjects/ape-demo-project>
 ```
 
-For more information on compiling your project, see [this guide](./compile.html).
+In this case, my terminal's current working directory is the same as a local project named `ape-demo-project`.
 
-## Deploying Contracts
+## Other Projects
 
-After compiling, the contract containers are accessible from the `project` manager.
-Deploy them in the `console` or in scripts; for example:
+You can reference other local projects on your computer by using the `Project` factory class (notice the capital `P`):
 
 ```python
-from ape import accounts, project
+from ape import Project
 
-account = accounts.load("my_account_alias")
-account.deploy(project.MyContract)
+my_other_project = Project("../path/to/my/other/project")
+_ = my_other_project.MyContract  # Do anything you can do to the root-level project.
 ```
 
-**NOTE**: You can also deploy contracts from the container itself:
+## Project Manifests
+
+Ape stores and caches artifacts in an [EthPM package manifest](https://eips.ethereum.org/EIPS/eip-2678).
+When working with local projects, the manifests get placed in the `<project-path>/.build/__local__.json`.
+However, you may obtain a manifest from a different location.
+If that is the case, you can create a project directly from the manifest itself:
 
 ```python
-from ape import accounts, project
+from ape import Project
 
-account = accounts.load("my_account_alias")
-project.MyContract.deploy(sender=account)
+# Pass in a manifest (object or dictionary), or a path to a manifest's JSON file.
+project = Project.from_manifest("path/to/manifest.json")
+_ = project.MyContract  # Do anything you can do to the root-level project.
 ```
 
-### Dependencies
-
-To set up and use dependencies in your project, follow [this guide](./dependencies.html).
+## Dependencies
 
-## Scripts
+Use other projects as dependencies in Ape.
+There is an extensive guide you can read on this [here](./dependencies.html).
+But it is important to note that the dependency system largely is dependent on the project system.
+Dependencies are just projects after all; projects containing source files you both use in your projects or compile independently.
 
-The scripts folder contains project automation scripts, such as deploy scripts, as well as other executable jobs, such as scripts for running simulations.
-To learn more about scripting in Ape, see [the scripting guide](./scripts.html).
+For example, access a dependency project and treat it like any other project this way:
 
-## Testing
+```python
+from ape import project
 
-Use tests to verify your project.
-You can test your project using the `ape test` command.
-The `ape test` command comes with the core-plugin `ape-test`.
-The `ape-test` plugin extends the popular python testing framework [pytest](https://docs.pytest.org/en/6.2.x/contents.html).
-Testing is a complex topic; learn more about testing using Ape framework [here](./testing.html).
+dependency = project.dependencies.get_dependency("my-dependency", "1.0.0")
+contract_type = dependency.project.ContractFromDependency
+```
```

### Comparing `eth-ape-0.7.9/docs/userguides/proxy.md` & `eth-ape-0.8.0/docs/userguides/proxy.md`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/docs/userguides/publishing.md` & `eth-ape-0.8.0/docs/userguides/publishing.md`

 * *Files 9% similar despite different names*

```diff
@@ -12,34 +12,34 @@
 ```
 
 To learn more about project compilation, follow [this guide](./compile.html).
 Once your project has successfully compiled, you will have the start of your `PackageManifest` generated in your project's `.build/` directory.
 
 ## Tracking Deployments
 
-If your project contains deployments that you wish to include in its package manifest, use the [track_deployment()](../methoddocs/managers.html#ape.managers.project.manager.ProjectManager.track_deployment) method.
+If your project contains deployments that you wish to include in its package manifest, use the [project.deployments.track](../methoddocs/managers.html#ape.managers.project.manager.DeploymentManager.track) method.
 Example:
 
 ```python
 from ape import accounts, project
 
 account = accounts.load("mainnet-account")
 
 # Assume your project has a contract named 'MyContract' with constructor that accepts argument '123'.
 contract = project.MyContract.deploy(123, sender=account)
-project.track_deployment(contract)
+project.deployments.track(contract)
 ```
 
 If the contract is already deployed, you can use [Contract](../methoddocs/ape.html#ape.Contract) to get a contract instance:
 
 ```python
 from ape import Contract, project
 
 contract = Contract("0x12c17f958d2ee523a2206206994597c13d831e34")
-project.track_deployment(contract)
+project.deployments.track(contract)
 ```
 
 For more information on accessing contract instances, follow [this guide](./contracts.html).
 
 ## Publishing to Explorer
 
 If you want to publish your contracts to an explorer, you can use the [publish_contract](../methoddocs/api.html#ape.explorers.ExplorerAPI.publish_contract) on the `ExplorerAPI`.
```

### Comparing `eth-ape-0.7.9/docs/userguides/scripts.md` & `eth-ape-0.8.0/docs/userguides/scripts.md`

 * *Files 2% similar despite different names*

```diff
@@ -70,19 +70,19 @@
 
 ```python
 import click
 from ape.cli import ape_cli_context
 
 @click.command()
 @ape_cli_context()
-def cli(cli_ctx):        
+def cli(cli_ctx):
     # There is no connection yet at this point.
     testnets = {
-        "ethereum": ["sepolia", "goerli"],
-        "polygon": ["mumbai"]
+        "ethereum": ["sepolia"],
+        "polygon": ["amoy"]
     }
     nm = cli_ctx.network_manager
 
     for ecosystem_name, networks in testnets.items():
         ecosystem = nm.ecosystems[ecosystem_name]
 
         for network_name in networks:
@@ -133,12 +133,12 @@
 ape run foobar
 ```
 
 Without specifying `--network`, the script with connect to your default network.
 Else, specify the network using the `--network` flag:
 
 ```shell
-ape run foobar --network polygon:mumbai:alchemy
+ape run foobar --network polygon:amoy:alchemy
 ```
 
 You can also change networks within the script using the `ProviderContextManager` (see examples in the CLI-script section above).
 For multi-chain use-cases, we recommend sticking to the CLI based scripts to avoid the initial connection `main`-method scripts make.
```

### Comparing `eth-ape-0.7.9/docs/userguides/testing.md` & `eth-ape-0.8.0/docs/userguides/testing.md`

 * *Files 3% similar despite different names*

```diff
@@ -231,28 +231,59 @@
 
 ```bash
 ape test test_my_contract -I -s
 ```
 
 ## Test Providers
 
-Out-of-the-box, your tests run using the `eth-tester` provider, which comes bundled with ape. If you have `geth` installed, you can use the `ape-geth` plugin that also comes with ape.
+Out-of-the-box, your tests run using the `eth-tester` provider, which comes bundled with ape.
+If you have Ethereum node software installed, you can use the `ape-node` plugin that also comes with ape.
 
 ```bash
-ape test --network ethereum:local:geth
+ape test --network ethereum:local:node
 ```
 
 Each testing plugin should work the same way. You will have access to the same test accounts.
 
 Another option for testing providers is the [ape-hardhat](https://github.com/ApeWorX/ape-hardhat) plugin, which does not come with `ape` but can be installed by including it in the `plugins` list in your `ape-config.yaml` file or manually installing it using the command:
 
 ```bash
 ape plugins install hardhat
 ```
 
+### Mining
+
+Test providers allow you to control mining.
+For example, mine an empty block using the [mine](../methoddocs/api.html#ape.api.providers.TestProviderAPI.mine) method:
+
+```python
+from ape import chain
+
+chain.provider.mine()
+```
+
+You can also pass it a number of blocks to mine:
+
+```python
+from ape import chain
+
+chain.provider.mine(5)
+```
+
+By default, testing providers automatically mine after sending transactions.
+However, you can disable this feature by setting the property.
+
+```python
+from ape import chain
+
+chain.provider.auto_mine = False
+# You can also re-enable
+chain.provider.auto_mine = True
+```
+
 ## Advanced Testing Tips
 
 If you want to use sample projects, follow this link to [Ape Academy](https://github.com/ApeAcademy).
 
 ```
 project                     # The root project directory
  tests/                  # Project tests folder, ran using the 'ape test' command to run all tests within the folder.
@@ -275,14 +306,16 @@
 ## Testing Transaction Failures
 
 Similar to `pytest.raises()`, you can use `ape.reverts()` to assert that contract transactions fail and revert.
 
 From our earlier example we can see this in action:
 
 ```python
+import ape
+
 def test_authorization(my_contract, owner, not_owner):
     my_contract.set_owner(sender=owner)
     assert owner == my_contract.owner()
 
     with ape.reverts("!authorized"):
         my_contract.authorized_method(sender=not_owner)
 ```
@@ -293,14 +326,17 @@
 
 This is the expected revert reason given when the transaction fails.
 If the message in the `ContractLogicError` raised by the transaction failure is empty or does not match the `expected_message`, then `ape.reverts()` will raise an `AssertionError`.
 
 You may also supply an `re.Pattern` object to assert on a message pattern, rather than on an exact match.
 
 ```python
+import ape
+import re
+
 # Matches explicitly "foo" or "bar"
 with ape.reverts(re.compile(r"^(foo|bar)$")):
     ...
 ```
 
 ### `dev_message`
 
@@ -323,14 +359,16 @@
     assert _value != 0  # dev: invalid value
     return True
 ```
 
 We can explicitly cause a transaction revert and check the failed line by supplying an expected `dev_message`:
 
 ```python
+import ape
+
 def test_authorization(my_contract, owner):
     with ape.reverts(dev_message="dev: invalid value"):
         my_contract.check_value(sender=owner)
 ```
 
 When the transaction reverts and `ContractLogicError` is raised, `ape.reverts()` will check the source contract to see if the failed line contains a message.
 
@@ -341,14 +379,16 @@
 - If the transaction trace cannot be obtained
 
 Because `dev_message` relies on transaction tracing to function, you must use a provider like [ape-hardhat](https://github.com/ApeWorX/ape-hardhat) when testing with `dev_message`.
 
 You may also supply an `re.Pattern` object to assert on a dev message pattern, rather than on an exact match.
 
 ```python
+import ape
+
 # Matches explictly "dev: foo" or "dev: bar"
 with ape.reverts(dev_message=re.compile(r"^dev: (foo|bar)$")):
     ...
 ```
 
 ### Caveats
 
@@ -476,20 +516,18 @@
 The Ape framework supports connecting to alternative networks / providers in tests.
 
 To run an entire test using a specific network / provider combination, use the `use_network` pytest marker:
 
 ```python
 import pytest
 
-
 @pytest.mark.use_network("fantom:local:test")
 def test_my_fantom_test(chain):
     assert chain.provider.network.ecosystem.name == "fantom"
 
-
 @pytest.mark.use_network("ethereum:local:test")
 def test_my_ethereum_test(chain):
     assert chain.provider.network.ecosystem.name == "ethereum"
 ```
 
 To switch networks mid-test, use the `networks` context-manager:
 
@@ -509,59 +547,52 @@
 
 You can also set the network context in a pytest fixture.
 This is useful if certain fixtures must run in certain networks.
 
 ```python
 import pytest
 
-
 @pytest.fixture
 def stark_contract(networks, project):
     with networks.parse_network_choice("starknet:local"):
         yield project.MyStarknetContract.deploy()
 
-
 def test_starknet_thing(stark_contract, stark_account):
     # Uses the starknet connection via the stark_contract fixture
     receipt = stark_contract.my_method(sender=stark_account)
     assert not receipt.failed
 ```
 
 When you exit a provider's context, Ape **does not** disconnect the provider.
 When you re-enter that provider's context, Ape uses the previously-connected provider.
 At the end of the tests, Ape disconnects all the providers.
 Thus, you can enter and exit a provider's context as much as you need in tests.
 
 ## Gas Reporting
 
 To include a gas report at the end of your tests, you can use the `--gas` flag.
-**NOTE**: This feature requires using a provider with tracing support, such as [ape-hardhat](https://github.com/ApeWorX/ape-hardhat).
+**NOTE**: This feature works best when using a provider with tracing support, such as [ape-foundry](https://github.com/ApeWorX/ape-foundry).
+When not using a provider with adequate tracing support, such as `EthTester`, gas reporting is limited to receipt-level data.
 
 ```bash
-ape test --network ethereum:local:hardhat --gas
+ape test --network ethereum:local:foundry --gas
 ```
 
 At the end of test suite, you will see tables such as:
 
 ```sh
                             FundMe Gas
 
   Method           Times called    Min.    Max.    Mean   Median
  
   fund                        8   57198   91398   82848    91398
   withdraw                    2   28307   38679   33493    33493
   changeOnStatus              2   23827   45739   34783    34783
   getSecret                   1   24564   24564   24564    24564
 
-                  Transferring ETH Gas
-
-  Method     Times called   Min.   Max.   Mean   Median
- 
-  to:test0              2   2400   9100   5750     5750
-
                      TestContract Gas
 
   Method      Times called    Min.    Max.    Mean   Median
  
   setNumber              1   51021   51021   51021    51021
 ```
 
@@ -614,14 +645,15 @@
 To get contract coverage, use the `--coverage` flag when running `ape test`:
 
 ```shell
 ape test --coverage
 ```
 
 **NOTE**: Some types of coverage require using a provider that supports transaction tracing, such as `ape-hardhat` or `ape-foundry`.
+Without using a provider with adequate tracing support, coverage is limited to receipt-level data.
 
 Afterwards, you should see a coverage report looking something like:
 
 ```shell
 ============================================= Coverage Profile =============================================
                Contract Coverage
```

### Comparing `eth-ape-0.7.9/pyproject.toml` & `eth-ape-0.8.0/pyproject.toml`

 * *Files 5% similar despite different names*

```diff
@@ -17,15 +17,15 @@
 
 # NOTE: you have to use single-quoted strings in TOML for regular expressions.
 # It's the equivalent of r-strings in Python.  Multiline strings are treated as
 # verbose regular expressions by Black.  Use [ ] to denote a significant space
 # character.
 [tool.black]
 line-length = 100
-target-version = ['py38', 'py39', 'py310']
+target-version = ['py38', 'py39', 'py310', 'py311', 'py312']
 include = '\.pyi?$'
 
 [tool.pytest.ini_options]
 norecursedirs = "projects"
 addopts = "-p no:ape_test"  # NOTE: Prevents the ape plugin from activating on our tests
 python_files = "test_*.py"
 testpaths = "tests"
```

### Comparing `eth-ape-0.7.9/setup.py` & `eth-ape-0.8.0/setup.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,39 +1,41 @@
 #!/usr/bin/env python
+import re
 from pathlib import Path
-from typing import Dict
 
 from setuptools import find_packages, setup
 
-here = Path(__file__).parent.absolute()
-packages_data: Dict = {}
-with open(here / "src" / "ape" / "__modules__.py", encoding="utf8") as modules_file:
-    exec(modules_file.read(), packages_data)
+_HERE = Path(__file__).parent.absolute()
+_CORE_PLUGIN_PATTERN = re.compile(r"\bape_\w+(?!\S)")
+_PACKAGES = find_packages("src")
+_MODULES = {p for p in _PACKAGES if re.match(_CORE_PLUGIN_PATTERN, p)}
+_MODULES.add("ape")
 
 extras_require = {
     "test": [  # `test` GitHub Action jobs uses this
-        "pytest-xdist>=3.5.0,<4",  # Multi-process runner
+        "pytest-xdist>=3.6.1,<4",  # Multi-process runner
         "pytest-cov>=4.0.0,<5",  # Coverage analyzer plugin
         "pytest-mock",  # For creating mocks
-        "pytest-timeout~=2.2.0",
+        "pytest-timeout>=2.2.0,<3",  # For avoiding timing out during tests
         "hypothesis>=6.2.0,<7.0",  # Strategy-based fuzzer
         "hypothesis-jsonschema==0.19.0",  # JSON Schema fuzzer extension
     ],
     "lint": [
-        "black>=24.1.1,<25",  # Auto-formatter and linter
-        "mypy>=1.8.0,<2",  # Static type analyzer
+        "black>=24.4.2,<25",  # Auto-formatter and linter
+        "mypy>=1.10.0,<2",  # Static type analyzer
         "types-PyYAML",  # Needed due to mypy typeshed
         "types-requests",  # Needed due to mypy typeshed
         "types-setuptools",  # Needed due to mypy typeshed
-        "pandas-stubs==1.2.0.62",  # Needed due to mypy typeshed
+        "pandas-stubs>=2.2.1.240316",  # Needed due to mypy typeshed
         "types-SQLAlchemy>=1.4.49",  # Needed due to mypy typeshed
+        "types-python-dateutil",  # Needed due to mypy typeshed
         "flake8>=7.0.0,<8",  # Style linter
         "flake8-breakpoint>=1.1.0,<2",  # Detect breakpoints left in code
         "flake8-print>=4.0.1,<5",  # Detect print statements left in code
-        "isort>=5.10.1,<6",  # Import sorting linter
+        "isort>=5.13.2,<6",  # Import sorting linter
         "mdformat>=0.7.17",  # Auto-formatter for markdown
         "mdformat-gfm>=0.3.5",  # Needed for formatting GitHub-flavored markdown
         "mdformat-frontmatter>=0.4.1",  # Needed for frontmatters-style headers in issue templates
         "mdformat-pyproject>=0.0.1",  # Allows configuring in pyproject.toml
     ],
     "doc": [
         "pygments>=2.17.0,<3",  # Needed for the Vyper lexer
@@ -47,23 +49,23 @@
     "release": [  # `release` GitHub Action job uses this
         "setuptools",  # Installation tool
         "wheel",  # Packaging tool
         "twine==3.8.0",  # Package upload tool
     ],
     "dev": [
         # commitizen: Manage commits and publishing releases
-        (here / "cz-requirement.txt").read_text().strip(),
+        (_HERE / "cz-requirement.txt").read_text().strip(),
         "pre-commit",  # Ensure that linters are run prior to committing
         "pytest-watch",  # `ptw` test watcher/runner
         "ipdb",  # Debugger (Must use `export PYTHONBREAKPOINT=ipdb.set_trace`)
     ],
     # NOTE: These are extras that someone can install to get up and running quickly w/ ape
     #       They should be kept up to date with what works and what doesn't out of the box
     #       Usage example: `pipx install eth-ape[recommended-plugins]`
-    "recommended-plugins": (here / "recommended-plugins.txt").read_text().splitlines(),
+    "recommended-plugins": (_HERE / "recommended-plugins.txt").read_text().splitlines(),
 }
 
 # NOTE: `pip install -e .[dev]` to install package
 extras_require["dev"] = (
     extras_require["test"]
     + extras_require["lint"]
     + extras_require["doc"]
@@ -93,46 +95,46 @@
         "Tracker": "https://github.com/ApeWorX/ape/issues",
         "Twitter": "https://twitter.com/ApeFramework",
     },
     include_package_data=True,
     install_requires=[
         "click>=8.1.6,<9",
         "ijson>=3.1.4,<4",
-        "importlib-metadata",
-        "ipython>=8.5.0,<9",
+        "ipython>=8.18.1,<9",
         "lazyasd>=0.1.4",
         "packaging>=23.0,<24",
         "pandas>=1.3.0,<2",
         "pluggy>=1.3,<2",
-        "pydantic>=2.5.2,<3",
+        "pydantic>=2.6.4,<3",
         "pydantic-settings>=2.0.3,<3",
-        "PyGithub>=1.59,<2",
-        "pytest>=6.0,<8.0",
+        "pytest>=8.0,<9.0",
         "python-dateutil>=2.8.2,<3",
         "PyYAML>=5.0,<7",
         "requests>=2.28.1,<3",
         "rich>=12.5.1,<14",
         "SQLAlchemy>=1.4.35",
         "tqdm>=4.62.3,<5.0",
         "traitlets>=5.3.0",
         "urllib3>=2.0.0,<3",
         "watchdog>=3.0,<4",
         # ** Dependencies maintained by Ethereum Foundation **
-        "eth-abi>=4.2.1,<5",
-        "eth-account>=0.10.0,<0.11",
+        "eth-abi>=5.1.0,<6",
+        "eth-account>=0.11.2,<0.12",
         "eth-typing>=3.5.2,<4",
         "eth-utils>=2.3.1,<3",
-        "py-geth>=4.2.0,<5",
-        "web3[tester]>=6.15.1,<7",
+        "hexbytes",  # Peer
+        "py-geth>=4.4.0,<5",
+        "trie>=3.0.0,<4",  # Peer: stricter pin needed for uv support.
+        "web3[tester]>=6.17.2,<7",
         # ** Dependencies maintained by ApeWorX **
-        "eip712>=0.2.3,<0.4",
-        "ethpm-types>=0.6.7,<0.7",
-        "eth_pydantic_types>=0.1.0a5,<0.2",
-        "evmchains>=0.0.2,<0.1",
-        "evm-trace>=0.1.2",
+        "eip712>=0.2.7,<0.3",
+        "ethpm-types>=0.6.9,<0.7",
+        "eth_pydantic_types>=0.1.0,<0.2",
+        "evmchains>=0.0.7,<0.1",
+        "evm-trace>=0.1.5,<0.2",
     ],
     entry_points={
         "console_scripts": ["ape=ape._cli:cli"],
         "pytest11": ["ape_test=ape.pytest.plugin"],
         "ape_cli_subcommands": [
             "ape_accounts=ape_accounts._cli:cli",
             "ape_cache=ape_cache._cli:cli",
@@ -142,30 +144,30 @@
             "ape_run=ape_run._cli:cli",
             "ape_networks=ape_networks._cli:cli",
             "ape_test=ape_test._cli:cli",
             "ape_init=ape_init._cli:cli",
             "ape_pm=ape_pm._cli:cli",
         ],
     },
-    python_requires=">=3.8,<4",
+    python_requires=">=3.9,<4",
     extras_require=extras_require,
-    py_modules=packages_data["__modules__"],
+    py_modules=list(_MODULES),
     license="Apache-2.0",
     zip_safe=False,
     keywords="ethereum",
-    packages=find_packages("src"),
+    packages=_PACKAGES,
     package_dir={"": "src"},
-    package_data={p: ["py.typed"] for p in packages_data["__modules__"]},
+    package_data={p: ["py.typed"] for p in _MODULES},
     classifiers=[
         "Development Status :: 5 - Production/Stable",
         "Intended Audience :: Developers",
         "License :: OSI Approved :: MIT License",
         "Natural Language :: English",
         "Operating System :: MacOS",
         "Operating System :: POSIX",
         "Programming Language :: Python :: 3",
-        "Programming Language :: Python :: 3.8",
         "Programming Language :: Python :: 3.9",
         "Programming Language :: Python :: 3.10",
         "Programming Language :: Python :: 3.11",
+        "Programming Language :: Python :: 3.12",
     ],
 )
```

### Comparing `eth-ape-0.7.9/src/ape/__init__.py` & `eth-ape-0.8.0/src/ape/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,10 +1,13 @@
 import signal
+import threading
 
-signal.signal(signal.SIGINT, lambda s, f: _sys.exit(130))
+if threading.current_thread() is threading.main_thread():
+    # If we are in the main thread, we can safely set the signal handler
+    signal.signal(signal.SIGINT, lambda s, f: _sys.exit(130))
 
 import sys as _sys
 
 from ape.managers.project import ProjectManager as Project
 from ape.pytest.contextmanagers import RevertsContextManager
 from ape.utils import ManagerAccessMixin as _ManagerAccessMixin
 
@@ -30,15 +33,15 @@
 Useful for development purposes, such as controlling the state of the blockchain.
 Also handy for querying data about the chain and managing local caches.
 """
 
 accounts = _ManagerAccessMixin.account_manager
 """Manages accounts for the current project. See :class:`ape.managers.accounts.AccountManager`."""
 
-project = _ManagerAccessMixin.project_manager
+project = _ManagerAccessMixin.local_project
 """The currently active project. See :class:`ape.managers.project.ProjectManager`."""
 
 Contract = chain.contracts.instance_at
 """User-facing class for instantiating contracts."""
 
 convert = _ManagerAccessMixin.conversion_manager.convert
 """Conversion utility function. See :class:`ape.managers.converters.ConversionManager`."""
```

### Comparing `eth-ape-0.7.9/src/ape/_cli.py` & `eth-ape-0.8.0/src/ape/_cli.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,40 +1,46 @@
 import difflib
 import re
 import sys
+import warnings
+from collections.abc import Iterable
 from gettext import gettext
-from typing import Any, Dict, List, Optional, Tuple
+from importlib.metadata import entry_points
+from pathlib import Path
+from typing import Any, Optional
 
 import click
-import importlib_metadata as metadata
 import yaml
 
 from ape.cli import ape_cli_context
 from ape.exceptions import Abort, ApeException, handle_ape_exception
 from ape.logging import logger
-from ape.plugins import clean_plugin_name
-from ape.plugins._utils import PluginMetadataList
+from ape.plugins._utils import PluginMetadataList, clean_plugin_name
 from ape.utils.basemodel import ManagerAccessMixin
 
 _DIFFLIB_CUT_OFF = 0.6
 
 
 def display_config(ctx, param, value):
     # NOTE: This is necessary not to interrupt how version or help is intercepted
     if not value or ctx.resilient_parsing:
         return
 
     click.echo("# Current configuration")
-    click.echo(yaml.dump(ManagerAccessMixin.project_manager.config_manager.model_dump(mode="json")))
+
+    # NOTE: Using json-mode as yaml.dump requires JSON-like structure.
+    model = ManagerAccessMixin.local_project.config_manager.model_dump(mode="json")
+
+    click.echo(yaml.dump(model))
 
     ctx.exit()  # NOTE: Must exit to bypass running ApeCLI
 
 
 class ApeCLI(click.MultiCommand):
-    _commands: Optional[Dict] = None
+    _commands: Optional[dict] = None
     _CLI_GROUP_NAME = "ape_cli_subcommands"
 
     def format_commands(self, ctx, formatter) -> None:
         commands = []
         for subcommand in self.list_commands(ctx):
             cmd = self.get_command(ctx, subcommand)
             if cmd is None or cmd.hidden:
@@ -43,24 +49,27 @@
             commands.append((subcommand, cmd))
 
         # Allow for 3 times the default spacing.
         if len(commands):
             limit = formatter.width - 6 - max(len(cmd[0]) for cmd in commands)
 
             # Split the commands into 3 sections.
-            sections: Dict[str, List[Tuple[str, str]]] = {
+            sections: dict[str, list[tuple[str, str]]] = {
                 "Core": [],
                 "Plugin": [],
                 "3rd-Party Plugin": [],
             }
-            metadata = PluginMetadataList.load(ManagerAccessMixin.plugin_manager)
+
+            pl_metadata = PluginMetadataList.load(
+                ManagerAccessMixin.plugin_manager, include_available=False
+            )
 
             for cli_name, cmd in commands:
                 help = cmd.get_short_help_str(limit)
-                plugin = metadata.get_plugin(cli_name)
+                plugin = pl_metadata.get_plugin(cli_name)
                 if not plugin:
                     continue
 
                 if plugin.in_core:
                     sections["Core"].append((cli_name, help))
                 elif plugin.is_installed and not plugin.is_third_party:
                     sections["Plugin"].append((cli_name, help))
@@ -76,15 +85,18 @@
 
     def invoke(self, ctx) -> Any:
         try:
             return super().invoke(ctx)
         except click.UsageError as err:
             self._suggest_cmd(err)
         except ApeException as err:
-            if handle_ape_exception(err, [ctx.obj.project_manager.path]):
+            path = ctx.obj.local_project.path
+
+            # NOTE: isinstance check for type-checkers.
+            if isinstance(path, Path) and handle_ape_exception(err, (path,)):
                 # All exc details already outputted.
                 sys.exit(1)
             else:
                 raise Abort.from_ape_exception(err) from err
 
     @staticmethod
     def _suggest_cmd(usage_error):
@@ -107,28 +119,33 @@
                 usage_error.message = (
                     f"No such command '{bad_arg}'. Did you mean {' or '.join(suggested_commands)}?"
                 )
 
         raise usage_error
 
     @property
-    def commands(self) -> Dict:
+    def commands(self) -> dict:
         if self._commands:
             return self._commands
 
-        entry_points = metadata.entry_points(group=self._CLI_GROUP_NAME)
-        if not entry_points:
-            raise Abort("Missing registered CLI subcommands.")
-
-        self._commands = {
-            clean_plugin_name(entry_point.name): entry_point.load for entry_point in entry_points
-        }
+        _entry_points = entry_points()
+        eps: Iterable
+        if select_fn := getattr(_entry_points, "select", None):
+            # NOTE: Using getattr because mypy.
+            eps = select_fn(group=self._CLI_GROUP_NAME)
+        else:
+            # Python 3.9. Can remove once we drop support.
+            with warnings.catch_warnings():
+                warnings.simplefilter("ignore")
+                eps = _entry_points.get(self._CLI_GROUP_NAME, [])  # type: ignore
+
+        self._commands = {clean_plugin_name(cmd.name): cmd.load for cmd in eps}
         return self._commands
 
-    def list_commands(self, ctx) -> List[str]:
+    def list_commands(self, ctx) -> list[str]:
         return list(sorted(self.commands))
 
     def get_command(self, ctx, name) -> Optional[click.Command]:
         if name in self.commands:
             try:
                 return self.commands[name]()
             except Exception as err:
```

### Comparing `eth-ape-0.7.9/src/ape/api/__init__.py` & `eth-ape-0.8.0/src/ape/api/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -16,14 +16,15 @@
     NetworkAPI,
     ProviderContextManager,
     create_network_type,
 )
 from .projects import DependencyAPI, ProjectAPI
 from .providers import BlockAPI, ProviderAPI, SubprocessProvider, TestProviderAPI, UpstreamProvider
 from .query import QueryAPI, QueryType
+from .trace import TraceAPI
 from .transactions import ReceiptAPI, TransactionAPI
 
 __all__ = [
     "AccountAPI",
     "AccountContainerAPI",
     "Address",
     "BlockAPI",
@@ -45,10 +46,11 @@
     "QueryAPI",
     "NetworkAPI",
     "ReceiptAPI",
     "SubprocessProvider",
     "TestAccountAPI",
     "TestAccountContainerAPI",
     "TestProviderAPI",
+    "TraceAPI",
     "TransactionAPI",
     "UpstreamProvider",
 ]
```

### Comparing `eth-ape-0.7.9/src/ape/api/accounts.py` & `eth-ape-0.8.0/src/ape/api/accounts.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,16 +1,18 @@
+import os
+from collections.abc import Iterator
 from pathlib import Path
-from typing import TYPE_CHECKING, Any, Iterator, List, Optional, Type, Union
+from typing import TYPE_CHECKING, Any, Optional, Union
 
 import click
 from eip712.messages import EIP712Message
 from eip712.messages import SignableMessage as EIP712SignableMessage
 from eth_account import Account
 from eth_account.messages import encode_defunct
-from hexbytes import HexBytes
+from eth_pydantic_types import HexBytes
 
 from ape.api.address import BaseAddress
 from ape.api.transactions import ReceiptAPI, TransactionAPI
 from ape.exceptions import (
     AccountsError,
     AliasAlreadyInUseError,
     MethodNonPayableError,
@@ -27,20 +29,20 @@
 
 
 class AccountAPI(BaseInterfaceModel, BaseAddress):
     """
     An API class representing an account.
     """
 
-    def __dir__(self) -> List[str]:
+    def __dir__(self) -> list[str]:
         """
         Display methods to IPython on ``a.[TAB]`` tab completion.
 
         Returns:
-            List[str]: Method names that IPython uses for tab completion.
+            list[str]: Method names that IPython uses for tab completion.
         """
         base_value_excludes = ("code", "codesize", "is_contract")  # Not needed for accounts
         base_values = [v for v in self._base_dir_values if v not in base_value_excludes]
         return base_values + [
             self.__class__.alias.fget.__name__,  # type: ignore[attr-defined]
             self.__class__.call.__name__,
             self.__class__.deploy.__name__,
@@ -53,14 +55,31 @@
     @property
     def alias(self) -> Optional[str]:
         """
         A shortened-name for quicker access to the account.
         """
         return None
 
+    def sign_raw_msghash(self, msghash: HexBytes) -> Optional[MessageSignature]:
+        """
+        Sign a raw message hash.
+
+        Args:
+          msghash (:class:`~eth_pydantic_types.HexBytes`):
+            The message hash to sign. Plugins may or may not support this operation.
+            Default implementation is to raise ``NotImplementedError``.
+
+        Returns:
+          :class:`~ape.types.signatures.MessageSignature` (optional):
+            The signature corresponding to the message.
+        """
+        raise NotImplementedError(
+            f"Raw message signing is not supported by '{self.__class__.__name__}'"
+        )
+
     @abstractmethod
     def sign_message(self, msg: Any, **signer_options) -> Optional[MessageSignature]:
         """
         Sign a message.
 
         Args:
           msg (Any): The message to sign. Account plugins can handle various types of messages.
@@ -257,17 +276,18 @@
         styled_address = click.style(receipt.contract_address, bold=True)
         contract_name = contract_type.name or "<Unnamed Contract>"
         logger.success(f"Contract '{contract_name}' deployed to: {styled_address}")
         instance = self.chain_manager.contracts.instance_from_receipt(receipt, contract_type)
         self.chain_manager.contracts.cache_deployment(instance)
 
         if publish:
-            self.project_manager.track_deployment(instance)
+            self.local_project.deployments.track(instance)
             self.provider.network.publish_contract(address)
 
+        instance.base_path = contract.base_path or self.local_project.path
         return instance
 
     def declare(self, contract: "ContractContainer", *args, **kwargs) -> ReceiptAPI:
         """
         Deploy the "blueprint" of a contract type. For EVM providers, this likely means
         using `EIP-5202 <https://eips.ethereum.org/EIPS/eip-5202>`__, which is implemented
         in the core ``ape-ethereum`` plugin.
@@ -291,48 +311,58 @@
         else:
             logger.debug("Failed to cache contract declaration: missing contract address.")
 
         return receipt
 
     def check_signature(
         self,
-        data: Union[SignableMessage, TransactionAPI, str, EIP712Message, int],
+        data: Union[SignableMessage, TransactionAPI, str, EIP712Message, int, bytes],
         signature: Optional[MessageSignature] = None,  # TransactionAPI doesn't need it
+        recover_using_eip191: bool = True,
     ) -> bool:
         """
         Verify a message or transaction was signed by this account.
 
         Args:
             data (Union[:class:`~ape.types.signatures.SignableMessage`, :class:`~ape.api.transactions.TransactionAPI`]):  # noqa: E501
               The message or transaction to verify.
             signature (Optional[:class:`~ape.types.signatures.MessageSignature`]):
               The signature to check. Defaults to ``None`` and is not needed when the first
               argument is a transaction class.
+            recover_using_eip191 (bool):
+              Perform recovery using EIP-191 signed message check. If set False, then will attempt
+              recovery as raw hash. `data`` must be a 32 byte hash if this is set False.
+              Defaults to ``True``.
 
         Returns:
             bool: ``True`` if the data was signed by this account. ``False`` otherwise.
         """
         if isinstance(data, str):
             data = encode_defunct(text=data)
         elif isinstance(data, int):
             data = encode_defunct(hexstr=HexBytes(data).hex())
+        elif isinstance(data, bytes) and (len(data) != 32 or recover_using_eip191):
+            data = encode_defunct(data)
         elif isinstance(data, EIP712Message):
             data = data.signable_message
         if isinstance(data, (SignableMessage, EIP712SignableMessage)):
             if signature:
                 return self.address == Account.recover_message(data, vrs=signature)
 
             else:
                 raise AccountsError(
                     "Parameter 'signature' required when verifying a 'SignableMessage'."
                 )
 
         elif isinstance(data, TransactionAPI):
             return self.address == Account.recover_transaction(data.serialize_transaction())
 
+        elif isinstance(data, bytes) and len(data) == 32 and not recover_using_eip191:
+            return self.address == Account._recover_hash(data, vrs=signature)
+
         else:
             raise AccountsError(f"Unsupported message type: {type(data)}.")
 
     def prepare_transaction(self, txn: TransactionAPI) -> TransactionAPI:
         """
         Set default values on a transaction.
 
@@ -370,38 +400,57 @@
 
 class AccountContainerAPI(BaseInterfaceModel):
     """
     An API class representing a collection of :class:`~ape.api.accounts.AccountAPI`
     instances.
     """
 
-    data_folder: Path
+    name: str
+    """
+    The name of the account container.
+    For example, the ``ape-ledger`` plugin
+    uses ``"ledger"`` as its name.
+    """
 
-    account_type: Type[AccountAPI]
+    account_type: type[AccountAPI]
+    """
+    The type of account in this container.
+    See :class:`~ape.api.accounts.AccountAPI`.
+    """
 
     @property
     @abstractmethod
     def aliases(self) -> Iterator[str]:
         """
-        Iterate over all available aliases.
+        All available aliases.
 
         Returns:
             Iterator[str]
         """
 
     @property
     @abstractmethod
     def accounts(self) -> Iterator[AccountAPI]:
         """
-        Iterate over all accounts.
+        All accounts.
 
         Returns:
             Iterator[:class:`~ape.api.accounts.AccountAPI`]
         """
 
+    @property
+    def data_folder(self) -> Path:
+        """
+        The path to the account data files.
+        Defaults to ``$HOME/.ape/<plugin_name>`` unless overriden.
+        """
+        path = self.config_manager.DATA_FOLDER / self.name
+        path.mkdir(parents=True, exist_ok=True)
+        return path
+
     @abstractmethod
     def __len__(self) -> int:
         """
         Number of accounts.
         """
 
     def __getitem__(self, address: AddressType) -> AccountAPI:
@@ -409,24 +458,24 @@
         Get an account by address.
 
         Args:
             address (:class:`~ape.types.address.AddressType`): The address to get. The type is an alias to
               `ChecksumAddress <https://eth-typing.readthedocs.io/en/latest/types.html#checksumaddress>`__.  # noqa: E501
 
         Raises:
-            IndexError: When there is no local account with the given address.
+            KeyError: When there is no local account with the given address.
 
         Returns:
             :class:`~ape.api.accounts.AccountAPI`
         """
         for account in self.accounts:
             if account.address == address:
                 return account
 
-        raise IndexError(f"No local account {address}.")
+        raise KeyError(f"No local account {address}.")
 
     def append(self, account: AccountAPI):
         """
         Add an account to the container.
 
         Raises:
             :class:`~ape.exceptions.AccountsError`: When the account is already in the container.
@@ -488,15 +537,15 @@
         Returns:
             bool: ``True`` if ``ape`` manages the account with the given address.
         """
         try:
             self.__getitem__(address)
             return True
 
-        except (IndexError, AttributeError):
+        except (IndexError, KeyError, AttributeError):
             return False
 
     def _verify_account_type(self, account):
         if not isinstance(account, self.account_type):
             container_type_name = getattr(type(account), "__name__", "<CustomContainerType>")
             account_type_name = getattr(self.account_type, "__name__", "<UnknownAccount>")
             message = (
@@ -511,37 +560,53 @@
             raise AliasAlreadyInUseError(account.alias)
 
 
 class TestAccountContainerAPI(AccountContainerAPI):
     """
     Test account containers for ``ape test`` (such containers that generate accounts using
     :class:`~ape.utils.GeneratedDevAccounts`) should implement this API instead of
-    ``AccountContainerAPI`` directly. This is how they show up in the ``accounts`` test fixture.
+    ``AccountContainerAPI`` directly. Then, they show up in the ``accounts`` test fixture.
     """
 
+    @property
+    def data_folder(self) -> Path:
+        """
+        **NOTE**: Test account containers do not touch
+        persistant data. By default and unless overriden,
+        this property returns the path to ``/dev/null`` and
+        it is not used for anything.
+        """
+        if os.name == "posix":
+            return Path("/dev/null")
+
+        return Path("NUL")
+
     @abstractmethod
     def generate_account(self) -> "TestAccountAPI":
         """
-        Generate a new test account
+        Generate a new test account.
         """
 
 
 class TestAccountAPI(AccountAPI):
     """
     Test accounts for ``ape test`` (such accounts that use
     :class:`~ape.utils.GeneratedDevAccounts`) should implement this API
-    instead of ``AccountAPI`` directly. This is how they show up in the ``accounts`` test fixture.
+    instead of ``AccountAPI`` directly. Then, they show up in the ``accounts`` test fixture.
     """
 
 
 class ImpersonatedAccount(AccountAPI):
     """
     An account to use that does not require signing.
     """
 
+    """
+    The field-address of the account.
+    """
     raw_address: AddressType
 
     @property
     def address(self) -> AddressType:
         return self.raw_address
 
     def sign_message(self, msg: Any, **signer_options) -> Optional[MessageSignature]:
```

### Comparing `eth-ape-0.7.9/src/ape/api/address.py` & `eth-ape-0.8.0/src/ape/api/address.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,27 +1,27 @@
-from typing import TYPE_CHECKING, Any, List
+from typing import TYPE_CHECKING, Any
 
 from eth_pydantic_types import HexBytes
 
 from ape.exceptions import ConversionError
 from ape.types import AddressType, ContractCode
-from ape.utils import BaseInterface, abstractmethod, cached_property
+from ape.utils import BaseInterface, abstractmethod, cached_property, log_instead_of_fail
 
 if TYPE_CHECKING:
     from ape.api.transactions import ReceiptAPI, TransactionAPI
     from ape.managers.chain import AccountHistory
 
 
 class BaseAddress(BaseInterface):
     """
     A base address API class. All account-types subclass this type.
     """
 
     @property
-    def _base_dir_values(self) -> List[str]:
+    def _base_dir_values(self) -> list[str]:
         """
         This exists because when you call ``dir(BaseAddress)``, you get the type's return
         value and not the instances. This allows base-classes to make use of shared
         ``IPython`` ``__dir__`` values.
         """
 
         # NOTE: mypy is confused by properties.
@@ -57,24 +57,25 @@
 
         try:
             return convert(self, AddressType) == convert(other, AddressType)
         except ConversionError:
             # Check other __eq__
             return NotImplemented
 
-    def __dir__(self) -> List[str]:
+    def __dir__(self) -> list[str]:
         """
         Display methods to IPython on ``a.[TAB]`` tab completion.
         Overridden to lessen amount of methods shown to only those that are useful.
 
         Returns:
-            List[str]: Method names that IPython uses for tab completion.
+            list[str]: Method names that IPython uses for tab completion.
         """
         return self._base_dir_values
 
+    @log_instead_of_fail(default="<BaseAddress>")
     def __repr__(self) -> str:
         cls_name = getattr(type(self), "__name__", BaseAddress.__name__)
         return f"<{cls_name} {self.address}>"
 
     def __str__(self) -> str:
         """
         Convert this class to a ``str`` address.
```

### Comparing `eth-ape-0.7.9/src/ape/api/compiler.py` & `eth-ape-0.8.0/src/ape/api/compiler.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,168 +1,190 @@
+from collections.abc import Iterable, Iterator
 from functools import cached_property
 from pathlib import Path
-from typing import Dict, Iterator, List, Optional, Sequence, Set, Tuple
+from typing import TYPE_CHECKING, Optional
 
 from eth_pydantic_types import HexBytes
 from ethpm_types import ContractType
 from ethpm_types.source import Content, ContractSource
-from evm_trace.geth import TraceFrame as EvmTraceFrame
-from evm_trace.geth import create_call_node_data
 from packaging.version import Version
 
 from ape.api.config import PluginConfig
+from ape.api.trace import TraceAPI
 from ape.exceptions import APINotImplementedError, ContractLogicError
 from ape.types.coverage import ContractSourceCoverage
-from ape.types.trace import SourceTraceback, TraceFrame
-from ape.utils import BaseInterfaceModel, abstractmethod, raises_not_implemented
+from ape.types.trace import SourceTraceback
+from ape.utils import (
+    BaseInterfaceModel,
+    abstractmethod,
+    log_instead_of_fail,
+    raises_not_implemented,
+)
+
+if TYPE_CHECKING:
+    from ape.managers.project import ProjectManager
 
 
 class CompilerAPI(BaseInterfaceModel):
     """
     Compiler plugins, such as for languages like
     `Solidity <https://docs.soliditylang.org/en/v0.8.11/>`__ or
     `Vyper <https://vyper.readthedocs.io/en/stable/>`__, implement this API.
 
     See the repository for the `ape-solidity <https://github.com/ApeWorX/ape-solidity>`__ plugin or
     the `ape-vyper <https://github.com/ApeWorX/ape-vyper>`__ plugin as example implementations of
     this API.
     """
 
-    compiler_settings: Dict = {}
+    compiler_settings: dict = {}
     """
     Adhoc compiler settings.
     """
 
     @property
     @abstractmethod
     def name(self) -> str:
         """
         The name of the compiler.
         """
 
-    @property
-    def config(self) -> PluginConfig:
-        """
-        The provider's configuration.
-        """
-        return self.config_manager.get_config(self.name)
-
-    @property
-    def settings(self) -> PluginConfig:
+    def get_config(self, project: Optional["ProjectManager"] = None) -> PluginConfig:
         """
         The combination of settings from ``ape-config.yaml`` and ``.compiler_settings``.
+
+        Args:
+            project (Optional[:class:`~ape.managers.project.ProjectManager`]): Optionally provide
+              the project containing the base paths and full source set. Defaults to the local
+              project. Dependencies will change this value to their respective projects.
+
+        Returns:
+            :class:`~ape.api.config.PluginConfig`
         """
-        CustomConfig = self.config.__class__
-        data = {**self.config.model_dump(mode="json", by_alias=True), **self.compiler_settings}
-        return CustomConfig.model_validate(data)
+        pm = project or self.local_project
+        config = pm.config.get_config(self.name)
+        data = {**config.model_dump(mode="json", by_alias=True), **self.compiler_settings}
+        return config.model_validate(data)
 
-    @abstractmethod
-    def get_versions(self, all_paths: Sequence[Path]) -> Set[str]:
+    @raises_not_implemented
+    def get_versions(self, all_paths: Iterable[Path]) -> set[str]:  # type: ignore[empty-body]
         """
         Retrieve the set of available compiler versions for this plugin to compile ``all_paths``.
 
         Args:
-            all_paths (Sequence[pathlib.Path]): The list of paths.
+            all_paths (Iterable[pathlib.Path]): The list of paths.
 
         Returns:
-            Set[str]: A set of available compiler versions.
+            set[str]: A set of available compiler versions.
         """
 
     @raises_not_implemented
     def get_compiler_settings(  # type: ignore[empty-body]
-        self, contract_filepaths: Sequence[Path], base_path: Optional[Path] = None
-    ) -> Dict[Version, Dict]:
+        self,
+        contract_filepaths: Iterable[Path],
+        project: Optional["ProjectManager"] = None,
+        **overrides,
+    ) -> dict[Version, dict]:
         """
         Get a mapping of the settings that would be used to compile each of the sources
         by the compiler version number.
 
         Args:
-            contract_filepaths (Sequence[pathlib.Path]): The list of paths.
-            base_path (Optional[pathlib.Path]): The contracts folder base path.
+            contract_filepaths (Iterable[pathlib.Path]): The list of paths.
+            project (Optional[:class:`~ape.managers.project.ProjectManager`]): Optionally provide
+              the project containing the base paths and full source set. Defaults to the local
+              project. Dependencies will change this value to their respective projects.
+            **overrides: Settings overrides.
 
         Returns:
-            Dict[Version, Dict]: A dict of compiler settings by compiler version.
+            dict[Version, dict]: A dict of compiler settings by compiler version.
         """
 
     @abstractmethod
     def compile(
-        self, contract_filepaths: Sequence[Path], base_path: Optional[Path]
-    ) -> List[ContractType]:
+        self,
+        contract_filepaths: Iterable[Path],
+        project: Optional["ProjectManager"],
+        settings: Optional[dict] = None,
+    ) -> Iterator[ContractType]:
         """
         Compile the given source files. All compiler plugins must implement this function.
 
         Args:
-            contract_filepaths (Sequence[pathlib.Path]): A list of source file paths to compile.
-            base_path (Optional[pathlib.Path]): Optionally provide the base path, such as the
-              project ``contracts/`` directory. Defaults to ``None``. When using in a project
-              via ``ape compile``, gets set to the project's ``contracts/`` directory.
+            contract_filepaths (Iterable[pathlib.Path]): A list of source file paths to compile.
+            project (Optional[:class:`~ape.managers.project.ProjectManager`]): Optionally provide
+              the project containing the base paths and full source set. Defaults to the local
+              project. Dependencies will change this value to their respective projects.
+            settings (Optional[dict]): Adhoc compiler settings.
 
         Returns:
-            List[:class:`~ape.type.contract.ContractType`]
+            list[:class:`~ape.type.contract.ContractType`]
         """
 
     @raises_not_implemented
     def compile_code(  # type: ignore[empty-body]
         self,
         code: str,
-        base_path: Optional[Path] = None,
+        project: Optional["ProjectManager"],
+        settings: Optional[dict] = None,
         **kwargs,
     ) -> ContractType:
         """
         Compile a program.
 
         Args:
             code (str): The code to compile.
-            base_path (Optional[pathlib.Path]): Optionally provide the base path, such as the
-              project ``contracts/`` directory. Defaults to ``None``. When using in a project
-              via ``compilers.compile_source()``, gets set to the project's ``contracts/``
-              directory.
+            project (Optional[:class:`~ape.managers.project.ProjectManager`]): Optionally provide
+              the project containing the base paths and full source set. Defaults to the local
+              project. Dependencies will change this value to their respective projects.
+            settings (Optional[Dict]): Adhoc compiler settings.
             **kwargs: Additional overrides for the ``ethpm_types.ContractType`` model.
 
         Returns:
             ``ContractType``: A compiled contract artifact.
         """
 
     @raises_not_implemented
     def get_imports(  # type: ignore[empty-body]
-        self, contract_filepaths: Sequence[Path], base_path: Optional[Path]
-    ) -> Dict[str, List[str]]:
+        self, contract_filepaths: Iterable[Path], project: Optional["ProjectManager"]
+    ) -> dict[str, list[str]]:
         """
         Returns a list of imports as source_ids for each contract's source_id in a given
         compiler.
 
         Args:
-            contract_filepaths (Sequence[pathlib.Path]): A list of source file paths to compile.
-            base_path (Optional[pathlib.Path]): Optionally provide the base path, such as the
-              project ``contracts/`` directory. Defaults to ``None``. When using in a project
-              via ``ape compile``, gets set to the project's ``contracts/`` directory.
+            contract_filepaths (Iterable[pathlib.Path]): A list of source file paths to compile.
+            project (Optional[:class:`~ape.managers.project.ProjectManager`]): Optionally provide
+              the project containing the base paths and full source set. Defaults to the local
+              project. Dependencies will change this value to their respective projects.
 
         Returns:
-            Dict[str, List[str]]: A dictionary like ``{source_id: [import_source_id, ...], ...}``
+            dict[str, list[str]]: A dictionary like ``{source_id: [import_source_id, ...], ...}``
         """
 
     @raises_not_implemented
     def get_version_map(  # type: ignore[empty-body]
         self,
-        contract_filepaths: Sequence[Path],
-        base_path: Optional[Path] = None,
-    ) -> Dict[Version, Set[Path]]:
+        contract_filepaths: Iterable[Path],
+        project: Optional["ProjectManager"] = None,
+    ) -> dict[Version, set[Path]]:
         """
         Get a map of versions to source paths.
 
         Args:
-            contract_filepaths (Sequence[Path]): Input source paths. Defaults to all source paths
+            contract_filepaths (Iterable[Path]): Input source paths. Defaults to all source paths
               per compiler.
-            base_path (Path): The base path of sources. Defaults to the project's
-              ``contracts_folder``.
+            project (Optional[:class:`~ape.managers.project.ProjectManager`]): Optionally provide
+              the project containing the base paths and full source set. Defaults to the local
+              project. Dependencies will change this value to their respective projects.
 
         Returns:
-            Dict[Version, Set[Path]]
+            dict[Version, set[Path]]
         """
 
+    @log_instead_of_fail(default="<CompilerAPI>")
     def __repr__(self) -> str:
         cls_name = getattr(type(self), "__name__", CompilerAPI.__name__)
         return f"<{cls_name} {self.name}>"
 
     def __str__(self) -> str:
         return self.name
 
@@ -195,67 +217,53 @@
             :class:`~ape.exceptions.ContractLogicError`: The enriched exception.
         """
 
         return err
 
     @raises_not_implemented
     def trace_source(  # type: ignore[empty-body]
-        self, contract_type: ContractType, trace: Iterator[TraceFrame], calldata: HexBytes
+        self, contract_source: ContractSource, trace: TraceAPI, calldata: HexBytes
     ) -> SourceTraceback:
         """
         Get a source-traceback for the given contract type.
         The source traceback object contains all the control paths taken in the transaction.
         When available, source-code location information is accessible from the object.
 
         Args:
-            contract_type (``ContractType``): A contract type that was created by this compiler.
-            trace (Iterator[:class:`~ape.types.trace.TraceFrame`]): The resulting frames from
-              executing a function defined in the given contract type.
+            contract_source (``ContractSource``): A contract type with a local-source that was
+              compiled by this compiler.
+            trace (:class:`~ape.api.trace.TraceAPI`]): The resulting trace from executing a
+              function defined in the given contract type.
             calldata (``HexBytes``): Calldata passed to the top-level call.
 
         Returns:
             :class:`~ape.types.trace.SourceTraceback`
         """
 
     @raises_not_implemented
-    def flatten_contract(self, path: Path, **kwargs) -> Content:  # type: ignore[empty-body]
+    def flatten_contract(  # type: ignore[empty-body]
+        self, path: Path, project: Optional["ProjectManager"] = None, **kwargs
+    ) -> Content:
         """
         Get the content of a flattened contract via its source path.
         Plugin implementations handle import resolution, SPDX de-duplication,
         and anything else needed.
 
         Args:
             path (``pathlib.Path``): The source path of the contract.
+            project (Optional[:class:`~ape.managers.project.ProjectManager`]): Optionally provide
+              the project containing the base paths and full source set. Defaults to the local
+              project. Dependencies will change this value to their respective projects.
             **kwargs (Any): Additional compiler-specific settings. See specific
               compiler plugins when applicable.
 
         Returns:
             ``ethpm_types.source.Content``: The flattened contract content.
         """
 
-    def _create_contract_from_call(
-        self, frame: TraceFrame
-    ) -> Tuple[Optional[ContractSource], HexBytes]:
-        evm_frame = EvmTraceFrame(**frame.raw)
-        data = create_call_node_data(evm_frame)
-        calldata = data.get("calldata", HexBytes(""))
-        if not (address := (data.get("address", frame.contract_address) or None)):
-            return None, calldata
-
-        try:
-            address = self.provider.network.ecosystem.decode_address(address)
-        except Exception:
-            return None, calldata
-
-        if address not in self.chain_manager.contracts:
-            return None, calldata
-
-        called_contract = self.chain_manager.contracts[address]
-        return self.project_manager._create_contract_source(called_contract), calldata
-
     @raises_not_implemented
     def init_coverage_profile(
         self, source_coverage: ContractSourceCoverage, contract_source: ContractSource
     ):  # type: ignore[empty-body]
         """
         Initialize an empty report for the given source ID. Modifies the given source
         coverage in-place.
```

### Comparing `eth-ape-0.7.9/src/ape/api/convert.py` & `eth-ape-0.8.0/src/ape/api/convert.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/src/ape/api/explorers.py` & `eth-ape-0.8.0/src/ape/api/explorers.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/src/ape/api/networks.py` & `eth-ape-0.8.0/src/ape/api/networks.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,60 +1,51 @@
+from collections.abc import Collection, Iterator, Sequence
 from functools import partial
 from pathlib import Path
-from typing import (
-    TYPE_CHECKING,
-    Any,
-    ClassVar,
-    Collection,
-    Dict,
-    Iterator,
-    List,
-    Optional,
-    Sequence,
-    Tuple,
-    Type,
-    Union,
-)
+from typing import TYPE_CHECKING, Any, ClassVar, Optional, Union
 
 from eth_account import Account as EthAccount
 from eth_account._utils.legacy_transactions import (
     encode_transaction,
     serializable_unsigned_transaction_from_dict,
 )
 from eth_pydantic_types import HexBytes
 from eth_utils import keccak, to_int
 from ethpm_types import BaseModel, ContractType
 from ethpm_types.abi import ABIType, ConstructorABI, EventABI, MethodABI
 
 from ape.exceptions import (
+    CustomError,
     NetworkError,
     NetworkMismatchError,
     NetworkNotFoundError,
     ProviderNotConnectedError,
     ProviderNotFoundError,
     SignatureError,
 )
 from ape.logging import logger
-from ape.types import AddressType, AutoGasLimit, CallTreeNode, ContractLog, GasLimit, RawAddress
+from ape.types import AddressType, AutoGasLimit, ContractLog, GasLimit, RawAddress
 from ape.utils import (
     DEFAULT_TRANSACTION_ACCEPTANCE_TIMEOUT,
     BaseInterfaceModel,
     ExtraAttributesMixin,
     ExtraModelAttributes,
     ManagerAccessMixin,
     abstractmethod,
     cached_property,
+    log_instead_of_fail,
     raises_not_implemented,
 )
 
 from .config import PluginConfig
 
 if TYPE_CHECKING:
     from .explorers import ExplorerAPI
     from .providers import BlockAPI, ProviderAPI, UpstreamProvider
+    from .trace import TraceAPI
     from .transactions import ReceiptAPI, TransactionAPI
 
 
 LOCAL_NETWORK_NAME = "local"
 
 
 class ProxyInfoAPI(BaseModel):
@@ -72,32 +63,38 @@
     """
 
     name: str
     """
     The name of the ecosystem. This should be set the same name as the plugin.
     """
 
-    data_folder: Path
-    """The path to the ``.ape`` directory."""
-
-    request_header: Dict
+    request_header: dict
     """A shareable HTTP header for network requests."""
 
     fee_token_symbol: str
     """The token symbol for the currency that pays for fees, such as ETH."""
 
     fee_token_decimals: int = 18
     """The number of the decimals the fee token has."""
 
     _default_network: Optional[str] = None
     """The default network of the ecosystem, such as ``local``."""
 
+    @log_instead_of_fail(default="<EcosystemAPI>")
     def __repr__(self) -> str:
         return f"<{self.name}>"
 
+    @property
+    def data_folder(self) -> Path:
+        """
+        The path to the ecosystem's data folder,
+        e.g. ``$HOME/.ape/{self.name}`` unless overridden.
+        """
+        return self.config_manager.DATA_FOLDER / self.name
+
     @cached_property
     def custom_network(self) -> "NetworkAPI":
         """
         A :class:`~ape.api.networks.NetworkAPI` for custom networks where the
         network is either not known, unspecified, or does not have an Ape plugin.
         """
 
@@ -107,26 +104,21 @@
                 ethereum_class = ecosystem_class
                 break
 
         if ethereum_class is None:
             raise NetworkError("Core Ethereum plugin missing.")
 
         request_header = self.config_manager.REQUEST_HEADER
-        init_kwargs = {
-            "name": "ethereum",
-            "data_folder": self.data_folder,
-            "request_header": request_header,
-        }
+        init_kwargs = {"name": "ethereum", "request_header": request_header}
         ethereum = ethereum_class(**init_kwargs)  # type: ignore
         return NetworkAPI(
             name="custom",
             ecosystem=ethereum,
-            data_folder=self.data_folder / "custom",
             request_header=request_header,
-            _default_provider="geth",
+            _default_provider="node",
             _is_custom=True,
         )
 
     @classmethod
     @abstractmethod
     def decode_address(cls, raw_address: RawAddress) -> AddressType:
         """
@@ -196,56 +188,55 @@
 
         if self.sender and EthAccount.recover_transaction(signed_txn) != self.sender:
             raise SignatureError("Recovered signer doesn't match sender!")
 
         return signed_txn
 
     @abstractmethod
-    def decode_receipt(self, data: Dict) -> "ReceiptAPI":
+    def decode_receipt(self, data: dict) -> "ReceiptAPI":
         """
         Convert data to :class:`~ape.api.transactions.ReceiptAPI`.
 
         Args:
             data (Dict): A dictionary of Receipt properties.
 
         Returns:
             :class:`~ape.api.transactions.ReceiptAPI`
         """
 
     @abstractmethod
-    def decode_block(self, data: Dict) -> "BlockAPI":
+    def decode_block(self, data: dict) -> "BlockAPI":
         """
         Decode data to a :class:`~ape.api.providers.BlockAPI`.
 
         Args:
             data (Dict): A dictionary of data to decode.
 
         Returns:
             :class:`~ape.api.providers.BlockAPI`
         """
 
-    @cached_property
+    @property
     def config(self) -> PluginConfig:
         """
         The configuration of the ecosystem. See :class:`ape.managers.config.ConfigManager`
         for more information on plugin configurations.
 
         Returns:
             :class:`ape.api.config.PluginConfig`
         """
-
         return self.config_manager.get_config(self.name)
 
     @property
-    def networks(self) -> Dict[str, "NetworkAPI"]:
+    def networks(self) -> dict[str, "NetworkAPI"]:
         """
         A dictionary of network names mapped to their API implementation.
 
         Returns:
-            Dict[str, :class:`~ape.api.networks.NetworkAPI`]
+            dict[str, :class:`~ape.api.networks.NetworkAPI`]
         """
         networks = {**self._networks_from_plugins}
 
         # Include configured custom networks.
         custom_networks = [
             n
             for n in self.config_manager.get_config("networks").custom
@@ -253,35 +244,29 @@
         ]
         for custom_net in custom_networks:
             if custom_net.name in networks:
                 raise NetworkError(
                     f"More than one network named '{custom_net.name}' in ecosystem '{self.name}'."
                 )
 
-            network_data = custom_net.model_dump(
-                mode="json", by_alias=True, exclude=("default_provider",)
-            )
-            network_data["data_folder"] = self.data_folder / custom_net.name
+            network_data = custom_net.model_dump(by_alias=True, exclude=("default_provider",))
             network_data["ecosystem"] = self
             network_type = create_network_type(custom_net.chain_id, custom_net.chain_id)
             network_api = network_type.model_validate(network_data)
             network_api._default_provider = custom_net.default_provider
             network_api._is_custom = True
             networks[custom_net.name] = network_api
 
         return networks
 
     @cached_property
-    def _networks_from_plugins(self) -> Dict[str, "NetworkAPI"]:
+    def _networks_from_plugins(self) -> dict[str, "NetworkAPI"]:
         return {
             network_name: network_class(
-                name=network_name,
-                ecosystem=self,
-                data_folder=self.data_folder / network_name,
-                request_header=self.request_header,
+                name=network_name, ecosystem=self, request_header=self.request_header
             )
             for _, (ecosystem_name, network_name, network_class) in self.plugin_manager.networks
             if ecosystem_name == self.name
         }
 
     def __post_init__(self):
         if len(self.networks) == 0:
@@ -316,28 +301,30 @@
         """
         The name of the default network in this ecosystem.
 
         Returns:
             str
         """
         if network := self._default_network:
-            # Was set programatically.
+            # Was set programmatically.
             return network
 
         elif network := self.config.get("default_network"):
-            # Default found in config.
-            return network
+            # Default found in config. Ensure is an installed network.
+            if network in self.networks:
+                return network
 
-        elif LOCAL_NETWORK_NAME in self.networks:
+        if LOCAL_NETWORK_NAME in self.networks:
             # Default to the LOCAL_NETWORK_NAME, at last resort.
             return LOCAL_NETWORK_NAME
 
         elif len(self.networks) >= 1:
             # Use the first network.
-            return self.networks[0]
+            key = next(iter(self.networks.keys()))
+            return self.networks[key].name
 
         # Very unlikely scenario.
         raise NetworkError("No networks found.")
 
     @property
     def default_network(self) -> "NetworkAPI":
         return self.get_network(self.default_network_name)
@@ -390,42 +377,42 @@
             **kwargs (Any): Transaction arguments.
 
         Returns:
             class:`~ape.api.transactions.TransactionAPI`
         """
 
     @abstractmethod
-    def decode_logs(self, logs: Sequence[Dict], *events: EventABI) -> Iterator["ContractLog"]:
+    def decode_logs(self, logs: Sequence[dict], *events: EventABI) -> Iterator["ContractLog"]:
         """
         Decode any contract logs that match the given event ABI from the raw log data.
 
         Args:
             logs (Sequence[Dict]): A list of raw log data from the chain.
             *events (EventABI): Event definitions to decode.
 
         Returns:
             Iterator[:class:`~ape.types.ContractLog`]
         """
 
     @raises_not_implemented
     def decode_primitive_value(  # type: ignore[empty-body]
-        self, value: Any, output_type: Union[str, Tuple, List]
-    ) -> Union[str, HexBytes, Tuple]:
+        self, value: Any, output_type: Union[str, tuple, list]
+    ) -> Union[str, HexBytes, tuple]:
         """
         Decode a primitive value-type given its ABI type as a ``str``
         and the value itself. This method is a hook for converting
         addresses, HexBytes, or other primitive data-types into
         friendlier Python equivalents.
 
         Args:
             value (Any): The value to decode.
-            output_type (Union[str, Tuple, List]): The value type.
+            output_type (Union[str, tuple, list]): The value type.
 
         Returns:
-            Union[str, HexBytes, Tuple]
+            Union[str, HexBytes, tuple]
         """
 
     @abstractmethod
     def create_transaction(self, **kwargs) -> "TransactionAPI":
         """
         Create a transaction using key-value arguments.
 
@@ -433,15 +420,15 @@
             **kwargs: Everything the transaction needs initialize.
 
         Returns:
             class:`~ape.api.transactions.TransactionAPI`
         """
 
     @abstractmethod
-    def decode_calldata(self, abi: Union[ConstructorABI, MethodABI], calldata: bytes) -> Dict:
+    def decode_calldata(self, abi: Union[ConstructorABI, MethodABI], calldata: bytes) -> dict:
         """
         Decode method calldata.
 
         Args:
             abi (Union[ConstructorABI, MethodABI]): The method called.
             calldata (bytes): The raw calldata bytes.
 
@@ -500,30 +487,30 @@
                 # Is an adhoc-custom network NOT from config.
                 return self.custom_network
 
         raise NetworkNotFoundError(network_name, ecosystem=self.name, options=self.networks)
 
     def get_network_data(
         self, network_name: str, provider_filter: Optional[Collection[str]] = None
-    ) -> Dict:
+    ) -> dict:
         """
         Get a dictionary of data about providers in the network.
 
         **NOTE**: The keys are added in an opinionated order for nicely
         translating into ``yaml``.
 
         Args:
             network_name (str): The name of the network to get provider data from.
             provider_filter (Optional[Collection[str]]): Optionally filter the providers
               by name.
 
         Returns:
             dict: A dictionary containing the providers in a network.
         """
-        data: Dict[str, Any] = {"name": str(network_name)}
+        data: dict[str, Any] = {"name": str(network_name)}
 
         # Only add isDefault key when True
         if network_name == self.default_network_name:
             data["isDefault"] = True
 
         data["providers"] = []
         network = self[network_name]
@@ -531,15 +518,15 @@
         if network.explorer:
             data["explorer"] = str(network.explorer.name)
 
         for provider_name in network.providers:
             if provider_filter and provider_name not in provider_filter:
                 continue
 
-            provider_data: Dict = {"name": str(provider_name)}
+            provider_data: dict = {"name": str(provider_name)}
 
             # Only add isDefault key when True
             if provider_name == network.default_provider_name:
                 provider_data["isDefault"] = True
 
             data["providers"].append(provider_data)
 
@@ -578,41 +565,63 @@
 
         Returns:
             HexBytes: The hashed method selector value.
         """
 
         return HexBytes(keccak(text=abi.selector)[:4])
 
-    def enrich_calltree(self, call: CallTreeNode, **kwargs) -> CallTreeNode:
+    def enrich_trace(self, trace: "TraceAPI", **kwargs) -> "TraceAPI":
         """
         Enhance the data in the call tree using information about the ecosystem.
 
         Args:
-            call (:class:`~ape.types.trace.CallTreeNode`): The call tree node to enrich.
-            kwargs: Additional kwargs to help with enrichment.
+            trace (:class:`~ape.api.trace.TraceAPI`): The trace to enrich.
+            **kwargs: Additional kwargs to control enrichment, defined at the
+              plugin level.
 
         Returns:
-            :class:`~ape.types.trace.CallTreeNode`
+            :class:`~ape.api.trace.TraceAPI`
         """
-        return call
+        return trace
 
     @raises_not_implemented
     def get_python_types(  # type: ignore[empty-body]
         self, abi_type: ABIType
-    ) -> Union[Type, Sequence]:
+    ) -> Union[type, Sequence]:
         """
         Get the Python types for a given ABI type.
 
         Args:
             abi_type (``ABIType``): The ABI type to get the Python types for.
 
         Returns:
             Union[Type, Sequence]: The Python types for the given ABI type.
         """
 
+    @raises_not_implemented
+    def decode_custom_error(
+        self,
+        data: HexBytes,
+        address: AddressType,
+        **kwargs,
+    ) -> Optional[CustomError]:
+        """
+        Decode a custom error class from an ABI defined in a contract.
+
+        Args:
+            data (HexBytes): The error data containing the selector
+              and input data.
+            address (AddressType): The address of the contract containing
+              the error.
+            **kwargs: Additional init kwargs for the custom error class.
+
+        Returns:
+            Optional[CustomError]: If it able to decode one, else ``None``.
+        """
+
 
 class ProviderContextManager(ManagerAccessMixin):
     """
     A context manager for temporarily connecting to a network.
     When entering the context, calls the :meth:`ape.api.providers.ProviderAPI.connect` method.
     And conversely, when exiting, calls the :meth:`ape.api.providers.ProviderPAI.disconnect`
     method, unless in a multi-chain context, in which case it disconnects all providers at
@@ -631,17 +640,17 @@
 
         # Or, using choice-strings:
 
         with networks.parse_network_choice("ethereum:local:test"):
             ...
     """
 
-    connected_providers: Dict[str, "ProviderAPI"] = {}
-    provider_stack: List[str] = []
-    disconnect_map: Dict[str, bool] = {}
+    connected_providers: dict[str, "ProviderAPI"] = {}
+    provider_stack: list[str] = []
+    disconnect_map: dict[str, bool] = {}
 
     # We store a provider object at the class level for use when disconnecting
     # due to an exception, when interactive mode is set. If we don't hold on
     # to a reference to this object, the provider is dropped and reconnecting results
     # in losing state when using a spawned local provider
     _recycled_provider: ClassVar[Optional["ProviderAPI"]] = None
 
@@ -756,18 +765,15 @@
 
     name: str  # Name given when registered in ecosystem
     """The name of the network."""
 
     ecosystem: EcosystemAPI
     """The ecosystem of the network."""
 
-    data_folder: Path  # For caching any data that might need caching
-    """The path to the ``.ape`` directory."""
-
-    request_header: Dict
+    request_header: dict
     """A shareable network HTTP header."""
 
     # See ``.default_provider`` which is the proper field.
     _default_provider: str = ""
 
     _is_custom: bool = False
 
@@ -789,58 +795,62 @@
                 name = self.name
             except Exception:
                 name = None
 
             return f"<{name}>" if name else f"{type(self)}"
 
     @property
-    def config(self) -> PluginConfig:
+    def data_folder(self) -> Path:
+        """
+        The path to the network's data folder,
+        e.g. ``$HOME/.ape/{self.ecosystem_name}/{self.name}`` unless
+        overridden.
+        """
+        return self.ecosystem.data_folder / self.name
+
+    @property
+    def ecosystem_config(self) -> PluginConfig:
         """
         The configuration of the network. See :class:`~ape.managers.config.ConfigManager`
         for more information on plugin configurations.
         """
-
         return self.config_manager.get_config(self.ecosystem.name)
 
     @property
-    def _network_config(self) -> PluginConfig:
+    def config(self) -> PluginConfig:
         name_options = {self.name, self.name.replace("-", "_"), self.name.replace("_", "-")}
         cfg: Any
         for opt in name_options:
-            if cfg := self.config.get(opt):
+            if cfg := self.ecosystem_config.get(opt):
                 if isinstance(cfg, dict):
                     return cfg
-
                 elif isinstance(cfg, PluginConfig):
                     return cfg
-
                 else:
                     raise TypeError(f"Network config must be a dictionary. Received '{type(cfg)}'.")
 
-                return cfg
-
         return PluginConfig()
 
     @cached_property
     def gas_limit(self) -> GasLimit:
-        return self._network_config.get("gas_limit", "auto")
+        return self.config.get("gas_limit", "auto")
 
     @cached_property
     def auto_gas_multiplier(self) -> float:
         """
         The value to multiply estimated gas by for tx-insurance.
         """
         return self.gas_limit.multiplier if isinstance(self.gas_limit, AutoGasLimit) else 1.0
 
     @property
     def base_fee_multiplier(self) -> float:
         """
         A multiplier to apply to a transaction base fee.
         """
-        return self._network_config.get("base_fee_multiplier", 1.0)
+        return self.config.get("base_fee_multiplier", 1.0)
 
     @property
     def chain_id(self) -> int:
         """
         The ID of the blockchain.
 
         **NOTE**: Unless overridden, returns same as
@@ -863,39 +873,39 @@
     def required_confirmations(self) -> int:
         """
         The default amount of confirmations recommended to wait
         before considering a transaction "confirmed". Confirmations
         refer to the number of blocks that have been added since the
         transaction's block.
         """
-        return self._network_config.get("required_confirmations", 0)
+        return self.config.get("required_confirmations", 0)
 
     @property
     def block_time(self) -> int:
         """
         The approximate amount of time it takes for a new block to get mined to the chain.
         Configure in your ``ape-config.yaml`` file.
 
         Config example::
 
             ethereum:
               mainnet:
                 block_time: 15
         """
 
-        return self._network_config.get("block_time", 0)
+        return self.config.get("block_time", 0)
 
     @property
     def transaction_acceptance_timeout(self) -> int:
         """
         The amount of time to wait for a transaction to be accepted on the network.
         Does not include waiting for block-confirmations. Defaults to two minutes.
         Local networks use smaller timeouts.
         """
-        return self._network_config.get(
+        return self.config.get(
             "transaction_acceptance_timeout", DEFAULT_TRANSACTION_ACCEPTANCE_TIMEOUT
         )
 
     @cached_property
     def explorer(self) -> Optional["ExplorerAPI"]:
         """
         The block-explorer for the given network.
@@ -952,51 +962,49 @@
         """
         Is a custom network from CLI only, e.g. was not configured
         in any CLI value and is mostly an "unknown" network.
         """
         return self.name == "custom" and not self._is_custom
 
     @cached_property
-    def providers(self):  # -> Dict[str, Partial[ProviderAPI]]
+    def providers(self):  # -> dict[str, Partial[ProviderAPI]]
         """
-        The providers of the network, such as Infura, Alchemy, or Geth.
+        The providers of the network, such as Infura, Alchemy, or Node.
 
         Returns:
-            Dict[str, partial[:class:`~ape.api.providers.ProviderAPI`]]
+            dict[str, partial[:class:`~ape.api.providers.ProviderAPI`]]
         """
 
-        from ape.plugins import clean_plugin_name
+        from ape.plugins._utils import clean_plugin_name
 
         providers = {}
-        for plugin_name, plugin_tuple in self.plugin_manager.providers:
+        for _, plugin_tuple in self.plugin_manager.providers:
             ecosystem_name, network_name, provider_class = plugin_tuple
             provider_name = clean_plugin_name(provider_class.__module__.split(".")[0])
 
             # NOTE: Custom networks that are NOT from config must work with any provider.
             if (
                 self.is_adhoc
                 or (self.ecosystem.name == ecosystem_name and self.name == network_name)
                 or (self._is_custom and self.default_provider_name == provider_name)
             ):
                 # NOTE: Lazily load provider config
                 providers[provider_name] = partial(
                     provider_class,
                     name=provider_name,
                     network=self,
-                    # NOTE: No need to have separate folder, caching should be interoperable
-                    data_folder=self.data_folder,
                     request_header=self.request_header,
                 )
 
         return providers
 
     def get_provider(
         self,
         provider_name: Optional[str] = None,
-        provider_settings: Optional[Dict] = None,
+        provider_settings: Optional[dict] = None,
     ):
         """
         Get a provider for the given name. If given ``None``, returns the default provider.
 
         Args:
             provider_name (str, optional): The name of the provider to get. Defaults to ``None``.
               When ``None``, returns the default provider.
@@ -1019,41 +1027,45 @@
             )
 
         provider_settings = provider_settings or {}
 
         if ":" in provider_name:
             # NOTE: Shortcut that allows `--network ecosystem:network:http://...` to work
             provider_settings["uri"] = provider_name
-            provider_name = "geth"
+            provider_name = "node"
 
         elif provider_name.endswith(".ipc"):
             provider_settings["ipc_path"] = provider_name
-            provider_name = "geth"
+            provider_name = "node"
 
         if provider_name in self.providers:
             provider = self.providers[provider_name](provider_settings=provider_settings)
             connection_id = provider.connection_id
             if connection_id in ProviderContextManager.connected_providers:
                 # Likely multi-chain testing or utilizing multiple on-going connections.
-                return ProviderContextManager.connected_providers[connection_id]
+                provider = ProviderContextManager.connected_providers[connection_id]
+                if not provider.is_connected:
+                    provider.connect()
+
+                return provider
 
             return provider
 
         else:
             raise ProviderNotFoundError(
                 provider_name,
                 network=self.name,
                 ecosystem=self.ecosystem.name,
                 options=self.providers,
             )
 
     def use_provider(
         self,
         provider: Union[str, "ProviderAPI"],
-        provider_settings: Optional[Dict] = None,
+        provider_settings: Optional[dict] = None,
         disconnect_after: bool = False,
         disconnect_on_exit: bool = True,
     ) -> ProviderContextManager:
         """
         Use and connect to a provider in a temporary context. When entering the context, it calls
         method :meth:`ape.api.providers.ProviderAPI.connect` and when exiting, it calls
         method :meth:`ape.api.providers.ProviderAPI.disconnect`.
@@ -1104,18 +1116,18 @@
 
         Returns:
             Optional[str]
         """
 
         provider_from_config: str
         if provider := self._default_provider:
-            # Was set programatically.
+            # Was set programmatically.
             return provider
 
-        elif provider_from_config := self._network_config.get("default_provider"):
+        elif provider_from_config := self.config.get("default_provider"):
             # The default is found in the Network's config class.
             return provider_from_config
 
         elif len(self.providers) > 0:
             # No default set anywhere - use the first installed.
             return list(self.providers)[0]
 
@@ -1147,15 +1159,15 @@
         if provider_name in self.providers:
             self._default_provider = provider_name
         else:
             raise NetworkError(f"Provider '{provider_name}' not found in network '{self.choice}'.")
 
     def use_default_provider(
         self,
-        provider_settings: Optional[Dict] = None,
+        provider_settings: Optional[dict] = None,
         disconnect_after: bool = False,
     ) -> ProviderContextManager:
         """
         Temporarily connect and use the default provider. When entering the context, it calls
         method :meth:`ape.api.providers.ProviderAPI.connect` and when exiting, it calls
         method :meth:`ape.api.providers.ProviderAPI.disconnect`.
 
@@ -1233,15 +1245,15 @@
         """
         The provider used when requesting data before the local fork.
         Set this in your config under the network settings.
         When not set, will attempt to use the default provider, if one
         exists.
         """
 
-        config_choice: str = self._network_config.get("upstream_provider")
+        config_choice: str = self.config.get("upstream_provider")
         if provider_name := config_choice or self.upstream_network.default_provider_name:
             return self.upstream_network.get_provider(provider_name)
 
         raise NetworkError(f"Upstream network '{self.upstream_network}' has no providers.")
 
     @property
     def upstream_chain_id(self) -> int:
@@ -1260,15 +1272,15 @@
 
         Returns:
             :class:`~ape.api.networks.ProviderContextManager`
         """
         return self.upstream_network.use_provider(self.upstream_provider)
 
 
-def create_network_type(chain_id: int, network_id: int) -> Type[NetworkAPI]:
+def create_network_type(chain_id: int, network_id: int) -> type[NetworkAPI]:
     """
     Easily create a :class:`~ape.api.networks.NetworkAPI` subclass.
     """
 
     class network_def(NetworkAPI):
         @property
         def chain_id(self) -> int:
```

### Comparing `eth-ape-0.7.9/src/ape/api/projects.py` & `eth-ape-0.8.0/src/ape_ethereum/trace.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,657 +1,702 @@
-import os.path
-import re
-import tempfile
-from pathlib import Path
-from typing import TYPE_CHECKING, Any, Dict, Iterator, List, Optional, Sequence, Union
-
-from ethpm_types import Checksum, Compiler, ContractType, PackageManifest, Source
-from ethpm_types.source import Content
-from packaging.version import InvalidVersion, Version
-from pydantic import AnyUrl, ValidationError
+import json
+import sys
+from abc import abstractmethod
+from collections.abc import Iterable, Iterator, Sequence
+from enum import Enum
+from functools import cached_property
+from typing import IO, Any, Optional, Union
+
+from eth_utils import is_0x_prefixed
+from evm_trace import (
+    CallTreeNode,
+    CallType,
+    ParityTraceList,
+    TraceFrame,
+    create_trace_frames,
+    get_calltree_from_geth_call_trace,
+    get_calltree_from_geth_trace,
+    get_calltree_from_parity_trace,
+)
+from evm_trace.gas import merge_reports
+from hexbytes import HexBytes
+from pydantic import field_validator
+from rich.tree import Tree
 
-from ape.exceptions import ProjectError
+from ape.api import EcosystemAPI, TraceAPI, TransactionAPI
+from ape.exceptions import ProviderError, TransactionNotFoundError
 from ape.logging import logger
-from ape.utils import (
-    BaseInterfaceModel,
-    ExtraAttributesMixin,
-    ExtraModelAttributes,
-    abstractmethod,
-    cached_property,
-    get_all_files_in_directory,
-    get_relative_path,
-)
+from ape.types import AddressType, ContractFunctionPath, GasReport
+from ape.utils import ZERO_ADDRESS, is_evm_precompile, is_zero_hex
+from ape.utils.trace import TraceStyles, _exclude_gas
+from ape_ethereum._print import extract_debug_logs
+
+_INDENT = 2
+_WRAP_THRESHOLD = 50
+_REVERT_PREFIX = "0x08c379a00000000000000000000000000000000000000000000000000000000000000020"
+
+
+class TraceApproach(Enum):
+    """RPC trace_transaction."""
 
-if TYPE_CHECKING:
-    from ape.contracts import ContractContainer
+    BASIC = 0
+    """No tracing support; think of EthTester."""
 
+    PARITY = 1
+    """RPC 'trace_transaction'."""
 
-class ProjectAPI(BaseInterfaceModel):
+    GETH_CALL_TRACER = 2
+    """RPC debug_traceTransaction using tracer='callTracer'."""
+
+    GETH_STRUCT_LOG_PARSE = 3
     """
-    An abstract base-class for working with projects.
-    This class can also be extended to a plugin for supporting non-ape projects.
+    RPC debug_traceTransaction using struct-log tracer
+    and sophisticated parsing from the evm-trace library.
+    NOT RECOMMENDED.
     """
 
-    path: Path
-    """The project path."""
-
-    contracts_folder: Path
-    """The path to the contracts in the project."""
 
-    name: Optional[str] = None
-    """The name of this project when another project uses it as a dependency."""
+class Trace(TraceAPI):
+    """
+    Set to ``True`` to use an ERC-20's SYMBOL as the contract's identifier.
+    Is ``True`` when showing pretty traces without gas tables. When gas is
+    involved, Ape must use the ``.name`` as the identifier for all contracts.
+    """
 
-    version: Optional[str] = None
-    """The version of the project whe another project uses it as a dependency."""
+    call_trace_approach: Optional[TraceApproach] = None
+    """When None, attempts to deduce."""
 
-    config_file_name: str = "ape-config.yaml"
+    _enriched_calltree: Optional[dict] = None
 
-    _cached_manifest: Optional[PackageManifest] = None
+    def __repr__(self) -> str:
+        try:
+            return f"{self}"
+        except Exception as err:
+            # Don't let __repr__ fail.
+            logger.debug(f"Problem transaction trace: {err}")
+            return "<Trace>"
 
-    _contracts: Optional[Dict[str, ContractType]] = None
+    def __str__(self) -> str:
+        return _call_to_str(self.enriched_calltree)
 
-    def __repr__(self):
-        cls_name = getattr(type(self), "__name__", ProjectAPI.__name__)
-        return f"<{cls_name} {self.path.name}>"
+    def _repr_pretty_(self, *args, **kwargs):
+        self.show()
 
     @property
     @abstractmethod
-    def is_valid(self) -> bool:
+    def raw_trace_frames(self) -> Iterator[dict]:
         """
-        ``True`` if the project at the given path matches this project type.
-        Useful for figuring out the best ``ProjectAPI`` to use when compiling a project.
+        The raw trace frames.
         """
 
     @property
-    def manifest(self) -> PackageManifest:
-        return self.cached_manifest or PackageManifest()
-
     @abstractmethod
-    def create_manifest(
-        self, file_paths: Optional[Sequence[Path]] = None, use_cache: bool = True
-    ) -> PackageManifest:
-        """
-        Create a manifest from the project.
-
-        Args:
-            file_paths (Optional[Sequence[Path]]): An optional list of paths to compile
-              from this project.
-            use_cache (bool): Set to ``False`` to clear caches and force a re-compile.
-
-        Returns:
-            ``PackageManifest``
+    def transaction(self) -> dict:
         """
-
-    @property
-    def manifest_cachefile(self) -> Path:
+        The transaction data (obtained differently on
+        calls versus transactions).
         """
-        The path to the project's cached manifest. The manifest
-        is a cached file representing the project and is useful
-        for sharing, such as uploading to IPFS.
 
-        Returns:
-            pathlib.Path
+    @abstractmethod
+    def get_calltree(self) -> CallTreeNode:
+        """
+        Get an un-enriched call-tree node.
         """
 
-        file_name = self.name or "__local__"
-        return self._cache_folder / f"{file_name}.json"
+    @cached_property
+    def debug_logs(self) -> Iterable[tuple[Any]]:
+        """
+        Calls from ``console.log()`` and ``print()`` from a transactions call tree.
+        """
+        return list(extract_debug_logs(self.get_calltree()))
 
     @property
-    def cached_manifest(self) -> Optional[PackageManifest]:
+    def enriched_calltree(self) -> dict:
         """
-        The ``PackageManifest`` at :py:attr:`~ape.api.projects.ProjectAPI.manifest_cachefile`
-        if it exists and is valid.
+        The fully enriched calltree node.
         """
-        if self._cached_manifest is None:
-            self._cached_manifest = _load_manifest_from_file(self.manifest_cachefile)
-            if self._cached_manifest is None:
-                return None
-
-        manifest = self._cached_manifest
-        if manifest.contract_types and not self.contracts:
-            # Rely on individual cache files.
-            self._contracts = manifest.contract_types
-            manifest.contract_types = {}
+        if self._enriched_calltree is not None:
+            return self._enriched_calltree
 
-        else:
-            contracts: Dict[str, ContractType] = {}
+        # Side-effect: sets `_enriched_calltree` if using Ethereum node provider.
+        self.provider.network.ecosystem.enrich_trace(self)
+
+        if self._enriched_calltree is None:
+            # If still None (shouldn't be), set to avoid repeated attempts.
+            self._enriched_calltree = {}
+
+        # Add top-level data if missing.
+        if not self._enriched_calltree.get("gas_cost"):
+            # Happens on calltrees built from structLogs.
+            if gas_used := self.transaction.get("gas_used"):
+                if "data" in self.transaction:
+                    # Subtract base gas costs.
+                    # (21_000 + 4 gas per 0-byte and 16 gas per non-zero byte).
+                    data_gas = sum(
+                        [4 if x == 0 else 16 for x in HexBytes(self.transaction["data"])]
+                    )
+                    self._enriched_calltree["gas_cost"] = gas_used - 21_000 - data_gas
 
-            # Exclude contracts with missing sources, else you'll get validation errors.
-            # This scenario happens if changing branches and you have some contracts on
-            # one branch and others on the next.
-            for name, contract in self.contracts.items():
-                if (source_id := contract.source_id) and source_id in (manifest.sources or {}):
-                    contracts[name] = contract
+        return self._enriched_calltree
 
-            manifest.contract_types = contracts
+    @property
+    def frames(self) -> Iterator[TraceFrame]:
+        yield from create_trace_frames(iter(self.raw_trace_frames))
 
-        return manifest
+    @property
+    def addresses(self) -> Iterator[AddressType]:
+        yield from self.get_addresses_used()
 
     @property
-    def contracts(self) -> Dict[str, ContractType]:
-        if self._contracts is not None:
-            return self._contracts
-
-        contracts = {}
-        for p in self._cache_folder.glob("*.json"):
-            if p == self.manifest_cachefile:
+    def _ecosystem(self) -> EcosystemAPI:
+        if provider := self.network_manager.active_provider:
+            return provider.network.ecosystem
+
+        # Default to Ethereum (since we are in that plugin!)
+        return self.network_manager.ethereum
+
+    def get_addresses_used(self, reverse: bool = False):
+        frames: Iterable
+        if reverse:
+            frames = list(self.frames)
+            frames = frames[::-1] if reverse else frames
+        else:
+            # Don't need to run whole list.
+            frames = self.frames
+
+        for frame in frames:
+            if not (addr := frame.address):
                 continue
 
-            contract_name = p.stem
-            contract_type = ContractType.model_validate_json(p.read_text())
-            contract_type.name = contract_name if contract_type.name is None else contract_type.name
-            contracts[contract_type.name] = contract_type
+            yield self._ecosystem.decode_address(addr)
 
-        self._contracts = contracts
-        return self._contracts
+    @cached_property
+    def return_value(self) -> Any:
+        calltree = self.enriched_calltree
 
-    @property
-    def _cache_folder(self) -> Path:
-        folder = self.contracts_folder.parent / ".build"
-        # NOTE: If we use the cache folder, we expect it to exist
-        folder.mkdir(exist_ok=True, parents=True)
-        return folder
+        # Check if was cached from enrichment.
+        if "return_value" in self.__dict__:
+            return self.__dict__["return_value"]
+
+        # If enriching too much, Ethereum places regular values in a key
+        # named "unenriched_return_values".
+        return calltree.get("unenriched_return_values") or calltree.get("returndata")
 
-    def update_manifest(self, **kwargs) -> PackageManifest:
-        """
-        Add additional package manifest parts to the cache.
+    @cached_property
+    def revert_message(self) -> Optional[str]:
+        call = self.enriched_calltree
+        if not call.get("failed", False):
+            return None
 
-        Args:
-            **kwargs: Fields from ``ethpm_types.manifest.PackageManifest``.
-        """
-        new_manifest = self.manifest.model_copy(update=kwargs)
-        return self.replace_manifest(new_manifest)
+        def try_get_revert_msg(c) -> Optional[str]:
+            if msg := c.get("revert_message"):
+                return msg
 
-    def replace_manifest(self, manifest: PackageManifest) -> PackageManifest:
-        """
-        Replace the entire cached manifest.
+            for sub_c in c.get("calls", []):
+                if msg := try_get_revert_msg(sub_c):
+                    return msg
 
-        Args:
-            manifest (``ethpm_types.manifest.PackageManifest``): The manifest
-              to use.
-        """
-        self.manifest_cachefile.unlink(missing_ok=True)
-        self.manifest_cachefile.write_text(manifest.model_dump_json())
-        self._cached_manifest = manifest
-        return manifest
+            return None
 
-    def process_config_file(self, **kwargs) -> bool:
-        """
-        Process the project's config file.
-        Returns ``True`` if had to create a temporary ``ape-config.yaml`` file.
-        """
+        if message := try_get_revert_msg(call):
+            return message
 
-        return False
+        # Enrichment call-tree not available. Attempt looking in trace-frames.
+        try:
+            frames = list(self.raw_trace_frames)
+        except Exception as err:
+            logger.error(f"Failed getting traceback: {err}")
+            frames = []
+
+        data = frames[-1] if len(frames) > 0 else {}
+        memory = data.get("memory", [])
+        if ret := "".join([x[2:] for x in memory[4:]]):
+            return HexBytes(ret).hex()
 
-    def add_compiler_data(self, compiler_data: Sequence[Compiler]) -> List[Compiler]:
-        """
-        Add compiler data to the existing cached manifest.
+        return None
 
-        Args:
-            compiler_data (List[``ethpm_types.Compiler``]): Compilers to add.
+    """ API Methods """
 
-        Returns:
-            List[``ethpm_types.source.Compiler``]: The full list of compilers.
-        """
-        # Validate given data.
-        given_compilers = set(compiler_data)
-        if len(given_compilers) != len(compiler_data):
-            raise ProjectError(
-                f"`{self.add_compiler_data.__name__}()` was given multiple of the same compiler. "
-                "Please filter inputs."
+    def show(self, verbose: bool = False, file: IO[str] = sys.stdout):
+        call = self.enriched_calltree
+        failed = call.get("failed", False)
+        revert_message = None
+        if failed:
+            revert_message = self.revert_message
+            revert_message = (
+                f'reverted with message: "{revert_message}"'
+                if revert_message
+                else "reverted without message"
             )
 
-        # Filter out given compilers without contract types.
-        given_compilers = {c for c in given_compilers if c.contractTypes}
-        if len(given_compilers) != len(compiler_data):
-            logger.warning(
-                f"`{self.add_compiler_data.__name__}()` given compilers without contract types. "
-                "Ignoring these inputs."
-            )
+        root = self._get_tree(verbose=verbose)
+        console = self.chain_manager._reports._get_console(file=file)
+        if txn_hash := getattr(self, "transaction_hash", None):
+            # Only works on TransactionTrace (not CallTrace).
+            console.print(f"Call trace for [bold blue]'{txn_hash}'[/]")
+
+        if revert_message:
+            console.print(f"[bold red]{revert_message}[/]")
+
+        if sender := self.transaction.get("from"):
+            console.print(f"tx.origin=[{TraceStyles.CONTRACTS}]{sender}[/]")
+
+        console.print(root)
+
+    def get_gas_report(self, exclude: Optional[Sequence[ContractFunctionPath]] = None) -> GasReport:
+        call = self.enriched_calltree
+        return self._get_gas_report_from_call(call, exclude=exclude)
+
+    def _get_gas_report_from_call(
+        self, call: dict, exclude: Optional[Sequence[ContractFunctionPath]] = None
+    ) -> GasReport:
+        tx = self.transaction
+
+        # Enrich transfers.
+        contract_id = call.get("contract_id", "")
+        is_transfer = contract_id.startswith("__") and contract_id.endswith("transfer__")
+        if is_transfer and tx.get("to") is not None and tx["to"] in self.account_manager:
+            receiver_id = self.account_manager[tx["to"]].alias or tx["to"]
+            call["method_id"] = f"to:{receiver_id}"
+
+        elif is_transfer and (receiver := tx.get("to")):
+            call["method_id"] = f"to:{receiver}"
+
+        exclusions = exclude or []
+        calls = call.get("calls", [])
+        sub_reports = (self._get_gas_report_from_call(c, exclude=exclusions) for c in calls)
+
+        if (
+            not call.get("contract_id")
+            or not call.get("method_id")
+            or _exclude_gas(exclusions, call.get("contract_id", ""), call.get("method_id", ""))
+        ):
+            return merge_reports(*sub_reports)
+
+        elif not is_zero_hex(call["method_id"]) and not is_evm_precompile(call["method_id"]):
+            report: GasReport = {
+                call["contract_id"]: {
+                    call["method_id"]: (
+                        [int(call["gas_cost"])] if call.get("gas_cost") is not None else []
+                    )
+                }
+            }
+            return merge_reports(*sub_reports, report)
 
-        for given_compiler in given_compilers:
-            other_given_compilers = [c for c in given_compilers if c != given_compiler]
-            contract_types_from_others = [
-                n for c in other_given_compilers for n in (c.contractTypes or [])
-            ]
+        return merge_reports(*sub_reports)
 
-            collisions = {
-                n for n in (given_compiler.contractTypes or []) if n in contract_types_from_others
-            }
-            if collisions:
-                collide_str = ", ".join(collisions)
-                raise ProjectError(f"Contract type(s) '{collide_str}' collision across compilers.")
-
-        new_types = [n for c in given_compilers for n in (c.contractTypes or [])]
-
-        # Merge given compilers with existing compilers.
-        existing_compilers = self.manifest.compilers or []
-
-        # Existing compilers remaining after processing new compilers.
-        remaining_existing_compilers: List[Compiler] = []
-
-        for existing_compiler in existing_compilers:
-            find_iter = iter(x for x in compiler_data if x == existing_compiler)
-
-            if matching_given_compiler := next(find_iter, None):
-                # Compiler already exists in the system, possibly with different contract types.
-                # Merge contract types.
-                matching_given_compiler.contractTypes = list(
-                    {
-                        *(existing_compiler.contractTypes or []),
-                        *(matching_given_compiler.contractTypes or []),
-                    }
-                )
-                # NOTE: Purposely we don't add the exising compiler back,
-                #   as it is the same as the given compiler, (meaning same
-                #   name, version, and settings), and we have
-                #   merged their contract types.
+    def show_gas_report(self, verbose: bool = False, file: IO[str] = sys.stdout):
+        gas_report = self.get_gas_report()
+        self.chain_manager._reports.show_gas(gas_report, file=file)
 
-                continue
+    def get_raw_frames(self) -> Iterator[dict]:
+        yield from self.raw_trace_frames
 
-            else:
-                # Filter out contract types added now under a different compiler.
-                existing_compiler.contractTypes = [
-                    c for c in (existing_compiler.contractTypes or []) if c not in new_types
-                ]
-
-                # Remove compilers without contract types.
-                if existing_compiler.contractTypes:
-                    remaining_existing_compilers.append(existing_compiler)
-
-        # Use Compiler.__hash__ to remove duplicated.
-        # Also, sort for consistency.
-        compilers = sorted(
-            list({*remaining_existing_compilers, *compiler_data}),
-            key=lambda x: f"{x.name}@{x.version}",
-        )
-        manifest = self.update_manifest(compilers=compilers)
-        return manifest.compilers or compilers  # Or for mypy.
+    def get_raw_calltree(self) -> dict:
+        return self.get_calltree().model_dump(mode="json", by_alias=True)
+
+    """ Shared helpers """
 
-    def update_manifest_sources(
-        self,
-        source_paths: List[Path],
-        contracts_path: Path,
-        contract_types: Dict[str, ContractType],
-        name: Optional[str] = None,
-        version: Optional[str] = None,
-        compiler_data: Optional[List[Compiler]] = None,
-        **kwargs: Any,
-    ) -> PackageManifest:
-        items: Dict = {
-            "contract_types": contract_types,
-            "sources": self._create_source_dict(source_paths, contracts_path),
-            "compilers": compiler_data or [],
+    def _get_tx_calltree_kwargs(self) -> dict:
+        if (receiver := self.transaction.get("to")) and receiver != ZERO_ADDRESS:
+            call_type = CallType.CALL
+        else:
+            call_type = CallType.CREATE
+            receiver = self.transaction.get("contract_address")
+
+        return {
+            "address": receiver,
+            "call_type": call_type,
+            "calldata": self.transaction.get("data", b""),
+            "gas_cost": self.transaction.get("gasCost"),
+            "failed": False,
+            "value": self.transaction.get("value", 0),
         }
-        if name is not None:
-            items["name"] = name.lower()
-        if version:
-            items["version"] = version
 
-        return self.update_manifest(**{**items, **kwargs})
+    def _debug_trace_transaction_struct_logs_to_call(self) -> CallTreeNode:
+        init_kwargs = self._get_tx_calltree_kwargs()
+        return get_calltree_from_geth_trace(self.frames, **init_kwargs)
+
+    def _get_tree(self, verbose: bool = False) -> Tree:
+        return parse_rich_tree(self.enriched_calltree, verbose=verbose)
 
-    @classmethod
-    def _create_source_dict(
-        cls, contract_filepaths: Union[Path, List[Path]], base_path: Path
-    ) -> Dict[str, Source]:
-        filepaths = (
-            [contract_filepaths] if isinstance(contract_filepaths, Path) else contract_filepaths
+
+class TransactionTrace(Trace):
+    transaction_hash: str
+    debug_trace_transaction_parameters: dict = {"enableMemory": True}
+    _frames: list[dict] = []
+
+    @property
+    def raw_trace_frames(self) -> Iterator[dict]:
+        """
+        The raw trace ``"structLogs"`` from ``debug_traceTransaction``
+        for deeper investigation.
+        """
+        if self._frames:
+            yield from self._frames
+
+        else:
+            for frame in self._stream_struct_logs():
+                self._frames.append(frame)
+                yield frame
+
+    @cached_property
+    def transaction(self) -> dict:
+        receipt = self.chain_manager.get_receipt(self.transaction_hash)
+        data = receipt.transaction.model_dump(mode="json", by_alias=True)
+        return {**data, **receipt.model_dump(by_alias=True)}
+
+    def _stream_struct_logs(self) -> Iterator[dict]:
+        parameters = self.debug_trace_transaction_parameters
+        yield from self.provider.stream_request(
+            "debug_traceTransaction",
+            [self.transaction_hash, parameters],
+            iter_path="result.structLogs.item",
         )
-        source_imports: Dict[str, List[str]] = cls.compiler_manager.get_imports(
-            filepaths, base_path
-        )  # {source_id: [import_source_ids, ...], ...}
-        source_references: Dict[str, List[str]] = cls.compiler_manager.get_references(
-            imports_dict=source_imports
-        )  # {source_id: [referring_source_ids, ...], ...}
-
-        source_dict: Dict[str, Source] = {}
-        for source_path in filepaths:
-            key = str(get_relative_path(source_path, base_path))
 
+    def get_calltree(self) -> CallTreeNode:
+        if self.call_trace_approach is TraceApproach.BASIC:
+            return self._get_basic_calltree()
+
+        elif self.call_trace_approach is TraceApproach.PARITY:
+            return self._trace_transaction()
+
+        elif self.call_trace_approach is TraceApproach.GETH_CALL_TRACER:
+            return self._debug_trace_transaction_call_tracer()
+
+        elif self.call_trace_approach is TraceApproach.GETH_STRUCT_LOG_PARSE:
+            return self._debug_trace_transaction_struct_logs_to_call()
+
+        elif "erigon" in self.provider.client_version.lower():
+            # Based on the client version, we know parity works.
+            call = self._trace_transaction()
+            self._set_approach(TraceApproach.PARITY)
+            return call
+
+        return self._discover_calltrace_approach()
+
+    def _discover_calltrace_approach(self) -> CallTreeNode:
+        # NOTE: This method is only called once, if at all.
+        #   After discovery, short-circuits to the correct approach.
+        #   It tries to create an evm_trace.CallTreeNode using
+        #   all the approaches in order from fastest to slowest.
+
+        TA = TraceApproach
+        approaches = {
+            TA.PARITY: self._trace_transaction,
+            TA.GETH_CALL_TRACER: self._debug_trace_transaction_call_tracer,
+            TA.GETH_STRUCT_LOG_PARSE: self._debug_trace_transaction_struct_logs_to_call,
+            TA.BASIC: self._get_basic_calltree,
+        }
+
+        reason = ""
+        for approach, fn in approaches.items():
             try:
-                text = source_path.read_text("utf8")
-            except UnicodeDecodeError:
-                # Let it attempt to find the encoding.
-                # (this is much slower and a-typical).
-                text = source_path.read_text()
-
-            source_dict[key] = Source(
-                checksum=Checksum.from_file(source_path),
-                urls=[],
-                content=Content(root={i + 1: x for i, x in enumerate(text.splitlines())}),
-                imports=source_imports.get(key, []),
-                references=source_references.get(key, []),
-            )
+                call = fn()
+            except Exception as err:
+                reason = f"{err}"
+                continue
 
-        return source_dict  # {source_id: Source}
+            self._set_approach(approach)
+            return call
 
+        # Not sure this would happen, as the basic-approach should
+        # always work.
+        raise ProviderError(f"Unable to create CallTreeNode. Reason: {reason}")
+
+    def _debug_trace_transaction(self, parameters: Optional[dict] = None) -> dict:
+        parameters = parameters or self.debug_trace_transaction_parameters
+        return self.provider.make_request(
+            "debug_traceTransaction", [self.transaction_hash, parameters]
+        )
 
-class DependencyAPI(ExtraAttributesMixin, BaseInterfaceModel):
-    """
-    A base-class for dependency sources, such as GitHub or IPFS.
-    """
+    def _debug_trace_transaction_call_tracer(self) -> CallTreeNode:
+        parameters = {**self.debug_trace_transaction_parameters, "tracer": "callTracer"}
+        data = self._debug_trace_transaction(parameters)
+        return get_calltree_from_geth_call_trace(data)
 
-    name: str
-    """The name of the dependency."""
+    def _trace_transaction(self) -> CallTreeNode:
+        try:
+            data = self.provider.make_request("trace_transaction", [self.transaction_hash])
+        except ProviderError as err:
+            if "transaction not found" in str(err).lower():
+                raise TransactionNotFoundError(transaction_hash=self.transaction_hash) from err
 
-    version: Optional[str] = None
-    """
-    The version of the dependency. Omit to use the latest.
-    """
+            raise  # The ProviderError as-is
 
-    contracts_folder: str = "contracts"
-    """
-    The name of the dependency's ``contracts/`` directory.
-    This is where ``ape`` will look for source files when compiling
-    the manifest for this dependency.
+        parity_objects = ParityTraceList.model_validate(data)
+        return get_calltree_from_parity_trace(parity_objects)
+
+    def _get_basic_calltree(self) -> CallTreeNode:
+        init_kwargs = self._get_tx_calltree_kwargs()
+        receipt = self.chain_manager.get_receipt(self.transaction_hash)
+        init_kwargs["gas_cost"] = receipt.gas_used
+
+        # Figure out the 'returndata' using 'eth_call' RPC.
+        tx = receipt.transaction.model_copy(update={"nonce": None})
+        return_value = self.provider.send_call(tx, block_id=receipt.block_number)
+        init_kwargs["returndata"] = return_value
+
+        return CallTreeNode(**init_kwargs)
+
+    def _set_approach(self, approach: TraceApproach):
+        self.call_trace_approach = approach
+        if hasattr(self.provider, "_call_trace_approach"):
+            self.provider._call_trace_approach = approach
 
-    **NOTE**: This must be the name of a directory in the project.
-    """
 
-    exclude: List[str] = ["package.json", "package-lock.json", "**/.build/**/*.json"]
+class CallTrace(Trace):
+    tx: dict
     """
-    A list of glob-patterns for excluding files in dependency projects.
+    Transaction data. Is a dictionary to allow traces to easily
+    be created near sending the request.
     """
 
-    config_override: Dict = {}
+    arguments: list[Any] = []
     """
-    Extra settings to include in the dependency's configuration.
+    Remaining eth-call arguments, minus the transaction.
     """
 
-    _cached_manifest: Optional[PackageManifest] = None
+    call_trace_approach: TraceApproach = TraceApproach.GETH_STRUCT_LOG_PARSE
+    """debug_traceCall must use the struct-log tracer."""
 
-    def __repr__(self):
-        cls_name = getattr(type(self), "__name__", DependencyAPI.__name__)
-        return f"<{cls_name} name='{self.name}'>"
-
-    def __ape_extra_attributes__(self) -> Iterator[ExtraModelAttributes]:
-        yield ExtraModelAttributes(
-            name=self.name,
-            attributes=lambda: self.contracts,
-            include_getattr=True,
-            include_getitem=True,
-            additional_error_message="Do you have the necessary compiler plugins installed?",
-        )
+    supports_debug_trace_call: Optional[bool] = None
+
+    @field_validator("tx", mode="before")
+    @classmethod
+    def _tx_to_dict(cls, value):
+        if isinstance(value, TransactionAPI):
+            return value.model_dump(by_alias=True)
+
+        return value
 
     @property
-    @abstractmethod
-    def version_id(self) -> str:
-        """
-        The ID to use as the sub-directory in the download cache.
-        Most often, this is either a version number or a branch name.
-        """
+    def raw_trace_frames(self) -> Iterator[dict]:
+        yield from self._traced_call.get("structLogs", [])
 
     @property
-    @abstractmethod
-    def uri(self) -> AnyUrl:
-        """
-        The URI to use when listing in a PackageManifest.
-        """
+    def return_value(self) -> Any:
+        return self._traced_call.get("returnValue", "")
 
     @cached_property
-    def _base_cache_path(self) -> Path:
-        version_id = self.version_id
+    def _traced_call(self) -> dict:
+        if self.supports_debug_trace_call is True:
+            return self._debug_trace_call()
+        elif self.supports_debug_trace_call is False:
+            return {}
 
         try:
-            _ = Version(version_id)  # Will raise if can't parse
-            if not version_id.startswith("v"):
-                version_id = f"v{version_id}"
-        except InvalidVersion:
-            pass
+            result = self._debug_trace_call()
+        except Exception:
+            self._set_supports_trace_call(False)
+            return {}
 
-        return self.config_manager.packages_folder / self.name / version_id
+        self._set_supports_trace_call(True)
+        return result
 
     @property
-    def _target_manifest_cache_file(self) -> Path:
-        return self._base_cache_path / f"{self.name}.json"
+    def transaction(self) -> dict:
+        return self.tx
 
-    @abstractmethod
-    def extract_manifest(self, use_cache: bool = True) -> PackageManifest:
-        """
-        Create a ``PackageManifest`` definition,
-        presumably by downloading and compiling the dependency.
+    def get_calltree(self) -> CallTreeNode:
+        calltree = self._debug_trace_transaction_struct_logs_to_call()
+        calltree.gas_cost = self._traced_call.get("gas", calltree.gas_cost)
+        calltree.failed = self._traced_call.get("failed", calltree.failed)
+        return calltree
 
-        Implementations may use ``self.project_manager`` to call method
-        :meth:`~ape.managers.project.ProjectManager.get_project`
-        to dynamically get the correct :class:`~ape.api.projects.ProjectAPI`.
-        based on the project's structure.
-
-        Args:
-            use_cache (bool): Defaults to ``True``. Set to ``False`` to force
-              a re-install.
+    def _set_supports_trace_call(self, value: bool):
+        self.supports_debug_trace_call = value
+        if hasattr(self.provider, "_supports_debug_trace_call"):
+            self.provider._supports_debug_trace_call = True
 
-        Returns:
-            ``PackageManifest``
-        """
+    def _debug_trace_call(self):
+        arguments = [self.transaction, *self.arguments]
 
-    @property
-    def cached_manifest(self) -> Optional[PackageManifest]:
-        """
-        The manifest from the ``.ape/packages/<dependency-name>/<version-id>``
-        if it exists and is valid.
-        """
-        if self._cached_manifest is None:
-            self._cached_manifest = _load_manifest_from_file(self._target_manifest_cache_file)
+        # Block ID is required, at least for regular geth nodes.
+        if len(arguments) == 1:
+            arguments.append("latest")
 
-        return self._cached_manifest
+        return self.provider.make_request("debug_traceCall", arguments)
 
-    @cached_property
-    def contracts(self) -> Dict[str, "ContractContainer"]:
-        """
-        A mapping of name to contract type of all the contracts
-        in this dependency.
-        """
-        return {
-            n: self.chain_manager.contracts.get_container(c)
-            for n, c in (self.compile().contract_types or {}).items()
-        }
 
-    def get(self, contract_name: str) -> Optional["ContractContainer"]:
-        return self.contracts.get(contract_name)
+def parse_rich_tree(call: dict, verbose: bool = False) -> Tree:
+    tree = _create_tree(call, verbose=verbose)
+    for sub_call in call["calls"]:
+        sub_tree = parse_rich_tree(sub_call, verbose=verbose)
+        tree.add(sub_tree)
 
-    def compile(self, use_cache: bool = True) -> PackageManifest:
-        """
-        Compile the contract types in this dependency into
-        a package manifest.
+    return tree
 
-        Args:
-            use_cache (bool): Defaults to ``True``. Set to ``False`` to force
-              a re-compile.
 
-        **NOTE**: By default, dependency's compile lazily.
-        """
+def _call_to_str(call: dict, stylize: bool = False, verbose: bool = False) -> str:
+    contract = str(call.get("contract_id", ""))
+    is_create = "CREATE" in call.get("call_type", "")
+    method = (
+        "__new__"
+        if is_create and call["method_id"] and is_0x_prefixed(call["method_id"])
+        else str(call.get("method_id") or "")
+    )
+    if "(" in method:
+        # Only show short name, not ID name
+        # (it is the full signature when multiple methods have the same name).
+        method = method.split("(")[0].strip() or method
 
-        manifest = self.extract_manifest()
-        if use_cache and manifest.contract_types:
-            # Already compiled
-            return manifest
+    if stylize:
+        contract = f"[{TraceStyles.CONTRACTS}]{contract}[/]"
+        method = f"[{TraceStyles.METHODS}]{method}[/]"
 
-        # Figure the config data needed to compile this dependency.
-        # Use a combination of looking at the manifest's other artifacts
-        # as well, config overrides, and the base project's config.
-        config_data: Dict[str, Any] = {
-            **_get_compile_configs_from_manifest(manifest),
-            **_get_dependency_configs_from_manifest(manifest),
-            **self.config_override,
-        }
+    call_path = f"{contract}.{method}"
 
-        with tempfile.TemporaryDirectory() as temp_dir:
-            path = Path(temp_dir)
-            contracts_folder = path / config_data.get("contracts_folder", "contracts")
-
-            if "contracts_folder" not in config_data:
-                config_data["contracts_folder"] = contracts_folder
-
-            with self.config_manager.using_project(path, **config_data) as project:
-                manifest.unpack_sources(contracts_folder)
-                compiled_manifest = project.local_project.create_manifest()
-
-                if not compiled_manifest.contract_types:
-                    # Manifest is empty. No need to write to disk.
-                    logger.warning(
-                        "Compiled manifest produced no contract types! "
-                        "Are you missing compiler plugins?"
-                    )
-                    return compiled_manifest
+    if call.get("call_type") is not None and call["call_type"].upper() == "DELEGATECALL":
+        delegate = "(delegate)"
+        if stylize:
+            delegate = f"[orange]{delegate}[/]"
 
-                self.replace_manifest(compiled_manifest)
-                return compiled_manifest
+        call_path = f"{delegate} {call_path}"
 
-    def _extract_local_manifest(
-        self, project_path: Path, use_cache: bool = True
-    ) -> PackageManifest:
-        cached_manifest = (
-            _load_manifest_from_file(self._target_manifest_cache_file)
-            if use_cache and self._target_manifest_cache_file.is_file()
-            else None
-        )
-        if cached_manifest:
-            return cached_manifest
+    arguments_str = _get_inputs_str(call.get("calldata"), stylize=stylize)
+    if is_create and is_0x_prefixed(arguments_str):
+        # Un-enriched CREATE calldata is a massive hex.
+        arguments_str = ""
 
-        if project_path.is_file() and project_path.suffix == ".json":
-            try:
-                manifest = PackageManifest.model_validate_json(project_path.read_text())
+    signature = f"{call_path}{arguments_str}"
+    returndata = call.get("returndata", "")
+    if not is_create and returndata not in ((), [], None, {}, ""):
+        if return_str := _get_outputs_str(returndata, stylize=stylize):
+            signature = f"{signature} -> {return_str}"
 
-            except ValueError as err:
-                if project_path.parent.is_dir():
-                    project_path = project_path.parent
+    if call.get("value"):
+        value = str(call["value"])
+        if stylize:
+            value = f"[{TraceStyles.VALUE}]{value}[/]"
 
-                else:
-                    raise ProjectError(f"Invalid manifest file: '{project_path}'.") from err
+        signature += f" {value}"
+
+    if call.get("gas_cost"):
+        gas_value = f"[{call['gas_cost']} gas]"
+        if stylize:
+            gas_value = f"[{TraceStyles.GAS_COST}]{gas_value}[/]"
+
+        signature += f" {gas_value}"
+
+    if verbose:
+        verbose_items = {k: v for k, v in call.items() if type(v) in (int, str, bytes, float)}
+        extra = json.dumps(verbose_items, indent=2)
+        signature = f"{signature}\n{extra}"
+
+    return signature
 
-            else:
-                # Was given a path to a manifest JSON.
-                self.replace_manifest(manifest)
-                return manifest
-
-        elif (project_path.parent / project_path.name.replace("-", "_")).is_dir():
-            project_path = project_path.parent / project_path.name.replace("-", "_")
-
-        elif (project_path.parent / project_path.name.replace("_", "-")).is_dir():
-            project_path = project_path.parent / project_path.name.replace("_", "-")
-
-        elif project_path.parent.is_dir():
-            project_path = project_path.parent
-
-        # NOTE: Dependencies are not compiled here. Instead, the sources are packaged
-        # for later usage via imports. For legacy reasons, many dependency-esque projects
-        # are not meant to compile on their own.
-
-        with self.config_manager.using_project(
-            project_path,
-            contracts_folder=(project_path / self.contracts_folder).expanduser().resolve(),
-        ) as pm:
-            project = pm.local_project
-            if sources := self._get_sources(project):
-                dependencies = self.project_manager._extract_manifest_dependencies()
-
-                extras: Dict = {}
-                if dependencies:
-                    extras["dependencies"] = dependencies
-
-                project.update_manifest_sources(
-                    sources,
-                    project.contracts_folder,
-                    {},
-                    name=project.name,
-                    version=project.version,
-                    **extras,
-                )
-            else:
-                raise ProjectError(
-                    f"No source files found in dependency '{self.name}'. "
-                    "Try adjusting its config using `config_override` to "
-                    "get Ape to recognize the project. "
-                    "\nMore information: https://docs.apeworx.io/ape/stable"
-                    "/userguides/dependencies.html#config-override"
-                )
-
-        # Replace the dependency's manifest with the temp project's.
-        self.replace_manifest(project.manifest)
-        return project.manifest
-
-    def _get_sources(self, project: ProjectAPI) -> List[Path]:
-        escaped_extensions = [re.escape(ext) for ext in self.compiler_manager.registered_compilers]
-        extension_pattern = "|".join(escaped_extensions)
-        pattern = rf".*({extension_pattern})"
-        all_sources = get_all_files_in_directory(project.contracts_folder, pattern=pattern)
-
-        excluded_files = set()
-        for pattern in set(self.exclude):
-            excluded_files.update({f for f in project.contracts_folder.glob(pattern)})
-
-        return [s for s in all_sources if s not in excluded_files]
-
-    def replace_manifest(self, manifest: PackageManifest):
-        self._target_manifest_cache_file.unlink(missing_ok=True)
-        self._target_manifest_cache_file.parent.mkdir(exist_ok=True, parents=True)
-        self._target_manifest_cache_file.write_text(manifest.model_dump_json())
-        self._cached_manifest = manifest
 
+def _create_tree(call: dict, verbose: bool = False) -> Tree:
+    signature = _call_to_str(call, stylize=True, verbose=verbose)
+    return Tree(signature)
 
-def _load_manifest_from_file(file_path: Path) -> Optional[PackageManifest]:
-    if not file_path.is_file():
+
+def _get_inputs_str(inputs: Any, stylize: bool = False) -> str:
+    color = TraceStyles.INPUTS if stylize else None
+    if inputs in ["0x", None, (), [], {}]:
+        return "()"
+
+    elif isinstance(inputs, dict):
+        return _dict_to_str(inputs, color=color)
+
+    elif isinstance(inputs, bytes):
+        return HexBytes(inputs).hex()
+
+    return f"({inputs})"
+
+
+def _get_outputs_str(outputs: Any, stylize: bool = False) -> Optional[str]:
+    if outputs in ["0x", None, (), [], {}]:
         return None
 
-    try:
-        return PackageManifest.model_validate_json(file_path.read_text())
-    except ValidationError as err:
-        logger.warning(
-            f"Existing manifest file '{file_path}' corrupted (problem={err}). Re-building."
+    elif isinstance(outputs, dict):
+        color = TraceStyles.OUTPUTS if stylize else None
+        return _dict_to_str(outputs, color=color)
+
+    elif isinstance(outputs, (list, tuple)):
+        return (
+            f"[{TraceStyles.OUTPUTS}]{_list_to_str(outputs)}[/]"
+            if stylize
+            else _list_to_str(outputs)
         )
-        return None
 
+    return f"[{TraceStyles.OUTPUTS}]{outputs}[/]" if stylize else str(outputs)
 
-def _get_compile_configs_from_manifest(manifest: PackageManifest) -> Dict[str, Dict]:
-    configs: Dict[str, Dict] = {}
-    for compiler in [x for x in manifest.compilers or [] if x.settings]:
-        name = compiler.name.strip().lower()
-        compiler_data = {}
-        settings = compiler.settings or {}
-        remapping_list = []
-        for remapping in settings.get("remappings") or []:
-            parts = remapping.split("=")
-            key = parts[0]
-            link = parts[1]
-            if link.startswith(f".cache{os.path.sep}"):
-                link = os.path.sep.join(link.split(f".cache{os.path.sep}"))[1:]
-
-            new_entry = f"{key}={link}"
-            remapping_list.append(new_entry)
-
-        if remapping_list:
-            compiler_data["import_remapping"] = remapping_list
-
-        if "evm_version" in settings:
-            compiler_data["evm_version"] = settings["evm_version"]
-
-        if compiler_data:
-            configs[name] = compiler_data
-
-    return configs
-
-
-def _get_dependency_configs_from_manifest(manifest: PackageManifest) -> Dict:
-    dependencies_config: List[Dict] = []
-    dependencies = manifest.dependencies or {}
-    for package_name, uri in dependencies.items():
-        if "://" not in str(uri) and hasattr(uri, "scheme"):
-            uri_str = f"{uri.scheme}://{uri}"
-        else:
-            uri_str = str(uri)
 
-        dependency: Dict = {"name": str(package_name)}
-        if uri_str.startswith("https://"):
-            # Assume GitHub dependency
-            version = uri_str.split("/")[-1]
-            dependency["github"] = uri_str.replace(f"/releases/tag/{version}", "")
-            dependency["github"] = dependency["github"].replace("https://github.com/", "")
+def _dict_to_str(dictionary: dict, color: Optional[str] = None) -> str:
+    length = sum(len(str(v)) for v in [*dictionary.keys(), *dictionary.values()])
+    do_wrap = length > _WRAP_THRESHOLD
+
+    index = 0
+    end_index = len(dictionary) - 1
+    kv_str = "(\n" if do_wrap else "("
+
+    for key, value in dictionary.items():
+        if do_wrap:
+            kv_str += _INDENT * " "
+
+        if isinstance(value, (list, tuple)):
+            value = _list_to_str(value, 1 if do_wrap else 0)
+
+        value_str = f"[{color}]{value}[/]" if color is not None else str(value)
+        kv_str += f"{key}={value_str}" if key and not key.isnumeric() else value_str
+        if index < end_index:
+            kv_str += ", "
+
+        if do_wrap:
+            kv_str += "\n"
+
+        index += 1
+
+    return f"{kv_str})"
+
+
+def _list_to_str(ls: Union[list, tuple], depth: int = 0) -> str:
+    if not isinstance(ls, (list, tuple)) or len(str(ls)) < _WRAP_THRESHOLD:
+        return str(ls)
+
+    elif ls and isinstance(ls[0], (list, tuple)):
+        # List of lists
+        sub_lists = [_list_to_str(i) for i in ls]
+
+        # Use multi-line if exceeds threshold OR any of the sub-lists use multi-line
+        extra_chars_len = (len(sub_lists) - 1) * 2
+        use_multiline = len(str(sub_lists)) + extra_chars_len > _WRAP_THRESHOLD or any(
+            ["\n" in ls for ls in sub_lists]
+        )
+
+        if not use_multiline:
+            # Happens for lists like '[[0], [1]]' that are short.
+            return f"[{', '.join(sub_lists)}]"
+
+        value = "[\n"
+        num_sub_lists = len(sub_lists)
+        index = 0
+        spacing = _INDENT * " " * 2
+        for formatted_list in sub_lists:
+            if "\n" in formatted_list:
+                # Multi-line sub list. Append 1 more spacing to each line.
+                indented_item = f"\n{spacing}".join(formatted_list.splitlines())
+                value = f"{value}{spacing}{indented_item}"
+            else:
+                # Single line sub-list
+                value = f"{value}{spacing}{formatted_list}"
+
+            if index < num_sub_lists - 1:
+                value = f"{value},"
+
+            value = f"{value}\n"
+            index += 1
 
-            # NOTE: If version fails, the dependency system will automatically try `ref`.
-            dependency["version"] = version
+        value = f"{value}]"
+        return value
 
-        elif uri_str.startswith("file://"):
-            dependency["local"] = uri_str.replace("file://", "")
+    return _list_to_multiline_str(ls, depth=depth)
 
-        dependencies_config.append(dependency)
 
-    return {"dependencies": dependencies_config} if dependencies_config else {}
+def _list_to_multiline_str(value: Union[list, tuple], depth: int = 0) -> str:
+    spacing = _INDENT * " "
+    ls_spacing = spacing * (depth + 1)
+    joined = ",\n".join([f"{ls_spacing}{v}" for v in value])
+    new_val = f"[\n{joined}\n{spacing * depth}]"
+    return new_val
```

### Comparing `eth-ape-0.7.9/src/ape/api/providers.py` & `eth-ape-0.8.0/src/ape/api/providers.py`

 * *Files 4% similar despite different names*

```diff
@@ -3,92 +3,158 @@
 import datetime
 import logging
 import platform
 import shutil
 import sys
 import time
 import warnings
+from collections.abc import Iterable, Iterator
 from logging import FileHandler, Formatter, Logger, getLogger
 from pathlib import Path
 from signal import SIGINT, SIGTERM, signal
 from subprocess import DEVNULL, PIPE, Popen
-from typing import Any, Dict, Iterator, List, Optional, Union, cast
+from typing import Any, Optional, Union, cast
 
 from eth_pydantic_types import HexBytes
 from ethpm_types.abi import EventABI
 from pydantic import Field, computed_field, model_validator
 
 from ape.api.config import PluginConfig
 from ape.api.networks import NetworkAPI
 from ape.api.query import BlockTransactionQuery
+from ape.api.trace import TraceAPI
 from ape.api.transactions import ReceiptAPI, TransactionAPI
 from ape.exceptions import (
     APINotImplementedError,
     ProviderError,
+    QueryEngineError,
     RPCTimeoutError,
     SubprocessError,
     SubprocessTimeoutError,
     VirtualMachineError,
 )
 from ape.logging import LogLevel, logger
-from ape.types import (
-    AddressType,
-    BlockID,
-    CallTreeNode,
-    ContractCode,
-    ContractLog,
-    LogFilter,
-    SnapshotID,
-    TraceFrame,
-)
-from ape.utils import (
+from ape.types import AddressType, BlockID, ContractCode, ContractLog, LogFilter, SnapshotID
+from ape.utils import BaseInterfaceModel, JoinableQueue, abstractmethod, cached_property, spawn
+from ape.utils.misc import (
     EMPTY_BYTES32,
-    BaseInterfaceModel,
-    JoinableQueue,
-    abstractmethod,
-    cached_property,
+    _create_raises_not_implemented_error,
+    log_instead_of_fail,
     raises_not_implemented,
-    spawn,
 )
-from ape.utils.misc import _create_raises_not_implemented_error
 
 
 class BlockAPI(BaseInterfaceModel):
     """
     An abstract class representing a block and its attributes.
     """
 
     # NOTE: All fields in this class (and it's subclasses) should not be `Optional`
     #       except the edge cases noted below
 
+    """
+    The number of transactions in the block.
+    """
     num_transactions: int = 0
+
+    """
+    The block hash identifier.
+    """
     hash: Optional[Any] = None  # NOTE: pending block does not have a hash
+
+    """
+    The block number identifier.
+    """
     number: Optional[int] = None  # NOTE: pending block does not have a number
+
+    """
+    The preceeding block's hash.
+    """
     parent_hash: Any = Field(
         EMPTY_BYTES32, alias="parentHash"
     )  # NOTE: genesis block has no parent hash
-    size: int
+
+    """
+    The timestamp the block was produced.
+    NOTE: The pending block uses the current timestamp.
+    """
     timestamp: int
 
+    _size: Optional[int] = None
+
+    @log_instead_of_fail(default="<BlockAPI>")
+    def __repr__(self) -> str:
+        return super().__repr__()
+
     @property
     def datetime(self) -> datetime.datetime:
+        """
+        The block timestamp as a datetime object.
+        """
         return datetime.datetime.fromtimestamp(self.timestamp, tz=datetime.timezone.utc)
 
     @model_validator(mode="before")
     @classmethod
     def convert_parent_hash(cls, data):
         parent_hash = data.get("parent_hash", data.get("parentHash")) or EMPTY_BYTES32
         data["parentHash"] = parent_hash
         return data
 
+    @model_validator(mode="wrap")
+    @classmethod
+    def validate_size(cls, values, handler):
+        """
+        A validator for handling non-computed size.
+        Saves it to a private member on this class and
+        gets returned in computed field "size".
+        """
+
+        if not hasattr(values, "pop"):
+            # Handle weird AttributeDict missing pop method.
+            # https://github.com/ethereum/web3.py/issues/3326
+            values = {**values}
+
+        size = values.pop("size", None)
+        model = handler(values)
+        if size is not None:
+            model._size = size
+
+        return model
+
     @computed_field()  # type: ignore[misc]
     @cached_property
-    def transactions(self) -> List[TransactionAPI]:
-        query = BlockTransactionQuery(columns=["*"], block_id=self.hash)
-        return cast(List[TransactionAPI], list(self.query_manager.query(query)))
+    def transactions(self) -> list[TransactionAPI]:
+        """
+        All transactions in a block.
+        """
+        try:
+            query = BlockTransactionQuery(columns=["*"], block_id=self.hash)
+            return cast(list[TransactionAPI], list(self.query_manager.query(query)))
+        except QueryEngineError as err:
+            # NOTE: Re-raising a better error here because was confusing
+            #  when doing anything with fields, and this would fail.
+            raise ProviderError(f"Unable to find block transactions: {err}") from err
+
+    @computed_field()  # type: ignore[misc]
+    @cached_property
+    def size(self) -> int:
+        """
+        The size of the block in gas. Most of the time,
+        this field is passed to the model at validation time,
+        but occassionally it is missing (like in `eth_subscribe:newHeads`),
+        in which case it gets calculated if and only if the user
+        requests it (or during serialization of this model to disk).
+        """
+
+        if self._size is not None:
+            # The size was provided with the rest of the model
+            # (normal).
+            return self._size
+
+        raise APINotImplementedError()
 
 
 class ProviderAPI(BaseInterfaceModel):
     """
     An abstraction of a connection to a network in an ecosystem. Example ``ProviderAPI``
     implementations include the `ape-infura <https://github.com/ApeWorX/ape-infura>`__
     plugin or the `ape-hardhat <https://github.com/ApeWorX/ape-hardhat>`__ plugin.
@@ -96,35 +162,40 @@
 
     name: str
     """The name of the provider (should be the plugin name)."""
 
     network: NetworkAPI
     """A reference to the network this provider provides."""
 
-    provider_settings: Dict = {}
+    provider_settings: dict = {}
     """The settings for the provider, as overrides to the configuration."""
 
-    data_folder: Path
-    """The path to the  ``.ape`` directory."""
-
-    request_header: Dict
+    request_header: dict
     """A header to set on HTTP/RPC requests."""
 
     block_page_size: int = 100
     """
     The amount of blocks to fetch in a response, as a default.
     This is particularly useful for querying logs across a block range.
     """
 
     concurrency: int = 4
     """
     How many parallel threads to use when fetching logs.
     """
 
     @property
+    def data_folder(self) -> Path:
+        """
+        The path to the provider's data,
+        e.g. ``$HOME/.api/{self.name}`` unless overridden.
+        """
+        return self.config_manager.DATA_FOLDER / self.name
+
+    @property
     @abstractmethod
     def is_connected(self) -> bool:
         """
         ``True`` if currently connected to the provider. ``False`` otherwise.
         """
 
     @property
@@ -190,21 +261,21 @@
                 return None
 
         # NOTE: If other provider settings are different, ``.update_settings()``
         #    should be called.
         return f"{self.network_choice}:{chain_id}"
 
     @abstractmethod
-    def update_settings(self, new_settings: Dict):
+    def update_settings(self, new_settings: dict):
         """
         Change a provider's setting, such as configure a new port to run on.
         May require a reconnect.
 
         Args:
-            new_settings (Dict): The new provider settings.
+            new_settings (dict): The new provider settings.
         """
 
     @property
     @abstractmethod
     def chain_id(self) -> int:
         """
         The blockchain ID.
@@ -250,14 +321,38 @@
             return self.connection_str
 
         elif self.network.is_adhoc:
             raise ProviderError("Custom network provider missing `connection_str`.")
 
         return f"{self.network.choice}:{self.name}"
 
+    @abstractmethod
+    def make_request(self, rpc: str, parameters: Optional[Iterable] = None) -> Any:
+        """
+        Make a raw RPC request to the provider.
+        Advanced featues such as tracing may utilize this to by-pass unnecessary
+        class-serializations.
+        """
+
+    @raises_not_implemented
+    def stream_request(  # type: ignore[empty-body]
+        self, method: str, params: Iterable, iter_path: str = "result.item"
+    ) -> Iterator[Any]:
+        """
+        Stream a request, great for large requests like events or traces.
+
+        Args:
+            method (str): The RPC method to call.
+            params (Iterable): Parameters for the method.s
+            iter_path (str): The response dict-path to the items.
+
+        Returns:
+            An iterator of items.
+        """
+
     def get_storage_at(self, *args, **kwargs) -> HexBytes:
         warnings.warn(
             "'provider.get_storage_at()' is deprecated. Use 'provider.get_storage()'.",
             DeprecationWarning,
         )
         return self.get_storage(*args, **kwargs)
 
@@ -383,27 +478,27 @@
         """
 
     @abstractmethod
     def send_call(
         self,
         txn: TransactionAPI,
         block_id: Optional[BlockID] = None,
-        state: Optional[Dict] = None,
+        state: Optional[dict] = None,
         **kwargs,
     ) -> HexBytes:  # Return value of function
         """
         Execute a new transaction call immediately without creating a
         transaction on the block chain.
 
         Args:
             txn: :class:`~ape.api.transactions.TransactionAPI`
             block_id (Optional[:class:`~ape.types.BlockID`]): The block ID
                 to use to send a call at a historical point of a contract.
                 Useful for checking a past estimation cost of a transaction.
-            state (Optional[Dict]): Modify the state of the blockchain
+            state (Optional[dict]): Modify the state of the blockchain
                 prior to sending the call, for testing purposes.
             **kwargs: Provider-specific extra kwargs.
 
         Returns:
             str: The result of the transaction call.
         """
 
@@ -448,35 +543,14 @@
             start_nonce (int): The nonce of the account to start the search with.
             stop_nonce (int): The nonce of the account to stop the search with.
 
         Returns:
             Iterator[:class:`~ape.api.transactions.ReceiptAPI`]
         """
 
-    @raises_not_implemented
-    def get_contract_creation_receipts(  # type: ignore[empty-body]
-        self,
-        address: AddressType,
-        start_block: int = 0,
-        stop_block: int = -1,
-        contract_code: Optional[HexBytes] = None,
-    ) -> Iterator[ReceiptAPI]:
-        """
-        Get all receipts where a contract address was created or re-created.
-
-        Args:
-            address (:class:`~ape.types.address.AddressType`): The address of the account.
-            start_block (int): The block number to start the search with.
-            stop_block (int): The block number to stop the search with.
-            contract_code (Optional[bytes]): The code of the contract at the stop block.
-
-        Returns:
-            Iterator[:class:`~ape.api.transactions.ReceiptAPI`]
-        """
-
     @abstractmethod
     def send_transaction(self, txn: TransactionAPI) -> ReceiptAPI:
         """
         Send a transaction to the network.
 
         Args:
             txn (:class:`~ape.api.transactions.TransactionAPI`): The transaction to send.
@@ -534,15 +608,15 @@
         :class:`ape.managers.chain.ChainManager`.
 
         Raises:
             :class:`~ape.exceptions.APINotImplementedError`: Unless overriden.
         """
 
     @raises_not_implemented
-    def revert(self, snapshot_id: SnapshotID):
+    def restore(self, snapshot_id: SnapshotID):
         """
         Defined to make the ``ProviderAPI`` interchangeable with a
         :class:`~ape.api.providers.TestProviderAPI`, as in
         :class:`ape.managers.chain.ChainManager`.
 
         Raises:
             :class:`~ape.exceptions.APINotImplementedError`: Unless overriden.
@@ -576,22 +650,17 @@
         Change the balance of an account.
 
         Args:
             address (AddressType): An address on the network.
             amount (int): The balance to set in the address.
         """
 
+    @log_instead_of_fail(default="<ProviderAPI>")
     def __repr__(self) -> str:
-        try:
-            chain_id = self.chain_id
-        except Exception as err:
-            logger.error(str(err))
-            chain_id = None
-
-        return f"<{self.name} chain_id={self.chain_id}>" if chain_id else f"<{self.name}>"
+        return f"<{self.name.capitalize()} chain_id={self.chain_id}>"
 
     @raises_not_implemented
     def set_code(  # type: ignore[empty-body]
         self, address: AddressType, code: ContractCode
     ) -> bool:
         """
         Change the code of a smart contract, for development purposes.
@@ -631,24 +700,25 @@
 
         Returns:
             bool: ``True`` if successfully unlocked account and ``False`` otherwise.
         """
 
     @raises_not_implemented
     def get_transaction_trace(  # type: ignore[empty-body]
-        self, txn_hash: str
-    ) -> Iterator[TraceFrame]:
+        self, txn_hash: Union[HexBytes, str]
+    ) -> TraceAPI:
         """
         Provide a detailed description of opcodes.
 
         Args:
-            txn_hash (str): The hash of a transaction to trace.
+            transaction_hash (Union[HexBytes, str]): The hash of a transaction
+              to trace.
 
         Returns:
-            Iterator(:class:`~ape.type.trace.TraceFrame`): Transaction execution trace.
+            :class:`~ape.api.trace.TraceAPI`: A transaction trace.
         """
 
     @raises_not_implemented
     def poll_blocks(  # type: ignore[empty-body]
         self,
         stop_block: Optional[int] = None,
         required_confirmations: Optional[int] = None,
@@ -679,18 +749,18 @@
         """
 
     @raises_not_implemented
     def poll_logs(  # type: ignore[empty-body]
         self,
         stop_block: Optional[int] = None,
         address: Optional[AddressType] = None,
-        topics: Optional[List[Union[str, List[str]]]] = None,
+        topics: Optional[list[Union[str, list[str]]]] = None,
         required_confirmations: Optional[int] = None,
         new_block_timeout: Optional[int] = None,
-        events: Optional[List[EventABI]] = None,
+        events: Optional[list[EventABI]] = None,
     ) -> Iterator[ContractLog]:
         """
         Poll new blocks. Optionally set a start block to include historical blocks.
 
         **NOTE**: This is a daemon method; it does not terminate unless an exception occurs.
 
         Usage example::
@@ -699,41 +769,28 @@
                 print(f"New event log found: block_number={new_log.block_number}")
 
         Args:
             stop_block (Optional[int]): Optionally set a future block number to stop at.
               Defaults to never-ending.
             address (Optional[str]): The address of the contract to filter logs by.
               Defaults to all addresses.
-            topics (Optional[List[Union[str, List[str]]]]): The topics to filter logs by.
+            topics (Optional[list[Union[str, list[str]]]]): The topics to filter logs by.
               Defaults to all topics.
             required_confirmations (Optional[int]): The amount of confirmations to wait
               before yielding the block. The more confirmations, the less likely a reorg will occur.
               Defaults to the network's configured required confirmations.
             new_block_timeout (Optional[int]): The amount of time to wait for a new block before
               quitting. Defaults to 10 seconds for local networks or ``50 * block_time`` for live
               networks.
-            events (Optional[List[``EventABI``]]): An optional list of events to listen on.
+            events (Optional[list[``EventABI``]]): An optional list of events to listen on.
 
         Returns:
             Iterator[:class:`~ape.types.ContractLog`]
         """
 
-    @raises_not_implemented
-    def get_call_tree(self, txn_hash: str) -> CallTreeNode:  # type: ignore[empty-body]
-        """
-        Create a tree structure of calls for a transaction.
-
-        Args:
-            txn_hash (str): The hash of a transaction to trace.
-
-        Returns:
-            :class:`~ape.types.trace.CallTreeNode`: Transaction execution
-            call-tree objects.
-        """
-
     def prepare_transaction(self, txn: TransactionAPI) -> TransactionAPI:
         """
         Set default values on the transaction.
 
         Raises:
             :class:`~ape.exceptions.TransactionError`: When given negative required confirmations.
 
@@ -776,15 +833,15 @@
         to go back to this point. This method is for local networks only.
 
         Returns:
             :class:`~ape.types.SnapshotID`: The snapshot ID.
         """
 
     @abstractmethod
-    def revert(self, snapshot_id: SnapshotID):
+    def restore(self, snapshot_id: SnapshotID):
         """
         Regress the current call using the given snapshot ID.
         Allows developers to go back to a previous state.
 
         Args:
             snapshot_id (str): The snapshot ID.
         """
@@ -806,28 +863,42 @@
         """
         Advance by the given number of blocks.
 
         Args:
             num_blocks (int): The number of blocks allotted to mine. Defaults to ``1``.
         """
 
+    @property
+    @abstractmethod
+    def auto_mine(self) -> bool:
+        """
+        Whether automine is enabled.
+        """
+
+    @auto_mine.setter
+    @abstractmethod
+    def auto_mine(self) -> bool:
+        """
+        Enable or disbale automine.
+        """
+
     def _increment_call_func_coverage_hit_count(self, txn: TransactionAPI):
         """
         A helper method for incrementing a method call function hit count in a
         non-orthodox way. This is because Hardhat does not support call traces yet.
         """
         if (
             not txn.receiver
             or not self._test_runner
             or not self._test_runner.config_wrapper.track_coverage
         ):
             return
 
         if not (contract_type := self.chain_manager.contracts.get(txn.receiver)) or not (
-            contract_src := self.project_manager._create_contract_source(contract_type)
+            contract_src := self.local_project._create_contract_source(contract_type)
         ):
             return
 
         method_id = txn.data[:4]
         if method_id in contract_type.view_methods:
             method = contract_type.methods[method_id]
             self._test_runner.coverage_tracker.hit_function(contract_src, method)
@@ -853,21 +924,21 @@
 
     @property
     @abstractmethod
     def process_name(self) -> str:
         """The name of the process, such as ``Hardhat node``."""
 
     @abstractmethod
-    def build_command(self) -> List[str]:
+    def build_command(self) -> list[str]:
         """
         Get the command as a list of ``str``.
         Subclasses should override and add command arguments if needed.
 
         Returns:
-            List[str]: The command to pass to ``subprocess.Popen``.
+            list[str]: The command to pass to ``subprocess.Popen``.
         """
 
     @property
     def base_logs_path(self) -> Path:
         return self.config_manager.DATA_FOLDER / self.name / "subprocess_output"
 
     @property
```

### Comparing `eth-ape-0.7.9/src/ape/api/query.py` & `eth-ape-0.8.0/src/ape/api/query.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,44 +1,44 @@
-from functools import lru_cache
-from typing import Any, Dict, Iterator, List, Optional, Sequence, Set, Type, Union
+from collections.abc import Iterator, Sequence
+from functools import cache
+from typing import Any, Optional, Union
 
-from ethpm_types.abi import BaseModel, EventABI, MethodABI
+from ethpm_types.abi import EventABI, MethodABI
 from pydantic import NonNegativeInt, PositiveInt, model_validator
 
 from ape.api.transactions import ReceiptAPI, TransactionAPI
 from ape.logging import logger
 from ape.types import AddressType
 from ape.utils import BaseInterface, BaseInterfaceModel, abstractmethod, cached_property
+from ape.utils.basemodel import BaseModel
 
 QueryType = Union[
     "BlockQuery",
     "BlockTransactionQuery",
     "AccountTransactionQuery",
     "ContractCreationQuery",
     "ContractEventQuery",
     "ContractMethodQuery",
 ]
 
 
-# TODO: Replace with `functools.cache` when Py3.8 dropped
-@lru_cache(maxsize=None)
-def _basic_columns(Model: Type[BaseInterfaceModel]) -> Set[str]:
+@cache
+def _basic_columns(Model: type[BaseInterfaceModel]) -> set[str]:
     columns = set(Model.model_fields)
 
     # TODO: Remove once `ReceiptAPI` fields cleaned up for better processing
     if Model == ReceiptAPI:
         columns.remove("transaction")
         columns |= _basic_columns(TransactionAPI)
 
     return columns
 
 
-# TODO: Replace with `functools.cache` when Py3.8 dropped
-@lru_cache(maxsize=None)
-def _all_columns(Model: Type[BaseInterfaceModel]) -> Set[str]:
+@cache
+def _all_columns(Model: type[BaseInterfaceModel]) -> set[str]:
     columns = _basic_columns(Model)
     # NOTE: Iterate down the series of subclasses of `Model` (e.g. Block and BlockAPI)
     #       and get all of the public property methods of each class (which are valid columns)
     columns |= {
         field_name
         for cls in Model.__mro__
         if issubclass(cls, BaseInterfaceModel) and cls is not BaseInterfaceModel
@@ -50,16 +50,16 @@
     if Model == ReceiptAPI:
         columns |= _all_columns(TransactionAPI)
 
     return columns
 
 
 def validate_and_expand_columns(
-    columns: Sequence[str], Model: Type[BaseInterfaceModel]
-) -> List[str]:
+    columns: Sequence[str], Model: type[BaseInterfaceModel]
+) -> list[str]:
     if len(columns) == 1 and columns[0] == "*":
         # NOTE: By default, only pull explicit fields
         #       (because they are cheap to pull, but properties might not be)
         return sorted(_basic_columns(Model))
 
     else:
         # NOTE: Validate if selected columns in the total set of fields + properties
@@ -79,21 +79,21 @@
             return sorted(selected_fields)
 
     # NOTE: No recognized fields available to query, so raise ValueError
     err_msg = _unrecognized_columns(deduped_columns, all_columns)
     raise ValueError(err_msg)
 
 
-def _unrecognized_columns(selected_columns: Set[str], all_columns: Set[str]) -> str:
+def _unrecognized_columns(selected_columns: set[str], all_columns: set[str]) -> str:
     unrecognized = "', '".join(sorted(selected_columns - all_columns))
     all_cols = ", ".join(sorted(all_columns))
     return f"Unrecognized field(s) '{unrecognized}', must be one of '{all_cols}'."
 
 
-def extract_fields(item: BaseInterfaceModel, columns: Sequence[str]) -> List[Any]:
+def extract_fields(item: BaseInterfaceModel, columns: Sequence[str]) -> list[Any]:
     return [getattr(item, col, None) for col in columns]
 
 
 class _BaseQuery(BaseModel):
     columns: Sequence[str]
 
     # TODO: Support "*" from getting the EcosystemAPI fields
@@ -103,15 +103,21 @@
     start_block: NonNegativeInt = 0
     stop_block: NonNegativeInt
     step: PositiveInt = 1
 
     @model_validator(mode="before")
     @classmethod
     def check_start_block_before_stop_block(cls, values):
-        if values["stop_block"] < values["start_block"]:
+        start_block = values.get("start_block")
+        stop_block = values.get("stop_block")
+        if (
+            isinstance(start_block, int)
+            and isinstance(stop_block, int)
+            and stop_block < start_block
+        ):
             raise ValueError(
                 f"stop_block: '{values['stop_block']}' cannot be less than "
                 f"start_block: '{values['start_block']}'."
             )
 
         return values
 
@@ -140,48 +146,73 @@
 
     account: AddressType
     start_nonce: NonNegativeInt = 0
     stop_nonce: NonNegativeInt
 
     @model_validator(mode="before")
     @classmethod
-    def check_start_nonce_before_stop_nonce(cls, values: Dict) -> Dict:
+    def check_start_nonce_before_stop_nonce(cls, values: dict) -> dict:
         if values["stop_nonce"] < values["start_nonce"]:
             raise ValueError(
                 f"stop_nonce: '{values['stop_nonce']}' cannot be less than "
                 f"start_nonce: '{values['start_nonce']}'."
             )
 
         return values
 
 
-class ContractCreationQuery(_BaseBlockQuery):
+class ContractCreationQuery(_BaseQuery):
+    """
+    A ``QueryType`` that obtains information about contract deployment.
+    Returns ``ContractCreation(txn_hash, block, deployer, factory)``.
+    """
+
     contract: AddressType
 
 
+class ContractCreation(BaseModel, BaseInterface):
+    txn_hash: str
+    block: int
+    deployer: AddressType
+    factory: Optional[AddressType] = None
+
+    @property
+    def receipt(self):
+        return self.chain_manager.get_receipt(self.txn_hash)
+
+    @classmethod
+    def from_receipt(cls, receipt: ReceiptAPI):
+        return cls(
+            txn_hash=receipt.txn_hash,
+            block=receipt.block_number,
+            deployer=receipt.sender,
+            # factory is not detected since this is meant for eoa deployments
+        )
+
+
 class ContractEventQuery(_BaseBlockQuery):
     """
     A ``QueryType`` that collects members from ``event`` over a range of
     logs emitted by ``contract`` between ``start_block`` and ``stop_block``.
     """
 
-    contract: Union[List[AddressType], AddressType]
+    contract: Union[list[AddressType], AddressType]
     event: EventABI
-    search_topics: Optional[Dict[str, Any]] = None
+    search_topics: Optional[dict[str, Any]] = None
 
 
 class ContractMethodQuery(_BaseBlockQuery):
     """
     A ``QueryType`` that collects return values from calling ``method`` in ``contract``
     over a range of blocks between ``start_block`` and ``stop_block``.
     """
 
     contract: AddressType
     method: MethodABI
-    method_args: Dict[str, Any]
+    method_args: dict[str, Any]
 
 
 class QueryAPI(BaseInterface):
     @abstractmethod
     def estimate_query(self, query: QueryType) -> Optional[int]:
         """
         Estimation of time needed to complete the query. The estimation is returned
```

### Comparing `eth-ape-0.7.9/src/ape/api/transactions.py` & `eth-ape-0.8.0/src/ape/api/transactions.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 import sys
 import time
+from collections.abc import Iterator
 from datetime import datetime
-from typing import IO, TYPE_CHECKING, Any, Iterator, List, NoReturn, Optional, Union
+from typing import IO, TYPE_CHECKING, Any, NoReturn, Optional, Union
 
 from eth_pydantic_types import HexBytes
 from eth_utils import is_0x_prefixed, is_hex, to_int
 from ethpm_types.abi import EventABI, MethodABI
 from pydantic import ConfigDict, field_validator
 from pydantic.fields import Field
 from tqdm import tqdm  # type: ignore
@@ -20,28 +21,29 @@
 )
 from ape.logging import logger
 from ape.types import (
     AddressType,
     AutoGasLimit,
     ContractLogContainer,
     SourceTraceback,
-    TraceFrame,
     TransactionSignature,
 )
 from ape.utils import (
     BaseInterfaceModel,
     ExtraAttributesMixin,
     ExtraModelAttributes,
     abstractmethod,
     cached_property,
+    log_instead_of_fail,
     raises_not_implemented,
 )
 
 if TYPE_CHECKING:
     from ape.api.providers import BlockAPI
+    from ape.api.trace import TraceAPI
     from ape.contracts import ContractEvent
 
 
 class TransactionAPI(BaseInterfaceModel):
     """
     An API class representing a transaction.
     Ecosystem plugins implement one or more of transaction APIs
@@ -152,15 +154,15 @@
 
         try:
             return self.provider.get_receipt(txn_hash, required_confirmations=0, timeout=0)
         except (TransactionNotFoundError, ProviderNotConnectedError):
             return None
 
     @property
-    def trace(self) -> Iterator[TraceFrame]:
+    def trace(self) -> "TraceAPI":
         """
         The transaction trace. Only works if this transaction was published
         and you are using a provider that support tracing.
 
         Raises:
             :class:`~ape.exceptions.APINotImplementedError`: When using a provider
               that does not support tracing.
@@ -169,21 +171,24 @@
 
     @abstractmethod
     def serialize_transaction(self) -> bytes:
         """
         Serialize the transaction
         """
 
+    @log_instead_of_fail(default="<TransactionAPI>")
     def __repr__(self) -> str:
+        # NOTE: Using JSON mode for style.
         data = self.model_dump(mode="json")
         params = ", ".join(f"{k}={v}" for k, v in data.items())
         cls_name = getattr(type(self), "__name__", TransactionAPI.__name__)
         return f"<{cls_name} {params}>"
 
     def __str__(self) -> str:
+        # NOTE: Using JSON mode for style.
         data = self.model_dump(mode="json")
         if len(data["data"]) > 9:
             # only want to specify encoding if data["data"] is a string
             if isinstance(data["data"], str):
                 data["data"] = (
                     "0x"
                     + bytes(data["data"][:3], encoding="utf8").hex()
@@ -261,42 +266,69 @@
     Get a receipt by making transactions in ``ape``, such as interacting with
     a :class:`ape.contracts.base.ContractInstance`.
     """
 
     contract_address: Optional[AddressType] = None
     block_number: int
     gas_used: int
-    logs: List[dict] = []
+    logs: list[dict] = []
     status: int
     txn_hash: str
     transaction: TransactionAPI
 
+    @log_instead_of_fail(default="<ReceiptAPI>")
     def __repr__(self) -> str:
         cls_name = getattr(self.__class__, "__name__", ReceiptAPI.__name__)
         return f"<{cls_name} {self.txn_hash}>"
 
     def __ape_extra_attributes__(self) -> Iterator[ExtraModelAttributes]:
         yield ExtraModelAttributes(name="transaction", attributes=lambda: vars(self.transaction))
 
     @field_validator("transaction", mode="before")
     @classmethod
-    def confirm_transaction(cls, value):
-        if isinstance(value, dict):
-            value = TransactionAPI.model_validate(value)
+    def _validate_transaction(cls, value):
+        if not isinstance(value, dict):
+            # Already a `TransactionAPI`.
+            return value
 
-        return value
+        # Attempt to create a transaction model for the data.
+        if provider := cls.network_manager.active_provider:
+            ecosystem = provider.network.ecosystem
+        else:
+            logger.warning(
+                "Given raw-transaction data when not connected to any provider. "
+                "Network is unknown. Assuming EVM-like transaction model."
+            )
+            ecosystem = cls.network_manager.ethereum
+
+        return ecosystem.create_transaction(**value)
 
     @field_validator("txn_hash", mode="before")
     @classmethod
     def validate_txn_hash(cls, value):
         return HexBytes(value).hex()
 
-    @property
-    def call_tree(self) -> Optional[Any]:
-        return None
+    @cached_property
+    def debug_logs_typed(self) -> list[tuple[Any]]:
+        """Return any debug log data outputted by the transaction."""
+        return []
+
+    @cached_property
+    def debug_logs_lines(self) -> list[str]:
+        """
+        Return any debug log data outputted by the transaction as strings suitable for printing
+        """
+        return [" ".join(map(str, ln)) for ln in self.debug_logs_typed]
+
+    def show_debug_logs(self):
+        """
+        Output debug logs to logging system
+        """
+        for ln in self.debug_logs_lines:
+            logger.info(f"[DEBUG-LOG] {ln}")
 
     @property
     def failed(self) -> bool:
         """
         Whether the receipt represents a failing transaction.
         Ecosystem plugins override this property when their receipts
         are able to be failing.
@@ -319,19 +351,19 @@
 
         Returns:
             bool:  ``True`` when the transaction failed and used the
             same amount of gas as the given ``gas_limit``.
         """
 
     @property
-    def trace(self) -> Iterator[TraceFrame]:
+    def trace(self) -> "TraceAPI":
         """
-        The trace of the transaction, if available from your provider.
+        The :class:`~ape.api.trace.TraceAPI` of the transaction.
         """
-        return self.provider.get_transaction_trace(txn_hash=self.txn_hash)
+        return self.provider.get_transaction_trace(self.txn_hash)
 
     @property
     def _explorer(self) -> Optional[ExplorerAPI]:
         return self.provider.network.explorer
 
     @property
     def _block_time(self) -> int:
@@ -366,25 +398,25 @@
 
         return self.decode_logs()  # Decodes all logs by default.
 
     @abstractmethod
     def decode_logs(
         self,
         abi: Optional[
-            Union[List[Union[EventABI, "ContractEvent"]], Union[EventABI, "ContractEvent"]]
+            Union[list[Union[EventABI, "ContractEvent"]], Union[EventABI, "ContractEvent"]]
         ] = None,
     ) -> ContractLogContainer:
         """
         Decode the logs on the receipt.
 
         Args:
             abi (``EventABI``): The ABI of the event to decode into logs.
 
         Returns:
-            List[:class:`~ape.types.ContractLog`]
+            list[:class:`~ape.types.ContractLog`]
         """
 
     def raise_for_status(self) -> Optional[NoReturn]:
         """
         Handle provider-specific errors regarding a non-successful
         :class:`~api.providers.TransactionStatusEnum`.
         """
@@ -458,29 +490,19 @@
     @property
     def return_value(self) -> Any:
         """
         Obtain the final return value of the call. Requires tracing to function,
         since this is not available from the receipt object.
         """
 
-        if not (call_tree := self.call_tree) or not (method_abi := self.method_called):
-            return None
-
-        if isinstance(call_tree.outputs, (str, HexBytes, int)):
-            output = self.provider.network.ecosystem.decode_returndata(
-                method_abi, HexBytes(call_tree.outputs)
-            )
-        else:
-            # Already enriched.
-            output = call_tree.outputs
+        if trace := self.trace:
+            ret_val = trace.return_value
+            return ret_val[0] if isinstance(ret_val, tuple) and len(ret_val) == 1 else ret_val
 
-        if isinstance(output, tuple) and len(output) < 2:
-            output = output[0] if len(output) == 1 else None
-
-        return output
+        return None
 
     @property
     @raises_not_implemented
     def source_traceback(self) -> SourceTraceback:  # type: ignore[empty-body]
         """
         A Pythonic style traceback for both failing and non-failing receipts.
         Requires a provider that implements
@@ -519,25 +541,25 @@
         to get full data. Else, is limited to receipt-level data.
         This gets called when running tests with the ``--gas`` flag.
         """
         address = self.receiver or self.contract_address
         if not address or not self._test_runner:
             return
 
-        if self.provider.supports_tracing and (call_tree := self.call_tree):
+        if self.provider.supports_tracing and (trace := self.trace):
             tracker = self._test_runner.gas_tracker
-            tracker.append_gas(call_tree.enrich(in_line=False), address)
+            tracker.append_gas(trace, address)
 
         elif (
             (contract_type := self.chain_manager.contracts.get(address))
             and contract_type.source_id
             and (method := self.method_called)
         ):
             # Can only track top-level gas.
-            if contract := self.project_manager._create_contract_source(contract_type):
+            if contract := self.local_project._create_contract_source(contract_type):
                 self._test_runner.gas_tracker.append_toplevel_gas(contract, method, self.gas_used)
 
     def track_coverage(self):
         """
         Track this receipt's source code coverage in the on-going
         session coverage report. Requires using a provider that supports
         transaction traces to track full coverage. Else, is limited
@@ -561,9 +583,9 @@
             # Unable to track detailed coverage like statement or branch
             # The user will receive a warning at the end regarding this.
             # At the very least, we can track function coverage.
             contract_type = self.chain_manager.contracts.get(address)
             if not contract_type or not contract_type.source_id:
                 return
 
-            if contract := self.project_manager._create_contract_source(contract_type):
+            if contract := self.local_project._create_contract_source(contract_type):
                 tracker.hit_function(contract, method)
```

### Comparing `eth-ape-0.7.9/src/ape/cli/__init__.py` & `eth-ape-0.8.0/src/ape/cli/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -5,53 +5,54 @@
 )
 from ape.cli.choices import (
     AccountAliasPromptChoice,
     Alias,
     NetworkChoice,
     OutputFormat,
     PromptChoice,
-    get_user_selected_account,
     output_format_choice,
     select_account,
 )
-from ape.cli.commands import ConnectedProviderCommand, NetworkBoundCommand
+from ape.cli.commands import ConnectedProviderCommand
 from ape.cli.options import (
     ApeCliContextObject,
     NetworkOption,
     account_option,
     ape_cli_context,
+    config_override_option,
     contract_option,
     incompatible_with,
     network_option,
     output_format_option,
+    project_option,
     skip_confirmation_option,
     verbosity_option,
 )
-from ape.cli.paramtype import AllFilePaths, Path
+from ape.cli.paramtype import JSON, Path
 
 __all__ = [
     "account_option",
     "AccountAliasPromptChoice",
     "Alias",
-    "AllFilePaths",
     "ape_cli_context",
     "ApeCliContextObject",
+    "config_override_option",
     "ConnectedProviderCommand",
     "contract_file_paths_argument",
     "contract_option",
     "existing_alias_argument",
-    "get_user_selected_account",
     "incompatible_with",
+    "JSON",
     "network_option",
-    "NetworkBoundCommand",
     "NetworkChoice",
     "NetworkOption",
     "non_existing_alias_argument",
     "output_format_choice",
     "output_format_option",
     "OutputFormat",
     "Path",
+    "project_option",
     "PromptChoice",
     "select_account",
     "skip_confirmation_option",
     "verbosity_option",
 ]
```

### Comparing `eth-ape-0.7.9/src/ape/cli/choices.py` & `eth-ape-0.8.0/src/ape/cli/choices.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,28 +1,28 @@
 import re
-import warnings
+from collections.abc import Callable, Iterator, Sequence
 from enum import Enum
 from functools import lru_cache
-from typing import Any, Callable, Iterator, List, Optional, Sequence, Type, Union
+from typing import Any, Optional, Union
 
 import click
 from click import BadParameter, Choice, Context, Parameter
 
 from ape.api.accounts import AccountAPI
 from ape.api.providers import ProviderAPI
 from ape.exceptions import AccountsError
 from ape.types import _LazySequence
 from ape.utils.basemodel import ManagerAccessMixin
 
 _ACCOUNT_TYPE_FILTER = Union[
-    None, Sequence[AccountAPI], Type[AccountAPI], Callable[[AccountAPI], bool]
+    None, Sequence[AccountAPI], type[AccountAPI], Callable[[AccountAPI], bool]
 ]
 
 
-def _get_accounts(key: _ACCOUNT_TYPE_FILTER) -> List[AccountAPI]:
+def _get_accounts(key: _ACCOUNT_TYPE_FILTER) -> list[AccountAPI]:
     add_test_accounts = False
     if key is None:
         account_list = list(ManagerAccessMixin.account_manager)
 
         # Include test accounts at end.
         add_test_accounts = True
 
@@ -135,38 +135,26 @@
         choice_idx = int(choice)
         if 0 <= choice_idx < len(self.choices):
             return self.choices[choice_idx]
 
         raise IndexError(f"Choice index '{choice_idx}' out of range.")
 
 
-def get_user_selected_account(
-    prompt_message: Optional[str] = None, account_type: _ACCOUNT_TYPE_FILTER = None
-) -> AccountAPI:
-    """
-    **DEPRECATED**: Use :meth:`~ape.cli.choices.select_account` instead.
-    """
-    warnings.warn(
-        "'get_user_selected_account' is deprecated. Use 'select_account'.", DeprecationWarning
-    )
-    return select_account(prompt_message=prompt_message, key=account_type)
-
-
 def select_account(
     prompt_message: Optional[str] = None, key: _ACCOUNT_TYPE_FILTER = None
 ) -> AccountAPI:
     """
     Prompt the user to pick from their accounts and return that account.
     Use this method if you want to prompt users to select accounts _outside_
     of CLI options. For CLI options, use
     :meth:`~ape.cli.options.account_option`.
 
     Args:
         prompt_message (Optional[str]): Customize the prompt message.
-        key (Union[None, Type[AccountAPI], Callable[[AccountAPI], bool]]):
+        key (Union[None, type[AccountAPI], Callable[[AccountAPI], bool]]):
           If given, the user may only select a matching account. You can provide
           a list of accounts, an account class type, or a callable for filtering
           the accounts.
 
     Returns:
         :class:`~ape.api.accounts.AccountAPI`
     """
@@ -269,15 +257,15 @@
         self.print_choices()
         return click.prompt(self._prompt_message, type=self)
 
     def fail_from_invalid_choice(self, param):
         return self.fail("Invalid choice. Type the number or the alias.", param=param)
 
 
-_NETWORK_FILTER = Optional[Union[List[str], str]]
+_NETWORK_FILTER = Optional[Union[list[str], str]]
 _NONE_NETWORK = "__NONE_NETWORK__"
 
 
 def get_networks(
     ecosystem: _NETWORK_FILTER = None,
     network: _NETWORK_FILTER = None,
     provider: _NETWORK_FILTER = None,
@@ -335,15 +323,15 @@
 
     def __init__(
         self,
         case_sensitive=True,
         ecosystem: _NETWORK_FILTER = None,
         network: _NETWORK_FILTER = None,
         provider: _NETWORK_FILTER = None,
-        base_type: Type = ProviderAPI,
+        base_type: type = ProviderAPI,
         callback: Optional[Callable] = None,
     ):
         if not issubclass(base_type, (ProviderAPI, str)):
             raise TypeError(f"Unhandled type '{base_type}' for NetworkChoice.")
 
         self.base_type = base_type
         self.callback = callback
@@ -412,20 +400,20 @@
     TREE = "TREE"
     """A rich text tree view of the data."""
 
     YAML = "YAML"
     """A standard .yaml format of the data."""
 
 
-def output_format_choice(options: Optional[List[OutputFormat]] = None) -> Choice:
+def output_format_choice(options: Optional[list[OutputFormat]] = None) -> Choice:
     """
     Returns a ``click.Choice()`` type for the given options.
 
     Args:
-        options (List[:class:`~ape.choices.OutputFormat`], optional):
+        options (list[:class:`~ape.choices.OutputFormat`], optional):
           Limit the formats to accept. Defaults to allowing all formats.
 
     Returns:
         :class:`click.Choice`
     """
 
     options = options or list(OutputFormat)
```

### Comparing `eth-ape-0.7.9/src/ape/cli/commands.py` & `eth-ape-0.8.0/src/ape/cli/commands.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,9 @@
 import inspect
-import warnings
-from typing import Any, List, Optional
+from typing import Any, Optional
 
 import click
 from click import Context
 
 from ape.api import ProviderAPI, ProviderContextManager
 from ape.cli.choices import _NONE_NETWORK, NetworkChoice
 from ape.exceptions import NetworkError
@@ -31,17 +30,19 @@
         return provider.network.use_provider(provider, disconnect_on_exit=not interactive)
 
     provider = get_param_from_ctx(ctx, "network")
     if provider is not None and isinstance(provider, ProviderAPI):
         return provider.network.use_provider(provider, disconnect_on_exit=not interactive)
 
     elif provider not in (None, _NONE_NETWORK) and isinstance(provider, str):
+        # Is using a choice-str network param value instead of the network object instances.
         return ManagerAccessMixin.network_manager.parse_network_choice(
             provider, disconnect_on_exit=not interactive
         )
+
     elif provider is None:
         ecosystem = ManagerAccessMixin.network_manager.default_ecosystem
         network = ecosystem.default_network
         if provider_name := network.default_provider_name:
             return network.use_provider(provider_name, disconnect_on_exit=not interactive)
         else:
             raise NetworkError(f"Network {network.name} has no providers.")
@@ -59,15 +60,16 @@
     """
 
     def __init__(self, *args, **kwargs):
         self._use_cls_types = kwargs.pop("use_cls_types", True)
         self._network_callback = kwargs.pop("network_callback", None)
         super().__init__(*args, **kwargs)
 
-    def parse_args(self, ctx: Context, args: List[str]) -> List[str]:
+    def parse_args(self, ctx: Context, args: list[str]) -> list[str]:
+        arguments = args  # Renamed for better pdb support.
         base_type = ProviderAPI if self._use_cls_types else str
         if existing_option := next(
             iter(
                 x
                 for x in self.params
                 if isinstance(x, click.core.Option)
                 and x.name == "network"
@@ -81,15 +83,15 @@
         else:
             # Add the option automatically.
             from ape.cli.options import NetworkOption
 
             option = NetworkOption(base_type=base_type, callback=self._network_callback)
             self.params.append(option)
 
-        return super().parse_args(ctx, args)
+        return super().parse_args(ctx, arguments)
 
     def invoke(self, ctx: Context) -> Any:
         if self.callback is None:
             return
 
         elif network_ctx := parse_network(ctx):
             with network_ctx as provider:
@@ -123,25 +125,11 @@
                     name not in ctx.params
                     or ctx.params[name] is None
                     or isinstance(ctx.params[name], str)
                 ):
                     ctx.params[name] = options.get(name)
 
         elif not self._use_cls_types and provider is not None:
-            # Legacy behavior, but may have a purpose.
+            # Keep choice-str instead of parsing to objects.
             ctx.params["network"] = provider.network_choice
 
         return ctx.invoke(self.callback or (lambda: None), **ctx.params)
-
-
-# TODO: 0.8 delete
-class NetworkBoundCommand(ConnectedProviderCommand):
-    def __init__(self, *args, **kwargs):
-        warnings.warn(
-            "'NetworkBoundCommand' is deprecated. Use 'ConnectedProviderCommand'.",
-            DeprecationWarning,
-        )
-
-        # Disable the advanced network class types so it behaves legacy.
-        kwargs["use_cls_types"] = False
-
-        super().__init__(*args, **kwargs)
```

### Comparing `eth-ape-0.7.9/src/ape/cli/options.py` & `eth-ape-0.8.0/src/ape/cli/options.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,25 +1,28 @@
 import inspect
+from collections.abc import Callable
 from functools import partial
-from typing import Callable, Dict, List, NoReturn, Optional, Type, Union
+from pathlib import Path
+from typing import NoReturn, Optional, Union
 
 import click
 from click import Option
 from ethpm_types import ContractType
 
-from ape.api import ProviderAPI
-from ape.cli import ConnectedProviderCommand
+from ape.api.providers import ProviderAPI
 from ape.cli.choices import (
     _ACCOUNT_TYPE_FILTER,
     _NONE_NETWORK,
     AccountAliasPromptChoice,
     NetworkChoice,
     OutputFormat,
     output_format_choice,
 )
+from ape.cli.commands import ConnectedProviderCommand
+from ape.cli.paramtype import JSON
 from ape.exceptions import Abort, ProjectError
 from ape.logging import DEFAULT_LOG_LEVEL, ApeLogger, LogLevel, logger
 from ape.utils.basemodel import ManagerAccessMixin
 
 _VERBOSITY_VALUES = ("--verbosity", "-v")
 
 
@@ -61,15 +64,15 @@
     _logger = cli_logger or logger
     kwarguments = _create_verbosity_kwargs(_logger=_logger, default=default)
     return lambda f: click.option(*_VERBOSITY_VALUES, **kwarguments)(f)
 
 
 def _create_verbosity_kwargs(
     _logger: Optional[ApeLogger] = None, default: str = DEFAULT_LOG_LEVEL
-) -> Dict:
+) -> dict:
     cli_logger = _logger or logger
 
     def set_level(ctx, param, value):
         cli_logger._load_from_sys_argv(default=value.upper())
 
     level_names = [lvl.name for lvl in LogLevel]
     names_str = f"{', '.join(level_names[:-1])}, or {level_names[-1]}"
@@ -80,15 +83,15 @@
         "expose_value": False,
         "help": f"One of {names_str}",
         "is_eager": True,
     }
 
 
 def ape_cli_context(
-    default_log_level: str = DEFAULT_LOG_LEVEL, obj_type: Type = ApeCliContextObject
+    default_log_level: str = DEFAULT_LOG_LEVEL, obj_type: type = ApeCliContextObject
 ) -> Callable:
     """
     A ``click`` context object with helpful utilities.
     Use in your commands to get access to common utility features,
     such as logging or accessing managers.
 
     Args:
@@ -166,32 +169,32 @@
             **kwargs,
         }
         super().__init__(**kwargs)
 
 
 def network_option(
     default: Optional[Union[str, Callable]] = "auto",
-    ecosystem: Optional[Union[List[str], str]] = None,
-    network: Optional[Union[List[str], str]] = None,
-    provider: Optional[Union[List[str], str]] = None,
+    ecosystem: Optional[Union[list[str], str]] = None,
+    network: Optional[Union[list[str], str]] = None,
+    provider: Optional[Union[list[str], str]] = None,
     required: bool = False,
     **kwargs,
 ) -> Callable:
     """
     A ``click.option`` for specifying a network.
 
     Args:
         default (Optional[str]): Optionally, change which network to
           use as the default. Defaults to how ``ape`` normally
           selects a default network unless ``required=True``, then defaults to ``None``.
-        ecosystem (Optional[Union[List[str], str]]): Filter the options by ecosystem.
+        ecosystem (Optional[Union[list[str], str]]): Filter the options by ecosystem.
           Defaults to getting all ecosystems.
-        network (Optional[Union[List[str], str]]): Filter the options by network.
+        network (Optional[Union[list[str], str]]): Filter the options by network.
           Defaults to getting all networks in ecosystems.
-        provider (Optional[Union[List[str], str]]): Filter the options by provider.
+        provider (Optional[Union[list[str], str]]): Filter the options by provider.
           Defaults to getting all providers in networks.
         required (bool): Whether the option is required. Defaults to ``False``.
           When set to ``True``, the default value is ``None``.
         kwargs: Additional overrides to ``click.option``.
     """
 
     def decorator(f):
@@ -206,22 +209,22 @@
         requested_network_objects = [x for x in command_kwargs if x in network_object_names]
 
         # When using network_option, handle parsing now so we can pass to
         # callback outside of command context.
         user_callback = kwargs.pop("callback", None)
 
         def callback(ctx, param, value):
-            is_legacy = param.type.base_type is str
-            use_default = default == "auto"
+            keep_as_choice_str = param.type.base_type is str
+            use_default = value is None and default == "auto"
 
-            if not is_legacy and value is None and use_default:
+            if not keep_as_choice_str and use_default:
                 default_ecosystem = ManagerAccessMixin.network_manager.default_ecosystem
                 provider_obj = default_ecosystem.default_network.default_provider
 
-            elif value is None or is_legacy:
+            elif value is None or keep_as_choice_str:
                 provider_obj = None
 
             elif isinstance(value, ProviderAPI):
                 provider_obj = value
 
             elif value == _NONE_NETWORK:
                 provider_obj = None
@@ -256,20 +259,27 @@
                         except Exception:
                             # This would only happen if using an unusual context object.
                             raise Abort(
                                 "Cannot use connected-provider command type(s) "
                                 "with non key-settable context object."
                             )
 
+            elif keep_as_choice_str:
+                # Add raw choice to object context.
+                ctx.obj = ctx.obj or {}
+                ctx.params = ctx.params or {}
+                ctx.obj["network"] = value
+                ctx.params["network"] = value
+
             # else: provider is None, meaning not connected intentionally.
 
             return value if user_callback is None else user_callback(ctx, param, value)
 
         # Prevent argument errors but initializing callback to use None placeholders.
-        partial_kwargs: Dict = {}
+        partial_kwargs: dict = {}
         for arg_type in network_object_names:
             if arg_type in requested_network_objects:
                 partial_kwargs[arg_type] = None
 
         if partial_kwargs:
             wrapped_f = partial(f, **partial_kwargs)
 
@@ -345,30 +355,30 @@
     return click.option(
         "--account",
         type=AccountAliasPromptChoice(key=account_type),
         callback=_account_callback,
     )
 
 
-def _load_contracts(ctx, param, value) -> Optional[Union[ContractType, List[ContractType]]]:
+def _load_contracts(ctx, param, value) -> Optional[Union[ContractType, list[ContractType]]]:
     if not value:
         return None
 
-    if len(ManagerAccessMixin.project_manager.contracts) == 0:
+    if len(ManagerAccessMixin.local_project.contracts) == 0:
         raise ProjectError("Project has no contracts.")
 
     # If the user passed in `multiple=True`, then `value` is a list,
     # and therefore we should also return a list.
     is_multiple = isinstance(value, (tuple, list))
 
     def get_contract(contract_name: str) -> ContractType:
-        if contract_name not in ManagerAccessMixin.project_manager.contracts:
+        if contract_name not in ManagerAccessMixin.local_project.contracts:
             raise ProjectError(f"No contract named '{value}'")
 
-        return ManagerAccessMixin.project_manager.contracts[contract_name]
+        return ManagerAccessMixin.local_project.contracts[contract_name]
 
     return [get_contract(c) for c in value] if is_multiple else get_contract(value)
 
 
 def contract_option(help=None, required=False, multiple=False) -> Callable:
     """
     Contract(s) from the current project.
@@ -397,15 +407,15 @@
         "output_format",
         type=output_format_choice(),
         default=default.value,
         callback=lambda ctx, param, value: OutputFormat(value.upper()),
     )
 
 
-def incompatible_with(incompatible_opts) -> Type[click.Option]:
+def incompatible_with(incompatible_opts) -> type[click.Option]:
     """
     Factory for creating custom ``click.Option`` subclasses that
     enforce incompatibility with the option strings passed to this function.
 
     Usage example::
 
         import click
@@ -434,7 +444,56 @@
                     raise click.BadOptionUsage(
                         option_name=self.name,
                         message=f"'--{name}' can't be used with '{found_incompatible}'.",
                     )
             return super().handle_parse_result(ctx, opts, args)
 
     return IncompatibleOption
+
+
+def _project_callback(ctx, param, val):
+    pm = None
+    if not val:
+        pm = ManagerAccessMixin.local_project
+
+    else:
+        path = Path(val)
+        if path == ManagerAccessMixin.local_project.path:
+            pm = ManagerAccessMixin.local_project
+
+        else:
+            Project = ManagerAccessMixin.Project
+            if path.is_file() and path.suffix == ".json":
+                pm = Project.from_manifest(path)
+
+            elif path.is_dir():
+                pm = Project(path)
+
+    if pm is None:
+        raise click.BadOptionUsage("--project", "Not a valid project")
+
+    return pm
+
+
+def project_option(**kwargs):
+    return click.option(
+        "--project",
+        help="The path to a local project or manifest",
+        callback=_project_callback,
+        metavar="PATH",
+        is_eager=True,
+        **kwargs,
+    )
+
+
+def _json_option(name, help, **kwargs):
+    return click.option(
+        name,
+        help=help,
+        type=JSON(),
+        metavar='{"KEY": "VAL"}',
+        **kwargs,
+    )
+
+
+def config_override_option(**kwargs):
+    return _json_option("--config-override", help="Config override mappings", **kwargs)
```

### Comparing `eth-ape-0.7.9/src/ape/contracts/base.py` & `eth-ape-0.8.0/src/ape/contracts/base.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,40 +1,58 @@
 import difflib
 import types
+from collections.abc import Callable, Iterator
 from functools import partial
 from itertools import islice
 from pathlib import Path
-from typing import Any, Callable, Dict, Iterator, List, Optional, Tuple, Type, Union
+from typing import Any, Optional, Union
 
 import click
 import pandas as pd
 from eth_pydantic_types import HexBytes
+from eth_utils import to_hex
 from ethpm_types.abi import ConstructorABI, ErrorABI, EventABI, MethodABI
 from ethpm_types.contract_type import ABI_W_SELECTOR_T, ContractType
 
 from ape.api import AccountAPI, Address, ReceiptAPI, TransactionAPI
 from ape.api.address import BaseAddress
-from ape.api.query import ContractEventQuery, extract_fields, validate_and_expand_columns
+from ape.api.query import (
+    ContractCreation,
+    ContractEventQuery,
+    extract_fields,
+    validate_and_expand_columns,
+)
 from ape.exceptions import (
     ApeAttributeError,
     ArgumentsLengthError,
     ChainError,
     ContractDataError,
     ContractLogicError,
     ContractNotFoundError,
     CustomError,
     MethodNonPayableError,
     MissingDeploymentBytecodeError,
-    TransactionNotFoundError,
 )
 from ape.logging import logger
 from ape.types import AddressType, ContractLog, LogFilter, MockContractLog
-from ape.utils import BaseInterfaceModel, ManagerAccessMixin, cached_property, singledispatchmethod
+from ape.utils import (
+    BaseInterfaceModel,
+    ManagerAccessMixin,
+    cached_property,
+    log_instead_of_fail,
+    singledispatchmethod,
+)
 from ape.utils.abi import StructParser
-from ape.utils.basemodel import _assert_not_ipython_check
+from ape.utils.basemodel import (
+    ExtraAttributesMixin,
+    ExtraModelAttributes,
+    _assert_not_ipython_check,
+    get_attribute_with_extras,
+    only_raise_attribute_error,
+)
 
 
 class ContractConstructor(ManagerAccessMixin):
     def __init__(
         self,
         deployment_bytecode: HexBytes,
         abi: ConstructorABI,
@@ -42,23 +60,24 @@
         self.deployment_bytecode = deployment_bytecode
         self.abi = abi
 
         if not self.deployment_bytecode:
             logger.warning("Deploying an empty contract (no bytecode)")
             self.deployment_bytecode = HexBytes("")
 
+    @log_instead_of_fail(default="<ContractConstructor>")
     def __repr__(self) -> str:
         return self.abi.signature if self.abi else "constructor()"
 
     def encode_input(self, *args) -> HexBytes:
         ecosystem = self.provider.network.ecosystem
         encoded_calldata = ecosystem.encode_calldata(self.abi, *args)
         return HexBytes(encoded_calldata)
 
-    def decode_input(self, calldata: bytes) -> Tuple[str, Dict[str, Any]]:
+    def decode_input(self, calldata: bytes) -> tuple[str, dict[str, Any]]:
         decoded_inputs = self.provider.network.ecosystem.decode_calldata(self.abi, calldata)
         return self.abi.selector, decoded_inputs
 
     def serialize_transaction(self, *args, **kwargs) -> TransactionAPI:
         arguments = self.conversion_manager.convert_method_args(self.abi, args)
         converted_kwargs = self.conversion_manager.convert_method_kwargs(kwargs)
         return self.provider.network.ecosystem.encode_deployment(
@@ -83,14 +102,15 @@
 
 class ContractCall(ManagerAccessMixin):
     def __init__(self, abi: MethodABI, address: AddressType) -> None:
         super().__init__()
         self.abi = abi
         self.address = address
 
+    @log_instead_of_fail(default="<ContractCall>")
     def __repr__(self) -> str:
         return self.abi.signature
 
     def serialize_transaction(self, *args, **kwargs) -> TransactionAPI:
         converted_kwargs = self.conversion_manager.convert_method_kwargs(kwargs)
         return self.provider.network.ecosystem.encode_transaction(
             self.address, self.abi, *args, **converted_kwargs
@@ -113,21 +133,22 @@
             return output[0] if len(output) == 1 else None
 
         return output
 
 
 class ContractMethodHandler(ManagerAccessMixin):
     contract: "ContractInstance"
-    abis: List[MethodABI]
+    abis: list[MethodABI]
 
-    def __init__(self, contract: "ContractInstance", abis: List[MethodABI]) -> None:
+    def __init__(self, contract: "ContractInstance", abis: list[MethodABI]) -> None:
         super().__init__()
         self.contract = contract
         self.abis = abis
 
+    @log_instead_of_fail(default="<ContractMethodHandler>")
     def __repr__(self) -> str:
         # `<ContractName 0x1234...AbCd>.method_name`
         return f"{self.contract.__repr__()}.{self.abis[-1].name}"
 
     def __str__(self) -> str:
         # `method_name(type1 arg1, ...) -> return_type`
         abis = sorted(self.abis, key=lambda abi: len(abi.inputs or []))
@@ -137,15 +158,15 @@
         selected_abi = _select_method_abi(self.abis, args)
         arguments = self.conversion_manager.convert_method_args(selected_abi, args)
         ecosystem = self.provider.network.ecosystem
         encoded_calldata = ecosystem.encode_calldata(selected_abi, *arguments)
         method_id = ecosystem.get_method_selector(selected_abi)
         return HexBytes(method_id + encoded_calldata)
 
-    def decode_input(self, calldata: bytes) -> Tuple[str, Dict[str, Any]]:
+    def decode_input(self, calldata: bytes) -> tuple[str, dict[str, Any]]:
         matching_abis = []
         rest_calldata = None
         err = ContractDataError(
             f"Unable to find matching method ABI for calldata '{calldata.hex()}'. "
             "Try prepending a method ID to the beginning of the calldata."
         )
         for abi in self.abis:
@@ -241,15 +262,15 @@
         """
 
         selected_abi = _select_method_abi(self.abis, args)
         arguments = self.conversion_manager.convert_method_args(selected_abi, args)
         return self.transact.estimate_gas_cost(*arguments, **kwargs)
 
 
-def _select_method_abi(abis: List[MethodABI], args: Union[Tuple, List]) -> MethodABI:
+def _select_method_abi(abis: list[MethodABI], args: Union[tuple, list]) -> MethodABI:
     args = args or []
     selected_abi = None
     for abi in abis:
         inputs = abi.inputs or []
         if len(args) == len(inputs):
             selected_abi = abi
 
@@ -264,14 +285,15 @@
     address: AddressType
 
     def __init__(self, abi: MethodABI, address: AddressType) -> None:
         super().__init__()
         self.abi = abi
         self.address = address
 
+    @log_instead_of_fail(default="<ContractTransaction>")
     def __repr__(self) -> str:
         return self.abi.signature
 
     def serialize_transaction(self, *args, **kwargs) -> TransactionAPI:
         if "sender" in kwargs and isinstance(kwargs["sender"], (ContractInstance, Address)):
             # Automatically impersonate contracts (if API available) when sender
             kwargs["sender"] = self.account_manager.test_accounts[kwargs["sender"].address]
@@ -380,17 +402,18 @@
 
          # 'my_contract' refers to a ContractInstance in this case.
          my_event_type = my_contract.MyEvent
     """
 
     contract: "ContractTypeWrapper"
     abi: EventABI
-    _logs: Optional[List[ContractLog]] = None
+    _logs: Optional[list[ContractLog]] = None
 
-    def __repr__(self):
+    @log_instead_of_fail(default="<ContractEvent>")
+    def __repr__(self) -> str:
         return self.abi.signature
 
     @property
     def name(self) -> str:
         """
         The name of the contract event, as defined in the contract.
         """
@@ -408,15 +431,15 @@
     def log_filter(self) -> LogFilter:
         # NOTE: This shouldn't really be called when given contract containers.
         address = getattr(self.contract, "address", None)
         addresses = [] if not address else [address]
         return LogFilter.from_event(event=self.abi, addresses=addresses, start_block=0)
 
     @singledispatchmethod
-    def __getitem__(self, value) -> Union[ContractLog, List[ContractLog]]:  # type: ignore[override]
+    def __getitem__(self, value) -> Union[ContractLog, list[ContractLog]]:  # type: ignore[override]
         raise NotImplementedError(f"Cannot use '{type(value)}' to access logs.")
 
     @__getitem__.register
     def __getitem_int(self, index: int) -> ContractLog:
         """
         Access events on the contract by the index of when they occurred.
 
@@ -436,15 +459,15 @@
             else:
                 return list(logs)[index]
 
         except (IndexError, StopIteration) as err:
             raise IndexError(f"No log at index '{index}' for event '{self.abi.name}'.") from err
 
     @__getitem__.register
-    def __getitem_slice(self, value: slice) -> List[ContractLog]:
+    def __getitem_slice(self, value: slice) -> list[ContractLog]:
         """
         Access a slice of logs from this event.
 
         Args:
             value (slice): The range of log to get, e.g. ``[5:10]``.
 
         Returns:
@@ -455,15 +478,15 @@
 
     def __len__(self):
         logs = self.provider.get_contract_logs(self.log_filter)
         return sum(1 for _ in logs)
 
     def __call__(self, *args: Any, **kwargs: Any) -> MockContractLog:
         # Create a dictionary from the positional arguments
-        event_args: Dict[Any, Any] = dict(zip((ipt.name for ipt in self.abi.inputs), args))
+        event_args: dict[Any, Any] = dict(zip((ipt.name for ipt in self.abi.inputs), args))
 
         overlapping_keys = set(k for k in event_args.keys() if k is not None) & set(
             k for k in kwargs.keys() if k is not None
         )
 
         if overlapping_keys:
             raise ValueError(
@@ -507,15 +530,15 @@
 
             elif isinstance(value, (list, tuple)):
                 converted_args[key] = parser.decode_input(value)
 
             else:
                 converted_args[key] = self.conversion_manager.convert(value, py_type)
 
-        properties: Dict = {"event_arguments": converted_args, "event_name": self.abi.name}
+        properties: dict = {"event_arguments": converted_args, "event_name": self.abi.name}
         if hasattr(self.contract, "address"):
             # Only address if this is off an instance.
             properties["contract_address"] = self.contract.address
 
         return MockContractLog(**properties)
 
     def query(
@@ -555,15 +578,15 @@
             stop_block = self.chain_manager.blocks.height + stop_block
 
         elif stop_block > self.chain_manager.blocks.height:
             raise ChainError(
                 f"'stop={stop_block}' cannot be greater than "
                 f"the chain length ({self.chain_manager.blocks.height})."
             )
-        query: Dict = {
+        query: dict = {
             "columns": list(ContractLog.model_fields) if columns[0] == "*" else columns,
             "event": self.abi,
             "start_block": start_block,
             "stop_block": stop_block,
             "step": step,
         }
         if hasattr(self.contract, "address"):
@@ -578,29 +601,29 @@
         data = map(partial(extract_fields, columns=columns_ls), contract_events)
         return pd.DataFrame(columns=columns_ls, data=data)
 
     def range(
         self,
         start_or_stop: int,
         stop: Optional[int] = None,
-        search_topics: Optional[Dict[str, Any]] = None,
-        extra_addresses: Optional[List] = None,
+        search_topics: Optional[dict[str, Any]] = None,
+        extra_addresses: Optional[list] = None,
     ) -> Iterator[ContractLog]:
         """
         Search through the logs for this event using the given filter parameters.
 
         Args:
             start_or_stop (int): When also given ``stop``, this is the earliest
               block number in the desired log set.
               Otherwise, it is the total amount of blocks to get starting from ``0``.
             stop (Optional[int]): The latest block number in the
               desired log set. Defaults to delegating to provider.
-            search_topics (Optional[Dict]): Search topics, such as indexed event inputs,
+            search_topics (Optional[dict]): Search topics, such as indexed event inputs,
               to query by. Defaults to getting all events.
-            extra_addresses (Optional[List[:class:`~ape.types.address.AddressType`]]):
+            extra_addresses (Optional[list[:class:`~ape.types.address.AddressType`]]):
               Additional contract addresses containing the same event type. Defaults to
               only looking at the contract instance where this event is defined.
 
         Returns:
             Iterator[:class:`~ape.contracts.base.ContractLog`]
         """
 
@@ -614,47 +637,45 @@
             contract = None
             try:
                 contract = self.chain_manager.contracts.instance_at(contract_address)
             except Exception:
                 pass
 
             if contract:
-                start_block = contract.receipt.block_number
-            else:
-                cache = self.chain_manager.contracts
-                receipt = cache.get_creation_receipt(contract_address)
-                start_block = receipt.block_number
+                if creation := contract.creation_metadata:
+                    start_block = creation.block
 
             stop_block = start_or_stop
+
         elif start_or_stop is not None and stop is not None:
             start_block = start_or_stop
             stop_block = stop - 1
 
         stop_block = min(stop_block, self.chain_manager.blocks.height)
 
         addresses = list(set([contract_address] + (extra_addresses or [])))
         contract_event_query = ContractEventQuery(
             columns=list(ContractLog.model_fields.keys()),
             contract=addresses,
             event=self.abi,
             search_topics=search_topics,
-            start_block=start_block,
+            start_block=start_block or 0,
             stop_block=stop_block,
         )
         yield from self.query_manager.query(contract_event_query)  # type: ignore
 
-    def from_receipt(self, receipt: ReceiptAPI) -> List[ContractLog]:
+    def from_receipt(self, receipt: ReceiptAPI) -> list[ContractLog]:
         """
         Get all the events from the given receipt.
 
         Args:
             receipt (:class:`~ape.api.transactions.ReceiptAPI`): The receipt containing the logs.
 
         Returns:
-            List[:class:`~ape.contracts.base.ContractLog`]
+            list[:class:`~ape.contracts.base.ContractLog`]
         """
         ecosystem = self.provider.network.ecosystem
 
         # NOTE: Safe to use a list because a receipt should never have too many logs.
         return list(ecosystem.decode_logs(receipt.logs, self.abi))
 
     def poll_logs(
@@ -708,70 +729,56 @@
                 new_block_timeout=new_block_timeout,
                 events=[self.abi],
             )
 
 
 class ContractTypeWrapper(ManagerAccessMixin):
     contract_type: ContractType
+    base_path: Optional[Path] = None
 
     @property
-    def selector_identifiers(self) -> Dict[str, str]:
+    def selector_identifiers(self) -> dict[str, str]:
         """
         Provides a mapping of function signatures (pre-hashed selectors) to
         selector identifiers.
         """
         return self.contract_type.selector_identifiers
 
     @property
-    def identifier_lookup(self) -> Dict[str, ABI_W_SELECTOR_T]:
+    def identifier_lookup(self) -> dict[str, ABI_W_SELECTOR_T]:
         """
         Provides a mapping of method, error, and event selector identifiers to
         ABI Types.
         """
         return self.contract_type.identifier_lookup
 
-    @cached_property
+    @property
     def source_path(self) -> Optional[Path]:
         """
         Returns the path to the local contract if determined that this container
         belongs to the active project by cross checking source_id.
-
-        WARN: The will return a path if the contract has the same
-        source ID as one in the current project. That does not necessarily mean
-        they are the same contract, however.
-        """
-        contract_name = self.contract_type.name
-        source_id = self.contract_type.source_id
-        if not (contract_name and source_id):
-            return None
-
-        contract_container = self.project_manager._get_contract(contract_name)
-        if not (
-            contract_container
-            and contract_container.contract_type.source_id
-            and self.contract_type.source_id
-        ):
+        """
+        if not (source_id := self.contract_type.source_id):
             return None
 
-        if source_id == contract_container.contract_type.source_id:
-            return self.project_manager.contracts_folder / source_id
-        else:
-            return None
+        base = self.base_path or self.local_project.path
+        path = base / source_id
+        return path if path.is_file() else None
 
-    def decode_input(self, calldata: bytes) -> Tuple[str, Dict[str, Any]]:
+    def decode_input(self, calldata: bytes) -> tuple[str, dict[str, Any]]:
         """
         Decode the given calldata using this contract.
         If the calldata has a method ID prefix, Ape will detect it and find
         the corresponding method, else it will error.
 
         Args:
             calldata (bytes): The calldata to decode.
 
         Returns:
-            Tuple[str, Dict[str, Any]]: A tuple containing the method selector
+            tuple[str, dict[str, Any]]: A tuple containing the method selector
             along a mapping of input names to their decoded values.
             If an input does not have a number, it will have the stringified
             index as its key.
         """
 
         ecosystem = self.provider.network.ecosystem
         if calldata in self.contract_type.mutable_methods:
@@ -789,15 +796,15 @@
 
         method_id = ecosystem.get_method_selector(method)
         cutoff = len(method_id)
         rest_calldata = calldata[cutoff:]
         input_dict = ecosystem.decode_calldata(method, rest_calldata)
         return method.selector, input_dict
 
-    def _create_custom_error_type(self, abi: ErrorABI) -> Type[CustomError]:
+    def _create_custom_error_type(self, abi: ErrorABI) -> type[CustomError]:
         def exec_body(namespace):
             namespace["abi"] = abi
             namespace["contract"] = self
 
         return types.new_class(abi.name, (CustomError,), {}, exec_body)
 
 
@@ -815,21 +822,22 @@
         contract = a.deploy(project.MyContract)  # The result of 'deploy()' is a ContractInstance
     """
 
     def __init__(
         self,
         address: AddressType,
         contract_type: ContractType,
-        txn_hash: Optional[str] = None,
+        txn_hash: Optional[Union[str, HexBytes]] = None,
     ) -> None:
         super().__init__()
         self._address = address
         self.contract_type = contract_type
-        self.txn_hash = txn_hash
-        self._cached_receipt: Optional[ReceiptAPI] = None
+        self.txn_hash = (
+            (txn_hash if isinstance(txn_hash, str) else to_hex(txn_hash)) if txn_hash else None
+        )
 
     def __call__(self, *args, **kwargs) -> ReceiptAPI:
         has_value = kwargs.get("value")
         has_data = kwargs.get("data") or kwargs.get("input")
         has_non_payable_fallback = (
             self.contract_type.fallback and not self.contract_type.fallback.is_payable
         )
@@ -848,54 +856,44 @@
                 "Sending both value= and data= but fallback is non-payable."
             )
 
         return super().__call__(*args, **kwargs)
 
     @classmethod
     def from_receipt(cls, receipt: ReceiptAPI, contract_type: ContractType) -> "ContractInstance":
+        """
+        Create a contract instance from the contract deployment receipt.
+        """
         address = receipt.contract_address
         if not address:
             raise ChainError(
                 "Receipt missing 'contract_address' field. "
                 "Was this from a deploy transaction (e.g. `project.MyContract.deploy()`)?"
             )
 
         instance = cls(
             address=address,
             contract_type=contract_type,
             txn_hash=receipt.txn_hash,
         )
-        instance._cached_receipt = receipt
+
+        # Cache creation.
+        creation = ContractCreation.from_receipt(receipt)
+        cls.chain_manager.contracts._local_contract_creation[address] = creation
+
         return instance
 
     @property
-    def receipt(self) -> ReceiptAPI:
+    def creation_metadata(self) -> Optional[ContractCreation]:
         """
-        The receipt associated with deploying the contract instance,
-        if it is known and exists.
+        Contract creation details: txn_hash, block, deployer, factory, receipt.
         """
+        return self.chain_manager.contracts.get_creation_metadata(self.address)
 
-        if self._cached_receipt:
-            return self._cached_receipt
-
-        if self.txn_hash:
-            # Hash is known. Use that to get the receipt.
-            try:
-                receipt = self.chain_manager.get_receipt(self.txn_hash)
-            except (TransactionNotFoundError, ValueError, ChainError):
-                pass
-            else:
-                self._cached_receipt = receipt
-                return receipt
-
-        # Brute force find the receipt.
-        receipt = self.chain_manager.contracts.get_creation_receipt(self.address)
-        self._cached_receipt = receipt
-        return receipt
-
+    @log_instead_of_fail(default="<ContractInstance>")
     def __repr__(self) -> str:
         contract_name = self.contract_type.name or "Unnamed contract"
         return f"<{contract_name} {self.address}>"
 
     @property
     def address(self) -> AddressType:
         """
@@ -904,16 +902,16 @@
         Returns:
             :class:`~ape.types.address.AddressType`
         """
 
         return self._address
 
     @cached_property
-    def _view_methods_(self) -> Dict[str, ContractCallHandler]:
-        view_methods: Dict[str, List[MethodABI]] = dict()
+    def _view_methods_(self) -> dict[str, ContractCallHandler]:
+        view_methods: dict[str, list[MethodABI]] = dict()
 
         for abi in self.contract_type.view_methods:
             if abi.name in view_methods:
                 view_methods[abi.name].append(abi)
             else:
                 view_methods[abi.name] = [abi]
 
@@ -923,16 +921,16 @@
                 for abi_name, abis in view_methods.items()
             }
         except Exception as err:
             # NOTE: Must raise AttributeError for __attr__ method or will seg fault
             raise ApeAttributeError(str(err)) from err
 
     @cached_property
-    def _mutable_methods_(self) -> Dict[str, ContractTransactionHandler]:
-        mutable_methods: Dict[str, List[MethodABI]] = dict()
+    def _mutable_methods_(self) -> dict[str, ContractTransactionHandler]:
+        mutable_methods: dict[str, list[MethodABI]] = dict()
 
         for abi in self.contract_type.mutable_methods:
             if abi.name in mutable_methods:
                 mutable_methods[abi.name].append(abi)
             else:
                 mutable_methods[abi.name] = [abi]
 
@@ -1038,15 +1036,15 @@
 
         for evt in options:
             if evt.abi.signature == signature:
                 return evt
 
         raise err
 
-    def get_error_by_signature(self, signature: str) -> Type[CustomError]:
+    def get_error_by_signature(self, signature: str) -> type[CustomError]:
         """
         Get an error by its signature, similar to
         :meth:`~ape.contracts.ContractInstance.get_event_by_signature`.
 
         Args:
             signature (str): The signature of the error.
 
@@ -1063,16 +1061,16 @@
         for contract_err in options:
             if contract_err.abi.signature == signature:
                 return contract_err
 
         raise err
 
     @cached_property
-    def _events_(self) -> Dict[str, List[ContractEvent]]:
-        events: Dict[str, List[EventABI]] = {}
+    def _events_(self) -> dict[str, list[ContractEvent]]:
+        events: dict[str, list[EventABI]] = {}
 
         for abi in self.contract_type.events:
             if abi.name in events:
                 events[abi.name].append(abi)
             else:
                 events[abi.name] = [abi]
 
@@ -1082,16 +1080,16 @@
                 for abi_name, abi_list in events.items()
             }
         except Exception as err:
             # NOTE: Must raise AttributeError for __attr__ method or will seg fault
             raise ApeAttributeError(str(err)) from err
 
     @cached_property
-    def _errors_(self) -> Dict[str, List[Type[CustomError]]]:
-        abis: Dict[str, List[ErrorABI]] = {}
+    def _errors_(self) -> dict[str, list[type[CustomError]]]:
+        abis: dict[str, list[ErrorABI]] = {}
 
         try:
             for abi in self.contract_type.errors:
                 if abi.name in abis:
                     abis[abi.name].append(abi)
                 else:
                     abis[abi.name] = [abi]
@@ -1121,39 +1119,40 @@
 
             return errors
 
         except Exception as err:
             # NOTE: Must raise AttributeError for __attr__ method or will seg fault
             raise ApeAttributeError(str(err)) from err
 
-    def __dir__(self) -> List[str]:
+    def __dir__(self) -> list[str]:
         """
         Display methods to IPython on ``c.[TAB]`` tab completion.
 
         Returns:
-            List[str]
+            list[str]
         """
 
         # NOTE: Type ignores because of this issue: https://github.com/python/typing/issues/1112
         #  They can be removed after next `mypy` release containing fix.
         values = [
             "contract_type",
             "txn_hash",
             self.decode_input.__name__,
             self.get_event_by_signature.__name__,
             self.invoke_transaction.__name__,
             self.call_view_method.__name__,
-            ContractInstance.receipt.fget.__name__,  # type: ignore[attr-defined]
+            ContractInstance.creation_metadata.fget.__name__,  # type: ignore[attr-defined]
         ]
         return list(
             set(self._base_dir_values).union(
                 self._view_methods_, self._mutable_methods_, self._events_, values
             )
         )
 
+    @only_raise_attribute_error
     def __getattr__(self, attr_name: str) -> Any:
         """
         Access a method, property, event, or error on the contract using ``.`` access.
 
         Usage example::
 
             result = contract.vote()  # Implies a method named "vote" exists on the contract.
@@ -1219,15 +1218,15 @@
 
         else:
             raise ApeAttributeError(
                 f"No attribute '{attr_name}' found in contract '{self.address}'."
             )
 
 
-class ContractContainer(ContractTypeWrapper):
+class ContractContainer(ContractTypeWrapper, ExtraAttributesMixin):
     """
     A wrapper around the contract type that has access to the provider.
     When you import your contracts from the :class:`ape.managers.project.ProjectManager`, you
     are using this class.
 
     Usage example::
 
@@ -1235,80 +1234,94 @@
 
         contract_container = project.MyContract  # Assuming there is a contract named "MyContract"
     """
 
     def __init__(self, contract_type: ContractType) -> None:
         self.contract_type = contract_type
 
+    @log_instead_of_fail(default="<ContractContainer>")
     def __repr__(self) -> str:
         return f"<{self.contract_type.name}>"
 
-    def __getattr__(self, name: str) -> Any:
+    @only_raise_attribute_error
+    def __getattr__(self, attr_name: str) -> Any:
         """
         Access a contract error or event type via its ABI name using ``.`` access.
 
         Args:
-            name (str): The name of the event or error.
+            attr_name (str): The name of the event or error.
 
         Returns:
             :class:`~ape.types.ContractEvent` or a subclass of :class:`~ape.exceptions.CustomError`
             or any real attribute of the class.
         """
-        _assert_not_ipython_check(name)
-        try:
-            # First, check if requesting a regular attribute on this class.
-            return self.__getattribute__(name)
-        except AttributeError:
-            pass
-
-        try:
-            if name in self.contract_type.events:
-                abi = self.contract_type.events[name]
-                return ContractEvent(contract=self, abi=abi)
-
-            elif name in self.contract_type.errors:
-                abi = self.contract_type.errors[name]
-                return self._create_custom_error_type(abi)
+        return get_attribute_with_extras(self, attr_name)
 
-        except Exception as err:
-            # __getattr__ must raise AttributeError
-            raise ApeAttributeError(str(err)) from err
-
-        raise ApeAttributeError(f"No ABI with name '{name}'.")
+    def __eq__(self, other):
+        if not hasattr(other, "contract_type"):
+            return NotImplemented
+
+        return other.contract_type == self.contract_type
+
+    def __ape_extra_attributes__(self) -> Iterator[ExtraModelAttributes]:
+        yield ExtraModelAttributes(
+            name="events",
+            attributes=lambda x: (
+                ContractEvent(contract=self, abi=self.contract_type.events[x])
+                if x in self.contract_type.events
+                else None
+            ),
+            include_getitem=True,
+        )
+        yield ExtraModelAttributes(
+            name="errors",
+            attributes=lambda x: (
+                self._create_custom_error_type(self.contract_type.errors[x])
+                if x in self.contract_type.errors
+                else None
+            ),
+            include_getitem=True,
+        )
+        yield ExtraModelAttributes(
+            name="contract_type",
+            attributes=self.contract_type,
+        )
 
     @property
     def deployments(self):
         """
         Contract deployments.
 
         Usage example::
 
             # Get the latest deployment
             my_contract = project.MyContract.deployments[-1]
         """
 
         return self.chain_manager.contracts.get_deployments(self)
 
-    def at(self, address: AddressType, txn_hash: Optional[str] = None) -> ContractInstance:
+    def at(
+        self, address: AddressType, txn_hash: Optional[Union[str, HexBytes]] = None
+    ) -> ContractInstance:
         """
         Get a contract at the given address.
 
         Usage example::
 
             from ape import project
 
             my_contract = project.MyContract.at("0xAbC1230001112223334445566611855443322111")
 
         Args:
             address (str): The address to initialize a contract.
               **NOTE**: Things will not work as expected if the contract is not actually
               deployed to this address or if the contract at the given address has
               a different ABI than :attr:`~ape.contracts.ContractContainer.contract_type`.
-            txn_hash (str): The hash of the transaction that deployed the contract, if
-              available. Defaults to ``None``.
+            txn_hash (Union[str, HexBytes]): The hash of the transaction that deployed the
+              contract, if available. Defaults to ``None``.
 
         Returns:
             :class:`~ape.contracts.ContractInstance`
         """
 
         return self.chain_manager.contracts.instance_at(
             address, self.contract_type, txn_hash=txn_hash
@@ -1377,17 +1390,18 @@
         styled_address = click.style(receipt.contract_address, bold=True)
         contract_name = self.contract_type.name or "<Unnamed Contract>"
         logger.success(f"Contract '{contract_name}' deployed to: {styled_address}")
         instance = ContractInstance.from_receipt(receipt, self.contract_type)
         self.chain_manager.contracts.cache_deployment(instance)
 
         if publish:
-            self.project_manager.track_deployment(instance)
+            self.local_project.deployments.track(instance)
             self.provider.network.publish_contract(address)
 
+        instance.base_path = self.base_path or self.local_project.contracts_folder
         return instance
 
     def _cache_wrap(self, function: Callable) -> ReceiptAPI:
         """
         A helper method to ensure a contract type is cached as early on
         as possible to help enrich errors from ``deploy()`` transactions
         as well produce nicer tracebacks for these errors. It also helps
@@ -1443,21 +1457,23 @@
     You can interact with them like this::
 
         account_interface = project.accounts.interface
         mock_interface = project.mocks.interface
 
     """
 
-    def __init__(self, name: str, contracts: List[ContractContainer]):
+    def __init__(self, name: str, contracts: list[ContractContainer]):
         self.name = name
         self.contracts = contracts
 
+    @log_instead_of_fail(default="<ContractNamespace>")
     def __repr__(self) -> str:
         return f"<{self.name}>"
 
+    @only_raise_attribute_error
     def __getattr__(self, item: str) -> Union[ContractContainer, "ContractNamespace"]:
         """
         Access the next contract container or namespace.
 
         Args:
             item (str): The name of the next node.
```

### Comparing `eth-ape-0.7.9/src/ape/exceptions.py` & `eth-ape-0.8.0/src/ape/exceptions.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,31 +1,34 @@
 import difflib
 import sys
 import tempfile
 import time
 import traceback
+from collections.abc import Collection, Iterable
+from functools import cached_property
 from inspect import getframeinfo, stack
 from pathlib import Path
 from types import CodeType, TracebackType
-from typing import TYPE_CHECKING, Any, Collection, Dict, Iterator, List, Optional, Union, cast
+from typing import TYPE_CHECKING, Any, Optional, Union, cast
 
 import click
 from eth_typing import Hash32
 from eth_utils import humanize_hash
 from ethpm_types import ContractType
 from ethpm_types.abi import ConstructorABI, ErrorABI, MethodABI
 from rich import print as rich_print
 
 from ape.logging import LogLevel, logger
 
 if TYPE_CHECKING:
     from ape.api.networks import NetworkAPI
     from ape.api.providers import SubprocessProvider
+    from ape.api.trace import TraceAPI
     from ape.api.transactions import ReceiptAPI, TransactionAPI
-    from ape.types import AddressType, BlockID, SnapshotID, SourceTraceback, TraceFrame
+    from ape.types import AddressType, BlockID, SnapshotID, SourceTraceback
 
 
 FailedTxn = Union["TransactionAPI", "ReceiptAPI"]
 
 
 class ApeException(Exception):
     """
@@ -98,26 +101,26 @@
     """
     Raised when calling a contract method with the wrong number of arguments.
     """
 
     def __init__(
         self,
         arguments_length: int,
-        inputs: Union[MethodABI, ConstructorABI, int, List, None] = None,
+        inputs: Union[MethodABI, ConstructorABI, int, list, None] = None,
         **kwargs,
     ):
         prefix = (
             f"The number of the given arguments ({arguments_length}) "
             f"do not match what is defined in the ABI"
         )
         if inputs is None:
             super().__init__(f"{prefix}.")
             return
 
-        inputs_ls: List[Union[MethodABI, ConstructorABI, int]] = (
+        inputs_ls: list[Union[MethodABI, ConstructorABI, int]] = (
             inputs if isinstance(inputs, list) else [inputs]
         )
         if not inputs_ls:
             suffix = ""
         elif any(not isinstance(x, int) for x in inputs_ls):
             # Handle ABI arguments
             parts = ""
@@ -168,15 +171,15 @@
 
     def __init__(
         self,
         message: Optional[str] = None,
         base_err: Optional[Exception] = None,
         code: Optional[int] = None,
         txn: Optional[FailedTxn] = None,
-        trace: Optional[Iterator["TraceFrame"]] = None,
+        trace: Optional["TraceAPI"] = None,
         contract_address: Optional["AddressType"] = None,
         source_traceback: Optional["SourceTraceback"] = None,
     ):
         message = message or (str(base_err) if base_err else self.DEFAULT_MESSAGE)
         self.message = message
         self.base_err = base_err
         self.code = code
@@ -188,23 +191,48 @@
 
         # Finalizes expected revert message.
         super().__init__(ex_message)
         self._set_tb()
 
     @property
     def address(self) -> Optional["AddressType"]:
+        if addr := self.contract_address:
+            return addr
+
+        receiver = getattr(self.txn, "receiver", None)
+        if receiver in (None, "0x0000000000000000000000000000000000000000"):
+            # Check if deploy
+            if addr := getattr(self.txn, "contract_address", None):
+                return addr
+
+        return receiver
+
         return (
             self.contract_address
             or getattr(self.txn, "receiver", None)
             or getattr(self.txn, "contract_address", None)
         )
 
+    @cached_property
+    def contract_type(self) -> Optional[ContractType]:
+        if not (address := self.address):
+            # Contract address not found.
+            return None
+
+        # Lazy import because of exceptions.py root nature.
+        from ape.utils.basemodel import ManagerAccessMixin
+
+        try:
+            return ManagerAccessMixin.chain_manager.contracts.get(address)
+        except (RecursionError, ProviderNotConnectedError):
+            return None
+
     def _set_tb(self):
         if not self.source_traceback and self.txn:
-            self.source_traceback = _get_ape_traceback(self.txn)
+            self.source_traceback = _get_ape_traceback_from_tx(self.txn)
 
         if (src_tb := self.source_traceback) and self.txn is not None:
             # Create a custom Pythonic traceback using lines from the sources
             # found from analyzing the trace of the transaction.
             if py_tb := _get_custom_python_traceback(self, self.txn, src_tb):
                 self.__traceback__ = py_tb
 
@@ -221,15 +249,15 @@
     such as from an assert/require statement.
     """
 
     def __init__(
         self,
         revert_message: Optional[str] = None,
         txn: Optional[FailedTxn] = None,
-        trace: Optional[Iterator["TraceFrame"]] = None,
+        trace: Optional["TraceAPI"] = None,
         contract_address: Optional["AddressType"] = None,
         source_traceback: Optional["SourceTraceback"] = None,
         base_err: Optional[Exception] = None,
     ):
         self.txn = txn
         self.trace = trace
         self.contract_address = contract_address
@@ -327,28 +355,40 @@
     def __init__(
         self,
         network: str,
         ecosystem: Optional[str] = None,
         options: Optional[Collection[str]] = None,
     ):
         self.network = network
-        message = (
-            f"No network in '{ecosystem}' named '{network}'."
-            if ecosystem
-            else f"No network named '{network}'."
-        )
+        options = options or []
+        if network in options:
+            # Only seen in testing scenarios. Not realistic.
+            raise ValueError(
+                f"{network} found in options. Should not have gotten `NetworkNotFoundError`."
+            )
+
         if options:
+            message = (
+                f"No network in '{ecosystem}' named '{network}'."
+                if ecosystem
+                else f"No network named '{network}'."
+            )
             close_matches = difflib.get_close_matches(network, options, cutoff=0.6)
             if close_matches:
                 message = f"{message} Did you mean '{', '.join(close_matches)}'?"
             else:
                 # No close matches - show all options.
                 options_str = "\n".join(sorted(options))
                 message = f"{message} Options:\n{options_str}"
 
+        elif ecosystem:
+            message = f"'{ecosystem}' has no networks."
+        else:
+            message = "No networks found."
+
         super().__init__(message)
 
 
 class ProviderNotFoundError(NetworkError):
     """
     Raised when the provider with the given name was not found.
     """
@@ -444,17 +484,21 @@
 
 
 class TransactionNotFoundError(ProviderError):
     """
     Raised when unable to find a transaction.
     """
 
-    def __init__(self, txn_hash: str, error_messsage: Optional[str] = None):
-        message = f"Transaction '{txn_hash}' not found."
-        suffix = f" Error: {error_messsage}" if error_messsage else ""
+    def __init__(self, transaction_hash: Optional[str] = None, error_message: Optional[str] = None):
+        message = (
+            f"Transaction '{transaction_hash}' not found."
+            if transaction_hash
+            else "Transaction not found"
+        )
+        suffix = f" Error: {error_message}" if error_message else ""
         super().__init__(f"{message}{suffix}")
 
 
 class NetworkMismatchError(ProviderError):
     """
     Raised when connecting a provider to the wrong network.
     """
@@ -633,34 +677,56 @@
             kwargs["seconds"] = seconds
         if exception:
             kwargs["exception"] = exception
 
         super().__init__(provider, *args, **kwargs)
 
 
-def handle_ape_exception(err: ApeException, base_paths: List[Path]) -> bool:
+class PluginInstallError(ApeException):
+    """
+    An error to use when installing a plugin fails.
+    """
+
+
+class PluginVersionError(PluginInstallError):
+    """
+    An error related to specified plugin version.
+    """
+
+    def __init__(
+        self, operation: str, reason: Optional[str] = None, resolution: Optional[str] = None
+    ):
+        message = f"Unable to {operation} plugin."
+        if reason:
+            message = f"{message}\nReason: {reason}"
+        if resolution:
+            message = f"{message}\nTo resolve: {resolution}"
+
+        super().__init__(message)
+
+
+def handle_ape_exception(err: ApeException, base_paths: Iterable[Path]) -> bool:
     """
     Handle a transaction error by showing relevant stack frames,
     including custom contract frames added to the exception.
     This method must be called within an ``except`` block or with
     an exception on the exc-stack.
 
     Args:
         err (:class:`~ape.exceptions.TransactionError`): The transaction error
           being handled.
-        base_paths (Optional[List[Path]]): Optionally include additional
+        base_paths (Optional[Iterable[Path]]): Optionally include additional
           source-path prefixes to use when finding relevant frames.
 
     Returns:
         bool: ``True`` if outputted something.
     """
 
     tb = traceback.extract_tb(sys.exc_info()[2])
-    relevant_tb = [f for f in tb if any(str(p) in f.filename for p in base_paths)]
-    if not relevant_tb:
+    if not (relevant_tb := [f for f in tb if any(str(p) in f.filename for p in base_paths)]):
         return False
 
     click.echo()
     formatted_tb = traceback.format_list(relevant_tb)
     rich_print("".join(formatted_tb))
 
     # Prevent double logging traceback.
@@ -710,17 +776,17 @@
     """
     An error defined in a smart contract.
     """
 
     def __init__(
         self,
         abi: ErrorABI,
-        inputs: Dict[str, Any],
+        inputs: dict[str, Any],
         txn: Optional[FailedTxn] = None,
-        trace: Optional[Iterator["TraceFrame"]] = None,
+        trace: Optional["TraceAPI"] = None,
         contract_address: Optional["AddressType"] = None,
         base_err: Optional[Exception] = None,
         source_traceback: Optional["SourceTraceback"] = None,
     ):
         self.abi = abi
         self.inputs = inputs
 
@@ -742,16 +808,21 @@
     @property
     def name(self) -> str:
         """
         The name of the error.
         """
         return self.abi.name
 
+    def __repr__(self) -> str:
+        name = self.__class__.__name__  # Custom error name
+        calldata = ", ".join(sorted([f"{k}={v}" for k, v in self.inputs.items()])) or ""
+        return f"{name}({calldata})"
+
 
-def _get_ape_traceback(txn: FailedTxn) -> Optional["SourceTraceback"]:
+def _get_ape_traceback_from_tx(txn: FailedTxn) -> Optional["SourceTraceback"]:
     from ape.api.transactions import ReceiptAPI
 
     receipt: "ReceiptAPI" = txn if isinstance(txn, ReceiptAPI) else txn.receipt  # type: ignore
     if not receipt:
         return None
 
     try:
@@ -772,15 +843,15 @@
     # Help received from Jinja lib:
     #  https://github.com/pallets/jinja/blob/main/src/jinja2/debug.py#L142
 
     _, exc_value, tb = sys.exc_info()
     depth = None
     idx = len(ape_traceback) - 1
     frames = []
-    project_path = txn.project_manager.path.as_posix()
+    project_path = txn.local_project.path.as_posix()
     while tb is not None:
         if not tb.tb_frame.f_code.co_filename.startswith(project_path):
             # Ignore frames outside the project.
             # This allows both contract code an scripts to appear.
             tb = tb.tb_next
             continue
```

### Comparing `eth-ape-0.7.9/src/ape/logging.py` & `eth-ape-0.8.0/src/ape/logging.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 # Inspired / borrowed from the `click-logging` python package.
 import logging
 import sys
 import traceback
+from collections.abc import Callable, Sequence
 from enum import IntEnum
 from pathlib import Path
-from typing import IO, Any, Callable, Dict, Optional, Sequence, Union
+from typing import IO, Any, Optional, Union
 
 import click
 from yarl import URL
 
 
 class LogLevel(IntEnum):
     ERROR = logging.ERROR
@@ -69,31 +70,31 @@
         fmt = fmt or DEFAULT_LOG_FORMAT
         super().__init__(fmt=fmt)
 
     def format(self, record):
         if _isatty(sys.stdout) and _isatty(sys.stderr):
             # Only color log messages when sys.stdout and sys.stderr are sent to the terminal.
             level = LogLevel(record.levelno)
-            default_dict: Dict[str, Any] = {}
-            styles: Dict[str, Any] = CLICK_STYLE_KWARGS.get(level, default_dict)
+            default_dict: dict[str, Any] = {}
+            styles: dict[str, Any] = CLICK_STYLE_KWARGS.get(level, default_dict)
             record.levelname = click.style(record.levelname, **styles)
 
         path = Path(record.pathname)
         record.plugin = ""
         for part in path.parts:
             if part.startswith("ape-"):
                 record.plugin = f" ({part})"
                 break
 
         return super().format(record)
 
 
 class ClickHandler(logging.Handler):
     def __init__(
-        self, echo_kwargs: Dict, handlers: Optional[Sequence[Callable[[str], str]]] = None
+        self, echo_kwargs: dict, handlers: Optional[Sequence[Callable[[str], str]]] = None
     ):
         super().__init__()
         self.echo_kwargs = echo_kwargs
         self.handlers = handlers or []
 
     def emit(self, record):
         try:
@@ -108,15 +109,15 @@
                 click.echo(msg)
         except Exception:
             self.handleError(record)
 
 
 class ApeLogger:
     _mentioned_verbosity_option = False
-    _extra_loggers: Dict[str, logging.Logger] = {}
+    _extra_loggers: dict[str, logging.Logger] = {}
 
     def __init__(
         self,
         _logger: logging.Logger,
         fmt: str,
     ):
         self.error = _logger.error
@@ -271,14 +272,16 @@
     elif isinstance(level, int) or level.isnumeric():
         return LogLevel(int(level)).name
 
     return level
 
 
 def sanitize_url(url: str) -> str:
+    """Removes sensitive information from given URL"""
+
     url_obj = URL(url).with_user(None).with_password(None)
 
     # If there is a path, hide it but show that you are hiding it.
     # Use string interpolation to prevent URL-character encoding.
     return f"{url_obj.with_path('')}/{HIDDEN_MESSAGE}" if url_obj.path else f"{url}"
```

### Comparing `eth-ape-0.7.9/src/ape/managers/accounts.py` & `eth-ape-0.8.0/src/ape/managers/accounts.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,25 +1,27 @@
 import contextlib
-from typing import ContextManager, Dict, Generator, Iterator, List, Optional, Type, Union
+from collections.abc import Generator, Iterator
+from contextlib import AbstractContextManager as ContextManager
+from typing import Optional, Union
 
 from eth_utils import is_hex
 
 from ape.api.accounts import (
     AccountAPI,
     AccountContainerAPI,
     ImpersonatedAccount,
     TestAccountAPI,
     TestAccountContainerAPI,
 )
 from ape.exceptions import ConversionError
 from ape.managers.base import BaseManager
 from ape.types import AddressType
-from ape.utils import ManagerAccessMixin, cached_property, singledispatchmethod
+from ape.utils import ManagerAccessMixin, cached_property, log_instead_of_fail, singledispatchmethod
 
-_DEFAULT_SENDERS: List[AccountAPI] = []
+_DEFAULT_SENDERS: list[AccountAPI] = []
 
 
 @contextlib.contextmanager
 def _use_sender(
     account: Union[AccountAPI, TestAccountAPI]
 ) -> Generator[AccountAPI, TestAccountAPI, None]:
     try:
@@ -28,29 +30,29 @@
     finally:
         _DEFAULT_SENDERS.pop()
 
 
 class TestAccountManager(list, ManagerAccessMixin):
     __test__ = False
 
-    _impersonated_accounts: Dict[AddressType, ImpersonatedAccount] = {}
+    _impersonated_accounts: dict[AddressType, ImpersonatedAccount] = {}
 
+    @log_instead_of_fail(default="<TestAccountManager>")
     def __repr__(self) -> str:
         accounts_str = ", ".join([a.address for a in self.accounts])
         return f"[{accounts_str}]"
 
     @cached_property
-    def containers(self) -> Dict[str, TestAccountContainerAPI]:
+    def containers(self) -> dict[str, TestAccountContainerAPI]:
         containers = {}
         account_types = [
             t for t in self.plugin_manager.account_types if issubclass(t[1][1], TestAccountAPI)
         ]
         for plugin_name, (container_type, account_type) in account_types:
-            # Pydantic validation won't allow passing None for data_folder/required attr
-            containers[plugin_name] = container_type(data_folder="", account_type=account_type)
+            containers[plugin_name] = container_type(name=plugin_name, account_type=account_type)
 
         return containers
 
     @property
     def accounts(self) -> Iterator[AccountAPI]:
         for container in self.containers.values():
             yield from container.accounts
@@ -94,33 +96,33 @@
     @__getitem__.register
     def __getitem_str(self, account_str: str):
         message_fmt = "No account with {} '{}'."
         try:
             account_id = self.conversion_manager.convert(account_str, AddressType)
         except ConversionError as err:
             message = message_fmt.format("ID", account_str)
-            raise IndexError(message) from err
+            raise KeyError(message) from err
 
         for account in self.accounts:
             if account.address == account_id:
                 return account
 
         can_impersonate = False
         err_message = message_fmt.format("address", account_id)
         try:
             if self.network_manager.active_provider:
                 can_impersonate = self.provider.unlock_account(account_id)
             # else: fall through to `IndexError`
         except NotImplementedError as err:
-            raise IndexError(
+            raise KeyError(
                 f"Your provider does not support impersonating accounts:\n{err_message}"
             ) from err
 
         if not can_impersonate:
-            raise IndexError(err_message)
+            raise KeyError(err_message)
 
         if account_id not in self._impersonated_accounts:
             acct = ImpersonatedAccount(raw_address=account_id)
             self._impersonated_accounts[account_id] = acct
 
         return self._impersonated_accounts[account_id]
 
@@ -152,15 +154,15 @@
     """
 
     @property
     def default_sender(self) -> Optional[AccountAPI]:
         return _DEFAULT_SENDERS[-1] if _DEFAULT_SENDERS else None
 
     @cached_property
-    def containers(self) -> Dict[str, AccountContainerAPI]:
+    def containers(self) -> dict[str, AccountContainerAPI]:
         """
         A dict of all :class:`~ape.api.accounts.AccountContainerAPI` instances
         across all installed plugins.
 
         Returns:
             dict[str, :class:`~ape.api.accounts.AccountContainerAPI`]
         """
@@ -169,19 +171,15 @@
         data_folder = self.config_manager.DATA_FOLDER
         data_folder.mkdir(exist_ok=True)
         for plugin_name, (container_type, account_type) in self.plugin_manager.account_types:
             # Ignore containers that contain test accounts.
             if issubclass(account_type, TestAccountAPI):
                 continue
 
-            accounts_folder = data_folder / plugin_name
-            accounts_folder.mkdir(exist_ok=True)
-            containers[plugin_name] = container_type(
-                data_folder=accounts_folder, account_type=account_type
-            )
+            containers[plugin_name] = container_type(name=plugin_name, account_type=account_type)
 
         return containers
 
     @property
     def aliases(self) -> Iterator[str]:
         """
         All account aliases from every account-related plugin. The "alias"
@@ -192,24 +190,24 @@
         Returns:
             Iterator[str]
         """
 
         for container in self.containers.values():
             yield from container.aliases
 
-    def get_accounts_by_type(self, type_: Type[AccountAPI]) -> List[AccountAPI]:
+    def get_accounts_by_type(self, type_: type[AccountAPI]) -> list[AccountAPI]:
         """
         Get a list of accounts by their type.
 
         Args:
-            type_ (Type[:class:`~ape.api.accounts.AccountAPI`]): The type of account
+            type_ (type[:class:`~ape.api.accounts.AccountAPI`]): The type of account
               to get.
 
         Returns:
-            List[:class:`~ape.api.accounts.AccountAPI`]
+            list[:class:`~ape.api.accounts.AccountAPI`]
         """
 
         return [acc for acc in self if isinstance(acc, type_)]
 
     def __len__(self) -> int:
         """
         The number of accounts managed by all account plugins.
@@ -220,14 +218,15 @@
 
         return sum(len(container) for container in self.containers.values())
 
     def __iter__(self) -> Iterator[AccountAPI]:
         for container in self.containers.values():
             yield from container.accounts
 
+    @log_instead_of_fail(default="<AccountManager>")
     def __repr__(self) -> str:
         return "[" + ", ".join(repr(a) for a in self) + "]"
 
     @cached_property
     def test_accounts(self) -> TestAccountManager:
         """
         Accounts generated from the configured test mnemonic. These accounts
@@ -249,28 +248,28 @@
         return TestAccountManager()
 
     def load(self, alias: str) -> AccountAPI:
         """
         Get an account by its alias.
 
         Raises:
-            IndexError: When there is no local account with the given alias.
+            KeyError: When there is no local account with the given alias.
 
         Returns:
             :class:`~ape.api.accounts.AccountAPI`
         """
 
         if alias == "":
             raise ValueError("Cannot use empty string as alias!")
 
         for account in self:
             if account.alias and account.alias == alias:
                 return account
 
-        raise IndexError(f"No account with alias '{alias}'.")
+        raise KeyError(f"No account with alias '{alias}'.")
 
     @singledispatchmethod
     def __getitem__(self, account_id) -> AccountAPI:
         raise NotImplementedError(f"Cannot use {type(account_id)} as account ID.")
 
     @__getitem__.register
     def __getitem_int(self, account_id: int) -> AccountAPI:
@@ -305,15 +304,15 @@
         accounts from a slice.
 
         **NOTE**: It is generally preferred to use
         :meth:`~ape.managers.accounts.AccountManager.load` or
         :meth:`~ape.managers.accounts.AccountManager.__getitem_str`.
 
         Returns:
-            List[:class:`~ape.api.accounts.AccountAPI`]
+            list[:class:`~ape.api.accounts.AccountAPI`]
         """
 
         start_idx = account_id.start or 0
         if start_idx < 0:
             start_idx += len(self)
         stop_idx = account_id.stop or len(self)
         if stop_idx < 0:
@@ -324,30 +323,30 @@
     @__getitem__.register
     def __getitem_str(self, account_str: str) -> AccountAPI:
         """
         Get an account by address. If we are using a provider that supports unlocking
         accounts, this method will return an impersonated account at that address.
 
         Raises:
-            IndexError: When there is no local account with the given address.
+            KeyError: When there is no local account with the given address.
 
         Returns:
             :class:`~ape.api.accounts.AccountAPI`
         """
 
         try:
             account_id = self.conversion_manager.convert(account_str, AddressType)
         except ConversionError as err:
             prefix = f"No account with ID '{account_str}'"
             if account_str.endswith(".eth"):
                 suffix = "Do you have `ape-ens` installed?"
             else:
                 suffix = "Do you have the necessary conversion plugins installed?"
 
-            raise IndexError(f"{prefix}. {suffix}") from err
+            raise KeyError(f"{prefix}. {suffix}") from err
 
         for container in self.containers.values():
             if account_id in container.accounts:
                 return container[account_id]
 
         # NOTE: Fallback to `TestAccountContainer`'s method for loading items
         return self.test_accounts[account_id]
```

### Comparing `eth-ape-0.7.9/src/ape/managers/chain.py` & `eth-ape-0.8.0/src/ape/managers/chain.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,44 +1,58 @@
 import json
+from collections.abc import Collection, Iterator
 from concurrent.futures import ThreadPoolExecutor
 from contextlib import contextmanager
 from functools import partial
 from pathlib import Path
-from typing import IO, Collection, Dict, Iterator, List, Optional, Set, Type, Union, cast
+from statistics import mean, median
+from typing import IO, Optional, Union, cast
 
 import pandas as pd
+from eth_pydantic_types import HexBytes
 from ethpm_types import ABI, ContractType
 from rich import get_console
+from rich.box import SIMPLE
 from rich.console import Console as RichConsole
+from rich.table import Table
 
 from ape.api import BlockAPI, ReceiptAPI
 from ape.api.address import BaseAddress
 from ape.api.networks import NetworkAPI, ProxyInfoAPI
 from ape.api.query import (
     AccountTransactionQuery,
     BlockQuery,
+    ContractCreation,
     ContractCreationQuery,
     extract_fields,
     validate_and_expand_columns,
 )
 from ape.contracts import ContractContainer, ContractInstance
 from ape.exceptions import (
     APINotImplementedError,
     ChainError,
     ContractNotFoundError,
     ConversionError,
     CustomError,
     ProviderNotConnectedError,
     QueryEngineError,
+    TransactionNotFoundError,
     UnknownSnapshotError,
 )
 from ape.logging import logger
 from ape.managers.base import BaseManager
-from ape.types import AddressType, BlockID, CallTreeNode, SnapshotID, SourceTraceback
-from ape.utils import BaseInterfaceModel, TraceStyles, nonreentrant, singledispatchmethod
+from ape.types import AddressType, GasReport, SnapshotID, SourceTraceback
+from ape.utils import (
+    BaseInterfaceModel,
+    is_evm_precompile,
+    is_zero_hex,
+    log_instead_of_fail,
+    nonreentrant,
+    singledispatchmethod,
+)
 
 
 class BlockContainer(BaseManager):
     """
     A list of blocks on the chain.
 
     Usages example::
@@ -51,15 +65,15 @@
 
     @property
     def head(self) -> BlockAPI:
         """
         The latest block.
         """
 
-        return self._get_block("latest")
+        return self.provider.get_block("latest")
 
     @property
     def height(self) -> int:
         """
         The latest block number.
         """
         if self.head.number is None:
@@ -83,15 +97,15 @@
         Returns:
             :class:`~ape.api.providers.BlockAPI`
         """
 
         if block_number < 0:
             block_number = len(self) + block_number
 
-        return self._get_block(block_number)
+        return self.provider.get_block(block_number)
 
     def __len__(self) -> int:
         """
         The number of blocks in the chain.
 
         Returns:
             int
@@ -160,15 +174,15 @@
             columns=list(columns),
             start_block=start_block,
             stop_block=stop_block,
             step=step,
         )
 
         blocks = self.query_manager.query(query, engine_to_use=engine_to_use)
-        columns: List[str] = validate_and_expand_columns(  # type: ignore
+        columns: list[str] = validate_and_expand_columns(  # type: ignore
             columns, self.head.__class__
         )
         extraction = partial(extract_fields, columns=columns)
         data = map(lambda b: extraction(b), blocks)
         return pd.DataFrame(columns=columns, data=data)
 
     def range(
@@ -288,29 +302,26 @@
 
         yield from self.provider.poll_blocks(
             stop_block=stop_block,
             required_confirmations=required_confirmations,
             new_block_timeout=new_block_timeout,
         )
 
-    def _get_block(self, block_id: BlockID) -> BlockAPI:
-        return self.provider.get_block(block_id)
-
 
 class AccountHistory(BaseInterfaceModel):
     """
     A container mapping account addresses to the transaction from the active session.
     """
 
     address: AddressType
     """
     The address to get history for.
     """
 
-    sessional: List[ReceiptAPI] = []
+    sessional: list[ReceiptAPI] = []
     """
     The receipts from the current Python session.
     """
 
     @property
     def outgoing(self) -> Iterator[ReceiptAPI]:
         """
@@ -427,15 +438,15 @@
                     )
                 ),
             )
         except StopIteration as e:
             raise IndexError(f"index {index} out of range") from e
 
     @__getitem__.register
-    def __getitem_slice(self, indices: slice) -> List[ReceiptAPI]:
+    def __getitem_slice(self, indices: slice) -> list[ReceiptAPI]:
         start, stop, step = (
             indices.start or 0,
             indices.stop or len(self),
             indices.step or 1,
         )
 
         if start < 0:
@@ -449,15 +460,15 @@
                 f"'stop={stop}' cannot be greater than account's current nonce ({len(self)})."
             )
 
         if stop <= start:
             return []  # nothing to query
 
         return cast(
-            List[ReceiptAPI],
+            list[ReceiptAPI],
             list(
                 self.query_manager.query(
                     AccountTransactionQuery(
                         columns=list(ReceiptAPI.model_fields),
                         account=self.address,
                         start_nonce=start,
                         stop_nonce=stop - 1,
@@ -490,16 +501,16 @@
 
 
 class TransactionHistory(BaseManager):
     """
     A container mapping Transaction History to the transaction from the active session.
     """
 
-    _account_history_cache: Dict[AddressType, AccountHistory] = {}
-    _hash_to_receipt_map: Dict[str, ReceiptAPI] = {}
+    _account_history_cache: dict[AddressType, AccountHistory] = {}
+    _hash_to_receipt_map: dict[str, ReceiptAPI] = {}
 
     @singledispatchmethod
     def __getitem__(self, key):
         raise NotImplementedError(f"Cannot use type of {type(key)} as Index")
 
     @__getitem__.register
     def __getitem_base_address(self, address: BaseAddress) -> AccountHistory:
@@ -604,22 +615,23 @@
     1. An in-memory cache of locally deployed contracts
     2. A cache of contracts per network (only permanent networks are stored this way)
 
     When retrieving a contract, if a :class:`~ape.api.explorers.ExplorerAPI` is used,
     it will be cached to disk for faster look-up next time.
     """
 
-    _local_contract_types: Dict[AddressType, ContractType] = {}
-    _local_proxies: Dict[AddressType, ProxyInfoAPI] = {}
-    _local_blueprints: Dict[str, ContractType] = {}
-    _local_deployments_mapping: Dict[str, Dict] = {}
+    _local_contract_types: dict[AddressType, ContractType] = {}
+    _local_proxies: dict[AddressType, ProxyInfoAPI] = {}
+    _local_blueprints: dict[str, ContractType] = {}
+    _local_deployments_mapping: dict[str, dict] = {}
+    _local_contract_creation: dict[str, ContractCreation] = {}
 
     # chain_id -> address -> custom_err
     # Cached to prevent calling `new_class` multiple times with conflicts.
-    _custom_error_types: Dict[int, Dict[AddressType, Set[Type[CustomError]]]] = {}
+    _custom_error_types: dict[int, dict[AddressType, set[type[CustomError]]]] = {}
 
     @property
     def _network(self) -> NetworkAPI:
         return self.provider.network
 
     @property
     def _ecosystem_name(self) -> str:
@@ -653,23 +665,27 @@
         return self._network_cache / "proxy_info"
 
     @property
     def _blueprint_cache(self) -> Path:
         return self._network_cache / "blueprints"
 
     @property
-    def _full_deployments(self) -> Dict:
+    def _contract_creation_cache(self) -> Path:
+        return self._network_cache / "contract_creation"
+
+    @property
+    def _full_deployments(self) -> dict:
         deployments = self._local_deployments_mapping
         if self._is_live_network:
             deployments = {**deployments, **self._load_deployments_cache()}
 
         return deployments
 
     @property
-    def _deployments(self) -> Dict:
+    def _deployments(self) -> dict:
         if not self.network_manager.active_provider:
             return {}
 
         deployments = self._full_deployments
         return deployments.get(self._ecosystem_name, {}).get(self._data_network_name, {})
 
     @_deployments.setter
@@ -757,15 +773,15 @@
               to cache.
         """
 
         address = contract_instance.address
         contract_type = contract_instance.contract_type
 
         # Cache contract type in memory before proxy check,
-        # in case it is needed somewhere. It may get overriden.
+        # in case it is needed somewhere. It may get overridden.
         self._local_contract_types[address] = contract_type
 
         proxy_info = self.provider.network.ecosystem.get_proxy_info(address)
         if proxy_info:
             self.cache_proxy_info(address, proxy_info)
             contract_type = self.get(proxy_info.target) or contract_type
             if contract_type:
@@ -825,14 +841,49 @@
 
         Returns:
             Optional[:class:`~ape.api.networks.ProxyInfoAPI`]
         """
 
         return self._local_proxies.get(address) or self._get_proxy_info_from_disk(address)
 
+    def get_creation_metadata(self, address: AddressType) -> Optional[ContractCreation]:
+        """
+        Get contract creation metadata containing txn_hash, deployer, factory, block.
+
+        Args:
+            address (AddressType): The address of the contract.
+
+        Returns:
+            Optional[:class:`~ape.api.query.ContractCreation`]
+        """
+        if creation := self._local_contract_creation.get(address):
+            return creation
+
+        # read from disk
+        elif creation := self._get_contract_creation_from_disk(address):
+            self._local_contract_creation[address] = creation
+            return creation
+
+        # query and cache
+        query = ContractCreationQuery(columns=["*"], contract=address)
+        get_creation = self.query_manager.query(query)
+
+        try:
+            if not (creation := next(get_creation, None)):  # type: ignore[arg-type]
+                return None
+
+        except QueryEngineError:
+            return None
+
+        if self._is_live_network:
+            self._cache_contract_creation_to_disk(address, creation)
+
+        self._local_contract_creation[address] = creation
+        return creation
+
     def get_blueprint(self, blueprint_id: str) -> Optional[ContractType]:
         """
         Get a cached blueprint contract type.
 
         Args:
             blueprint_id (``str``): The unique identifier used when caching
               the blueprint.
@@ -843,15 +894,15 @@
 
         return self._local_blueprints.get(blueprint_id) or self._get_blueprint_from_disk(
             blueprint_id
         )
 
     def _get_errors(
         self, address: AddressType, chain_id: Optional[int] = None
-    ) -> Set[Type[CustomError]]:
+    ) -> set[type[CustomError]]:
         if chain_id is None and self.network_manager.active_provider is not None:
             chain_id = self.provider.chain_id
         elif chain_id is None:
             raise ValueError("Missing chain ID.")
 
         if chain_id not in self._custom_error_types:
             return set()
@@ -859,15 +910,15 @@
         errors = self._custom_error_types[chain_id]
         if address in errors:
             return errors[address]
 
         return set()
 
     def _cache_error(
-        self, address: AddressType, error: Type[CustomError], chain_id: Optional[int] = None
+        self, address: AddressType, error: type[CustomError], chain_id: Optional[int] = None
     ):
         if chain_id is None and self.network_manager.active_provider is not None:
             chain_id = self.provider.chain_id
         elif chain_id is None:
             raise ValueError("Missing chain ID.")
 
         if chain_id not in self._custom_error_types:
@@ -897,32 +948,32 @@
     def __getitem__(self, address: AddressType) -> ContractType:
         contract_type = self.get(address)
         if not contract_type:
             # Create error message from custom exception cls.
             err = ContractNotFoundError(
                 address, self.provider.network.explorer is not None, self.provider.network_choice
             )
-            # Must raise IndexError.
-            raise IndexError(str(err))
+            # Must raise KeyError.
+            raise KeyError(str(err))
 
         return contract_type
 
     def get_multiple(
         self, addresses: Collection[AddressType], concurrency: Optional[int] = None
-    ) -> Dict[AddressType, ContractType]:
+    ) -> dict[AddressType, ContractType]:
         """
         Get contract types for all given addresses.
 
         Args:
-            addresses (List[AddressType): A list of addresses to get contract types for.
+            addresses (list[AddressType): A list of addresses to get contract types for.
             concurrency (Optional[int]): The number of threads to use. Defaults to
               ``min(4, len(addresses))``.
 
         Returns:
-            Dict[AddressType, ContractType]: A mapping of addresses to their respective
+            dict[AddressType, ContractType]: A mapping of addresses to their respective
             contract types.
         """
         if not addresses:
             logger.warning("No addresses provided.")
             return {}
 
         def get_contract_type(addr: AddressType):
@@ -931,15 +982,15 @@
 
             if not ct:
                 logger.warning(f"Failed to locate contract at '{addr}'.")
                 return addr, None
             else:
                 return addr, ct
 
-        converted_addresses: List[AddressType] = []
+        converted_addresses: list[AddressType] = []
         for address in converted_addresses:
             if not self.conversion_manager.is_type(address, AddressType):
                 converted_address = self.conversion_manager.convert(address, AddressType)
                 converted_addresses.append(converted_address)
             else:
                 converted_addresses.append(address)
 
@@ -1064,16 +1115,16 @@
 
         return ContractContainer(contract_type)
 
     def instance_at(
         self,
         address: Union[str, AddressType],
         contract_type: Optional[ContractType] = None,
-        txn_hash: Optional[str] = None,
-        abi: Optional[Union[List[ABI], Dict, str, Path]] = None,
+        txn_hash: Optional[Union[str, HexBytes]] = None,
+        abi: Optional[Union[list[ABI], dict, str, Path]] = None,
     ) -> ContractInstance:
         """
         Get a contract at the given address. If the contract type of the contract is known,
         either from a local deploy or a :class:`~ape.api.explorers.ExplorerAPI`, it will use that
         contract type. You can also provide the contract type from which it will cache and use
         next time.
 
@@ -1083,17 +1134,17 @@
             :class:`~ape.exceptions.ContractNotFoundError`: When the contract type is not found.
 
         Args:
             address (Union[str, AddressType]): The address of the plugin. If you are using the ENS
               plugin, you can also provide an ENS domain name.
             contract_type (Optional[``ContractType``]): Optionally provide the contract type
               in case it is not already known.
-            txn_hash (Optional[str]): The hash of the transaction responsible for deploying the
-              contract, if known. Useful for publishing. Defaults to ``None``.
-            abi (Optional[Union[List[ABI], Dict, str, Path]]): Use an ABI str, dict, path,
+            txn_hash (Optional[Union[str, HexBytes]]): The hash of the transaction responsible for
+              deploying the contract, if known. Useful for publishing. Defaults to ``None``.
+            abi (Optional[Union[list[ABI], dict, str, Path]]): Use an ABI str, dict, path,
               or ethpm models to create a contract instance class.
 
         Returns:
             :class:`~ape.contracts.base.ContractInstance`
         """
 
         if self.conversion_manager.is_type(address, AddressType):
@@ -1116,20 +1167,20 @@
 
         if abi:
             # if the ABI is a str then convert it to a JSON dictionary.
             if isinstance(abi, Path) or (
                 isinstance(abi, str) and "{" not in abi and Path(abi).is_file()
             ):
                 # Handle both absolute and relative paths
-                abi = Path(abi)
-                if not abi.is_absolute():
-                    abi = self.project_manager.path / abi
+                abi_path = Path(abi)
+                if not abi_path.is_absolute():
+                    abi_path = self.local_project.path / abi
 
                 try:
-                    abi = json.loads(abi.read_text())
+                    abi = json.loads(abi_path.read_text())
                 except Exception as err:
                     if contract_type:
                         # If a default contract type was provided, don't error and use it.
                         logger.error(str(err))
                     else:
                         raise  # Current exception
 
@@ -1146,15 +1197,15 @@
 
             # If the ABI was a str, it should be a list now.
             if isinstance(abi, list):
                 contract_type = ContractType(abi=abi)
 
             else:
                 raise TypeError(
-                    f"Invalid ABI type '{type(abi)}', expecting str, List[ABI] or a JSON file."
+                    f"Invalid ABI type '{type(abi)}', expecting str, list[ABI] or a JSON file."
                 )
 
         if not contract_type:
             raise ContractNotFoundError(
                 contract_address,
                 self.provider.network.explorer is not None,
                 self.provider.network_choice,
@@ -1186,53 +1237,53 @@
 
         Returns:
             :class:`~ape.contracts.base.ContractInstance`
         """
         # NOTE: Mostly just needed this method to avoid a local import.
         return ContractInstance.from_receipt(receipt, contract_type)
 
-    def get_deployments(self, contract_container: ContractContainer) -> List[ContractInstance]:
+    def get_deployments(self, contract_container: ContractContainer) -> list[ContractInstance]:
         """
         Retrieves previous deployments of a contract container or contract type.
         Locally deployed contracts are saved for the duration of the script and read from
         ``_local_deployments_mapping``, while those deployed on a live network are written to
         disk in ``deployments_map.json``.
 
         Args:
             contract_container (:class:`~ape.contracts.ContractContainer`): The
               ``ContractContainer`` with deployments.
 
         Returns:
-            List[:class:`~ape.contracts.ContractInstance`]: Returns a list of contracts that
+            list[:class:`~ape.contracts.ContractInstance`]: Returns a list of contracts that
             have been deployed.
         """
 
         contract_type = contract_container.contract_type
         contract_name = contract_type.name
         if not contract_name:
             return []
 
         config_deployments = []
         if self.network_manager.active_provider:
             ecosystem_name = self.provider.network.ecosystem.name
             network_name = self.provider.network.name
             all_config_deployments = (
-                self.config_manager.deployments.root if self.config_manager.deployments else {}
+                self.config_manager.deployments if self.config_manager.deployments else {}
             )
             ecosystem_deployments = all_config_deployments.get(ecosystem_name, {})
             network_deployments = ecosystem_deployments.get(network_name, {})
             config_deployments = [
                 c for c in network_deployments if c["contract_type"] == contract_name
             ]
 
         deployments = [*config_deployments, *self._deployments.get(contract_name, [])]
         if not deployments:
             return []
 
-        instances: List[ContractInstance] = []
+        instances: list[ContractInstance] = []
         for deployment in deployments:
             address = deployment["address"]
             txn_hash = deployment.get("transaction_hash")
             instance = ContractInstance(address, contract_type, txn_hash=txn_hash)
             instances.append(instance)
 
         return instances
@@ -1241,14 +1292,15 @@
         """
         Reset local caches to a blank state.
         """
         self._local_contract_types = {}
         self._local_proxies = {}
         self._local_blueprints = {}
         self._local_deployments_mapping = {}
+        self._local_creation_metadata = {}
 
     def _get_contract_type_from_disk(self, address: AddressType) -> Optional[ContractType]:
         address_file = self._contract_types_cache / f"{address}.json"
         if not address_file.is_file():
             return None
 
         return ContractType.model_validate_json(address_file.read_text())
@@ -1279,14 +1331,21 @@
 
         if contract_type:
             # Cache contract so faster look-up next time.
             self._cache_contract_to_disk(address, contract_type)
 
         return contract_type
 
+    def _get_contract_creation_from_disk(self, address: AddressType) -> Optional[ContractCreation]:
+        path = self._contract_creation_cache / f"{address}.json"
+        if not path.is_file():
+            return None
+
+        return ContractCreation.model_validate_json(path.read_text())
+
     def _cache_contract_to_disk(self, address: AddressType, contract_type: ContractType):
         self._contract_types_cache.mkdir(exist_ok=True, parents=True)
         address_file = self._contract_types_cache / f"{address}.json"
         address_file.write_text(contract_type.model_dump_json())
 
     def _cache_proxy_info_to_disk(self, address: AddressType, proxy_info: ProxyInfoAPI):
         self._proxy_info_cache.mkdir(exist_ok=True, parents=True)
@@ -1294,95 +1353,80 @@
         address_file.write_text(proxy_info.model_dump_json())
 
     def _cache_blueprint_to_disk(self, blueprint_id: str, contract_type: ContractType):
         self._blueprint_cache.mkdir(exist_ok=True, parents=True)
         blueprint_file = self._blueprint_cache / f"{blueprint_id}.json"
         blueprint_file.write_text(contract_type.model_dump_json())
 
-    def _load_deployments_cache(self) -> Dict:
+    def _cache_contract_creation_to_disk(self, address: AddressType, creation: ContractCreation):
+        self._contract_creation_cache.mkdir(exist_ok=True, parents=True)
+        path = self._contract_creation_cache / f"{address}.json"
+        path.write_text(creation.model_dump_json())
+
+    def _load_deployments_cache(self) -> dict:
         return (
             json.loads(self._deployments_mapping_cache.read_text())
             if self._deployments_mapping_cache.is_file()
             else {}
         )
 
-    def _write_deployments_mapping(self, deployments_map: Dict):
+    def _write_deployments_mapping(self, deployments_map: dict):
         self._deployments_mapping_cache.parent.mkdir(exist_ok=True, parents=True)
         with self._deployments_mapping_cache.open("w") as fp:
             json.dump(deployments_map, fp, sort_keys=True, indent=2, default=sorted)
 
-    def get_creation_receipt(
-        self, address: AddressType, start_block: int = 0, stop_block: Optional[int] = None
-    ) -> ReceiptAPI:
-        """
-        Get the receipt responsible for the initial creation of the contract.
-
-        Args:
-            address (:class:`~ape.types.address.AddressType`): The address of the contract.
-            start_block (int): The block to start looking from.
-            stop_block (Optional[int]): The block to stop looking at.
-
-        Returns:
-            :class:`~ape.apt.transactions.ReceiptAPI`
-        """
-        if stop_block is None:
-            stop_block = self.chain_manager.blocks.height
-
-        query = ContractCreationQuery(
-            columns=["*"],
-            contract=address,
-            start_block=start_block,
-            stop_block=stop_block,
-        )
-        creation_receipts = cast(Iterator[ReceiptAPI], self.query_manager.query(query))
-
-        if tx := next(creation_receipts, None):
-            return tx
-
-        raise ChainError(
-            f"Failed to find a contract-creation receipt for '{address}'. "
-            "Note that it may be the case that the backend used cannot detect contracts "
-            "deployed by other contracts, and you may receive better results by installing "
-            "a plugin that supports it, like Etherscan."
-        )
-
 
 class ReportManager(BaseManager):
     """
     A class representing the active Ape session. Useful for tracking data and
     building reports.
 
     **NOTE**: This class is not part of the public API.
     """
 
-    rich_console_map: Dict[str, RichConsole] = {}
+    rich_console_map: dict[str, RichConsole] = {}
 
-    def show_trace(
-        self,
-        call_tree: CallTreeNode,
-        sender: Optional[AddressType] = None,
-        transaction_hash: Optional[str] = None,
-        revert_message: Optional[str] = None,
-        file: Optional[IO[str]] = None,
-        verbose: bool = False,
-    ):
-        root = call_tree.as_rich_tree(verbose=verbose)
-        console = self._get_console(file)
+    def show_gas(self, report: GasReport, file: Optional[IO[str]] = None):
+        tables: list[Table] = []
 
-        if transaction_hash:
-            console.print(f"Call trace for [bold blue]'{transaction_hash}'[/]")
-        if revert_message:
-            console.print(f"[bold red]{revert_message}[/]")
-        if sender:
-            console.print(f"tx.origin=[{TraceStyles.CONTRACTS}]{sender}[/]")
+        for contract_id, method_calls in report.items():
+            title = f"{contract_id} Gas"
+            table = Table(title=title, box=SIMPLE)
+            table.add_column("Method")
+            table.add_column("Times called", justify="right")
+            table.add_column("Min.", justify="right")
+            table.add_column("Max.", justify="right")
+            table.add_column("Mean", justify="right")
+            table.add_column("Median", justify="right")
+            has_at_least_1_row = False
+
+            for method_call, gases in sorted(method_calls.items()):
+                if not gases:
+                    continue
+
+                if not method_call or is_zero_hex(method_call) or is_evm_precompile(method_call):
+                    continue
+
+                elif method_call == "__new__":
+                    # Looks better in the gas report.
+                    method_call = "__init__"
+
+                has_at_least_1_row = True
+                table.add_row(
+                    method_call,
+                    f"{len(gases)}",
+                    f"{min(gases)}",
+                    f"{max(gases)}",
+                    f"{int(round(mean(gases)))}",
+                    f"{int(round(median(gases)))}",
+                )
 
-        console.print(root)
+            if has_at_least_1_row:
+                tables.append(table)
 
-    def show_gas(self, call_tree: CallTreeNode, file: Optional[IO[str]] = None):
-        tables = call_tree.as_gas_tables()
         self.echo(*tables, file=file)
 
     def echo(self, *rich_items, file: Optional[IO[str]] = None):
         console = self._get_console(file=file)
         console.print(*rich_items)
 
     def show_source_traceback(
@@ -1411,18 +1455,18 @@
     Access the chain manager singleton from the root ``ape`` namespace.
 
     Usage example::
 
         from ape import chain
     """
 
-    _snapshots: List[SnapshotID] = []
-    _chain_id_map: Dict[str, int] = {}
-    _block_container_map: Dict[int, BlockContainer] = {}
-    _transaction_history_map: Dict[int, TransactionHistory] = {}
+    _snapshots: list[SnapshotID] = []
+    _chain_id_map: dict[str, int] = {}
+    _block_container_map: dict[int, BlockContainer] = {}
+    _transaction_history_map: dict[int, TransactionHistory] = {}
     contracts: ContractCache = ContractCache()
     _reports: ReportManager = ReportManager()
 
     @property
     def blocks(self) -> BlockContainer:
         """
         The list of blocks on the chain.
@@ -1496,16 +1540,17 @@
             chain.pending_timestamp += 3600
         """
 
         return self.provider.get_block("pending").timestamp
 
     @pending_timestamp.setter
     def pending_timestamp(self, new_value: str):
-        self.provider.set_timestamp(self.conversion_manager.convert(value=new_value, type=int))
+        self.provider.set_timestamp(self.conversion_manager.convert(new_value, int))
 
+    @log_instead_of_fail(default="<ChainManager>")
     def __repr__(self) -> str:
         props = f"id={self.chain_id}" if self.network_manager.active_provider else "disconnected"
         cls_name = getattr(type(self), "__name__", ChainManager.__name__)
         return f"<{cls_name} ({props})>"
 
     def snapshot(self) -> SnapshotID:
         """
@@ -1547,15 +1592,15 @@
             snapshot_id = self._snapshots.pop()
         elif snapshot_id not in self._snapshots:
             raise UnknownSnapshotError(snapshot_id)
         else:
             snapshot_index = self._snapshots.index(snapshot_id)
             self._snapshots = self._snapshots[:snapshot_index]
 
-        self.provider.revert(snapshot_id)
+        self.provider.restore(snapshot_id)
         self.history.revert_to_block(self.blocks.height)
 
     @contextmanager
     def isolate(self):
         """
         Run code in an isolated context.
         Requires using a local provider that supports snapshotting.
@@ -1655,10 +1700,10 @@
             transaction_hash (str): The hash of the transaction.
 
         Returns:
             :class:`~ape.apt.transactions.ReceiptAPI`
         """
         receipt = self.chain_manager.history[transaction_hash]
         if not isinstance(receipt, ReceiptAPI):
-            raise ChainError(f"No receipt found with hash '{transaction_hash}'.")
+            raise TransactionNotFoundError(transaction_hash=transaction_hash)
 
         return receipt
```

### Comparing `eth-ape-0.7.9/src/ape/managers/compilers.py` & `eth-ape-0.8.0/src/ape/managers/compilers.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,211 +1,178 @@
+from collections import defaultdict
+from collections.abc import Iterable, Iterator, Sequence
+from functools import cached_property
 from pathlib import Path
-from typing import Any, Dict, List, Optional, Sequence, Set, Union
+from typing import TYPE_CHECKING, Any, Optional, Union
 
+from eth_pydantic_types import HexBytes
 from ethpm_types import ContractType
 from ethpm_types.source import Content
 
-from ape.api import CompilerAPI
+from ape.api.compiler import CompilerAPI
 from ape.contracts import ContractContainer
-from ape.exceptions import ApeAttributeError, CompilerError, ContractLogicError
+from ape.exceptions import CompilerError, ContractLogicError, CustomError
 from ape.logging import logger
 from ape.managers.base import BaseManager
-from ape.utils.basemodel import _assert_not_ipython_check
-from ape.utils.os import get_relative_path
+from ape.utils import log_instead_of_fail
+from ape.utils.basemodel import (
+    ExtraAttributesMixin,
+    ExtraModelAttributes,
+    get_attribute_with_extras,
+    only_raise_attribute_error,
+)
+from ape.utils.os import get_full_extension
 
+if TYPE_CHECKING:
+    from ape.managers.project import ProjectManager
 
-class CompilerManager(BaseManager):
+
+class CompilerManager(BaseManager, ExtraAttributesMixin):
     """
     The singleton that manages :class:`~ape.api.compiler.CompilerAPI` instances.
     Each compiler plugin typically contains a single :class:`~ape.api.compiler.CompilerAPI`.
 
     **NOTE**: Typically, users compile their projects using the CLI via ``ape compile``,
     which uses the :class:`~ape.api.compiler.CompilerAPI` under-the-hood.
 
     Usage example::
 
         from ape import compilers  # "compilers" is the CompilerManager singleton
     """
 
-    _registered_compilers_cache: Dict[Path, Dict[str, CompilerAPI]] = {}
+    _registered_compilers_cache: dict[Path, dict[str, CompilerAPI]] = {}
 
-    def __repr__(self):
+    @log_instead_of_fail(default="<CompilerManager>")
+    def __repr__(self) -> str:
         num_compilers = len(self.registered_compilers)
         cls_name = getattr(type(self), "__name__", CompilerManager.__name__)
         return f"<{cls_name} len(registered_compilers)={num_compilers}>"
 
-    def __getattr__(self, name: str) -> Any:
-        _assert_not_ipython_check(name)
-
-        try:
-            return self.__getattribute__(name)
-        except AttributeError:
-            pass
-
-        if compiler := self.get_compiler(name):
-            return compiler
+    def __ape_extra_attributes__(self) -> Iterator[ExtraModelAttributes]:
+        yield ExtraModelAttributes(
+            name="compilers",
+            # Allow referencing compilers by name e.g. `compilers.vyper`.
+            attributes=lambda: {c.name: c for c in self.registered_compilers.values()},
+        )
 
-        raise ApeAttributeError(f"No attribute or compiler named '{name}'.")
+    @only_raise_attribute_error
+    def __getattr__(self, attr_name: str) -> Any:
+        return get_attribute_with_extras(self, attr_name)
 
-    @property
-    def registered_compilers(self) -> Dict[str, CompilerAPI]:
+    @cached_property
+    def registered_compilers(self) -> dict[str, CompilerAPI]:
         """
         Each compile-able file extension mapped to its respective
         :class:`~ape.api.compiler.CompilerAPI` instance.
 
         Returns:
-            Dict[str, :class:`~ape.api.compiler.CompilerAPI`]: The mapping of file-extensions
+            dict[str, :class:`~ape.api.compiler.CompilerAPI`]: The mapping of file-extensions
             to compiler API classes.
         """
-
-        cache_key = self.config_manager.PROJECT_FOLDER
-        if cache_key in self._registered_compilers_cache:
-            return self._registered_compilers_cache[cache_key]
-
         registered_compilers = {}
 
         for plugin_name, (extensions, compiler_class) in self.plugin_manager.register_compiler:
-            # TODO: Investigate side effects of loading compiler plugins.
-            #       See if this needs to be refactored.
             self.config_manager.get_config(plugin_name)
-
             compiler = compiler_class()
 
             for extension in extensions:
                 if extension not in registered_compilers:
                     registered_compilers[extension] = compiler
 
-        self._registered_compilers_cache[cache_key] = registered_compilers
         return registered_compilers
 
-    def get_compiler(self, name: str, settings: Optional[Dict] = None) -> Optional[CompilerAPI]:
+    def get_compiler(self, name: str, settings: Optional[dict] = None) -> Optional[CompilerAPI]:
         for compiler in self.registered_compilers.values():
             if compiler.name != name:
                 continue
 
             if settings is not None and settings != compiler.compiler_settings:
                 # Use a new instance to support multiple compilers of same type.
                 return compiler.model_copy(update={"compiler_settings": settings})
 
             return compiler
 
         return None
 
     def compile(
-        self, contract_filepaths: Sequence[Union[Path, str]], settings: Optional[Dict] = None
-    ) -> Dict[str, ContractType]:
+        self,
+        contract_filepaths: Union[Path, str, Iterable[Union[Path, str]]],
+        project: Optional["ProjectManager"] = None,
+        settings: Optional[dict] = None,
+    ) -> Iterator[ContractType]:
         """
         Invoke :meth:`ape.ape.compiler.CompilerAPI.compile` for each of the given files.
         For example, use the `ape-solidity plugin <https://github.com/ApeWorX/ape-solidity>`__
         to compile ``'.sol'`` files.
 
         Raises:
             :class:`~ape.exceptions.CompilerError`: When there is no compiler found for the given
               file-extension as well as when there are contract-type collisions across compilers.
 
         Args:
-            contract_filepaths (Sequence[Union[pathlib.Path], str]): The files to compile,
-              as ``pathlib.Path`` objects or path-strs.
+            contract_filepaths (Union[Path, str, Iterable[Union[Path, str]]]): The files to
+              compile, as ``pathlib.Path`` objects or path-strs.
+            project (Optional[:class:`~ape.managers.project.ProjectManager`]): Optionally
+              compile a different project that the one from the current-working directory.
             settings (Optional[Dict]): Adhoc compiler settings. Defaults to None.
               Ensure the compiler name key is present in the dict for it to work.
 
         Returns:
-            Dict[str, ``ContractType``]: A mapping of contract names to their type.
+            Iterator[``ContractType``]: An iterator of contract types.
         """
-        contract_file_paths = [Path(p) if isinstance(p, str) else p for p in contract_filepaths]
-        extensions = self._get_contract_extensions(contract_file_paths)
-        contracts_folder = self.config_manager.contracts_folder
-        contract_types_dict: Dict[str, ContractType] = {}
-        cached_manifest = self.project_manager.local_project.cached_manifest
-
-        # Load past compiled contracts for verifying type-collision and other things.
-        already_compiled_contracts: Dict[str, ContractType] = {}
-        already_compiled_paths: List[Path] = []
-        for name, ct in ((cached_manifest.contract_types or {}) if cached_manifest else {}).items():
-            if not ct.source_id:
-                continue
 
-            _file = contracts_folder / ct.source_id
-            if not _file.is_file():
-                continue
+        pm = project or self.local_project
+        files_by_ext = defaultdict(list)
 
-            already_compiled_contracts[name] = ct
-            already_compiled_paths.append(_file)
+        if isinstance(contract_filepaths, (str, Path)):
+            contract_filepaths = (contract_filepaths,)
 
-        exclusions = self.config_manager.get_config("compile").exclude
-        for extension in extensions:
-            ignore_path_lists = [contracts_folder.rglob(p) for p in exclusions]
-            paths_to_ignore = [
-                contracts_folder / get_relative_path(p, contracts_folder)
-                for files in ignore_path_lists
-                for p in files
-            ]
-
-            # Filter out in-source cache files from dependencies.
-            paths_to_compile = [
-                path
-                for path in contract_file_paths
-                if path.is_file()
-                and path not in paths_to_ignore
-                and path not in already_compiled_paths
-                and path.suffix == extension
-                and not any(x in [p.name for p in path.parents] for x in (".cache", ".build"))
-            ]
+        for path in map(Path, contract_filepaths):
+            suffix = get_full_extension(path)
+            if suffix in self.registered_compilers:
+                files_by_ext[suffix].append(path)
 
-            if not paths_to_compile:
-                continue
+        errors = []
+        tracker: dict[str, str] = {}
+        settings = settings or {}
 
-            source_ids = [get_relative_path(p, contracts_folder) for p in paths_to_compile]
-            for source_id in source_ids:
-                logger.info(f"Compiling '{source_id}'.")
-
-            name = self.registered_compilers[extension].name
-            compiler = self.get_compiler(name, settings=settings)
-            if compiler is None:
-                # For mypy - should not be possible.
-                raise ValueError("Compiler should not be None")
-
-            compiled_contracts = compiler.compile(paths_to_compile, base_path=contracts_folder)
-
-            # Validate some things about the compile contracts.
-            for contract_type in compiled_contracts:
-                contract_name = contract_type.name
-                if not contract_name:
-                    # Compiler plugins should have let this happen, but just in case we get here,
-                    # raise a better error so the user has some indication of what happened.
-                    if contract_type.source_id:
-                        raise CompilerError(
-                            f"Contract '{contract_type.source_id}' missing name. "
-                            f"Was compiler plugin for '{extension} implemented correctly?"
-                        )
-                    else:
+        for next_ext, path_set in files_by_ext.items():
+            compiler = self.registered_compilers[next_ext]
+            try:
+                compiler_settings = settings.get(compiler.name, {})
+                for contract in compiler.compile(path_set, project=pm, settings=compiler_settings):
+                    if contract.name in tracker:
                         raise CompilerError(
-                            f"Empty contract type found in compiler '{extension}'. "
-                            f"Was compiler plugin for '{extension} implemented correctly?"
+                            f"ContractType collision. "
+                            f"Contracts '{tracker[contract.name]}' and '{contract.source_id}' "
+                            f"share the name '{contract.name}'."
                         )
 
-                full_ct_dict = {**contract_types_dict, **already_compiled_contracts}
-                if contract_name in full_ct_dict:
-                    already_added_contract_type = full_ct_dict[contract_name]
-                    error_message = (
-                        f"{ContractType.__name__} collision between sources "
-                        f"'{contract_type.source_id}' and "
-                        f"'{already_added_contract_type.source_id}'."
-                    )
-                    raise CompilerError(error_message)
+                    if contract.name and contract.source_id:
+                        tracker[contract.name] = contract.source_id
 
-                contract_types_dict[contract_name] = contract_type
+                    yield contract
 
-        return contract_types_dict
+            except CompilerError as err:
+                # One of the compilers failed. Show the error but carry on.
+                logger.log_debug_stack_trace()
+                errors.append(err)
+                continue
+
+        if errors:
+            formatted_errors = [f"{e}" for e in errors]
+            error_message = "\n\n".join(formatted_errors)
+            raise CompilerError(error_message)
 
     def compile_source(
         self,
         compiler_name: str,
         code: str,
-        settings: Optional[Dict] = None,
+        project: Optional["ProjectManager"] = None,
+        settings: Optional[dict] = None,
         **kwargs,
     ) -> ContractContainer:
         """
         Compile the given program.
 
         Usage example::
 
@@ -215,149 +182,173 @@
                 code,
                 contractName="MyContract",
             )
 
         Args:
             compiler_name (str): The name of the compiler to use.
             code (str): The source code to compile.
-            settings (Optional[Dict]): Compiler settings.
+            project (Optional[:class:`~ape.managers.project.ProjectManager`]): Optionally
+              compile a different project that the one from the current-working directory.
+            settings (Optional[dict]): Compiler settings.
             **kwargs (Any): Additional overrides for the ``ethpm_types.ContractType`` model.
 
         Returns:
             ``ContractContainer``: A contract container ready to be deployed.
         """
         compiler = self.get_compiler(compiler_name, settings=settings)
         if not compiler:
             raise ValueError(f"Compiler '{compiler_name}' not found.")
 
-        contract_type = compiler.compile_code(
-            code,
-            base_path=self.project_manager.contracts_folder,
-            **kwargs,
-        )
+        contract_type = compiler.compile_code(code, project=project, **kwargs)
         return ContractContainer(contract_type=contract_type)
 
     def get_imports(
-        self, contract_filepaths: Sequence[Path], base_path: Optional[Path] = None
-    ) -> Dict[str, List[str]]:
+        self,
+        contract_filepaths: Sequence[Path],
+        project: Optional["ProjectManager"] = None,
+    ) -> dict[str, list[str]]:
         """
         Combine import dicts from all compilers, where the key is a contract's source_id
         and the value is a list of import source_ids.
 
         Args:
             contract_filepaths (Sequence[pathlib.Path]): A list of source file paths to compile.
-            base_path (Optional[pathlib.Path]): Optionally provide the base path, such as the
-              project ``contracts/`` directory. Defaults to ``None``. When using in a project
-              via ``ape compile``, gets set to the project's ``contracts/`` directory.
+            project (Optional[:class:`~ape.managers.project.ProjectManager`]): Optionally provide
+              the project.
 
         Returns:
-            Dict[str, List[str]]: A dictionary like ``{source_id: [import_source_id, ...], ...}``
+            dict[str, list[str]]: A dictionary like ``{source_id: [import_source_id, ...], ...}``
         """
-        imports_dict: Dict[str, List[str]] = {}
-        base_path = base_path or self.project_manager.contracts_folder
+        imports_dict: dict[str, list[str]] = {}
 
         for ext, compiler in self.registered_compilers.items():
             try:
-                sources = [p for p in contract_filepaths if p.suffix == ext and p.is_file()]
-                imports = compiler.get_imports(contract_filepaths=sources, base_path=base_path)
+                sources = [
+                    p for p in contract_filepaths if get_full_extension(p) == ext and p.is_file()
+                ]
+                imports = compiler.get_imports(contract_filepaths=sources, project=project)
             except NotImplementedError:
                 imports = None
 
             if imports:
                 imports_dict.update(imports)
 
         return imports_dict
 
-    def get_references(self, imports_dict: Dict[str, List[str]]) -> Dict[str, List[str]]:
+    def get_references(self, imports_dict: dict[str, list[str]]) -> dict[str, list[str]]:
         """
         Provide a mapping containing all referenced source_ids for a given project.
         Each entry contains a source_id as a key and list of source_ids that reference a
         given contract.
 
         Args:
-            imports_dict (Dict[str, List[str]]): A dictionary of source_ids from all compilers.
+            imports_dict (dict[str, list[str]]): A dictionary of source_ids from all compilers.
 
         Returns:
-            Dict[str, List[str]]: A dictionary like ``{source_id: [referring_source_id, ...], ...}``
+            dict[str, list[str]]: A dictionary like ``{source_id: [referring_source_id, ...], ...}``
         """
-        references_dict: Dict[str, List[str]] = {}
+        references_dict: dict[str, list[str]] = {}
         if not imports_dict:
             return {}
 
         for key, imports_list in imports_dict.items():
             for filepath in imports_list:
                 if filepath not in references_dict:
                     references_dict[filepath] = []
                 references_dict[filepath].append(key)
 
         return references_dict
 
-    def _get_contract_extensions(self, contract_filepaths: List[Path]) -> Set[str]:
-        extensions = {path.suffix for path in contract_filepaths}
-        unhandled_extensions = {s for s in extensions - set(self.registered_compilers) if s}
-        if len(unhandled_extensions) > 0:
-            unhandled_extensions_str = ", ".join(unhandled_extensions)
-            raise CompilerError(f"No compiler found for extensions [{unhandled_extensions_str}].")
-
-        return {e for e in extensions if e}
-
     def enrich_error(self, err: ContractLogicError) -> ContractLogicError:
         """
         Enrich a contract logic error using compiler information, such
         known PC locations for compiler runtime errors.
 
         Args:
             err (:class:`~ape.exceptions.ContractLogicError`): The exception
               to enrich.
 
         Returns:
             :class:`~ape.exceptions.ContractLogicError`: The enriched exception.
         """
-
-        address = err.address
-        if not address:
-            # Contract address not found.
+        # First, try enriching using their ABI.
+        err = self.get_custom_error(err) or err
+        if not (contract_type := err.contract_type):
             return err
 
-        try:
-            contract = self.chain_manager.contracts.get(address)
-        except RecursionError:
-            contract = None
+        # Delegate to compiler APIs.
+        elif source_id := contract_type.source_id:
+            # Source ID found! Delegate to a CompilerAPI for enrichment.
+            ext = get_full_extension(Path(source_id))
+            if ext not in self.registered_compilers:
+                # Compiler not found.
+                return err
+
+            compiler = self.registered_compilers[ext]
+            return compiler.enrich_error(err)
+
+        # No further enrichment.
+        return err
+
+    def get_custom_error(self, err: ContractLogicError) -> Optional[CustomError]:
+        """
+        Get a custom error for the given contract logic error using the contract-type
+        found from address-data in the error. Returns ``None`` if the given error is
+        not a custom-error or it is not able to find the associated contract type or
+        address.
 
-        if not contract or not contract.source_id:
-            # Contract or source not found.
-            return err
+        Args:
+            err (:class:`~ape.exceptions.ContractLogicError`): The error to enrich
+              as a custom error.
 
-        ext = Path(contract.source_id).suffix
-        if ext not in self.registered_compilers:
-            # Compiler not found.
-            return err
+        Returns:
+
+        """
+        message = err.revert_message
+        if not message.startswith("0x"):
+            return None
+        elif not (address := err.address):
+            return None
+
+        if provider := self.network_manager.active_provider:
+            ecosystem = provider.network.ecosystem
+        else:
+            # Default to Ethereum.
+            ecosystem = self.network_manager.ethereum
 
-        compiler = self.registered_compilers[ext]
-        return compiler.enrich_error(err)
+        try:
+            return ecosystem.decode_custom_error(
+                HexBytes(message),
+                address,
+                base_err=err.base_err,
+                source_traceback=err.source_traceback,
+                trace=err.trace,
+                txn=err.txn,
+            )
+        except NotImplementedError:
+            return None
 
-    def flatten_contract(self, path: Path) -> Content:
+    def flatten_contract(self, path: Path, **kwargs) -> Content:
         """
         Get the flattened version of a contract via its source path.
         Delegates to the matching :class:`~ape.api.compilers.CompilerAPI`.
 
         Args:
             path (``pathlib.Path``): The source path of the contract.
 
         Returns:
             ``ethpm_types.source.Content``: The flattened contract content.
         """
 
-        if path.suffix not in self.registered_compilers:
-            raise CompilerError(
-                f"Unable to flatten contract. Missing compiler for '{path.suffix}'."
-            )
+        suffix = get_full_extension(path)
+        if suffix not in self.registered_compilers:
+            raise CompilerError(f"Unable to flatten contract. Missing compiler for '{suffix}'.")
 
-        compiler = self.registered_compilers[path.suffix]
-        return compiler.flatten_contract(path)
+        compiler = self.registered_compilers[suffix]
+        return compiler.flatten_contract(path, **kwargs)
 
     def can_trace_source(self, filename: str) -> bool:
         """
         Check if Ape is able trace the source lines for the given file.
         Checks that both the compiler is registered and that it supports
         the :meth:`~ape.api.compilers.CompilerAPI.trace_source` API method.
 
@@ -367,15 +358,15 @@
         Returns:
             bool: ``True`` when the source is traceable.
         """
         path = Path(filename)
         if not path.is_file():
             return False
 
-        extension = path.suffix
+        extension = get_full_extension(path)
         if extension in self.registered_compilers:
             compiler = self.registered_compilers[extension]
             if compiler.supports_source_tracing:
                 return True
 
         # We are not able to get coverage for this file.
         return False
```

### Comparing `eth-ape-0.7.9/src/ape/managers/config.py` & `eth-ape-0.8.0/src/ape/api/config.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,391 +1,468 @@
 import os
-from contextlib import contextmanager
+from collections.abc import Iterator
+from enum import Enum
+from functools import cached_property
 from pathlib import Path
-from typing import TYPE_CHECKING, Any, Dict, Generator, List, Optional, Union
+from typing import TYPE_CHECKING, Any, Optional, TypeVar, cast
 
-from ethpm_types import PackageMeta
-from pydantic import RootModel, model_validator
+import yaml
+from ethpm_types import PackageManifest, PackageMeta
+from pydantic import ConfigDict, Field, model_validator
+from pydantic_settings import BaseSettings, SettingsConfigDict
 
-from ape.api import ConfigDict, DependencyAPI, PluginConfig
 from ape.exceptions import ConfigError
 from ape.logging import logger
-from ape.utils import BaseInterfaceModel, load_config
+from ape.types import AddressType
+from ape.utils.basemodel import (
+    ExtraAttributesMixin,
+    ExtraModelAttributes,
+    ManagerAccessMixin,
+    _assert_not_ipython_check,
+    get_attribute_with_extras,
+    only_raise_attribute_error,
+)
+from ape.utils.misc import load_config
 
 if TYPE_CHECKING:
-    from .project import ProjectManager
+    from ape.managers.config import ConfigManager
 
+ConfigItemType = TypeVar("ConfigItemType")
 
-CONFIG_FILE_NAME = "ape-config.yaml"
 
+class ConfigEnum(str, Enum):
+    """
+    A configuration `Enum <https://docs.python.org/3/library/enum.html>`__ type.
+    Use this to limit the values of a config item, such as colors ``"RED"``, ``"BLUE"``,
+    ``"GREEN"``, rather than any arbitrary ``str``.
 
-class DeploymentConfig(PluginConfig):
-    address: Union[str, bytes]
-    contract_type: str
+    Usage example::
 
+            class MyEnum(ConfigEnum):
+                FOO = "FOO"
+                BAR = "BAR"
+
+            class MyConfig(PluginConfig):
+                my_enum: MyEnum
+
+            model = MyConfig(my_enum="FOO")
+
+    """
+
+
+class PluginConfig(BaseSettings):
+    """
+    A base plugin configuration class. Each plugin that includes
+    a config API must register a subclass of this class.
+    """
+
+    # NOTE: This is probably partially initialized at the time of assignment
+    _config_manager: Optional["ConfigManager"]
+
+    model_config = SettingsConfigDict(extra="allow")
 
-class DeploymentConfigCollection(RootModel[dict]):
-    @model_validator(mode="before")
     @classmethod
-    def validate_deployments(cls, data: Dict, info):
-        valid_ecosystems = data.pop("valid_ecosystems", {})
-        valid_networks = data.pop("valid_networks", {})
-        valid_data: Dict = {}
-        for ecosystem_name, networks in data.items():
-            if ecosystem_name not in valid_ecosystems:
-                logger.warning(f"Invalid ecosystem '{ecosystem_name}' in deployments config.")
-                continue
+    def from_overrides(cls, overrides: dict) -> "PluginConfig":
+        default_values = cls().model_dump()
 
-            ecosystem = valid_ecosystems[ecosystem_name]
-            for network_name, contract_deployments in networks.items():
-                if network_name not in valid_networks:
-                    logger.warning(f"Invalid network '{network_name}' in deployments config.")
-                    continue
-
-                valid_deployments = []
-                for deployment in [d for d in contract_deployments]:
-                    if not (address := deployment.get("address")):
-                        logger.warning(
-                            f"Missing 'address' field in deployment "
-                            f"(ecosystem={ecosystem_name}, network={network_name})"
-                        )
-                        continue
-
-                    valid_deployment = {**deployment}
-                    try:
-                        valid_deployment["address"] = ecosystem.decode_address(address)
-                    except ValueError as err:
-                        logger.warning(str(err))
-
-                    valid_deployments.append(valid_deployment)
-
-                valid_data[ecosystem_name] = {
-                    **valid_data.get(ecosystem_name, {}),
-                    network_name: valid_deployments,
-                }
-
-        return valid_data
-
-
-class ConfigManager(BaseInterfaceModel):
-    """
-    The singleton responsible for managing the ``ape-config.yaml`` project file.
-    The config manager is useful for loading plugin configurations which contain
-    settings that determine how ``ape`` functions. When developing plugins,
-    you may want to have settings that control how the plugin works. When developing
-    scripts in a project, you may want to parametrize how it runs. The config manager
-    is how you can access those settings at runtime.
+        def update(root: dict, value_map: dict):
+            for key, val in value_map.items():
+                if isinstance(val, dict) and key in root and isinstance(root[key], dict):
+                    root[key] = update(root[key], val)
+                else:
+                    root[key] = val
+
+            return root
+
+        return cls(**update(default_values, overrides))
+
+    @only_raise_attribute_error
+    def __getattr__(self, attr_name: str) -> Any:
+        _assert_not_ipython_check(attr_name)
+
+        # Allow hyphens in plugin config files.
+        attr_name = attr_name.replace("-", "_")
+        extra = self.__pydantic_extra__ or {}
+        if attr_name in extra:
+            return extra[attr_name]
+
+        return super().__getattribute__(attr_name)
+
+    def __getitem__(self, item: str) -> Any:
+        extra = self.__pydantic_extra__ or {}
+        if item in self.__dict__:
+            return self.__dict__[item]
+
+        elif item in extra:
+            return extra[item]
+
+        raise KeyError(f"'{item}' not in config.")
+
+    def __contains__(self, key: str) -> bool:
+        return key in self.__dict__ or key in (self.__pydantic_extra__ or {})
+
+    def __str__(self) -> str:
+        data = self.model_dump(
+            mode="json",
+            by_alias=True,
+            exclude_none=True,
+            exclude_unset=True,
+            exclude_defaults=True,
+        )
+        return yaml.safe_dump(data)
 
-    Access the ``ConfigManager`` from the ``ape`` namespace directly via:
+    def get(self, key: str, default: Optional[ConfigItemType] = None) -> ConfigItemType:
+        extra: dict = self.__pydantic_extra__ or {}
+        return self.__dict__.get(key, extra.get(key, default))
 
-    Usage example::
 
-        from ape import config  # "config" is the ConfigManager singleton
+class GenericConfig(ConfigDict):
+    """
+    The default class used when no specialized class is used.
+    """
+
 
-        # Example: load the "ape-test" plugin and access the mnemonic
-        test_mnemonic = config.get_config("test").mnemonic
+class DeploymentConfig(PluginConfig):
+    """
+    Add 'deployments' to your config.
     """
 
-    DATA_FOLDER: Path
-    """The path to the ``ape`` directory such as ``$HOME/.ape``."""
+    address: AddressType
+    """
+    The address of the deployment.
+    """
 
-    REQUEST_HEADER: Dict
+    contract_type: str
+    """
+    The contract type name reference
+    (must be a contract in the project).
+    """
 
-    PROJECT_FOLDER: Path
-    """The path to the ``ape`` project."""
 
-    name: str = ""
-    """The name of the project."""
+class ApeConfig(ExtraAttributesMixin, BaseSettings, ManagerAccessMixin):
+    """
+    The top-level config.
+    """
 
-    version: str = ""
-    """The project's version."""
+    contracts_folder: Optional[str] = None
+    """
+    The path to the folder containing the contract source files.
+    **NOTE**: Non-absolute paths are relative to the project-root.
+    If not set, defaults to deducing the contracts folder.
+    When deducing, Ape first tries ``"contracts"``, but if
+    that folder does not exist, Ape tries to find a folder with
+    contracts.
+    """
 
-    meta: PackageMeta = PackageMeta()
-    """Metadata about the project."""
+    default_ecosystem: str = "ethereum"
+    """
+    The default ecosystem to use in Ape.
+    """
 
-    contracts_folder: Path = None  # type: ignore
+    dependencies: list[dict] = []
     """
-    The path to the project's ``contracts/`` directory
-    (differs by project structure).
+    Project dependency declarations.
+    Note: The actual dependency classes are decoded later.
     """
 
-    dependencies: List[DependencyAPI] = []
-    """A list of project dependencies."""
+    deployment_data: dict[str, dict[str, list[DeploymentConfig]]] = Field({}, alias="deployments")
+    """
+    Data for deployed contracts from the project.
+    """
 
-    deployments: Optional[DeploymentConfigCollection] = None
-    """A dict of contract deployments by address and contract type."""
+    interfaces_folder: str = "interfaces"
+    """
+    The path to the project's interfaces.
+    """
 
-    default_ecosystem: str = "ethereum"
-    """The default ecosystem to use. Defaults to ``"ethereum"``."""
+    meta: PackageMeta = PackageMeta()
+    """
+    Metadata about the active project as per EIP
+    https://eips.ethereum.org/EIPS/eip-2678#the-package-meta-object
+    """
+
+    name: str = ""
+    """
+    The name of the project.
+    """
 
-    _cached_configs: Dict[str, Dict[str, Any]] = {}
+    version: str = ""
+    """
+    The version of the project.
+    """
+
+    # NOTE: Plugin configs are technically "extras".
+    model_config = SettingsConfigDict(extra="allow")
 
     @model_validator(mode="before")
     @classmethod
-    def check_config_for_extra_fields(cls, values: Dict[str, Any]) -> Dict[str, Any]:
-        extra = [key for key in values.keys() if key not in cls.model_fields]
-        if extra:
-            logger.warning(f"Unprocessed extra config fields not set '{extra}'.")
-
-        return values
+    def validate_model(cls, model):
+        model = model or {}
+        fixed_model = {}
+        for key, val in model.items():
+            # Allows hyphens to work anywhere where underscores are.
+            fixed_model[key.replace("-", "_")] = val
+
+        if project := fixed_model.pop("project", None):
+            # Resolve local dependencies so relative paths don't cause
+            # problems when moving the project around (as happens in local
+            # dependencies).
+            fixed_deps = []
+            for dep in fixed_model.get("dependencies", []):
+                fixed_dep = {**dep}
+                if "project" not in fixed_dep:
+                    fixed_dep["project"] = project
+                # else: we might be told to use a different project.
+                #   when decoding dependencies, the project is mostly used for
+                #  stuff like resolving paths. If this is already set,
+                #  this is likely a dependency of a dependency.
+
+                fixed_deps.append(fixed_dep)
+
+            if fixed_deps:
+                fixed_model["dependencies"] = fixed_deps
+
+        # field: contracs_folder: Handle if given Path object.
+        if "contracts_folder" in fixed_model and isinstance(fixed_model["contracts_folder"], Path):
+            fixed_model["contracts_folder"] = str(fixed_model["contracts_folder"])
+
+        return fixed_model
+
+    @cached_property
+    def deployments(self) -> dict[str, dict[str, list[DeploymentConfig]]]:
+        # Lazily validated.
+        for ecosystem_name, ecosystem_deploys in self.deployment_data.items():
+            if ecosystem_name not in self.network_manager.ecosystems:
+                raise ConfigError(f"Invalid ecosystem '{ecosystem_name}' in deployments config.")
+
+            ecosystem = self.network_manager.ecosystems[ecosystem_name]
+            for network_name, network_deploys in ecosystem_deploys.items():
+                if network_name not in ecosystem.networks:
+                    raise ConfigError(
+                        f"Invalid network '{ecosystem_name}:{network_name}' in deployments config."
+                    )
+
+        return self.deployment_data
+
+    def __ape_extra_attributes__(self) -> Iterator[ExtraModelAttributes]:
+        # This allows `config.my_plugin` to work.
+        yield ExtraModelAttributes(
+            name="plugin_configs",
+            attributes=lambda n: self.get_config(n.replace("-", "_")),
+            include_getitem=True,
+        )
 
-    @model_validator(mode="after")
     @classmethod
-    def load_configs(cls, cm):
-        return cm.load()
+    def validate_file(cls, path: Path, **overrides) -> "ApeConfig":
+        data = {**load_config(path), **overrides}
 
-    @property
-    def packages_folder(self) -> Path:
-        self.dependency_manager.packages_folder.mkdir(parents=True, exist_ok=True)
-        return self.dependency_manager.packages_folder
+        # NOTE: We are including the project path here to assist
+        #  in relative-path resolution, such as for local dependencies.
+        #  You can use relative paths in local dependencies in your
+        #  ape-config.yaml file but Ape needs to know the source to be
+        #  relative from.
+        data["project"] = path.parent
 
-    @property
-    def _project_key(self) -> str:
-        return self.PROJECT_FOLDER.stem
+        return cls.model_validate(data)
 
-    @property
-    def _project_configs(self) -> Dict[str, Any]:
-        return self._cached_configs.get(self._project_key, {})
+    @classmethod
+    def from_manifest(cls, manifest: PackageManifest, **overrides) -> "ApeConfig":
+        return cls.model_validate(
+            {
+                **_get_compile_configs_from_manifest(manifest),
+                **_get_dependency_configs_from_manifest(manifest),
+                **overrides,
+            }
+        )
 
     @property
-    def _plugin_configs(self) -> Dict[str, PluginConfig]:
-        if cache := self._cached_configs.get(self._project_key):
-            self.name = cache.get("name", "")
-            self.version = cache.get("version", "")
-            self.default_ecosystem = cache.get("default_ecosystem", "ethereum")
-            self.meta = PackageMeta.model_validate(cache.get("meta", {}))
-            self.dependencies = cache.get("dependencies", [])
-            self.deployments = cache.get("deployments", {})
-            self.contracts_folder = cache.get("contracts_folder", self.PROJECT_FOLDER / "contracts")
-            return cache
-
-        # First, load top-level configs. Then, load all the plugin configs.
-        # The configs are popped off the dict for checking if all configs were processed.
-
-        configs = {}
-        global_config_file = self.DATA_FOLDER / CONFIG_FILE_NAME
-        global_config = load_config(global_config_file) if global_config_file.is_file() else {}
-        config_file = self.PROJECT_FOLDER / CONFIG_FILE_NAME
-
-        # NOTE: It is critical that we read in global config values first
-        # so that project config values will override them as-needed.
-        project_config = load_config(config_file) if config_file.is_file() else {}
-        user_config = merge_configs(global_config, project_config)
-
-        self.name = configs["name"] = user_config.pop("name", "")
-        self.version = configs["version"] = user_config.pop("version", "")
-        meta_dict = user_config.pop("meta", {})
-        meta_obj = PackageMeta.model_validate(meta_dict)
-        configs["meta"] = meta_dict
-        self.meta = meta_obj
-        self.default_ecosystem = configs["default_ecosystem"] = user_config.pop(
-            "default_ecosystem", "ethereum"
-        )
+    def _plugin_configs(self) -> dict:
+        # NOTE: Ensure a dict exists so we can add to it
+        #  and have it persist.
+        self.__pydantic_extra__ = self.__pydantic_extra__ or {}
+        return self.__pydantic_extra__
 
-        dependencies = user_config.pop("dependencies", []) or []
-        if not isinstance(dependencies, list):
-            raise ConfigError("'dependencies' config item must be a list of dicts.")
-
-        decode = self.dependency_manager.decode_dependency
-        configs["dependencies"] = [decode(dep) for dep in dependencies]
-        self.dependencies = configs["dependencies"]
-
-        # NOTE: It is okay for this directory not to exist at this point.
-        contracts_folder = user_config.pop(
-            "contracts_folder", user_config.pop("contracts-folder", None)
-        )
-        contracts_folder = (
-            (self.PROJECT_FOLDER / Path(contracts_folder)).expanduser().resolve()
-            if contracts_folder
-            else self.PROJECT_FOLDER / "contracts"
+    def __repr__(self):
+        return "<ape-config.yaml>"
+
+    def __str__(self) -> str:
+        data = self.model_dump(
+            mode="json",
+            by_alias=True,
+            exclude_none=True,
+            exclude_unset=True,
+            exclude_defaults=True,
         )
+        return yaml.dump(data)
 
-        self.contracts_folder = configs["contracts_folder"] = contracts_folder
-        deployments = user_config.pop("deployments", {})
-        valid_ecosystems = dict(self.plugin_manager.ecosystems)
-        valid_network_names = [n[1] for n in [e[1] for e in self.plugin_manager.networks]]
-        self.deployments = configs["deployments"] = DeploymentConfigCollection(
-            root={
-                **deployments,
-                "valid_ecosystems": valid_ecosystems,
-                "valid_networks": valid_network_names,
-            }
+    @only_raise_attribute_error
+    def __getattr__(self, attr_name: str) -> Any:
+        return get_attribute_with_extras(self, attr_name)
+
+    def __getitem__(self, name: str) -> Any:
+        return self.__getattr__(name)
+
+    def __contains__(self, item):
+        # Always return True o handle lazy loading plugins.
+        return True
+
+    def model_dump(self, *args, **kwargs):
+        res = super().model_dump(*args, **kwargs)
+        # TODO: For some reason underscore prefixed kwargs
+        #  still show up even though Pydantic says they
+        #  shouldn't. Figure out why.
+        return {k: v for k, v in res.items() if not k.startswith("_")}
+
+    def get(self, name: str) -> Optional[Any]:
+        return self.__getattr__(name)
+
+    def get_config(self, plugin_name: str) -> PluginConfig:
+        name = plugin_name.replace("-", "_")
+        return (
+            self.get_plugin_config(name)
+            or self.get_custom_ecosystem_config(name)
+            or self.get_unknown_config(name)
         )
 
-        ethereum_config_cls = None
-        for plugin_name, config_class in self.plugin_manager.config_class:
-            # `or {}` to handle the case when the empty config is `None`.
-            user_override = user_config.pop(plugin_name, {}) or {}
+    def get_plugin_config(self, name: str) -> Optional[PluginConfig]:
+        name = name.replace("-", "_")
+        cfg = self._plugin_configs.get(name, {})
+        if cfg and not isinstance(cfg, dict):
+            # Already decoded.
+            return cfg
 
-            # Store ethereum's class for custom network config loading.
-            if plugin_name == "ethereum":
-                ethereum_config_cls = config_class
+        for plugin_name, config_class in self.plugin_manager.config_class:
+            cls: type[PluginConfig] = config_class  # type: ignore
+            if plugin_name != name:
+                continue
 
-            if config_class != ConfigDict:
+            if cls != ConfigDict:
                 # NOTE: Will raise if improperly provided keys
-                config = config_class.from_overrides(user_override)  # type: ignore
+                config = cls.from_overrides(cfg)
             else:
                 # NOTE: Just use it directly as a dict if `ConfigDict` is passed
-                config = user_override
+                config = cfg
 
-            configs[plugin_name] = config
+            self._plugin_configs[name] = config
+            return config
 
-        # Load custom ecosystem configs.
-        if ethereum_config_cls is not None and user_config:
-            custom_ecosystem_names = {
-                x.get("ecosystem")
-                for x in configs.get("networks", {}).get("custom", [])
-                if x.get("ecosystem") and x["ecosystem"] not in configs
-            }
-            custom_ecosystem_configs = {
-                n: cfg for n, cfg in user_config.items() if n in custom_ecosystem_names
-            }
-
-            for ecosystem_name, cfg in custom_ecosystem_configs.items():
-                config = ethereum_config_cls.from_overrides(cfg)  # type: ignore
-                configs[ecosystem_name] = config
-                del user_config[ecosystem_name]
-
-        remaining_keys = user_config.keys()
-        if len(remaining_keys) > 0:
-            remaining_keys_str = ", ".join(remaining_keys)
-            logger.warning(
-                f"Unprocessed plugin config(s): {remaining_keys_str}. "
-                "Plugins may not be installed yet or keys may be mis-spelled."
-            )
-
-        self._cached_configs[self._project_key] = configs
-        return configs
+        return None
 
-    def __repr__(self):
-        return f"<{ConfigManager.__name__} project={self.PROJECT_FOLDER.name}>"
-
-    def load(self, force_reload: bool = False) -> "ConfigManager":
-        """
-        Load the user config file and return this class.
-        """
+    def get_custom_ecosystem_config(self, name: str) -> Optional[PluginConfig]:
+        name = name.replace("-", "_")
+        if not (networks := self.get_plugin_config("networks")):
+            # Shouldn't happen.
+            return None
 
-        if force_reload:
-            self._cached_configs = {}
+        for network in networks.custom:
+            if name not in (network.ecosystem, network.ecosystem.replace("-", "_")):
+                continue
 
-        _ = self._plugin_configs
+            # Check if has a cached override.
+            override = self._plugin_configs.get(name, {})
+            if not isinstance(override, dict):
+                return override
+
+            # Custom network found.
+            from ape_ethereum import EthereumConfig
+
+            ethereum = cast(EthereumConfig, self.get_plugin_config("ethereum"))
+            return ethereum.from_overrides(override)
+
+        return None
+
+    def get_unknown_config(self, name: str) -> PluginConfig:
+        # This happens when a plugin is not installed but still configured.
+        result = (self.__pydantic_extra__ or {}).get(name, PluginConfig())
+        if isinstance(result, dict):
+            return PluginConfig.from_overrides(result)
 
-        return self
+        return result
 
-    def get_config(self, plugin_name: str) -> PluginConfig:
+    def write_to_disk(self, destination: Path, replace: bool = False):
         """
-        Get a plugin config.
+        Write this config to a file.
 
         Args:
-            plugin_name (str): The name of the plugin to get the config for.
-
-        Returns:
-            :class:`~ape.api.config.PluginConfig`
-        """
-
-        self.load()  # Only loads if it needs to.
-
-        if plugin_name not in self._plugin_configs:
-            # plugin has no registered config class, so return empty config
-            return PluginConfig()
-
-        return self._plugin_configs[plugin_name]
-
-    @contextmanager
-    def using_project(
-        self, project_folder: Path, contracts_folder: Optional[Path] = None, **config
-    ) -> Generator["ProjectManager", None, None]:
+            destination (Path): The path to write to.
+            replace (bool): Set to ``True`` to overwrite the file if it exists.
         """
-        Temporarily change the project context.
-
-        Usage example::
+        if destination.exists() and not replace:
+            raise ValueError(f"Destination {destination} exists.")
+        elif replace:
+            destination.unlink(missing_ok=True)
+
+        if destination.suffix in (".yml", ".yaml"):
+            destination.parent.mkdir(parents=True, exist_ok=True)
+            with open(destination, "x") as file:
+                data = self.model_dump(by_alias=True, mode="json")
+                yaml.safe_dump(data, file)
 
-            from pathlib import Path
-            from ape import config, Project
+        elif destination.suffix == ".json":
+            destination.write_text(self.model_dump_json(by_alias=True))
 
-            project_path = Path("path/to/project")
-            contracts_path = project_path / "contracts"
-
-            with config.using_project(project_path):
-                my_project = Project(project_path)
-
-        Args:
-            project_folder (pathlib.Path): The path of the context's project.
-            contracts_folder (Optional[pathlib.Path]): The path to the context's source files.
-              Defaults to ``<project_path>/contracts``.
+        else:
+            raise ValueError(f"Unsupported destination file type {destination}.")
 
-        Returns:
-            Generator
-        """
 
-        initial_project_folder = self.project_manager.path
-        initial_contracts_folder = self.contracts_folder
+def _get_compile_configs_from_manifest(manifest: PackageManifest) -> dict[str, dict]:
+    configs: dict[str, dict] = {}
+    for compiler in [x for x in manifest.compilers or [] if x.settings]:
+        name = compiler.name.strip().lower()
+        compiler_data = {}
+        settings = compiler.settings or {}
+        remapping_list = []
+        for remapping in settings.get("remappings") or []:
+            parts = remapping.split("=")
+            key = parts[0]
+            link = parts[1]
+            if link.startswith(f".cache{os.path.sep}"):
+                link = os.path.sep.join(link.split(f".cache{os.path.sep}"))[1:]
+
+            new_entry = f"{key}={link}"
+            remapping_list.append(new_entry)
+
+        if remapping_list:
+            compiler_data["import_remapping"] = remapping_list
+
+        if "evm_version" in settings:
+            compiler_data["evm_version"] = settings["evm_version"]
+
+        if compiler_data:
+            configs[name] = compiler_data
+
+    return configs
+
+
+def _get_dependency_configs_from_manifest(manifest: PackageManifest) -> dict:
+    dependencies_config: list[dict] = []
+    dependencies = manifest.dependencies or {}
+    for package_name, uri in dependencies.items():
+        if "://" not in str(uri) and hasattr(uri, "scheme"):
+            uri_str = f"{uri.scheme}://{uri}"
+        else:
+            uri_str = str(uri)
 
-        if initial_project_folder == project_folder and (
-            not contracts_folder or initial_contracts_folder == contracts_folder
-        ):
-            # Already in project.
-            yield self.project_manager
-            return
-
-        self.PROJECT_FOLDER = project_folder
-        self.contracts_folder = (
-            contracts_folder if contracts_folder else project_folder / "contracts"
-        )
-        self.project_manager.path = project_folder
-        os.chdir(project_folder)
-        clean_config = False
-
-        try:
-            # Process and reload the project's configuration
-            project = self.project_manager.get_project(
-                project_folder, contracts_folder=contracts_folder
-            )
-            clean_config = project.process_config_file(contracts_folder=contracts_folder, **config)
-            self.load(force_reload=True)
-            yield self.project_manager
-
-        finally:
-            temp_project_path = self.project_manager.path
-            self.PROJECT_FOLDER = initial_project_folder
-            self.contracts_folder = initial_contracts_folder
-            self.project_manager.path = initial_project_folder
-
-            if initial_project_folder.is_dir():
-                os.chdir(initial_project_folder)
-
-            config_file = temp_project_path / CONFIG_FILE_NAME
-            if clean_config and config_file.is_file():
-                config_file.unlink()
+        dependency: dict = {"name": str(package_name)}
+        if uri_str.startswith("https://github.com/") and "releases/tag" in uri_str:
+            # 'https:', '', 'github.com', org, repo, 'releases', 'tag', version
+            # Fails with ValueError if not matching
+            try:
+                _, _, _, org, repo, _, _, version = uri_str.split("/")
+            except ValueError:
+                raise ConfigError("")
 
+            dependency["github"] = f"{org}/{repo}"
 
-def merge_configs(base: Dict, secondary: Dict) -> Dict:
-    result: Dict = {}
+            # If version fails, the dependency system will automatically try `ref`.
+            dependency["version"] = version
 
-    # Short circuits
-    if not base and not secondary:
-        return result
-    elif not base:
-        return secondary
-    elif not secondary:
-        return base
-
-    for key, value in base.items():
-        if key not in secondary:
-            result[key] = value
-
-        elif not isinstance(value, dict):
-            # Is a primitive value found in both configs.
-            # Must use the second one.
-            result[key] = secondary[key]
+        elif uri_str.startswith("file://"):
+            dependency["local"] = uri_str.replace("file://", "")
 
         else:
-            # Merge the dictionaries.
-            sub = merge_configs(base[key], secondary[key])
-            result[key] = sub
-
-    # Add missed keys from secondary.
-    for key, value in secondary.items():
-        if key not in base:
-            result[key] = value
+            logger.error(f"Manifest URI {uri_str} not a supported dependency.")
+            continue
+
+        dependencies_config.append(dependency)
 
-    return result
+    return {"dependencies": dependencies_config} if dependencies_config else {}
```

### Comparing `eth-ape-0.7.9/src/ape/managers/converters.py` & `eth-ape-0.8.0/src/ape/managers/converters.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,38 +1,40 @@
+import re
+from collections.abc import Sequence
 from datetime import datetime, timedelta, timezone
 from decimal import Decimal
-from typing import Any, Dict, List, Sequence, Tuple, Type, Union
+from typing import Any, Union
 
-from dateutil.parser import parse  # type: ignore
-from eth_pydantic_types import HexBytes
+from dateutil.parser import parse
+from eth_pydantic_types import Address, HexBytes
 from eth_typing.evm import ChecksumAddress
 from eth_utils import (
     is_0x_prefixed,
     is_checksum_address,
     is_hex,
     is_hex_address,
     to_checksum_address,
-    to_hex,
     to_int,
 )
 from ethpm_types import ConstructorABI, EventABI, MethodABI
 
 from ape.api import ConverterAPI, TransactionAPI
 from ape.api.address import BaseAddress
 from ape.exceptions import ConversionError
+from ape.logging import logger
 from ape.types import AddressType
-from ape.utils import cached_property
+from ape.utils import cached_property, log_instead_of_fail
 
 from .base import BaseManager
 
 
-# NOTE: This utility converter ensures that all bytes args can accept hex too
 class HexConverter(ConverterAPI):
     """
     A converter that converts ``str`` to ``HexBytes``.
+    NOTE: This utility converter ensures that all bytes args can accept hex too
     """
 
     def is_convertible(self, value: Any) -> bool:
         return (
             (isinstance(value, str) and is_hex(value) and is_0x_prefixed(value))
             or isinstance(value, bytes)
             or isinstance(value, int)
@@ -144,19 +146,51 @@
 
 
 class IntAddressConverter(ConverterAPI):
     """
     A converter that converts an integer address to an :class:`~ape.types.address.AddressType`.
     """
 
+    _cache: dict[int, Union[AddressType, bool]] = {}
+
     def is_convertible(self, value: Any) -> bool:
-        return isinstance(value, int) and is_hex_address(to_hex(value))
+        if not isinstance(value, int):
+            return False
+        elif isinstance(self._cache.get(value), str):
+            return True
+
+        val = self._convert(value)
+        self._cache[value] = val
+        return isinstance(val, str)
 
     def convert(self, value: Any) -> AddressType:
-        return to_checksum_address(to_hex(value))
+        err_msg = f"Failed to convert '{value}' to 'AddressType'."
+        if cached_val := self._cache.get(value):
+            if not isinstance(cached_val, str):
+                # Shouldn't get here in normal execution.
+                raise ConversionError(err_msg)
+
+            return cached_val
+
+        # Shouldn't get here in normal execution.
+        res = self._convert(value)
+        self._cache[value] = res
+
+        if not isinstance(res, str):
+            raise ConversionError(err_msg)
+
+        return res
+
+    def _convert(self, value: int) -> Union[AddressType, bool]:
+        try:
+            val = Address.__eth_pydantic_validate__(value)
+        except Exception:
+            return False
+
+        return AddressType(to_checksum_address(val))
 
 
 class TimestampConverter(ConverterAPI):
     """
     Converts either a string, datetime object, or a timedelta object to a timestamp.
     No timezone required, but should be formatted to UTC.
     """
@@ -181,14 +215,30 @@
             return int(value.replace(tzinfo=timezone.utc).timestamp())
         elif isinstance(value, timedelta):
             return int((datetime.now(timezone.utc) + value).timestamp())
         else:
             raise ConversionError()
 
 
+class StringDecimalConverter(ConverterAPI):
+    """
+    Convert string-formatted floating point values to `Decimal` type.
+    """
+
+    def is_convertible(self, value: Any) -> bool:
+        # Matches only string-formatted floats with an optional sign character (+/-).
+        # Leading and trailing zeros are required.
+        # NOTE: `re.fullmatch` will only match the full string, so "1.0 ether" and "10.0 USDC"
+        # will not be identified as convertible.
+        return isinstance(value, str) and re.fullmatch(r"[+-]?\d+\.\d+", value) is not None
+
+    def convert(self, value: str) -> Decimal:
+        return Decimal(value)
+
+
 class ConversionManager(BaseManager):
     """
     A singleton that manages all the converters.
 
     **NOTE**: typically, users will not interact with this class directly,
     but rather its ``convert()`` method, which is accessible from
     the root ``ape`` namespace.
@@ -196,34 +246,35 @@
     Usage example::
 
         from ape import convert
 
         amount = convert("1 gwei", int)
     """
 
-    def __repr__(self):
+    @log_instead_of_fail(default="<DependencyAPI>")
+    def __repr__(self) -> str:
         return f"<{ConversionManager.__name__}>"
 
     @cached_property
-    def _converters(self) -> Dict[Type, List[ConverterAPI]]:
-        converters: Dict[Type, List[ConverterAPI]] = {
+    def _converters(self) -> dict[type, list[ConverterAPI]]:
+        converters: dict[type, list[ConverterAPI]] = {
             AddressType: [
                 AddressAPIConverter(),
                 BytesAddressConverter(),
                 HexAddressConverter(),
                 IntAddressConverter(),
             ],
             bytes: [HexConverter()],
             int: [
                 TimestampConverter(),
                 HexIntConverter(),
                 StringIntConverter(),
                 AccountIntConverter(),
             ],
-            Decimal: [],
+            Decimal: [StringDecimalConverter()],
             bool: [],
             str: [],
         }
 
         for plugin_name, (conversion_type, converter_class) in self.plugin_manager.converters:
             converter = converter_class()
             if conversion_type is ChecksumAddress:
@@ -234,86 +285,95 @@
                 options = ", ".join([_get_type_name_from_type(t) for t in converters])
                 raise ConversionError(f"Type '{conversion_type}' must be one of [{options}].")
 
             converters[conversion_type].append(converter)
 
         return converters
 
-    def is_type(self, value: Any, type: Type) -> bool:
+    def is_type(self, value: Any, to_type: type) -> bool:
         """
         Check if the value is the given type.
         If given an :class:`~ape.types.address.AddressType`, will also check
         that it is checksummed.
 
         Args:
             value (any): The value to check.
-            type (type): The type to check against.
+            to_type (type): The type to check against.
 
         Returns:
             bool: ``True`` when we consider the given value to be the given type.
         """
+        return is_checksum_address(value) if to_type is AddressType else isinstance(value, to_type)
 
-        return is_checksum_address(value) if type is AddressType else isinstance(value, type)
-
-    def convert(self, value: Any, type: Union[Type, Tuple, List]) -> Any:
+    def convert(self, value: Any, to_type: Union[type, tuple, list]) -> Any:
         """
         Convert the given value to the given type. This method accesses
         all :class:`~ape.api.convert.ConverterAPI` instances known to
         `ape`` and selects the appropriate one, so long that it exists.
 
         Raises:
             :class:`~ape.exceptions.ConversionError`: When there is not a registered
               converter for the given arguments.
 
         Args:
             value (any): The value to convert.
-            type (type): The type to convert the value to.
+            to_type (to_type): The type to convert the value to.
 
         Returns:
             any: The same given value but with the new given type.
         """
 
-        if isinstance(value, (list, tuple)) and isinstance(type, tuple):
+        if isinstance(value, (list, tuple)) and isinstance(to_type, tuple):
             # We expected to convert a tuple type, so convert each item in the tuple.
             # NOTE: We allow values to be a list, just in case it is a list
-            return [self.convert(v, t) for v, t in zip(value, type)]
+            return [self.convert(v, t) for v, t in zip(value, to_type)]
 
-        elif isinstance(value, (list, tuple)) and isinstance(type, list) and len(type) == 1:
+        elif isinstance(value, (list, tuple)) and isinstance(to_type, list) and len(to_type) == 1:
             # We expected to convert an array type(dynamic or static),
             # so convert each item in the list.
             # NOTE: type for static and dynamic array is a single item
             #  list containing the type of the array.
-            return [self.convert(v, type[0]) for v in value]
+            return [self.convert(v, to_type[0]) for v in value]
 
-        elif isinstance(type, (list, tuple)):
+        elif isinstance(to_type, (list, tuple)):
             raise ConversionError(
                 f"Value '{value}' must be a list or tuple when given multiple types."
             )
 
-        elif type is ChecksumAddress:
+        elif to_type is ChecksumAddress:
             # Use our Annotated alias.
             return self.convert(value, AddressType)
 
-        elif type not in self._converters:
+        elif to_type not in self._converters:
             options = ", ".join([_get_type_name_from_type(t) for t in self._converters])
-            raise ConversionError(f"Type '{type}' must be one of [{options}].")
+            raise ConversionError(f"Type '{to_type}' must be one of [{options}].")
 
-        elif self.is_type(value, type) and not isinstance(value, (list, tuple)):
+        elif self.is_type(value, to_type) and not isinstance(value, (list, tuple)):
             # NOTE: Always process lists and tuples
             return value
 
-        for converter in self._converters[type]:
-            if not converter.is_convertible(value):
+        for converter in self._converters[to_type]:
+            try:
+                is_convertible = converter.is_convertible(value)
+            except Exception as err:
+                # If errors while checking if we can convert, log the error
+                # and assume it's not convertible.
+                converter_name = converter.__class__.__name__
+                msg = f"Issue while checking `{converter_name}.is_convertible()`: {err}"
+                logger.error(msg)
+                continue
+
+            if not is_convertible:
                 continue
 
             try:
                 return converter.convert(value)
             except Exception as err:
                 try:
-                    error_value = f" '{value}' "
+                    error_value = f" '{value}' (type={type(value)}) "
                 except Exception:
                     error_value = " "
 
                 message = f"Failed to convert{error_value}"
                 if converter_type_name := getattr(type(converter), "__name__", None):
                     message = f"{message}using '{converter_type_name}'."
 
@@ -335,15 +395,15 @@
                 converted_value = self.convert(argument, AddressType)
                 converted_arguments.append(converted_value)
             else:
                 converted_arguments.append(argument)
 
         return converted_arguments
 
-    def convert_method_kwargs(self, kwargs) -> Dict:
+    def convert_method_kwargs(self, kwargs) -> dict:
         fields = TransactionAPI.model_fields
 
         def get_real_type(type_):
             all_types = getattr(type_, "_typevar_types", [])
             if not all_types or not isinstance(all_types, (list, tuple)):
                 return type_
 
@@ -374,15 +434,15 @@
                 converted_value = value
 
             converted_fields[field_name] = converted_value
 
         return {**kwargs, **converted_fields}
 
 
-def _get_type_name_from_type(var_type: Type) -> str:
+def _get_type_name_from_type(var_type: type) -> str:
     if hasattr(var_type, "__args__") and var_type.__args__:
         # Is Annotated
         real_type = var_type.__args__[0]
         return _get_type_name_from_type(real_type)
 
     elif var_type is ChecksumAddress:
         return "AddressType"  # Use our alias
```

### Comparing `eth-ape-0.7.9/src/ape/managers/networks.py` & `eth-ape-0.8.0/src/ape/managers/networks.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,46 +1,45 @@
-import json
+from collections.abc import Collection, Iterator
 from functools import cached_property
-from typing import Collection, Dict, Iterator, List, Optional, Set, Type, Union
-
-import yaml
+from typing import Optional, Union
 
 from ape.api import EcosystemAPI, ProviderAPI, ProviderContextManager
 from ape.api.networks import NetworkAPI
-from ape.exceptions import (
-    ApeAttributeError,
-    EcosystemNotFoundError,
-    NetworkError,
-    NetworkNotFoundError,
-)
+from ape.exceptions import EcosystemNotFoundError, NetworkError, NetworkNotFoundError
 from ape.managers.base import BaseManager
-from ape.utils.basemodel import _assert_not_ipython_check
-from ape.utils.misc import _dict_overlay
+from ape.utils.basemodel import (
+    ExtraAttributesMixin,
+    ExtraModelAttributes,
+    get_attribute_with_extras,
+    only_raise_attribute_error,
+)
+from ape.utils.misc import _dict_overlay, log_instead_of_fail
 from ape_ethereum.provider import EthereumNodeProvider
 
 
-class NetworkManager(BaseManager):
+class NetworkManager(BaseManager, ExtraAttributesMixin):
     """
     The set of all blockchain network ecosystems registered from the plugin system.
     Typically, you set the provider via the ``--network`` command line option.
     However, use this singleton for more granular access to networks.
 
     Usage example::
 
         from ape import networks
 
         # "networks" is the NetworkManager singleton
-        with networks.ethereum.mainnet.use_provider("geth"):
+        with networks.ethereum.mainnet.use_provider("node"):
            ...
     """
 
     _active_provider: Optional[ProviderAPI] = None
     _default_ecosystem_name: Optional[str] = None
 
-    def __repr__(self):
+    @log_instead_of_fail(default="<NetworkManager>")
+    def __repr__(self) -> str:
         provider = self.active_provider
         class_name = NetworkManager.__name__
         content = f"{class_name} active_provider={repr(provider)}" if provider else class_name
         return f"<{content}>"
 
     @property
     def active_provider(self) -> Optional[ProviderAPI]:
@@ -81,15 +80,15 @@
             :class:`~ape.api.providers.ProviderAPI`
         """
         return self.network.ecosystem
 
     def fork(
         self,
         provider_name: Optional[str] = None,
-        provider_settings: Optional[Dict] = None,
+        provider_settings: Optional[dict] = None,
         block_number: Optional[int] = None,
     ) -> ProviderContextManager:
         """
         Fork the currently connected network.
 
         Args:
             provider_name (str, optional): The name of the provider to get. Defaults to ``None``.
@@ -105,152 +104,149 @@
         """
         try:
             forked_network = self.ecosystem.get_network(f"{self.network.name}-fork")
         except NetworkNotFoundError as err:
             raise NetworkError(f"Unable to fork network '{self.network.name}'.") from err
 
         provider_settings = provider_settings or {}
-
+        fork_settings = {}
         if block_number is not None:
             # Negative block_number means relative to HEAD
             if block_number < 0:
                 latest_block_number = self.provider.get_block("latest").number or 0
                 block_number = latest_block_number + block_number
                 if block_number < 0:
                     # If the block number is still negative, they have forked past genesis.
                     raise NetworkError("Unable to fork past genesis block.")
 
             # Ensure block_number is set in config for this network
-            _dict_overlay(
-                provider_settings,
-                {
-                    "fork": {
-                        self.ecosystem.name: {self.network.name: {"block_number": block_number}}
-                    }
-                },
-            )
+            fork_settings["block_number"] = block_number
+
+        if uri := self.provider.connection_str:
+            fork_settings["upstream_provider"] = uri
+
+        _dict_overlay(
+            provider_settings,
+            {"fork": {self.ecosystem.name: {self.network.name: fork_settings}}},
+        )
 
         shared_kwargs: dict = {"provider_settings": provider_settings, "disconnect_after": True}
         return (
             forked_network.use_provider(provider_name, **shared_kwargs)
             if provider_name
             else forked_network.use_default_provider(**shared_kwargs)
         )
 
     @property
-    def ecosystem_names(self) -> Set[str]:
+    def ecosystem_names(self) -> set[str]:
         """
         The set of all ecosystem names in ``ape``.
         """
 
         return set(self.ecosystems)
 
     @property
-    def network_names(self) -> Set[str]:
+    def network_names(self) -> set[str]:
         """
         The set of all network names in ``ape``.
         """
 
         return {n for e in self.ecosystems.values() for n in e.networks}
 
     @property
-    def provider_names(self) -> Set[str]:
+    def provider_names(self) -> set[str]:
         """
         The set of all provider names in ``ape``.
         """
 
         return set(
             provider
             for ecosystem in self.ecosystems.values()
             for network in ecosystem.networks.values()
             for provider in network.providers
         )
 
     @property
-    def ecosystems(self) -> Dict[str, EcosystemAPI]:
+    def ecosystems(self) -> dict[str, EcosystemAPI]:
         """
         All the registered ecosystems in ``ape``, such as ``ethereum``.
         """
-        ecosystem_objs = self._plugin_ecosystems
+        plugin_ecosystems = self._plugin_ecosystems
 
         # Load config.
-        custom_networks: List = self.config_manager.get_config("networks").get("custom", [])
+        custom_networks: list = self.config_manager.get_config("networks").get("custom", [])
         for custom_network in custom_networks:
             ecosystem_name = custom_network.ecosystem
-            if ecosystem_name in ecosystem_objs:
+            if ecosystem_name in plugin_ecosystems:
                 # Already included in previous network.
                 continue
 
             base_ecosystem_name = (
                 custom_network.get("base_ecosystem_plugin") or self.default_ecosystem_name
             )
-            existing_cls = ecosystem_objs[base_ecosystem_name]
+            existing_cls = plugin_ecosystems[base_ecosystem_name]
             ecosystem_cls = existing_cls.model_copy(
                 update={"name": ecosystem_name}, cache_clear=("_networks_from_plugins",)
             )
-            ecosystem_objs[ecosystem_name] = ecosystem_cls
+            plugin_ecosystems[ecosystem_name] = ecosystem_cls
 
-        return ecosystem_objs
+        return plugin_ecosystems
 
     @cached_property
-    def _plugin_ecosystems(self) -> Dict[str, EcosystemAPI]:
-        def to_kwargs(name: str) -> Dict:
-            return {
-                "name": name,
-                "data_folder": self.config_manager.DATA_FOLDER / name,
-                "request_header": self.config_manager.REQUEST_HEADER,
-            }
+    def _plugin_ecosystems(self) -> dict[str, EcosystemAPI]:
+        def to_kwargs(name: str) -> dict:
+            return {"name": name, "request_header": self.config_manager.REQUEST_HEADER}
 
         # Load plugins.
         plugins = self.plugin_manager.ecosystems
         return {n: cls(**to_kwargs(n)) for n, cls in plugins}  # type: ignore[operator]
 
     def create_custom_provider(
         self,
         connection_str: str,
-        provider_cls: Type[ProviderAPI] = EthereumNodeProvider,
+        provider_cls: type[ProviderAPI] = EthereumNodeProvider,
         provider_name: Optional[str] = None,
     ) -> ProviderAPI:
         """
         Create a custom connection to a URI using the EthereumNodeProvider provider.
         **NOTE**: This provider will assume EVM-like behavior and this is generally not recommended.
         Use plugins when possible!
 
         Args:
             connection_str (str): The connection string of the node, such as its URI
               when using HTTP.
-            provider_cls (Type[:class:`~ape.api.providers.ProviderAPI`]): Defaults to
+            provider_cls (type[:class:`~ape.api.providers.ProviderAPI`]): Defaults to
               :class:`~ape_ethereum.providers.EthereumNodeProvider`.
             provider_name (Optional[str]): The name of the provider. Defaults to best guess.
 
         Returns:
             :class:`~ape.api.providers.ProviderAPI`: The Geth provider
               implementation that comes with Ape.
         """
 
         network = self.ethereum.custom_network
 
         if provider_name is None:
             if issubclass(provider_cls, EthereumNodeProvider):
-                name = "geth"
+                name = "node"
 
             elif cls_name := getattr(provider_cls, "name", None):
                 name = cls_name
 
             elif cls_name := getattr(provider_cls, "__name__"):
                 name = cls_name.lower()
 
             else:
                 # Would be unusual for this to happen though.
                 name = "provider"
 
         else:
             name = provider_name
 
-        provider_settings: Dict = {}
+        provider_settings: dict = {}
         if connection_str.startswith("https://") or connection_str.startswith("http://"):
             provider_settings["uri"] = connection_str
         elif connection_str.endswith(".ipc"):
             provider_settings["ipc_path"] = connection_str
         else:
             raise NetworkError(f"Scheme for '{connection_str}' not yet supported.")
 
@@ -267,80 +263,62 @@
         All the managed ecosystems in ``ape``, as an iterable.
 
         Returns:
             Iterator[:class:`~ape.api.networks.EcosystemAPI`]
         """
         yield from self.ecosystems
 
-    def __getitem__(self, ecosystem_name: str) -> EcosystemAPI:
-        """
-        Get an ecosystem by name.
-
-        Raises:
-            :class:`~ape.exceptions.NetworkError`: When the given ecosystem name is
-              unknown.
-
-        Args:
-            ecosystem_name (str): The name of the ecosystem to get.
-
-        Returns:
-            :class:`~ape.api.networks.EcosystemAPI`
-        """
-        if ecosystem_name not in self.ecosystems:
-            raise IndexError(f"Unknown ecosystem '{ecosystem_name}'.")
-
-        return self.ecosystems[ecosystem_name]
+    def __ape_extra_attributes__(self) -> Iterator[ExtraModelAttributes]:
+        yield ExtraModelAttributes(
+            name="ecosystems",
+            attributes=lambda: self.ecosystems,
+            include_getitem=True,
+        )
 
+    @only_raise_attribute_error
     def __getattr__(self, attr_name: str) -> EcosystemAPI:
         """
         Get an ecosystem via ``.`` access.
 
         Args:
             attr_name (str): The name of the ecosystem.
 
         Returns:
             :class:`~ape.api.networks.EcosystemAPI`
 
         Usage example::
 
             eth = networks.ethereum
         """
-        _assert_not_ipython_check(attr_name)
-        options = {attr_name, attr_name.replace("-", "_"), attr_name.replace("_", "-")}
-        ecosystems = self.ecosystems
-        for opt in options:
-            if opt in ecosystems:
-                return ecosystems[opt]
-
-        raise ApeAttributeError(f"{NetworkManager.__name__} has no attribute '{attr_name}'.")
+        return get_attribute_with_extras(self, attr_name)
 
     def get_network_choices(
         self,
-        ecosystem_filter: Optional[Union[List[str], str]] = None,
-        network_filter: Optional[Union[List[str], str]] = None,
-        provider_filter: Optional[Union[List[str], str]] = None,
+        ecosystem_filter: Optional[Union[list[str], str]] = None,
+        network_filter: Optional[Union[list[str], str]] = None,
+        provider_filter: Optional[Union[list[str], str]] = None,
     ) -> Iterator[str]:
         """
         The set of all possible network choices available as a "network selection"
         e.g. ``--network [ECOSYSTEM:NETWORK:PROVIDER]``.
 
         Each value is in the form ``ecosystem:network:provider`` and shortened options also
-        appear in the list. For example, ``::geth`` would default to ``:ethereum:local:geth``
+        appear in the list. For example, ``::node`` would default to ``:ethereum:local:node``
         and both will be in the returned list. The values come from each
         :class:`~ape.api.providers.ProviderAPI` that is installed.
 
         Use the CLI command ``ape networks list`` to list all the possible network
         combinations.
 
         Args:
-            ecosystem_filter (Optional[Union[List[str], str]]): Get only the specified ecosystems.
+            ecosystem_filter (Optional[Union[list[str], str]]): Get only the specified ecosystems.
               Defaults to getting all ecosystems.
-            network_filter (Optional[Union[List[str], str]]): Get only the specified networks.
+            network_filter (Optional[Union[list[str], str]]): Get only the specified networks.
               Defaults to getting all networks in ecosystems.
-            provider_filter (Optional[Union[List[str], str]]): Get only the specified providers.
+            provider_filter (Optional[Union[list[str], str]]): Get only the specified providers.
               Defaults to getting all providers in networks.
 
         Returns:
             Iterator[str]: An iterator over all the network-choice possibilities.
         """
 
         ecosystem_filter = _validate_filter(ecosystem_filter, self.ecosystem_names)
@@ -416,15 +394,15 @@
             raise EcosystemNotFoundError(ecosystem_name, options=self.ecosystem_names)
 
         return self.ecosystems[ecosystem_name]
 
     def get_provider_from_choice(
         self,
         network_choice: Optional[str] = None,
-        provider_settings: Optional[Dict] = None,
+        provider_settings: Optional[dict] = None,
     ) -> ProviderAPI:
         """
         Get a :class:`~ape.api.providers.ProviderAPI` from a network choice.
         A network choice is any value returned from
         :meth:`~ape.managers.networks.NetworkManager.get_network_choices`. Use the
         CLI command ``ape networks list`` to list all the possible network
         combinations.
@@ -491,15 +469,15 @@
         else:
             # NOTE: Might be unreachable
             raise NetworkError("Invalid network selection.")
 
     def parse_network_choice(
         self,
         network_choice: Optional[str] = None,
-        provider_settings: Optional[Dict] = None,
+        provider_settings: Optional[dict] = None,
         disconnect_after: bool = False,
         disconnect_on_exit: bool = True,
     ) -> ProviderContextManager:
         """
         Parse a network choice into a context manager for managing a temporary
         connection to a provider. See
         :meth:`~ape.managers.networks.NetworkManager.get_network_choices` for all
@@ -567,15 +545,15 @@
         if ecosystem_name in self.ecosystem_names:
             self._default_ecosystem_name = ecosystem_name
 
         else:
             raise EcosystemNotFoundError(ecosystem_name, options=self.ecosystem_names)
 
     @property
-    def network_data(self) -> Dict:
+    def network_data(self) -> dict:
         """
         Get a dictionary containing data about networks in the ecosystem.
 
         **NOTE**: The keys are added in an opinionated order for nicely
         translating into ``yaml``.
 
         Returns:
@@ -585,15 +563,15 @@
 
     def get_network_data(
         self,
         ecosystem_filter: Optional[Collection[str]] = None,
         network_filter: Optional[Collection[str]] = None,
         provider_filter: Optional[Collection[str]] = None,
     ):
-        data: Dict = {"ecosystems": []}
+        data: dict = {"ecosystems": []}
 
         for ecosystem_name in self:
             if ecosystem_filter and ecosystem_name not in ecosystem_filter:
                 continue
 
             ecosystem_data = self._get_ecosystem_data(
                 ecosystem_name, network_filter=network_filter, provider_filter=provider_filter
@@ -603,17 +581,17 @@
         return data
 
     def _get_ecosystem_data(
         self,
         ecosystem_name: str,
         network_filter: Optional[Collection[str]] = None,
         provider_filter: Optional[Collection[str]] = None,
-    ) -> Dict:
+    ) -> dict:
         ecosystem = self[ecosystem_name]
-        ecosystem_data: Dict = {"name": str(ecosystem_name)}
+        ecosystem_data: dict = {"name": str(ecosystem_name)}
 
         # Only add isDefault key when True
         if ecosystem_name == self.default_ecosystem.name:
             ecosystem_data["isDefault"] = True
 
         ecosystem_data["networks"] = []
         networks = getattr(self, ecosystem_name).networks
@@ -623,49 +601,16 @@
                 continue
 
             network_data = ecosystem.get_network_data(network_name, provider_filter=provider_filter)
             ecosystem_data["networks"].append(network_data)
 
         return ecosystem_data
 
-    @property
-    # TODO: Remove in 0.7
-    def networks_yaml(self) -> str:
-        """
-        Get a ``yaml`` ``str`` representing all the networks
-        in all the ecosystems.
-        **NOTE**: Deprecated.
-
-        View the result via CLI command ``ape networks list --format yaml``.
-
-        Returns:
-            str
-        """
-
-        data = self.network_data
-        if not isinstance(data, dict):
-            raise TypeError(
-                f"Unexpected network data type: {type(data)}. "
-                f"Expecting dict. YAML dump will fail."
-            )
-
-        try:
-            return yaml.dump(data, sort_keys=True)
-        except ValueError as err:
-            try:
-                data_str = json.dumps(data)
-            except Exception:
-                data_str = str(data)
-
-            raise NetworkError(
-                f"Network data did not dump to YAML: {data_str}\nActual err: {err}"
-            ) from err
-
 
-def _validate_filter(arg: Optional[Union[List[str], str]], options: Set[str]):
+def _validate_filter(arg: Optional[Union[list[str], str]], options: set[str]):
     filters = arg or []
 
     if isinstance(filters, str):
         filters = [filters]
 
     for _filter in filters:
         if _filter not in options:
```

### Comparing `eth-ape-0.7.9/src/ape/managers/project/types.py` & `eth-ape-0.8.0/src/ape/types/__init__.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,363 +1,500 @@
-import os
-from pathlib import Path
-from typing import Any, Dict, List, Optional, Sequence
-
-from ethpm_types import ContractType, PackageManifest, Source
-from ethpm_types.utils import compute_checksum
-from yaml import safe_dump, safe_load
-
-from ape.api import ProjectAPI
-from ape.logging import logger
-from ape.managers.config import CONFIG_FILE_NAME as APE_CONFIG_FILE_NAME
-from ape.utils import cached_property, get_all_files_in_directory, get_relative_path
-
-
-class _ProjectSources:
-    # NOTE: This class is an implementation detail and excluded from the public API.
-    # It helps with diff calculations between the project's cached manifest sources
-    # and the current, active sources. It's used to determine what files to compile when
-    # running `ape compile`.
-
-    def __init__(
-        self,
-        cached_manifest: PackageManifest,
-        active_sources: Sequence[Path],
-        contracts_folder: Path,
-        cache_folder: Path,
-    ):
-        self.cached_manifest = cached_manifest
-        self.active_sources = active_sources
-        self.contracts_folder = contracts_folder
-        self.cache_folder = cache_folder
+from collections.abc import Callable, Iterator, Sequence
+from dataclasses import dataclass
+from typing import TYPE_CHECKING, Any, Literal, Optional, TypeVar, Union, cast, overload
+
+from eth_abi.abi import encode
+from eth_abi.packed import encode_packed
+from eth_pydantic_types import HexBytes
+from eth_typing import Hash32, HexStr
+from eth_utils import encode_hex, keccak, to_hex
+from ethpm_types import (
+    ABI,
+    Bytecode,
+    Checksum,
+    Compiler,
+    ContractType,
+    PackageManifest,
+    PackageMeta,
+    Source,
+)
+from ethpm_types.abi import EventABI
+from ethpm_types.source import Closure
+from pydantic import BaseModel, field_validator, model_validator
+from web3.types import FilterParams
+
+from ape.types.address import AddressType, RawAddress
+from ape.types.coverage import (
+    ContractCoverage,
+    ContractSourceCoverage,
+    CoverageProject,
+    CoverageReport,
+    CoverageStatement,
+)
+from ape.types.signatures import MessageSignature, SignableMessage, TransactionSignature
+from ape.types.trace import ControlFlow, GasReport, SourceTraceback
+from ape.utils import (
+    BaseInterfaceModel,
+    ExtraAttributesMixin,
+    ExtraModelAttributes,
+    cached_property,
+)
+from ape.utils.misc import ZERO_ADDRESS, log_instead_of_fail, to_int
+
+if TYPE_CHECKING:
+    from ape.api.providers import BlockAPI
+    from ape.contracts import ContractEvent
+
+BlockID = Union[int, HexStr, HexBytes, Literal["earliest", "latest", "pending"]]
+"""
+An ID that can match a block, such as the literals ``"earliest"``, ``"latest"``, or ``"pending"``
+as well as a block number or hash (HexBytes).
+"""
+
+ContractCode = Union[str, bytes, HexBytes]
+"""
+A type that represents contract code, which can be represented in string, bytes, or HexBytes.
+"""
+
+SnapshotID = Union[str, int, bytes]
+"""
+An ID representing a point in time on a blockchain, as used in the
+:meth:`~ape.managers.chain.ChainManager.snapshot` and
+:meth:`~ape.managers.chain.ChainManager.snapshot` methods. Can be a ``str``, ``int``, or ``bytes``.
+Providers will expect and handle snapshot IDs differently. There shouldn't be a need to change
+providers when using this feature, so there should not be confusion over this type in practical use
+cases.
+"""
 
-    @cached_property
-    def cached_sources(self) -> Dict[str, Source]:
-        return self.cached_manifest.sources or {}
 
-    @cached_property
-    def remaining_cached_contract_types(self) -> Dict[str, ContractType]:
-        cached_contract_types = self.cached_manifest.contract_types or {}
+class AutoGasLimit(BaseModel):
+    """
+    Additional settings for ``gas_limit: auto``.
+    """
 
-        # Filter out deleted sources.
-        deleted_source_ids = self.cached_sources.keys() - set(
-            map(str, [get_relative_path(p, self.contracts_folder) for p in self.active_sources])
-        )
-        return {
-            name: contract_type
-            for name, contract_type in cached_contract_types.items()
-            if contract_type.source_id not in deleted_source_ids
-        }
+    multiplier: float = 1.0
+    """
+    A multiplier to estimated gas.
+    """
 
-    @cached_property
-    def sources_needing_compilation(self) -> List[Path]:
-        needs_compile = set(filter(self._check_needs_compiling, self.active_sources))
+    @field_validator("multiplier", mode="before")
+    @classmethod
+    def validate_multiplier(cls, value):
+        if isinstance(value, str):
+            return float(value)
 
-        # NOTE: Add referring path imports for each source path
-        all_referenced_paths: List[Path] = []
-        sources_to_check_refs = needs_compile.copy()
-        while sources_to_check_refs:
-            source_id = str(get_relative_path(sources_to_check_refs.pop(), self.contracts_folder))
-            reference_paths = [
-                s for s in self._source_reference_paths.get(source_id, []) if s.is_file()
-            ]
-            all_referenced_paths.extend(reference_paths)
-            needs_compile.update(reference_paths)
+        return value
 
-        needs_compile.update(all_referenced_paths)
-        return list(needs_compile)
 
-    @cached_property
-    def _source_reference_paths(self) -> Dict[str, List[Path]]:
-        return {
-            source_id: [self.contracts_folder.joinpath(Path(s)) for s in source.references or []]
-            for source_id, source in self.cached_sources.items()
+GasLimit = Union[Literal["auto", "max"], int, str, AutoGasLimit]
+"""
+A value you can give to Ape for handling gas-limit calculations.
+``"auto"`` refers to automatically figuring out the gas,
+``"max"`` refers to using the maximum block gas limit,
+and otherwise you can provide a numeric value.
+"""
+
+
+TopicFilter = Sequence[Union[Optional[HexStr], Sequence[Optional[HexStr]]]]
+
+
+@dataclass
+class ContractFunctionPath:
+    """
+    Useful for identifying a method in a contract.
+    """
+
+    contract_name: str
+    method_name: Optional[str] = None
+
+    @classmethod
+    def from_str(cls, value: str) -> "ContractFunctionPath":
+        if ":" in value:
+            contract_name, method_name = value.split(":")
+            return cls(contract_name=contract_name, method_name=method_name)
+
+        return cls(contract_name=value)
+
+    def __str__(self) -> str:
+        return f"{self.contract_name}:{self.method_name}"
+
+    @log_instead_of_fail(default="<ContractFunctionPath>")
+    def __repr__(self) -> str:
+        return f"<{self}>"
+
+
+class LogFilter(BaseModel):
+    addresses: list[AddressType] = []
+    events: list[EventABI] = []
+    topic_filter: TopicFilter = []
+    start_block: int = 0
+    stop_block: Optional[int] = None  # Use block height
+    selectors: dict[str, EventABI] = {}
+
+    @model_validator(mode="before")
+    @classmethod
+    def compute_selectors(cls, values):
+        values["selectors"] = {
+            encode_hex(keccak(text=event.selector)): event for event in values.get("events", [])
         }
 
-    def _check_needs_compiling(self, source_path: Path) -> bool:
-        source_id = str(get_relative_path(source_path, self.contracts_folder))
+        return values
 
-        if source_id not in self.cached_sources:
-            return True  # New file added
+    @field_validator("start_block", mode="before")
+    @classmethod
+    def validate_start_block(cls, value):
+        return value or 0
+
+    def model_dump(self, *args, **kwargs):
+        _Hash32 = Union[Hash32, HexBytes, HexStr]
+        topics = cast(Sequence[Optional[Union[_Hash32, Sequence[_Hash32]]]], self.topic_filter)
+        return FilterParams(
+            address=self.addresses,
+            fromBlock=to_hex(self.start_block),
+            toBlock=to_hex(self.stop_block or self.start_block),
+            topics=topics,
+        )
 
-        cached_source = self.cached_sources[source_id]
-        cached_checksum = cached_source.calculate_checksum()
-        source_file = self.contracts_folder / source_path
+    @classmethod
+    def from_event(
+        cls,
+        event: Union[EventABI, "ContractEvent"],
+        search_topics: Optional[dict[str, Any]] = None,
+        addresses: Optional[list[AddressType]] = None,
+        start_block=None,
+        stop_block=None,
+    ):
+        """
+        Construct a log filter from an event topic query.
+        """
+        from ape import convert
+        from ape.utils.abi import LogInputABICollection, is_dynamic_sized_type
 
-        # ethpm_types strips trailing white space and ensures
-        # a newline at the end so content so `splitlines()` works.
-        # We need to do the same here for to prevent the endless recompiling bug.
-        text = source_file.read_text("utf8").rstrip()
-        content = f"{text}\n" if text else ""
+        event_abi: EventABI = getattr(event, "abi", event)  # type: ignore
+        search_topics = search_topics or {}
+        topic_filter: list[Optional[HexStr]] = [encode_hex(keccak(text=event_abi.selector))]
+        abi_inputs = LogInputABICollection(event_abi)
+
+        def encode_topic_value(abi_type, value):
+            if isinstance(value, (list, tuple)):
+                return [encode_topic_value(abi_type, v) for v in value]
+            elif is_dynamic_sized_type(abi_type):
+                return encode_hex(keccak(encode_packed([str(abi_type)], [value])))
+            elif abi_type == "address":
+                value = convert(value, AddressType)
+
+            return encode_hex(encode([abi_type], [value]))
+
+        for topic in abi_inputs.topic_abi_types:
+            if topic.name in search_topics:
+                encoded_value = encode_topic_value(topic.type, search_topics[topic.name])
+                topic_filter.append(encoded_value)
+            else:
+                topic_filter.append(None)
+
+        topic_names = [i.name for i in abi_inputs.topic_abi_types if i.name]
+        invalid_topics = set(search_topics) - set(topic_names)
+        if invalid_topics:
+            raise ValueError(
+                f"{event_abi.name} defines {', '.join(topic_names)} as indexed topics, "
+                f"but you provided {', '.join(invalid_topics)}"
+            )
+
+        # remove trailing wildcards since they have no effect
+        while topic_filter[-1] is None:
+            topic_filter.pop()
+
+        return cls(
+            addresses=addresses or [],
+            events=[event_abi],
+            topic_filter=topic_filter,
+            start_block=start_block,
+            stop_block=stop_block,
+        )
+
+
+class BaseContractLog(BaseInterfaceModel):
+    """
+    Base class representing information relevant to an event instance.
+    """
+
+    event_name: str
+    """The name of the event."""
+
+    contract_address: AddressType = ZERO_ADDRESS
+    """The contract responsible for emitting the log."""
+
+    event_arguments: dict[str, Any] = {}
+    """The arguments to the event, including both indexed and non-indexed data."""
+
+    @field_validator("contract_address", mode="before")
+    @classmethod
+    def validate_address(cls, value):
+        return cls.conversion_manager.convert(value, AddressType)
 
-        checksum = compute_checksum(content.encode("utf8"), algorithm=cached_checksum.algorithm)
-        return checksum != cached_checksum.hash  # Contents changed
+    def __eq__(self, other: Any) -> bool:
+        if self.contract_address != other.contract_address or self.event_name != other.event_name:
+            return False
+
+        for k, v in self.event_arguments.items():
+            other_v = other.event_arguments.get(k)
+            if v != other_v:
+                return False
+
+        return True
 
-    def get_source_reference_paths(self, source_id: str) -> List[Path]:
-        return [s for s in self._source_reference_paths.get(source_id, []) if s.is_file()]
 
+class ContractLog(ExtraAttributesMixin, BaseContractLog):
+    """
+    An instance of a log from a contract.
+    """
+
+    transaction_hash: Any
+    """The hash of the transaction containing this log."""
+
+    block_number: int
+    """The number of the block containing the transaction that produced this log."""
+
+    block_hash: Any
+    """The hash of the block containing the transaction that produced this log."""
+
+    log_index: int
+    """The index of the log on the transaction."""
+
+    transaction_index: Optional[int] = None
+    """
+    The index of the transaction's position when the log was created.
+    Is `None` when from the pending block.
+    """
+
+    @field_validator("block_number", "log_index", "transaction_index", mode="before")
+    @classmethod
+    def validate_hex_ints(cls, value):
+        if value is None:
+            # Should only happen for optionals.
+            return value
+
+        elif not isinstance(value, int):
+            return to_int(value)
+
+        return value
+
+    @field_validator("contract_address", mode="before")
+    @classmethod
+    def validate_address(cls, value):
+        return cls.conversion_manager.convert(value, AddressType)
+
+    # NOTE: This class has an overridden `__getattr__` method, but `block` is a reserved keyword
+    #       in most smart contract languages, so it is safe to use. Purposely avoid adding
+    #       `.datetime` and `.timestamp` in case they are used as event arg names.
+    @cached_property
+    def block(self) -> "BlockAPI":
+        return self.chain_manager.blocks[self.block_number]
 
-class BaseProject(ProjectAPI):
     @property
-    def config_file(self) -> Path:
-        return self.path / APE_CONFIG_FILE_NAME
+    def timestamp(self) -> int:
+        """
+        The UNIX timestamp of when the event was emitted.
+
+        NOTE: This performs a block lookup.
+        """
+        return self.block.timestamp
 
     @property
-    def is_valid(self) -> bool:
-        if self.config_file.is_file():
-            return True
+    def _event_args_str(self) -> str:
+        return " ".join(f"{key}={val}" for key, val in self.event_arguments.items())
+
+    def __str__(self) -> str:
+        return f"{self.event_name}({self._event_args_str})"
 
-        logger.debug(
-            f"'{self.path.name}' is not an 'ApeProject', but attempting to process as one."
+    @log_instead_of_fail(default="<ContractLog>")
+    def __repr__(self) -> str:
+        event_arg_str = self._event_args_str
+        suffix = f" {event_arg_str}" if event_arg_str else ""
+        return f"<{self.event_name}{suffix}>"
+
+    def __ape_extra_attributes__(self) -> Iterator[ExtraModelAttributes]:
+        yield ExtraModelAttributes(
+            name=self.event_name,
+            attributes=lambda: self.event_arguments or {},
+            include_getattr=True,
+            include_getitem=True,
         )
 
-        # NOTE: We always return True as a last-chance attempt because it often
-        # works anyway and prevents unnecessary plugin requirements.
-        return True
+    def __contains__(self, item: str) -> bool:
+        return item in self.event_arguments
 
-    @property
-    def source_paths(self) -> List[Path]:
+    def __eq__(self, other: Any) -> bool:
         """
-        All the source files in the project.
-        Excludes files with extensions that don't have a registered compiler.
+        Check for equality between this instance and another ContractLog instance.
+
+        If the other object is not an instance of ContractLog, this method returns
+        NotImplemented. This triggers the Python interpreter to call the __eq__ method
+        on the other object (i.e., y.__eq__(x)) if it is defined, allowing for a custom
+        comparison. This behavior is leveraged by the MockContractLog class to handle
+        custom comparison logic between ContractLog and MockContractLog instances.
+
+        Args:
+            other (Any): The object to compare with this instance.
 
         Returns:
-            List[pathlib.Path]: A list of a source file paths in the project.
+            bool: True if the two instances are equal, False otherwise.
         """
-        files: List[Path] = []
 
-        if not self.contracts_folder.is_dir():
-            return files
+        if not isinstance(other, ContractLog):
+            return NotImplemented
 
-        compilers = self.compiler_manager.registered_compilers
-        for extension in compilers:
-            ext = extension.replace(".", "\\.")
-            pattern = rf"[\w|-]+{ext}"
-            ext_files = get_all_files_in_directory(self.contracts_folder, pattern=pattern)
-            files.extend(ext_files)
-
-        return files
-
-    def process_config_file(self, **kwargs) -> bool:
-        if self.config_file.is_file():
-            # Don't override existing config file.
-            return False
+        # call __eq__ on parent class
+        return super().__eq__(other)
 
-        # Create a temporary config file that should be cleaned up after.
-        config_data = {**kwargs}
-        if self.name:
-            config_data["name"] = self.name
-        if self.version:
-            config_data["version"] = self.version
-
-        contracts_folder = kwargs.get("contracts_folder") or self.contracts_folder
-        contracts_folder_config_item = (
-            str(contracts_folder).replace(str(self.path), "").strip(os.path.sep)
-        )
-        config_data["contracts_folder"] = contracts_folder_config_item
-        self.config_file.parent.mkdir(parents=True, exist_ok=True)
-        self.config_file.touch()
-        with open(self.config_file, "w") as file:
-            safe_dump(config_data, file)
+    def get(self, item: str, default: Optional[Any] = None) -> Any:
+        return self.event_arguments.get(item, default)
 
+
+def _equal_event_inputs(mock_input: Any, real_input: Any) -> bool:
+    if mock_input is None:
+        # Check is skipped.
         return True
 
-    def create_manifest(
-        self, file_paths: Optional[Sequence[Path]] = None, use_cache: bool = True
-    ) -> PackageManifest:
-        # Read the project config and migrate project-settings to Ape settings if needed.
-        compile_config = self.config_manager.get_config("compile")
-        self.project_manager.load_dependencies()
-        source_paths: List[Path] = list(
-            set(
-                [p for p in self.source_paths if p in file_paths]
-                if file_paths
-                else [
-                    p
-                    for p in self.source_paths
-                    if not any(p.match(e) for e in compile_config.exclude)
-                ]
-            )
-        )
+    elif isinstance(mock_input, (list, tuple)):
+        if not isinstance(real_input, (list, tuple)) or len(real_input) != len(mock_input):
+            return False
 
-        if use_cache:
-            manifest = self.manifest
-        else:
-            self._contracts = None
-            manifest = PackageManifest()
+        return all(_equal_event_inputs(m, r) for m, r in zip(mock_input, real_input))
 
-        # Generate sources and contract types.
-        project_sources = _ProjectSources(
-            manifest, source_paths, self.contracts_folder, self._cache_folder
-        )
-        contract_types = project_sources.remaining_cached_contract_types
-        compiled_contract_types = self._compile(project_sources)
-        contract_types.update(compiled_contract_types)
-
-        # NOTE: We need to prevent compilation or else we get an endless loop, because
-        # compilation results in creating a manifest, which triggers compilation, etc.
-        compiler_data = self.project_manager.get_compiler_data(compile_if_needed=False)
-
-        # Apply source and contracts to manifest.
-        self.update_manifest_sources(
-            source_paths,
-            self.contracts_folder,
-            contract_types,
-            name=self.name,
-            version=self.version,
-            compiler_data=compiler_data,
-        )
+    else:
+        return mock_input == real_input
 
-        if compiled_contract_types:
-            for name, contract_type in compiled_contract_types.items():
-                file = self.project_manager.local_project._cache_folder / f"{name}.json"
-                file.write_text(contract_type.model_dump_json())
-                self._contracts = self._contracts or {}
-                self._contracts[name] = contract_type
-
-        # Is cached.
-        return self.manifest
-
-    def _compile(
-        self, project_sources: _ProjectSources, use_cache: bool = True
-    ) -> Dict[str, ContractType]:
-        def _compile_sources(proj_srcs: _ProjectSources) -> Dict[str, ContractType]:
-            contracts_folder = self.contracts_folder
-            srcs_to_compile = proj_srcs.sources_needing_compilation
-
-            # Figure out what contracts have changed and delete them from the cache
-            # so they can be compiled.
-            exising_contract_types = (
-                (self.cached_manifest.contract_types or {})
-                if self.cached_manifest is not None
-                else {}
-            )
-            contracts_to_remove = [
-                ct
-                for ct in exising_contract_types.values()
-                if ct.source_id and (contracts_folder / ct.source_id) in srcs_to_compile
-            ]
-
-            for contract in contracts_to_remove:
-                path = self._cache_folder / f"{contract.name}.json"
-                path.unlink(missing_ok=True)
-
-            if cached_manifest := self.cached_manifest:
-                source_ids_to_remove = [ct.source_id for ct in contracts_to_remove]
-                filtered_contract_types = {
-                    n: ct
-                    for n, ct in (cached_manifest.contract_types or {}).items()
-                    if ct.source_id not in source_ids_to_remove
-                }
-
-                if self._cached_manifest is None:
-                    # Shouldn't happen, but type-safety's sake.
-                    self._cached_manifest = PackageManifest.model_validate({})
-
-                self._cached_manifest.contract_types = filtered_contract_types
-                self._contracts = filtered_contract_types
-
-            return self.compiler_manager.compile(srcs_to_compile)
-
-        if self.project_manager.path.absolute() != self.path.absolute():
-            # In case compiling a dependency (or anything outside the root project).
-            with self.config_manager.using_project(
-                self.path, contracts_folder=self.contracts_folder
-            ):
-                self.project_manager.load_dependencies()
-                return _compile_sources(project_sources)
-        else:
-            # Already in project
-            return _compile_sources(project_sources)
 
+class MockContractLog(BaseContractLog):
+    """
+    A mock version of the ContractLog class used for testing purposes.
+    This class is designed to match a subset of event arguments in a ContractLog instance
+    by only comparing those event arguments that the user explicitly provides.
+
+    Inherits from :class:`~ape.types.BaseContractLog`, and overrides the
+    equality method for custom comparison
+    of event arguments between a MockContractLog and a ContractLog instance.
+    """
+
+    def __eq__(self, other: Any) -> bool:
+        if (
+            not hasattr(other, "contract_address")
+            or not hasattr(other, "event_name")
+            or self.contract_address != other.contract_address
+            or self.event_name != other.event_name
+        ):
+            return False
+
+        # NOTE: `self.event_arguments` contains a subset of items from `other.event_arguments`,
+        #       but we skip those the user doesn't care to check
+        for name, value in self.event_arguments.items():
+            other_input = other.event_arguments.get(name)
+            if not _equal_event_inputs(value, other_input):
+                # Only exit on False; Else, keep checking.
+                return False
 
-class ApeProject(BaseProject):
+        return True
+
+
+class ContractLogContainer(list):
     """
-    The default implementation of the :class:`~ape.api.projects.ProjectAPI`.
-    By default, the `:class:`~ape.managers.project.ProjectManager` uses an
-    ``ApeProject`` at the current-working directory.
+    Container for ContractLogs which is adding capability of filtering logs
     """
 
+    def filter(self, event: "ContractEvent", **kwargs) -> list[ContractLog]:
+        return [
+            x
+            for x in self
+            if x.event_name == event.name
+            and x.contract_address == event.contract
+            and all(v == x.event_arguments.get(k) and v is not None for k, v in kwargs.items())
+        ]
 
-class BrownieProject(BaseProject):
-    config_file_name: str = "brownie-config.yaml"
+    def __contains__(self, val: Any) -> bool:
+        return any(log == val for log in self)
 
-    @property
-    def brownie_config_path(self) -> Path:
-        return self.path / self.config_file_name
 
-    @property
-    def is_valid(self) -> bool:
-        return self.brownie_config_path.is_file()
+_T = TypeVar("_T")  # _LazySequence generic.
 
-    def process_config_file(self, **kwargs) -> bool:
-        # Migrate the brownie-config.yaml file to ape-config.yaml
 
-        migrated_config_data: Dict[str, Any] = {}
-        with open(self.brownie_config_path) as brownie_config_file:
-            brownie_config_data = safe_load(brownie_config_file) or {}
-
-        # Migrate dependencies
-        dependencies = []
-        for dependency in brownie_config_data.get("dependencies", []):
-            dependency_dict = {}
-            dep_parts = dependency.split("/")
-            dep_name = dep_parts[0]
-            if len(dep_parts) > 1:
-                dependency_dict["name"] = dep_name
-                if "@" in dep_parts[1]:
-                    suffix_parts = dep_parts[1].split("@")
-                    dependency_dict["github"] = f"{dep_name}/{suffix_parts[0]}"
-                    dependency_dict["version"] = suffix_parts[1]
-                else:
-                    dependency_dict["github"] = dep_parts[1]
-
-            if dependency_dict:
-                dependencies.append(dependency_dict)
-
-        if dependencies:
-            migrated_config_data["dependencies"] = dependencies
-
-        # Migrate solidity remapping
-        import_remapping = []
-        solidity_version = None
-        if "compiler" in brownie_config_data:
-            compiler_config = brownie_config_data["compiler"]
-            if "solc" in compiler_config:
-                solidity_config = compiler_config["solc"]
-                solidity_version = solidity_config.get("version")
-
-                available_dependencies = [d["name"] for d in dependencies]
-                brownie_import_remapping = solidity_config.get("remappings", [])
-
-                for remapping in brownie_import_remapping:
-                    parts = remapping.split("=")
-                    map_key = parts[0]
-                    real_path = parts[1]
-
-                    real_path_parts = real_path.split("/")
-                    dependency_name = real_path_parts[0]
-
-                    if dependency_name in available_dependencies:
-                        suffix = real_path_parts[1]
-                        if "@" in suffix:
-                            version_id = suffix.split("@")[1]
-                            key = f"{map_key}/{self.contracts_folder.stem}"
-                            entry = f"{dependency_name}/{version_id}"
-                            import_remapping.append(f"{key}={entry}")
-                        else:
-                            import_remapping.append(
-                                f"{parts[0]}/{self.contracts_folder.stem}={dependency_name}"
-                            )
-
-        if import_remapping or solidity_version:
-            migrated_solidity_config: Dict[str, Any] = {}
-
-            if import_remapping:
-                migrated_solidity_config["import_remapping"] = import_remapping
+class _LazySequence(Sequence[_T]):
+    def __init__(self, generator: Union[Iterator[_T], Callable[[], Iterator[_T]]]):
+        self._generator = generator
+        self.cache: list = []
 
-            if solidity_version:
-                migrated_solidity_config["version"] = solidity_version
+    @overload
+    def __getitem__(self, index: int) -> _T: ...
 
-            migrated_config_data["solidity"] = migrated_solidity_config
+    @overload
+    def __getitem__(self, index: slice) -> Sequence[_T]: ...
 
-        return super().process_config_file(**kwargs, **migrated_config_data)
+    def __getitem__(self, index: Union[int, slice]) -> Union[_T, Sequence[_T]]:
+        if isinstance(index, int):
+            while len(self.cache) <= index:
+                # Catch up the cache.
+                if value := next(self.generator, None):
+                    self.cache.append(value)
+
+            return self.cache[index]
+
+        elif isinstance(index, slice):
+            # TODO: Make slices lazier. Right now, it deqeues all.
+            for item in self.generator:
+                self.cache.append(item)
+
+            return self.cache[index]
+
+        else:
+            raise TypeError("Index must be int or slice.")
+
+    def __len__(self) -> int:
+        # NOTE: This will deque everything.
+
+        for value in self.generator:
+            self.cache.append(value)
+
+        return len(self.cache)
+
+    def __iter__(self) -> Iterator[_T]:
+        yield from self.cache
+        for value in self.generator:
+            yield value
+            self.cache.append(value)
+
+    @property
+    def generator(self) -> Iterator:
+        if callable(self._generator):
+            self._generator = self._generator()
+
+        assert isinstance(self._generator, Iterator)  # For type-checking.
+        yield from self._generator
+
+
+__all__ = [
+    "ABI",
+    "AddressType",
+    "BlockID",
+    "Bytecode",
+    "Checksum",
+    "Closure",
+    "Compiler",
+    "ContractCoverage",
+    "ContractSourceCoverage",
+    "ContractLog",
+    "ContractLogContainer",
+    "ContractType",
+    "ControlFlow",
+    "CoverageProject",
+    "CoverageReport",
+    "CoverageStatement",
+    "GasReport",
+    "MessageSignature",
+    "PackageManifest",
+    "PackageMeta",
+    "RawAddress",
+    "SignableMessage",
+    "SnapshotID",
+    "Source",
+    "SourceTraceback",
+    "TransactionSignature",
+]
```

### Comparing `eth-ape-0.7.9/src/ape/managers/query.py` & `eth-ape-0.8.0/src/ape/managers/query.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,34 +1,37 @@
 import difflib
 import time
+from collections.abc import Iterator
 from itertools import tee
-from typing import Dict, Iterator, Optional
+from typing import Optional
 
 from ape.api import QueryAPI, QueryType, ReceiptAPI, TransactionAPI
 from ape.api.query import (
     AccountTransactionQuery,
     BaseInterfaceModel,
     BlockQuery,
     BlockTransactionQuery,
-    ContractCreationQuery,
     ContractEventQuery,
 )
 from ape.contracts.base import ContractLog, LogFilter
 from ape.exceptions import QueryEngineError
 from ape.logging import logger
-from ape.plugins import clean_plugin_name
+from ape.plugins._utils import clean_plugin_name
 from ape.utils import ManagerAccessMixin, cached_property, singledispatchmethod
 
 
 class DefaultQueryProvider(QueryAPI):
     """
     Default implementation of the :class:`~ape.api.query.QueryAPI`.
     Allows for the query of blockchain data using connected provider.
     """
 
+    def __init__(self):
+        self.supports_contract_creation = None
+
     @singledispatchmethod
     def estimate_query(self, query: QueryType) -> Optional[int]:  # type: ignore
         return None  # can't handle this query
 
     @estimate_query.register
     def estimate_block_query(self, query: BlockQuery) -> Optional[int]:
         # NOTE: Very loose estimate of 100ms per block
@@ -36,20 +39,14 @@
 
     @estimate_query.register
     def estimate_block_transaction_query(self, query: BlockTransactionQuery) -> int:
         # NOTE: Very loose estimate of 1000ms per block for this query.
         return self.provider.get_block(query.block_id).num_transactions * 100
 
     @estimate_query.register
-    def estimate_contract_creation_query(self, query: ContractCreationQuery) -> int:
-        # NOTE: Extremely expensive query, involves binary search of all blocks in a chain
-        #       Very loose estimate of 5s per transaction for this query.
-        return 5000
-
-    @estimate_query.register
     def estimate_contract_events_query(self, query: ContractEventQuery) -> int:
         # NOTE: Very loose estimate of 100ms per block for this query.
         return (1 + query.stop_block - query.start_block) * 100
 
     @estimate_query.register
     def estimate_account_transactions_query(self, query: AccountTransactionQuery) -> int:
         # NOTE: Extremely expensive query, involves binary search of all blocks in a chain
@@ -72,22 +69,14 @@
     @perform_query.register
     def perform_block_transaction_query(
         self, query: BlockTransactionQuery
     ) -> Iterator[TransactionAPI]:
         return self.provider.get_transactions_by_block(query.block_id)
 
     @perform_query.register
-    def perform_contract_creation_query(self, query: ContractCreationQuery) -> Iterator[ReceiptAPI]:
-        yield from self.provider.get_contract_creation_receipts(
-            address=query.contract,
-            start_block=query.start_block,
-            stop_block=query.stop_block,
-        )
-
-    @perform_query.register
     def perform_contract_events_query(self, query: ContractEventQuery) -> Iterator[ContractLog]:
         addresses = query.contract
         if not isinstance(addresses, list):
             addresses = [query.contract]  # type: ignore
 
         log_filter = LogFilter.from_event(
             event=query.event,
@@ -116,24 +105,24 @@
 
     Usage example::
 
          biggest_block_size = chain.blocks.query("size").max()
     """
 
     @cached_property
-    def engines(self) -> Dict[str, QueryAPI]:
+    def engines(self) -> dict[str, QueryAPI]:
         """
         A dict of all :class:`~ape.api.query.QueryAPI` instances across all
         installed plugins.
 
         Returns:
             dict[str, :class:`~ape.api.query.QueryAPI`]
         """
 
-        engines: Dict[str, QueryAPI] = {"__default__": DefaultQueryProvider()}
+        engines: dict[str, QueryAPI] = {"__default__": DefaultQueryProvider()}
 
         for plugin_name, engine_class in self.plugin_manager.query_engines:
             engine_name = clean_plugin_name(plugin_name)
             engines[engine_name] = engine_class()  # type: ignore
 
         return engines
 
@@ -147,15 +136,16 @@
     ) -> Iterator[BaseInterfaceModel]:
         """
         Args:
             query (``QueryType``): The type of query to execute
             engine_to_use (Optional[str]): Short-circuit selection logic using
               a specific engine. Defaults is set by performance-based selection logic.
 
-        Raises: :class:`~ape.exceptions.QueryEngineError`: When given an invalid or
+        Raises:
+            :class:`~ape.exceptions.QueryEngineError`: When given an invalid or
           inaccessible ``engine_to_use`` value.
 
         Returns:
             Iterator[``BaseInterfaceModel``]
         """
 
         if engine_to_use:
```

### Comparing `eth-ape-0.7.9/src/ape/plugins/_utils.py` & `eth-ape-0.8.0/src/ape/plugins/_utils.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,29 +1,59 @@
-import subprocess
+import re
 import sys
+from collections.abc import Iterable, Iterator, Sequence
 from enum import Enum
 from functools import cached_property
-from typing import Any, Dict, Iterator, List, Optional, Sequence, Set, Tuple
+from pathlib import Path
+from shutil import which
+from typing import Any, Optional
 
 import click
 from packaging.specifiers import SpecifierSet
 from packaging.version import Version
-from pkg_resources import working_set
 from pydantic import field_validator, model_validator
 
-from ape.__modules__ import __modules__
+from ape.exceptions import PluginVersionError
 from ape.logging import logger
-from ape.plugins import clean_plugin_name
-from ape.utils import BaseInterfaceModel, get_package_version, github_client
+from ape.utils import BaseInterfaceModel, get_package_version, log_instead_of_fail
+from ape.utils._github import github_client
 from ape.utils.basemodel import BaseModel
+from ape.utils.misc import _get_distributions
 from ape.version import version as ape_version_str
-from ape_plugins.exceptions import PluginVersionError
 
 # Plugins maintained OSS by ApeWorX (and trusted)
-CORE_PLUGINS = {p for p in __modules__ if p != "ape"}
+# Use `uv pip` if installed, otherwise `python -m pip`
+PIP_COMMAND = ["uv", "pip"] if which("uv") else [sys.executable, "-m", "pip"]
+PLUGIN_PATTERN = re.compile(r"\bape_\w+(?!\S)")
+CORE_PLUGINS = [
+    "ape",
+    *[
+        f.name
+        for f in Path(__file__).parent.parent.parent.iterdir()
+        if f.name.startswith("ape_") and f.is_dir() and re.match(PLUGIN_PATTERN, f.name)
+    ],
+]
+
+
+def clean_plugin_name(name: str) -> str:
+    return name.replace("_", "-").replace("ape-", "")
+
+
+def _filter_plugins_from_dists(dists: Iterable) -> Iterator[str]:
+    for dist in dists:
+        if name := getattr(dist, "name", ""):
+            # Python 3.10 or greater.
+            if name.startswith("ape-"):
+                yield name
+
+        elif metadata := getattr(dist, "metadata", {}):
+            # Python 3.9.
+            name = metadata.get("Name", "")
+            if name.startswith("ape-"):
+                yield name
 
 
 class ApeVersion:
     def __str__(self) -> str:
         return str(self.version)
 
     def __getitem__(self, item):
@@ -107,93 +137,59 @@
 
     AVAILABLE = "available"
     """
     Plugins that are available to install from a trusted-source.
     """
 
 
-def _check_pip_freeze() -> str:
-    result = subprocess.check_output([sys.executable, "-m", "pip", "freeze"])
-    return result.decode("utf8")
-
-
-class _PipFreeze:
-    cache: Optional[Set[str]] = None
-
-    def get_plugins(self, use_cache: bool = True, use_process: bool = False) -> Set[str]:
-        if use_cache and self.cache is not None:
-            return self.cache
-
-        lines = [
-            p
-            for p in (
-                _check_pip_freeze().splitlines()
-                if use_process
-                else [str(x).replace(" ", "==") for x in working_set]
-            )
-            if p.startswith("ape-") or (p.startswith("-e") and "ape-" in p)
-        ]
-
-        # NOTE: Package IDs should look like "name==version"
-        #  if version is available.
-        package_ids = []
-        for package in lines:
-            if "-e" in package:
-                package_ids.append(package.split(".git")[0].split("/")[-1])
-            elif "@" in package:
-                package_ids.append(package.split("@")[0].strip())
-            elif "==" in package:
-                package_ids.append(package)
-            else:
-                package_ids.append(package)
-
-        self.cache = set(x for x in package_ids)
-        return self.cache
-
-
-_pip_freeze = _PipFreeze()
-
-
-def _pip_freeze_plugins(use_cache: bool = True, use_process: bool = False):
-    # NOTE: In a method for mocking purposes in tests.
-    return _pip_freeze.get_plugins(use_cache=use_cache, use_process=use_process)
-
-
 class PluginMetadataList(BaseModel):
     """
     Metadata per plugin type, including information for all plugins.
     """
 
     core: "PluginGroup"
     available: "PluginGroup"
     installed: "PluginGroup"
     third_party: "PluginGroup"
 
     @classmethod
-    def load(cls, plugin_manager):
-        registered_plugins = plugin_manager.registered_plugins
-        available_plugins = github_client.available_plugins
-        return cls.from_package_names(registered_plugins.union(available_plugins))
+    def load(cls, plugin_manager, include_available: bool = True):
+        plugins = plugin_manager.registered_plugins
+        if include_available:
+            plugins = plugins.union(github_client.available_plugins)
+
+        return cls.from_package_names(plugins, include_available=include_available)
 
     @classmethod
-    def from_package_names(cls, packages: Sequence[str]) -> "PluginMetadataList":
+    def from_package_names(
+        cls, packages: Iterable[str], include_available: bool = True
+    ) -> "PluginMetadataList":
         PluginMetadataList.model_rebuild()
         core = PluginGroup(plugin_type=PluginType.CORE)
         available = PluginGroup(plugin_type=PluginType.AVAILABLE)
         installed = PluginGroup(plugin_type=PluginType.INSTALLED)
         third_party = PluginGroup(plugin_type=PluginType.THIRD_PARTY)
-        for name in {p for p in packages}:
-            plugin = PluginMetadata(name=name.strip())
+        for package_id in packages:
+            parts = package_id.split("==")
+            name = parts[0]
+            version = parts[1] if len(parts) == 2 else None
+            plugin = PluginMetadata(name=name.strip(), version=version)
             if plugin.in_core:
                 core.plugins[name] = plugin
-            elif plugin.is_available and not plugin.is_installed:
+                continue
+
+            # perf: only check these once.
+            is_installed = plugin.is_installed
+            is_available = include_available and plugin.is_available
+
+            if include_available and is_available and not is_installed:
                 available.plugins[name] = plugin
-            elif plugin.is_installed and not plugin.in_core and not plugin.is_available:
+            elif is_installed and not plugin.in_core and not is_available:
                 third_party.plugins[name] = plugin
-            elif plugin.is_installed:
+            elif is_installed:
                 installed.plugins[name] = plugin
             else:
                 logger.error(f"'{plugin.name}' is not a plugin.")
 
         return cls(core=core, available=available, installed=installed, third_party=third_party)
 
     def __str__(self) -> str:
@@ -235,17 +231,18 @@
 
     name: str
     """The name of the plugin, such as ``trezor``."""
 
     version: Optional[str] = None
     """The version requested, if there is one."""
 
-    _use_subprocess_pip_freeze: bool = False
+    pip_command: list[str] = PIP_COMMAND
     """
-    Set to True if verifying changes.
+    The pip base command to use.
+    (NOTE: is a field mainly for testing purposes).
     """
 
     @model_validator(mode="before")
     @classmethod
     def validate_name(cls, values):
         if "name" not in values:
             raise ValueError("'name' required.")
@@ -255,29 +252,28 @@
 
         if version and version.startswith("git+"):
             if f"ape-{name}" not in version:
                 # Just some small validation so you can't put a repo
                 # that isn't this plugin here. NOTE: Forks should still work.
                 raise ValueError("Plugin mismatch with remote git version.")
 
-            version = version
-
         elif not version:
             # Only check name for version constraint if not in version.
             # NOTE: This happens when using the CLI to provide version constraints.
             for constraint in ("==", "<=", ">=", "@git+"):
                 # Version constraint is part of name field.
                 if constraint not in name:
                     continue
 
                 # Constraint found.
                 name, version = _split_name_and_version(name)
                 break
 
-        return {"name": clean_plugin_name(name), "version": version}
+        pip_cmd = values.get("pip_command", PIP_COMMAND)
+        return {"name": clean_plugin_name(name), "version": version, "pip_command": pip_cmd}
 
     @cached_property
     def package_name(self) -> str:
         """
         Like 'ape-plugin'; the name of the package on PyPI.
         """
 
@@ -363,37 +359,14 @@
         return self.check_installed()
 
     @property
     def is_third_party(self) -> bool:
         return self.is_installed and not self.is_available
 
     @property
-    def pip_freeze_version(self) -> Optional[str]:
-        """
-        The version from ``pip freeze`` output.
-        This is useful because when updating a plugin, it is not available
-        until the next Python session but you can use the property to
-        verify the update.
-        """
-
-        for package in _pip_freeze_plugins(
-            use_cache=False, use_process=self._use_subprocess_pip_freeze
-        ):
-            parts = package.split("==")
-            if len(parts) != 2:
-                continue
-
-            name = parts[0]
-            if name == self.package_name:
-                version_str = parts[-1]
-                return version_str
-
-        return None
-
-    @property
     def is_available(self) -> bool:
         """
         Whether the plugin is maintained by the ApeWorX organization.
         """
 
         return self.module_name in _get_available_plugins()
 
@@ -403,26 +376,23 @@
         """
         if self.version and self.version.startswith("git+"):
             return self.version
 
         version_key = f"=={self.version}" if self.version and self.version[0].isnumeric() else ""
         return f"{self.name}{version_key}"
 
-    def check_installed(self, use_cache: bool = True):
-        ape_packages = [
-            _split_name_and_version(n)[0]
-            for n in _pip_freeze_plugins(
-                use_cache=use_cache, use_process=self._use_subprocess_pip_freeze
-            )
-        ]
-        return self.package_name in ape_packages
+    def check_installed(self, use_cache: bool = True) -> bool:
+        if not use_cache:
+            _get_distributions.cache_clear()
+
+        return any(n == self.package_name for n in _filter_plugins_from_dists(_get_distributions()))
 
     def _prepare_install(
         self, upgrade: bool = False, skip_confirmation: bool = False
-    ) -> Optional[Dict[str, Any]]:
+    ) -> Optional[dict[str, Any]]:
         # NOTE: Internal and only meant to be called by the CLI.
         if self.in_core:
             logger.error(f"Cannot install core 'ape' plugin '{self.name}'.")
             return None
 
         elif self.version is not None and upgrade:
             logger.error(
@@ -432,15 +402,15 @@
             return None
 
         # if plugin is installed but not trusted. It must be a third party
         elif self.is_third_party:
             logger.warning(f"Plugin '{self.name}' is not an trusted plugin.")
 
         result_handler = ModifyPluginResultHandler(self)
-        pip_arguments = [sys.executable, "-m", "pip", "install"]
+        pip_arguments = [*self.pip_command, "install"]
 
         if upgrade:
             logger.info(f"Upgrading '{self.name}' plugin ...")
 
             # NOTE: A simple --upgrade flag may upgrade the plugin
             # to a version outside Core Ape's. Thus, we handle it
             # with a version-specifier instead.
@@ -465,50 +435,59 @@
 
         else:
             logger.warning(
                 f"'{self.name}' is already installed. Did you mean to include '--upgrade'?"
             )
             return None
 
+    def _get_uninstall_args(self) -> list[str]:
+        arguments = [*self.pip_command, "uninstall"]
+
+        if self.pip_command[0] != "uv":
+            arguments.append("-y")
+
+        arguments.extend((self.package_name, "--quiet"))
+        return arguments
+
 
 class ModifyPluginResultHandler:
     def __init__(self, plugin: PluginMetadata):
         self._plugin = plugin
 
     def handle_install_result(self, result: int) -> bool:
         if not self._plugin.check_installed(use_cache=False):
             self._log_modify_failed("install")
             return False
         elif result != 0:
             self._log_errors_occurred("installing")
             return False
         else:
             plugin_id = self._plugin.name
-            version = self._plugin.pip_freeze_version
+            version = self._plugin.version
             if version:
                 # Sometimes, like in editable mode, the version is missing here.
                 plugin_id = f"{plugin_id}=={version}"
 
             logger.success(f"Plugin '{plugin_id}' has been installed.")
             return True
 
     def handle_upgrade_result(self, result: int, version_before: str) -> bool:
         if result != 0:
             self._log_errors_occurred("upgrading")
             return False
 
-        version_now = self._plugin.pip_freeze_version
+        version_now = self._plugin.version
         if version_now is not None and version_before == version_now:
             logger.info(f"'{self._plugin.name}' already has version '{version_now}'.")
             return True
 
-        elif self._plugin.pip_freeze_version:
+        elif self._plugin.version:
             logger.success(
                 f"Plugin '{self._plugin.name}' has been "
-                f"upgraded to version {self._plugin.pip_freeze_version}."
+                f"upgraded to version {self._plugin.version}."
             )
             return True
 
         else:
             # The process was successful but there is still no pip freeze version.
             # This may happen when installing things from GitHub.
             return True
@@ -527,15 +506,15 @@
     def _log_errors_occurred(self, verb: str):
         logger.error(f"Errors occurred when {verb} '{self._plugin}'.")
 
     def _log_modify_failed(self, verb: str):
         logger.error(f"Failed to {verb} plugin '{self._plugin}.")
 
 
-def _split_name_and_version(value: str) -> Tuple[str, Optional[str]]:
+def _split_name_and_version(value: str) -> tuple[str, Optional[str]]:
     if "@" in value:
         parts = [x for x in value.split("@") if x]
         return parts[0], "@".join(parts[1:])
 
     if not (chars := [c for c in ("=", "<", ">") if c in value]):
         return value, None
 
@@ -545,26 +524,22 @@
 
 class PluginGroup(BaseModel):
     """
     A group of plugin metadata by type.
     """
 
     plugin_type: PluginType
-    plugins: Dict[str, PluginMetadata] = {}
+    plugins: dict[str, PluginMetadata] = {}
 
     def __bool__(self) -> bool:
         return len(self.plugins) > 0
 
+    @log_instead_of_fail(default="<PluginGroup>")
     def __repr__(self) -> str:
-        try:
-            return f"<{self.name} Plugins Group>"
-        except Exception:
-            # Prevent exceptions happening in repr()
-            logger.log_debug_stack_trace()
-            return "<PluginGroup>"
+        return f"<{self.name} Plugins Group>"
 
     def __str__(self) -> str:
         return self.to_str()
 
     @field_validator("plugin_type", mode="before")
     @classmethod
     def validate_plugin_type(cls, value):
@@ -575,15 +550,15 @@
         return getattr(self.plugin_type, "value", str(self.plugin_type))
 
     @property
     def name(self) -> str:
         return self.plugin_type_str.capitalize()
 
     @property
-    def plugin_names(self) -> List[str]:
+    def plugin_names(self) -> list[str]:
         return [x.name for x in self.plugins.values()]
 
     def to_str(self, max_length: Optional[int] = None, include_version: bool = True) -> str:
         title = f"{self.name} Plugins"
         if len(self.plugins) <= 0:
             return title
 
@@ -617,22 +592,18 @@
 
     def __init__(
         self, metadata: PluginMetadataList, include: Optional[Sequence[PluginType]] = None
     ):
         self.include = include or (PluginType.INSTALLED, PluginType.THIRD_PARTY)
         self.metadata = metadata
 
+    @log_instead_of_fail(default="<ApePluginsRepr>")
     def __repr__(self) -> str:
-        try:
-            to_display_str = ", ".join([x.value for x in self.include])
-            return f"<PluginMap to_display='{to_display_str}'>"
-        except Exception:
-            # Prevent exceptions happening in repr()
-            logger.log_debug_stack_trace()
-            return "<ApePluginsRepr>"
+        to_display_str = ", ".join([x.value for x in self.include])
+        return f"<PluginMap to_display='{to_display_str}'>"
 
     def __str__(self) -> str:
         sections = []
 
         if PluginType.CORE in self.include and self.metadata.core:
             sections.append(self.metadata.core)
         if PluginType.INSTALLED in self.include and self.metadata.installed:
```

### Comparing `eth-ape-0.7.9/src/ape/plugins/account.py` & `eth-ape-0.8.0/src/ape/plugins/account.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-from typing import Tuple, Type
-
 from ape.api.accounts import AccountAPI, AccountContainerAPI
 
 from .pluggy_patch import PluginType, hookspec
 
 
 class AccountPlugin(PluginType):
     """
@@ -11,23 +9,23 @@
     an :class:`ape.api.accounts.AccountContainerAPI` as well as an
     :class:`ape.api.accounts.AccountAPI`.
     """
 
     @hookspec
     def account_types(  # type: ignore[empty-body]
         self,
-    ) -> Tuple[Type[AccountContainerAPI], Type[AccountAPI]]:
+    ) -> tuple[type[AccountContainerAPI], type[AccountAPI]]:
         """
         A hook for returning a tuple of an account container and an account type.
         Each account-base plugin defines and returns their own types here.
 
         Usage example::
 
             @plugins.register(plugins.AccountPlugin)
             def account_types():
                 return AccountContainer, KeyfileAccount
 
 
         Returns:
-            Tuple[Type[:class:`~ape.api.accounts.AccountContainerAPI`],
-            Type[:class:`~ape.api.accounts.AccountAPI`]]
+            tuple[type[:class:`~ape.api.accounts.AccountContainerAPI`],
+            type[:class:`~ape.api.accounts.AccountAPI`]]
         """
```

### Comparing `eth-ape-0.7.9/src/ape/plugins/compiler.py` & `eth-ape-0.8.0/src/ape/plugins/compiler.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,29 +1,27 @@
-from typing import Tuple, Type
-
 from ape.api import CompilerAPI
 
 from .pluggy_patch import PluginType, hookspec
 
 
 class CompilerPlugin(PluginType):
     """
     A plugin that implements the :class:`ape.api.CompilerAPI`, such
     as the `ape-solidity plugin <https://github.com/ApeWorX/ape-solidity>`__
     or the `ape-vyper plugin <https://github.com/ApeWorX/ape-vyper>`__.
     """
 
     @hookspec
-    def register_compiler(self) -> Tuple[Tuple[str], Type[CompilerAPI]]:  # type: ignore[empty-body]
+    def register_compiler(self) -> tuple[tuple[str], type[CompilerAPI]]:  # type: ignore[empty-body]
         """
         A hook for returning the set of file extensions the plugin handles
         and the compiler class that can be used to compile them.
 
         Usage example::
 
             @plugins.register(plugins.CompilerPlugin)
             def register_compiler():
                 return (".json",), InterfaceCompiler
 
         Returns:
-            Tuple[Tuple[str], Type[:class:`~ape.api.CompilerAPI`]]
+            tuple[tuple[str], type[:class:`~ape.api.CompilerAPI`]]
         """
```

### Comparing `eth-ape-0.7.9/src/ape/plugins/config.py` & `eth-ape-0.8.0/src/ape/plugins/config.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,33 +1,31 @@
-from typing import Type
-
 from ape.api import PluginConfig
 
 from .pluggy_patch import PluginType, hookspec
 
 
 class Config(PluginType):
     """
     A registered config item. Plugins register config implementations
     when they allow additional user-configuration, set in the ``ape-config.yaml``.
     See the :class:`~ape.managers.config.ConfigManager` documentation for more
     information on the ``ape-config.yaml``.
     """
 
     @hookspec
-    def config_class(self) -> Type[PluginConfig]:  # type: ignore[empty-body]
+    def config_class(self) -> type[PluginConfig]:  # type: ignore[empty-body]
         """
         A hook that returns a :class:`~ape.api.config.PluginConfig` parser class that can be
         used to deconstruct the user config options for this plugins.
 
         **NOTE**: If none are specified, all injected :class:`ape.api.config.PluginConfig`'s
         are empty.
 
         Usage example::
 
             @plugins.register(plugins.Config)
             def config_class():
                 return MyPluginConfig
 
         Returns:
-            Type[:class:`~ape.api.config.PluginConfig`]
+            type[:class:`~ape.api.config.PluginConfig`]
         """
```

### Comparing `eth-ape-0.7.9/src/ape/plugins/network.py` & `eth-ape-0.8.0/src/ape/plugins/network.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,110 +1,110 @@
-from typing import Iterator, Tuple, Type
+from collections.abc import Iterator
 
 from ape.api import EcosystemAPI, ExplorerAPI, NetworkAPI, ProviderAPI
 
 from .pluggy_patch import PluginType, hookspec
 
 
 class EcosystemPlugin(PluginType):
     """
     An ecosystem plugin, such as ``ape-ethereum``. See the
     :class:`ape.api.networks.EcosystemAPI` for more information on
     what is required to implement an ecosystem plugin.
     """
 
     @hookspec  # type: ignore[empty-body]
-    def ecosystems(self) -> Iterator[Type[EcosystemAPI]]:
+    def ecosystems(self) -> Iterator[type[EcosystemAPI]]:
         """
         A hook that must return an iterator of :class:`ape.api.networks.EcosystemAPI`
         subclasses.
 
         Usage example::
 
             @plugins.register(plugins.EcosystemPlugin)
             def ecosystems():
                 yield Ethereum
 
         Returns:
-            Iterator[Type[:class:`~ape.api.networks.EcosystemAPI`]]
+            Iterator[type[:class:`~ape.api.networks.EcosystemAPI`]]
         """
 
 
 class NetworkPlugin(PluginType):
     """
     A network plugin, such as ``mainnet`` or ``ropsten``. Likely, registering networks
     will happen soon after registering the ecosystem, as an ecosystem requires
     networks.
     """
 
     @hookspec  # type: ignore[empty-body]
-    def networks(self) -> Iterator[Tuple[str, str, Type[NetworkAPI]]]:
+    def networks(self) -> Iterator[tuple[str, str, type[NetworkAPI]]]:
         """
         A hook that must return an iterator of tuples of:
 
         * the target ecosystem plugin's name
         * the network name
         * a :class:`ape.api.networks.NetworkAPI` subclass
 
         Usage example::
 
             @plugins.register(plugins.NetworkPlugin)
             def networks():
                 yield "ethereum", "ShibaChain", ShibaNetwork
 
         Returns:
-            Iterator[tuple[str, str, Type[:class:`~ape.api.networks.NetworkAPI`]]]
+            Iterator[tuple[str, str, type[:class:`~ape.api.networks.NetworkAPI`]]]
         """
 
 
 class ProviderPlugin(PluginType):
     """
     A plugin representing a network provider, which is the main API responsible
     for making requests against a blockchain. Example provider plugins projects
     include `ape-infura <https://github.com/ApeWorX/ape-infura>`__ as well as
     `ape-alchemy <https://github.com/ApeWorX/ape-alchemy>`__.
     """
 
     @hookspec
-    def providers(self) -> Iterator[Tuple[str, str, Type[ProviderAPI]]]:  # type: ignore[empty-body]
+    def providers(self) -> Iterator[tuple[str, str, type[ProviderAPI]]]:  # type: ignore[empty-body]
         """
         A hook that must return an iterator of tuples of:
 
         * the target ecosystem plugin's name
         * the network it works with (which must be valid network in the ecosystem)
         * a :class:`ape.api.providers.ProviderAPI` subclass
 
         Usage example::
 
             @plugins.register(plugins.ProviderPlugin)
             def providers():
                 yield "ethereum", "local", MyProvider
 
         Returns:
-            Iterator[tuple[str, str, Type[:class:`~ape.api.providers.ProviderAPI`]]]
+            Iterator[tuple[str, str, type[:class:`~ape.api.providers.ProviderAPI`]]]
         """
 
 
 class ExplorerPlugin(PluginType):
     """
     A plugin for a blockchain explorer, such as
     `ape-etherscan <https://github.com/ApeWorX/ape-etherscan>`__.
     """
 
     @hookspec
-    def explorers(self) -> Iterator[Tuple[str, str, Type[ExplorerAPI]]]:  # type: ignore[empty-body]
+    def explorers(self) -> Iterator[tuple[str, str, type[ExplorerAPI]]]:  # type: ignore[empty-body]
         """
         A hook that must return an iterator of tuples of:
 
         * the target ecosystem plugin's name
         * the network it works with (which must be valid network in the ecosystem)
         * a :class:`~ape.api.explorers.ExplorerAPI` subclass
 
         Usage example::
 
             @plugins.register(plugins.ExplorerPlugin)
             def explorers():
                 yield "ethereum", "mainnet", MyBlockExplorer
 
         Returns:
-            Iterator[tuple[str, str, Type[:class:`ape.api.explorers.ExplorerAPI`]]]
+            Iterator[tuple[str, str, type[:class:`ape.api.explorers.ExplorerAPI`]]]
         """
```

### Comparing `eth-ape-0.7.9/src/ape/plugins/pluggy_patch.py` & `eth-ape-0.8.0/src/ape/plugins/pluggy_patch.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,9 @@
-from typing import Any, Callable, TypeVar, cast
+from collections.abc import Callable
+from typing import Any, TypeVar, cast
 
 import pluggy
 
 F = TypeVar("F", bound=Callable[..., Any])
 hookimpl = cast(Callable[[F], F], pluggy.HookimplMarker("ape"))
 hookspec = pluggy.HookspecMarker("ape")
```

### Comparing `eth-ape-0.7.9/src/ape/plugins/project.py` & `eth-ape-0.8.0/src/ape/plugins/project.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-from typing import Dict, Iterator, Type
+from collections.abc import Iterator
 
 from ape.api import DependencyAPI, ProjectAPI
 
 from .pluggy_patch import PluginType, hookspec
 
 
 class ProjectPlugin(PluginType):
@@ -11,34 +11,34 @@
     The default project plugin is the :class:`~ape.api.projects.ApeProject`.
     Otherwise, you can define your own project implementation for converting
     a set of files to a ``PackageManifest``, such as one that resolves dependencies
     via ``.gitmodules``.
     """
 
     @hookspec  # type: ignore[empty-body]
-    def projects(self) -> Iterator[Type[ProjectAPI]]:
+    def projects(self) -> Iterator[type[ProjectAPI]]:
         """
         A hook that returns a :class:`~ape.api.projects.ProjectAPI` subclass type.
 
         Returns:
-            Type[:class:`~ape.api.projects.ProjectAPI`]
+            type[:class:`~ape.api.projects.ProjectAPI`]
         """
 
 
 class DependencyPlugin(PluginType):
     """
     A plugin for downloading packages and creating
     :class:`~ape.plugins.project.ProjectPlugin` implementations.
     """
 
     @hookspec
-    def dependencies(self) -> Dict[str, Type[DependencyAPI]]:  # type: ignore[empty-body]
+    def dependencies(self) -> dict[str, type[DependencyAPI]]:  # type: ignore[empty-body]
         """
         A hook that returns a :class:`~ape.api.projects.DependencyAPI` mapped
         to its ``ape-config.yaml`` file dependencies special key. For example,
         when configuring GitHub dependencies, you set the ``github`` key in
         the ``dependencies:`` block of your ``ape-config.yaml`` file and it
         will automatically use this ``DependencyAPI`` implementation.
 
         Returns:
-            Type[:class:`~ape.api.projects.DependencyAPI`]
+            type[:class:`~ape.api.projects.DependencyAPI`]
         """
```

### Comparing `eth-ape-0.7.9/src/ape/plugins/query.py` & `eth-ape-0.8.0/src/ape/plugins/query.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,27 +1,28 @@
-from typing import TYPE_CHECKING, Iterator, Type
+from collections.abc import Iterator
+from typing import TYPE_CHECKING
 
 from .pluggy_patch import PluginType, hookspec
 
 if TYPE_CHECKING:
     from ape.api import QueryAPI
 
 
 class QueryPlugin(PluginType):
     """
     A plugin for querying chains.
     """
 
     @hookspec  # type: ignore[empty-body]
-    def query_engines(self) -> Iterator[Type["QueryAPI"]]:
+    def query_engines(self) -> Iterator[type["QueryAPI"]]:
         """
         A hook that returns an iterator of types of a ``QueryAPI`` subclasses
 
         Usage example::
 
             @plugins.register(plugins.QueryPlugin)
             def query_engines():
                 yield PostgresEngine
 
         Returns:
-            Iterator[Type[:class:`~ape.api.query.QueryAPI`]]
+            Iterator[type[:class:`~ape.api.query.QueryAPI`]]
         """
```

### Comparing `eth-ape-0.7.9/src/ape/pytest/README.md` & `eth-ape-0.8.0/src/ape/pytest/README.md`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/src/ape/pytest/config.py` & `eth-ape-0.8.0/src/ape/pytest/config.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,16 @@
-from typing import Any, Dict, List, Optional, Union
+from typing import Any, Optional, Union
 
 from _pytest.config import Config as PytestConfig
 
 from ape.types import ContractFunctionPath
 from ape.utils import ManagerAccessMixin, cached_property
 
 
-def _get_config_exclusions(config) -> List[ContractFunctionPath]:
+def _get_config_exclusions(config) -> list[ContractFunctionPath]:
     return [
         ContractFunctionPath(contract_name=x.contract_name, method_name=x.method_name)
         for x in config.exclude
     ]
 
 
 class ConfigWrapper(ManagerAccessMixin):
@@ -56,45 +56,45 @@
         return self.pytest_config.getoption("--gas") or self.ape_test_config.gas.show
 
     @cached_property
     def track_coverage(self) -> bool:
         return self.pytest_config.getoption("--coverage") or self.ape_test_config.coverage.track
 
     @property
-    def xml_coverage(self) -> Union[bool, Dict]:
+    def xml_coverage(self) -> Union[bool, dict]:
         return self.ape_test_config.coverage.reports.xml
 
     @property
-    def html_coverage(self) -> Union[bool, Dict]:
+    def html_coverage(self) -> Union[bool, dict]:
         return self.ape_test_config.coverage.reports.html
 
     @cached_property
     def show_internal(self) -> bool:
-        return self.pytest_config.getoption("showinternal")
+        return self.pytest_config.getoption("--show-internal")
 
     @cached_property
-    def gas_exclusions(self) -> List[ContractFunctionPath]:
+    def gas_exclusions(self) -> list[ContractFunctionPath]:
         """
         The combination of both CLI values and config values.
         """
 
         cli_value = self.pytest_config.getoption("--gas-exclude")
-        exclusions: List[ContractFunctionPath] = []
+        exclusions: list[ContractFunctionPath] = []
         if cli_value:
             items = cli_value.split(",")
             for item in items:
                 exclusion = ContractFunctionPath.from_str(item)
                 exclusions.append(exclusion)
 
         paths = _get_config_exclusions(self.ape_test_config.gas)
         exclusions.extend(paths)
         return exclusions
 
     @cached_property
-    def coverage_exclusions(self) -> List[ContractFunctionPath]:
+    def coverage_exclusions(self) -> list[ContractFunctionPath]:
         return _get_config_exclusions(self.ape_test_config.coverage)
 
     def get_pytest_plugin(self, name: str) -> Optional[Any]:
         if self.pytest_config.pluginmanager.has_plugin(name):
             return self.pytest_config.pluginmanager.get_plugin(name)
 
         return None
```

### Comparing `eth-ape-0.7.9/src/ape/pytest/contextmanagers.py` & `eth-ape-0.8.0/src/ape/pytest/contextmanagers.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 import re
 from re import Pattern
-from typing import Optional, Type, Union
+from typing import Optional, Union
 
 from ethpm_types.abi import ErrorABI
 
 from ape.contracts import ContractInstance
 from ape.exceptions import ContractLogicError, CustomError, TransactionError
 from ape.utils.basemodel import ManagerAccessMixin
 
@@ -21,15 +21,15 @@
     # and not when the user needs to access it.
     value: ContractLogicError = None  # type: ignore
 
 
 class RevertsContextManager(ManagerAccessMixin):
     def __init__(
         self,
-        expected_message: Optional[Union[_RevertMessage, Type[CustomError], ErrorABI]] = None,
+        expected_message: Optional[Union[_RevertMessage, type[CustomError], ErrorABI]] = None,
         dev_message: Optional[_RevertMessage] = None,
         **error_inputs,
     ):
         self.expected_message = expected_message
         self.dev_message = dev_message
         self.error_inputs = error_inputs
         self.revert_info: Optional[RevertInfo] = None
@@ -150,15 +150,15 @@
             raise AssertionError("\n".join(incorrect_values))
 
     def __enter__(self, *args, **kwargs):
         info = RevertInfo()
         self.revert_info = info
         return info
 
-    def __exit__(self, exc_type: Type, exc_value: Exception, traceback) -> bool:
+    def __exit__(self, exc_type: type, exc_value: Exception, traceback) -> bool:
         if exc_type is None:
             raise AssertionError("Transaction did not revert.")
 
         if not isinstance(exc_value, ContractLogicError):
             raise AssertionError(
                 f"Transaction did not revert.\n"
                 f"However, an exception of type {type(exc_value)} occurred: {exc_value}."
```

### Comparing `eth-ape-0.7.9/src/ape/pytest/coverage.py` & `eth-ape-0.8.0/src/ape/pytest/coverage.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,29 +1,28 @@
+from collections.abc import Iterable
 from pathlib import Path
-from typing import Iterable, List, Optional, Set, Tuple
+from typing import Optional
 
 import click
 from ethpm_types.abi import MethodABI
 from ethpm_types.source import ContractSource
 
 from ape.logging import logger
 from ape.pytest.config import ConfigWrapper
 from ape.types import (
     ContractFunctionPath,
     ControlFlow,
     CoverageProject,
     CoverageReport,
     SourceTraceback,
 )
-from ape.utils import (
-    ManagerAccessMixin,
-    get_current_timestamp_ms,
-    get_relative_path,
-    parse_coverage_tables,
-)
+from ape.utils.basemodel import ManagerAccessMixin
+from ape.utils.misc import get_current_timestamp_ms
+from ape.utils.os import get_full_extension, get_relative_path
+from ape.utils.trace import parse_coverage_tables
 
 
 class CoverageData(ManagerAccessMixin):
     def __init__(self, base_path: Path, sources: Iterable[ContractSource]):
         self.base_path = base_path
         self.sources = list(sources)
         self._report: Optional[CoverageReport] = None
@@ -44,48 +43,48 @@
         self,
     ) -> CoverageReport:
         # source_id -> pc(s) -> times hit
         project_coverage = CoverageProject(name=self.config_manager.name or "__local__")
 
         for src in self.sources:
             source_cov = project_coverage.include(src)
-            ext = Path(src.source_id).suffix
+            ext = get_full_extension(Path(src.source_id))
             if ext not in self.compiler_manager.registered_compilers:
                 continue
 
             compiler = self.compiler_manager.registered_compilers[ext]
             try:
                 compiler.init_coverage_profile(source_cov, src)
             except NotImplementedError:
                 continue
 
         timestamp = get_current_timestamp_ms()
         report = CoverageReport(
             projects=[project_coverage],
-            source_folders=[self.project_manager.contracts_folder],
+            source_folders=[self.local_project.contracts_folder],
             timestamp=timestamp,
         )
 
         # Remove emptys.
         for project in report.projects:
             project.sources = [x for x in project.sources if len(x.statements) > 0]
 
         self._report = report
         return report
 
     def cover(
         self, src_path: Path, pcs: Iterable[int], inc_fn_hits: bool = True
-    ) -> Tuple[Set[int], List[str]]:
+    ) -> tuple[set[int], list[str]]:
         source_id = str(get_relative_path(src_path.absolute(), self.base_path))
         if source_id not in self.report.sources:
             # The source is not tracked for coverage.
             return set(), []
 
         handled_pcs = set()
-        functions_incremented: List[str] = []
+        functions_incremented: list[str] = []
         for pc in pcs:
             if pc < 0:
                 continue
 
             if not (source_coverage := self.report.get_source_coverage(source_id)):
                 continue
 
@@ -119,28 +118,28 @@
 
         return handled_pcs, functions_incremented
 
 
 class CoverageTracker(ManagerAccessMixin):
     def __init__(self, config_wrapper: ConfigWrapper):
         self.config_wrapper = config_wrapper
-        sources = self.project_manager._contract_sources
+        sources = self.local_project._contract_sources
 
         self.data: Optional[CoverageData] = (
-            CoverageData(self.project_manager.contracts_folder, sources)
+            CoverageData(self.local_project.path, sources)
             if self.config_wrapper.track_coverage
             else None
         )
 
     @property
     def enabled(self) -> bool:
         return self.config_wrapper.track_coverage
 
     @property
-    def exclusions(self) -> List[ContractFunctionPath]:
+    def exclusions(self) -> list[ContractFunctionPath]:
         return self.config_wrapper.coverage_exclusions
 
     def reset(self):
         if self.data:
             self.data.reset()
 
     def cover(
@@ -163,29 +162,29 @@
               to ensure its hit count is bumped, even when there are not statements
               found. This is the only way to bump hit counts for auto-getters.
         """
         if not self.data:
             return
 
         last_path: Optional[Path] = None
-        last_pcs: Set[int] = set()
+        last_pcs: set[int] = set()
         last_call: Optional[str] = None
         main_fn = None
 
         if (contract and not function) or (function and not contract):
             raise ValueError("Must provide both function and contract if supplying one of them.")
 
         elif contract and function:
             # Make sure it is the actual source.
             source_path = traceback[0].source_path if len(traceback) > 0 else None
             for project in self.data.report.projects:
                 for src in project.sources:
                     # NOTE: We will allow this check to skip if there is no source is the
                     # traceback. This helps increment methods that are missing from the source map.
-                    path = self.project_manager.contracts_folder / src.source_id
+                    path = self.local_project.contracts_folder / src.source_id
                     if source_path is not None and path != source_path:
                         continue
 
                     # Source containing the auto-getter found.
                     for con in src.contracts:
                         if con.name != contract:
                             continue
@@ -220,17 +219,17 @@
             # is still called. Thus, we need to bump the hit count for the auto-getter.
             main_fn.hit_count += 1
 
     def _cover(
         self,
         control_flow: ControlFlow,
         last_path: Optional[Path] = None,
-        last_pcs: Optional[Set[int]] = None,
+        last_pcs: Optional[set[int]] = None,
         last_call: Optional[str] = None,
-    ) -> Tuple[Set[int], List[str]]:
+    ) -> tuple[set[int], list[str]]:
         if not self.data or control_flow.source_path is None:
             return set(), []
 
         last_pcs = last_pcs or set()
         pcs = control_flow.pcs
         if last_path is not None and control_flow.source_path == last_path:
             # Remove possibly duplicate PCs. This shouldn't happen,
@@ -276,15 +275,15 @@
 
     def show_session_coverage(self) -> bool:
         if not self.data or not self.data.report or not self.data.report.sources:
             return False
 
         # Reports are set in ape-config.yaml.
         reports = self.config_wrapper.ape_test_config.coverage.reports
-        out_folder = self.project_manager.local_project._cache_folder
+        out_folder = self.local_project.manifest_path.parent
         if reports.terminal:
             verbose = (
                 reports.terminal.get("verbose", False)
                 if isinstance(reports.terminal, dict)
                 else False
             )
             if isinstance(verbose, str):
```

### Comparing `eth-ape-0.7.9/src/ape/pytest/fixtures.py` & `eth-ape-0.8.0/src/ape/pytest/fixtures.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 import copy
+from collections.abc import Iterator
 from fnmatch import fnmatch
-from typing import Dict, Iterator, List, Optional
+from typing import Optional
 
 import pytest
 
 from ape.api import ReceiptAPI, TestAccountAPI
 from ape.exceptions import BlockNotFoundError, ChainError
 from ape.logging import logger
 from ape.managers.chain import ChainManager
@@ -31,15 +32,15 @@
     def _track_transactions(self) -> bool:
         has_reason = self.config_wrapper.track_gas or self.config_wrapper.track_coverage
         return (
             self.network_manager.provider is not None and self.provider.is_connected and has_reason
         )
 
     @pytest.fixture(scope="session")
-    def accounts(self) -> List[TestAccountAPI]:
+    def accounts(self) -> list[TestAccountAPI]:
         """
         A collection of pre-funded accounts.
         """
 
         return self.account_manager.test_accounts
 
     @pytest.fixture(scope="session")
@@ -68,15 +69,15 @@
 
     @pytest.fixture(scope="session")
     def project(self) -> ProjectManager:
         """
         Access contract types and dependencies.
         """
 
-        return self.project_manager
+        return self.local_project
 
     @pytest.fixture(scope="session")
     def Contract(self):
         """
         Instantiate a reference to an on-chain contract
         using its address (same as ``ape.Contract``).
         """
@@ -138,16 +139,16 @@
             return
 
         self.chain_manager.restore(snapshot_id)
 
 
 class ReceiptCapture(ManagerAccessMixin):
     config_wrapper: ConfigWrapper
-    receipt_map: Dict[str, Dict[str, ReceiptAPI]] = {}
-    enter_blocks: List[int] = []
+    receipt_map: dict[str, dict[str, ReceiptAPI]] = {}
+    enter_blocks: list[int] = []
 
     def __init__(self, config_wrapper: ConfigWrapper):
         self.config_wrapper = config_wrapper
 
     def __enter__(self):
         block_number = self._get_block_number()
         if block_number is not None:
@@ -238,15 +239,15 @@
             method_pattern = exclusion.method_name
             if not method_pattern or fnmatch(method_name, method_pattern):
                 return True
 
         return False
 
 
-def _build_report(report: Dict, contract: str, method: str, usages: List) -> Dict:
+def _build_report(report: dict, contract: str, method: str, usages: list) -> dict:
     new_dict = copy.deepcopy(report)
     if contract not in new_dict:
         new_dict[contract] = {method: usages}
     elif method not in new_dict[contract]:
         new_dict[contract][method] = usages
     else:
         new_dict[contract][method].extend(usages)
```

### Comparing `eth-ape-0.7.9/src/ape/pytest/gas.py` & `eth-ape-0.8.0/src/ape/pytest/gas.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,15 +1,16 @@
-from typing import Dict, List, Optional
+from typing import Optional
 
 from ethpm_types.abi import MethodABI
 from ethpm_types.source import ContractSource
 from evm_trace.gas import merge_reports
 
+from ape.api import TraceAPI
 from ape.pytest.config import ConfigWrapper
-from ape.types import AddressType, CallTreeNode, ContractFunctionPath, GasReport
+from ape.types import AddressType, ContractFunctionPath, GasReport
 from ape.utils import parse_gas_table
 from ape.utils.basemodel import ManagerAccessMixin
 from ape.utils.trace import _exclude_gas
 
 
 class GasTracker(ManagerAccessMixin):
     """
@@ -22,41 +23,37 @@
         self.session_gas_report: Optional[GasReport] = None
 
     @property
     def enabled(self) -> bool:
         return self.config_wrapper.track_gas
 
     @property
-    def gas_exclusions(self) -> List[ContractFunctionPath]:
+    def gas_exclusions(self) -> list[ContractFunctionPath]:
         return self.config_wrapper.gas_exclusions
 
     def show_session_gas(self) -> bool:
         if not self.session_gas_report:
             return False
 
         tables = parse_gas_table(self.session_gas_report)
         self.chain_manager._reports.echo(*tables)
         return True
 
-    def append_gas(
-        self,
-        call_tree: CallTreeNode,
-        contract_address: AddressType,
-    ):
+    def append_gas(self, trace: TraceAPI, contract_address: AddressType):
         contract_type = self.chain_manager.contracts.get(contract_address)
         if not contract_type:
             # Skip unknown contracts.
             return
 
-        report = call_tree.get_gas_report(exclude=self.gas_exclusions)
+        report = trace.get_gas_report(exclude=self.gas_exclusions)
         self._merge(report)
 
     def append_toplevel_gas(self, contract: ContractSource, method: MethodABI, gas_cost: int):
         exclusions = self.gas_exclusions or []
         if (contract_id := contract.contract_type.name) and not _exclude_gas(
             exclusions, contract_id, method.selector
         ):
             self._merge({contract_id: {method.selector: [gas_cost]}})
 
-    def _merge(self, report: Dict):
+    def _merge(self, report: dict):
         session_report = self.session_gas_report or {}
         self.session_gas_report = merge_reports(session_report, report)
```

### Comparing `eth-ape-0.7.9/src/ape/pytest/plugin.py` & `eth-ape-0.8.0/src/ape/pytest/plugin.py`

 * *Files 3% similar despite different names*

```diff
@@ -24,15 +24,15 @@
                     f"Another pytest plugin besides `ape_test` uses an option with "
                     f"one of '{name_str}'. Note that Ape does not support being "
                     f"installed alongside Brownie; please use separate environments!"
                 )
 
             raise ConfigError(f"Failed adding option {name_str}: {err}") from err
 
-    add_option("--showinternal", action="store_true")
+    add_option("--show-internal", action="store_true")
     add_option(
         "--network",
         action="store",
         default=ManagerAccessMixin.network_manager.default_ecosystem.name,
         help="Override the default network and provider (see ``ape networks list`` for options).",
     )
     add_option(
@@ -59,15 +59,15 @@
     parser.addoption("--coverage", action="store_true", help="Collect contract coverage.")
 
     # NOTE: Other pytest plugins, such as hypothesis, should integrate with pytest separately
 
 
 def pytest_configure(config):
     # Do not include ape internals in tracebacks unless explicitly asked
-    if not config.getoption("showinternal"):
+    if not config.getoption("--show-internal"):
         path_str = sys.modules["ape"].__file__
         if path_str:
             base_path = Path(path_str).parent.as_posix()
 
             def is_module(v):
                 return getattr(v, "__file__", None) and v.__file__.startswith(base_path)
 
@@ -102,25 +102,25 @@
 
 
 def pytest_load_initial_conftests(early_config):
     """
     Compile contracts before loading ``conftest.py``s.
     """
     capture_manager = early_config.pluginmanager.get_plugin("capturemanager")
+    pm = ManagerAccessMixin.local_project
 
-    if not ManagerAccessMixin.project_manager.sources_missing:
-        # Suspend stdout capture to display compilation data
-        capture_manager.suspend()
-        try:
-            ManagerAccessMixin.project_manager.load_contracts()
-        except Exception as err:
-            logger.log_debug_stack_trace()
-            message = "Unable to load project. "
-            if logger.level > LogLevel.DEBUG:
-                message = f"{message}Use `-v DEBUG` to see more info.\n"
-
-            err_type_name = getattr(type(err), "__name__", "Exception")
-            message = f"{message}Failure reason: ({err_type_name}) {err}"
-            raise pytest.UsageError(message)
+    # Suspend stdout capture to display compilation data
+    capture_manager.suspend()
+    try:
+        pm.load_contracts()
+    except Exception as err:
+        logger.log_debug_stack_trace()
+        message = "Unable to load project. "
+        if logger.level > LogLevel.DEBUG:
+            message = f"{message}Use `-v DEBUG` to see more info.\n"
+
+        err_type_name = getattr(type(err), "__name__", "Exception")
+        message = f"{message}Failure reason: ({err_type_name}) {err}"
+        raise pytest.UsageError(message)
 
-        finally:
-            capture_manager.resume()
+    finally:
+        capture_manager.resume()
```

### Comparing `eth-ape-0.7.9/src/ape/pytest/runners.py` & `eth-ape-0.8.0/src/ape/pytest/runners.py`

 * *Files 1% similar despite different names*

```diff
@@ -47,15 +47,15 @@
         A ``-I`` option triggers when an exception is raised which can be interactively handled.
         Outputs the full ``repr`` of the failed test and opens an interactive shell using the
         same console as the ``ape console`` command.
         """
 
         # Find the last traceback frame within the active project
         tb_frames: PytestTraceback = call.excinfo.traceback
-        base = self.project_manager.path.as_posix()
+        base = self.local_project.path.as_posix()
 
         if self.config_wrapper.show_internal:
             relevant_tb = list(tb_frames)
         else:
             relevant_tb = [
                 f
                 for f in tb_frames
@@ -110,15 +110,15 @@
             # get local namespace
             locals_dict = traceback.locals
             locals_dict = {k: v for k, v in locals_dict.items() if not k.startswith("@")}
 
             click.echo("Starting interactive mode. Type `exit` to halt current test.")
 
             namespace = {"_callinfo": call, **globals_dict, **locals_dict}
-            console(extra_locals=namespace, project=self.project_manager, embed=True)
+            console(extra_locals=namespace, project=self.local_project, embed=True)
 
             if capman:
                 capman.resume_global_capture()
 
         if type(call.excinfo.value) in (SystemExit, KeyboardInterrupt):
             # This will show the rest of Ape Test output as if the
             # tests had stopped here.
```

### Comparing `eth-ape-0.7.9/src/ape/types/coverage.py` & `eth-ape-0.8.0/src/ape/types/coverage.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 import itertools
 from datetime import datetime
 from html.parser import HTMLParser
 from pathlib import Path
-from typing import Any, Dict, List, Optional, Set
+from typing import Any, Optional
 from xml.dom.minidom import getDOMImplementation
 from xml.etree.ElementTree import Element, SubElement, tostring
 
 import requests
 from ethpm_types.source import ContractSource, SourceLocation
 from pydantic import NonNegativeInt, field_validator
 
@@ -129,15 +129,15 @@
 
     location: Optional[SourceLocation] = None
     """
     The location of the item (line, column, endline, endcolumn).
     If multiple PCs share an exact location, it is only tracked as one.
     """
 
-    pcs: Set[int]
+    pcs: set[int]
     """
     The PCs for this node.
     """
 
     hit_count: NonNegativeInt = 0
     """
     The times this node was hit.
@@ -161,15 +161,15 @@
     """
 
     full_name: str
     """
     The unique name of the function.
     """
 
-    statements: List[CoverageStatement] = []
+    statements: list[CoverageStatement] = []
     """
     For statement coverage, these are the individual items.
     See :class:`~ape.types.coverage.CoverageStatement` for more details.
     """
 
     hit_count: NonNegativeInt = 0
     """
@@ -269,21 +269,21 @@
     """
 
     name: str
     """
     The name of the contract.
     """
 
-    functions: List[FunctionCoverage] = []
+    functions: list[FunctionCoverage] = []
     """
     The coverage of each function individually.
     """
 
     @property
-    def statements(self) -> List[CoverageStatement]:
+    def statements(self) -> list[CoverageStatement]:
         """
         All valid coverage lines from every function in this contract.
         """
         return list(itertools.chain.from_iterable(f.statements for f in self.functions))
 
     @property
     def lines_covered(self) -> NonNegativeInt:
@@ -329,15 +329,15 @@
         return self.function_hits / len(self.functions)
 
     def __getitem__(self, function_name: str) -> FunctionCoverage:
         func = self.get_function(function_name)
         if func:
             return func
 
-        raise IndexError(f"Function '{function_name}' not found.")
+        raise KeyError(f"Function '{function_name}' not found.")
 
     def model_dump(self, *args, **kwargs) -> dict:
         attribs = super().model_dump(*args, **kwargs)
 
         # Add coverage stats.
         attribs["lines_covered"] = self.lines_covered
         attribs["lines_valid"] = self.lines_valid
@@ -369,21 +369,21 @@
     """
 
     source_id: str
     """
     The ID of the source covered.
     """
 
-    contracts: List[ContractCoverage] = []
+    contracts: list[ContractCoverage] = []
     """
     Coverage for each contract in the source file.
     """
 
     @property
-    def statements(self) -> List[CoverageStatement]:
+    def statements(self) -> list[CoverageStatement]:
         """
         All valid coverage lines from every function in every contract in this source.
         """
 
         return list(itertools.chain.from_iterable(c.statements for c in self.contracts))
 
     @property
@@ -467,21 +467,21 @@
     """
 
     name: str
     """
     The name of the project being covered.
     """
 
-    sources: List[ContractSourceCoverage] = []
+    sources: list[ContractSourceCoverage] = []
     """
     Coverage for each source in the project.
     """
 
     @property
-    def statements(self) -> List[CoverageStatement]:
+    def statements(self) -> list[CoverageStatement]:
         """
         All valid coverage lines from every function in every contract in every source
         in this project.
         """
 
         return list(itertools.chain.from_iterable(s.statements for s in self.sources))
 
@@ -556,44 +556,44 @@
 
 
 class CoverageReport(BaseModel):
     """
     Coverage report schema inspired from coverage.py.
     """
 
-    source_folders: List[Path]
+    source_folders: list[Path]
     """
     All source folders to use. This is needed for codecov.
     """
 
     timestamp: int
     """
     The timestamp the report was generated, in milliseconds.
     """
 
-    projects: List[CoverageProject] = []
+    projects: list[CoverageProject] = []
     """
     Each project with individual coverage tracked.
     """
 
     @field_validator("timestamp", mode="before")
     @classmethod
     def validate_timestamp(cls, value):
         # Default to current UTC timestamp (ms).
         return value or get_current_timestamp_ms()
 
     @property
-    def sources(self) -> List[str]:
+    def sources(self) -> list[str]:
         """
         Every source ID in the report.
         """
         return [s.source_id for p in self.projects for s in p.sources]
 
     @property
-    def statements(self) -> List[CoverageStatement]:
+    def statements(self) -> list[CoverageStatement]:
         """
         All valid coverage lines from every function in every contract in every source
         from every project in this report.
         """
         return list(itertools.chain.from_iterable(p.statements for p in self.projects))
 
     @property
@@ -732,20 +732,20 @@
                     # NOTE: I am not sure what this does or why it is needed.
                     # Also, I am not sure why we don't map statements to the methods.
                     # because we totally could do that. Nonetheless, we have to follow
                     # the schema.
                     xml_out.createElement("methods")
 
                     # Use name unless the same function found twice, then use full name.
-                    fn_map: Dict[str, FunctionCoverage] = {}
+                    fn_map: dict[str, FunctionCoverage] = {}
                     fn_singles_used = []
 
                     # For the XML report, we split all statements to be only 1 line long.
                     # Each class (contract) can only identify the statement (line number) once.
-                    lines_to_add: Dict[int, int] = {}
+                    lines_to_add: dict[int, int] = {}
                     xlines = xml_out.createElement("lines")
 
                     for function in contract.functions:
                         fn_singles_used.append(function.name)
                         if (
                             function.name in fn_map
                             and function.full_name != fn_map[function.name].full_name
```

### Comparing `eth-ape-0.7.9/src/ape/types/signatures.py` & `eth-ape-0.8.0/src/ape/types/signatures.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,15 +1,18 @@
-from typing import Iterator, Optional, Union
+from collections.abc import Iterator
+from typing import Optional, Union
 
 from eth_account import Account
 from eth_account.messages import SignableMessage
+from eth_pydantic_types import HexBytes
 from eth_utils import to_bytes, to_hex
-from hexbytes import HexBytes
 from pydantic.dataclasses import dataclass
 
+from ape.utils import log_instead_of_fail
+
 try:
     # Only on Python 3.11
     from typing import Self  # type: ignore
 except ImportError:
     from typing_extensions import Self  # type: ignore
 
 from ape.types import AddressType
@@ -58,16 +61,27 @@
 def _left_pad_bytes(val: bytes, num_bytes: int) -> bytes:
     return b"\x00" * (num_bytes - len(val)) + val if len(val) < num_bytes else val
 
 
 @dataclass(frozen=True)
 class _Signature:
     v: int
+    """
+    The version byte (``v``) in an Ethereum-style ECDSA signature.
+    """
+
     r: bytes
+    """
+    The random point (``r``) in an ECDSA signature.
+    """
+
     s: bytes
+    """
+    The signature proof point (``s``) in an ECDSA signature.
+    """
 
     def __iter__(self) -> Iterator[Union[int, bytes]]:
         # NOTE: Allows tuple destructuring
         yield self.v
         yield self.r
         yield self.s
 
@@ -83,14 +97,15 @@
     def from_vrs(cls, vrs: HexBytes) -> Self:
         # NOTE: Values may be padded.
         if len(vrs) != 65:
             raise ValueError("Length of VRS bytes must be 65.")
 
         return cls(v=vrs[0], r=HexBytes(vrs[1:33]), s=HexBytes(vrs[33:]))
 
+    @log_instead_of_fail(default="<_Signature>")
     def __repr__(self) -> str:
         class_name = getattr(type(self), "__name__", "_Signature")
         return f"<{class_name} v={self.v} r={to_hex(self.r)} s={to_hex(self.s)}>"
 
     def encode_vrs(self) -> bytes:
         return to_bytes(self.v) + _left_pad_bytes(self.r, 32) + _left_pad_bytes(self.s, 32)
```

### Comparing `eth-ape-0.7.9/src/ape/types/trace.py` & `eth-ape-0.8.0/src/ape/types/trace.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,238 +1,43 @@
-from itertools import chain, tee
+from collections.abc import Iterator
+from itertools import chain
 from pathlib import Path
-from typing import TYPE_CHECKING, Any, Dict, Iterator, List, Optional, Set, Union
+from typing import TYPE_CHECKING, Optional, Union
 
 from eth_pydantic_types import HexBytes
-from ethpm_types import ASTNode, BaseModel, ContractType
+from ethpm_types import ASTNode, BaseModel
 from ethpm_types.ast import SourceLocation
-from ethpm_types.source import Closure, Content, Function, SourceStatement, Statement
-from evm_trace.gas import merge_reports
-from pydantic import Field, RootModel
-from rich.table import Table
-from rich.tree import Tree
-
-from ape.types.address import AddressType
-from ape.utils.basemodel import BaseInterfaceModel
-from ape.utils.misc import is_evm_precompile, is_zero_hex
-from ape.utils.trace import _exclude_gas, parse_as_str, parse_gas_table, parse_rich_tree
+from ethpm_types.source import (
+    Closure,
+    Content,
+    ContractSource,
+    Function,
+    SourceStatement,
+    Statement,
+)
+from pydantic import RootModel
+
+from ape.utils.misc import log_instead_of_fail
 
 if TYPE_CHECKING:
-    from ape.types import ContractFunctionPath
+    from ape.api.trace import TraceAPI
 
 
-GasReport = Dict[str, Dict[str, List[int]]]
+GasReport = dict[str, dict[str, list[int]]]
 """
 A gas report in Ape.
 """
 
 
-class CallTreeNode(BaseInterfaceModel):
-    contract_id: str
-    """
-    The identifier representing the contract in this node.
-    A non-enriched identifier is an address; a more enriched
-    identifier is a token symbol or contract type name.
-    """
-
-    method_id: Optional[str] = None
-    """
-    The identifier representing the method in this node.
-    A non-enriched identifier is a method selector.
-    An enriched identifier is method signature.
-    """
-
-    txn_hash: Optional[str] = None
-    """
-    The transaction hash, if known and/or exists.
-    """
-
-    failed: bool = False
-    """
-    ``True`` where this tree represents a failed call.
-    """
-
-    inputs: Optional[Any] = None
-    """
-    The inputs to the call.
-    Non-enriched inputs are raw bytes or values.
-    Enriched inputs are decoded.
-    """
-
-    outputs: Optional[Any] = None
-    """
-    The output to the call.
-    Non-enriched inputs are raw bytes or values.
-    Enriched outputs are decoded.
-    """
-
-    value: Optional[int] = None
-    """
-    The value sent with the call, if applicable.
-    """
-
-    gas_cost: Optional[int] = None
-    """
-    The gas cost of the call, if known.
-    """
-
-    call_type: Optional[str] = None
-    """
-    A str indicating what type of call it is.
-    See ``evm_trace.enums.CallType`` for EVM examples.
-    """
-
-    calls: List["CallTreeNode"] = []
-    """
-    The list of subcalls made by this call.
-    """
-
-    raw: Dict = Field({}, exclude=True, repr=False)
-    """
-    The raw tree, as a dictionary, associated with the call.
-    """
-
-    def __repr__(self) -> str:
-        return parse_as_str(self)
-
-    def __str__(self) -> str:
-        return parse_as_str(self)
-
-    def _repr_pretty_(self, *args, **kwargs):
-        enriched_tree = self.enrich(use_symbol_for_tokens=True)
-        self.chain_manager._reports.show_trace(enriched_tree)
-
-    def enrich(self, **kwargs) -> "CallTreeNode":
-        """
-        Enrich the properties on this call tree using data from contracts
-        and using information about the ecosystem.
-
-        Args:
-            **kwargs: Key-word arguments to pass to
-              :meth:`~ape.api.networks.EcosystemAPI.enrich_calltree`, such as
-              ``use_symbol_for_tokens``.
-
-        Returns:
-            :class:`~ape.types.trace.CallTreeNode`: This call tree node with
-            its properties enriched.
-        """
-
-        return self.provider.network.ecosystem.enrich_calltree(self, **kwargs)
-
-    def add(self, sub_call: "CallTreeNode"):
-        """
-        Add a sub call to this node. This implies this call called the sub-call.
-
-        Args:
-            sub_call (:class:`~ape.types.trace.CallTreeNode`): The sub-call to add.
-        """
-
-        self.calls.append(sub_call)
-
-    def as_rich_tree(self, verbose: bool = False) -> Tree:
-        """
-        Return this object as a ``rich.tree.Tree`` for pretty-printing.
-
-        Returns:
-            ``Tree``
-        """
-
-        return parse_rich_tree(self, verbose=verbose)
-
-    def as_gas_tables(self, exclude: Optional[List["ContractFunctionPath"]] = None) -> List[Table]:
-        """
-        Return this object as list of rich gas tables for pretty printing.
-
-        Args:
-            exclude (Optional[List[:class:`~ape.types.ContractFunctionPath`]]):
-              A list of contract / method combinations to exclude from the gas
-              tables.
-
-        Returns:
-            List[``rich.table.Table``]
-        """
-
-        report = self.get_gas_report(exclude=exclude)
-        return parse_gas_table(report)
-
-    def get_gas_report(self, exclude: Optional[List["ContractFunctionPath"]] = None) -> "GasReport":
-        """
-        Get a unified gas-report of all the calls made in this tree.
-
-        Args:
-            exclude (Optional[List[:class:`~ape.types.ContractFunctionPath`]]):
-              A list of contract / method combinations to exclude from the gas
-              tables.
-
-        Returns:
-            :class:`~ape.types.trace.GasReport`
-        """
-
-        exclusions = exclude or []
-        if (
-            not self.contract_id
-            or not self.method_id
-            or _exclude_gas(exclusions, self.contract_id, self.method_id)
-        ):
-            return merge_reports(*(c.get_gas_report(exclude) for c in self.calls))
-
-        elif not is_zero_hex(self.method_id) and not is_evm_precompile(self.method_id):
-            reports = [
-                *[c.get_gas_report(exclude) for c in self.calls],
-                {
-                    self.contract_id: {
-                        self.method_id: [self.gas_cost] if self.gas_cost is not None else []
-                    }
-                },
-            ]
-            return merge_reports(*reports)
-
-        return merge_reports(*(c.get_gas_report(exclude) for c in self.calls))
-
-
-class TraceFrame(BaseInterfaceModel):
-    """
-    A low-level data structure modeling a transaction trace frame
-    from the Geth RPC ``debug_traceTransaction``.
-    """
-
-    pc: int
-    """Program counter."""
-
-    op: str
-    """Opcode."""
-
-    gas: int
-    """Remaining gas."""
-
-    gas_cost: int
-    """The cost to execute this opcode."""
-
-    depth: int
-    """
-    The number of external jumps away the initially called contract (starts at 0).
-    """
-
-    contract_address: Optional[AddressType] = None
-    """
-    The contract address, if this is a call trace frame.
-    """
-
-    raw: Dict = Field({}, exclude=True, repr=False)
-    """
-    The raw trace frame from the provider.
-    """
-
-
 class ControlFlow(BaseModel):
     """
     A collection of linear source nodes up until a jump.
     """
 
-    statements: List[Statement]
+    statements: list[Statement]
     """
     The source node statements.
     """
 
     closure: Closure
     """
     The defining closure, such as a function or module, of the code sequence.
@@ -249,14 +54,15 @@
     The depth at which this flow was executed,
     where 1 is the first calling function.
     """
 
     def __str__(self) -> str:
         return f"{self.source_header}\n{self.format()}"
 
+    @log_instead_of_fail(default="<ControlFlow>")
     def __repr__(self) -> str:
         source_name = f" {self.source_path.name} " if self.source_path is not None else " "
         representation = f"<control path,{source_name}{self.closure.name}"
 
         if len(self.statements) > 0:
             representation = f"{representation} num_statements={len(self.statements)}"
 
@@ -279,15 +85,15 @@
         except IndexError as err:
             raise IndexError(f"Statement index '{idx}' out of range.") from err
 
     def __len__(self) -> int:
         return len(self.statements)
 
     @property
-    def source_statements(self) -> List[SourceStatement]:
+    def source_statements(self) -> list[SourceStatement]:
         """
         All statements coming directly from a contract's source.
         Excludes implicit-compiler statements.
         """
         return [x for x in self.statements if isinstance(x, SourceStatement)]
 
     @property
@@ -303,30 +109,30 @@
         """
         The first line number in the sequence, including whitespace.
         """
         stmts = self.source_statements
         return stmts[0].ws_begin_lineno if stmts else None
 
     @property
-    def line_numbers(self) -> List[int]:
+    def line_numbers(self) -> list[int]:
         """
         The list of all line numbers as part of this node.
         """
 
         if self.begin_lineno is None:
             return []
 
         elif self.end_lineno is None:
             return [self.begin_lineno]
 
         return list(range(self.begin_lineno, self.end_lineno + 1))
 
     @property
     def content(self) -> Content:
-        result: Dict[int, str] = {}
+        result: dict[int, str] = {}
         for node in self.source_statements:
             result = {**result, **node.content.root}
 
         return Content(root=result)
 
     @property
     def source_header(self) -> str:
@@ -342,37 +148,37 @@
         """
         The last line number.
         """
         stmts = self.source_statements
         return stmts[-1].end_lineno if stmts else None
 
     @property
-    def pcs(self) -> Set[int]:
-        full_set: Set[int] = set()
+    def pcs(self) -> set[int]:
+        full_set: set[int] = set()
         for stmt in self.statements:
             full_set |= stmt.pcs
 
         return full_set
 
     def extend(
         self,
         location: SourceLocation,
-        pcs: Optional[Set[int]] = None,
+        pcs: Optional[set[int]] = None,
         ws_start: Optional[int] = None,
     ):
         """
         Extend this node's content with other content that follows it directly.
 
         Raises:
             ValueError: When there is a gap in content.
 
         Args:
             location (SourceLocation): The location of the content, in the form
               (lineno, col_offset, end_lineno, end_coloffset).
-            pcs (Optional[Set[int]]): The PC values of the statements.
+            pcs (Optional[set[int]]): The PC values of the statements.
             ws_start (Optional[int]): Optionally provide a white-space starting point
               to back-fill.
         """
 
         pcs = pcs or set()
         if ws_start is not None and ws_start > location[0]:
             # No new lines.
@@ -478,46 +284,38 @@
             return None
 
         sorted_dict = {k: content_dict[k] for k in sorted(content_dict)}
         content = Content(root=sorted_dict)
         return SourceStatement(asts=next_stmt_asts, content=content)
 
 
-class SourceTraceback(RootModel[List[ControlFlow]]):
+class SourceTraceback(RootModel[list[ControlFlow]]):
     """
     A full execution traceback including source code.
     """
 
     @classmethod
-    def create(
-        cls,
-        contract_type: ContractType,
-        trace: Iterator[TraceFrame],
-        data: Union[HexBytes, str],
-    ):
-        trace, second_trace = tee(trace)
-        if not second_trace or not (accessor := next(second_trace, None)):
-            return cls.model_validate([])
-
-        if not (source_id := contract_type.source_id):
-            return cls.model_validate([])
-
+    def create(cls, contract_source: ContractSource, trace: "TraceAPI", data: Union[HexBytes, str]):
+        # Use the trace as a 'ManagerAccessMixin'.
+        compilers = trace.compiler_manager
+        source_id = contract_source.source_id
         ext = f".{source_id.split('.')[-1]}"
-        if ext not in accessor.compiler_manager.registered_compilers:
+        if ext not in compilers.registered_compilers:
             return cls.model_validate([])
 
-        compiler = accessor.compiler_manager.registered_compilers[ext]
+        compiler = compilers.registered_compilers[ext]
         try:
-            return compiler.trace_source(contract_type, trace, HexBytes(data))
+            return compiler.trace_source(contract_source, trace, HexBytes(data))
         except NotImplementedError:
             return cls.model_validate([])
 
     def __str__(self) -> str:
         return self.format()
 
+    @log_instead_of_fail(default="<SourceTraceback>")
     def __repr__(self) -> str:
         return f"<ape.types.SourceTraceback control_paths={len(self.root)}>"
 
     def __len__(self) -> int:
         return len(self.root)
 
     def __iter__(self) -> Iterator[ControlFlow]:  # type: ignore[override]
@@ -560,30 +358,30 @@
     def last(self) -> Optional[ControlFlow]:
         """
         The last control flow in the traceback, if there is one.
         """
         return self.root[-1] if len(self.root) else None
 
     @property
-    def execution(self) -> List[ControlFlow]:
+    def execution(self) -> list[ControlFlow]:
         """
         All the control flows in order. Each set of statements in
         a control flow is separated by a jump.
         """
         return list(self.root)
 
     @property
-    def statements(self) -> List[Statement]:
+    def statements(self) -> list[Statement]:
         """
         All statements from each control flow.
         """
         return list(chain(*[x.statements for x in self.root]))
 
     @property
-    def source_statements(self) -> List[SourceStatement]:
+    def source_statements(self) -> list[SourceStatement]:
         """
         All source statements from each control flow.
         """
         return list(chain(*[x.source_statements for x in self.root]))
 
     def format(self) -> str:
         """
@@ -592,15 +390,15 @@
         if not len(self.root):
             # No calls.
             return ""
 
         header = "Traceback (most recent call last)"
         indent = "  "
         last_depth = None
-        segments: List[str] = []
+        segments: list[str] = []
         for control_flow in reversed(self.root):
             if last_depth is None or control_flow.depth == last_depth - 1:
                 if control_flow.depth == 0 and len(segments) >= 1:
                     # Ignore 0-layer segments if source code was hit
                     continue
 
                 last_depth = control_flow.depth
@@ -642,46 +440,46 @@
         return f"{header}{builder}"
 
     def add_jump(
         self,
         location: SourceLocation,
         function: Function,
         depth: int,
-        pcs: Optional[Set[int]] = None,
+        pcs: Optional[set[int]] = None,
         source_path: Optional[Path] = None,
     ):
         """
         Add an execution sequence from a jump.
 
         Args:
             location (``SourceLocation``): The location to add.
             function (``Function``): The function executing.
             source_path (Optional[``Path``]): The path of the source file.
             depth (int): The depth of the function call in the call tree.
-            pcs (Optional[Set[int]]): The program counter values.
+            pcs (Optional[set[int]]): The program counter values.
             source_path (Optional[``Path``]): The path of the source file.
         """
 
         asts = function.get_content_asts(location)
         content = function.get_content(location)
         if not asts or not content:
             return
 
         pcs = pcs or set()
         Statement.model_rebuild()
         ControlFlow.model_rebuild()
         self._add(asts, content, pcs, function, depth, source_path=source_path)
 
-    def extend_last(self, location: SourceLocation, pcs: Optional[Set[int]] = None):
+    def extend_last(self, location: SourceLocation, pcs: Optional[set[int]] = None):
         """
         Extend the last node with more content.
 
         Args:
             location (``SourceLocation``): The location of the new content.
-            pcs (Optional[Set[int]]): The PC values to add on.
+            pcs (Optional[set[int]]): The PC values to add on.
         """
 
         if not self.last:
             raise ValueError(
                 "`progress()` should only be called when "
                 "there is at least 1 ongoing execution trail."
             )
@@ -695,42 +493,42 @@
 
     def add_builtin_jump(
         self,
         name: str,
         _type: str,
         full_name: Optional[str] = None,
         source_path: Optional[Path] = None,
-        pcs: Optional[Set[int]] = None,
+        pcs: Optional[set[int]] = None,
     ):
         """
         A convenience method for appending a control flow that happened
         from an internal compiler built-in code. See the ape-vyper plugin
         for a usage example.
 
         Args:
             name (str): The name of the compiler built-in.
             _type (str): A str describing the type of check.
             full_name (Optional[str]): A full-name ID.
             source_path (Optional[Path]): The source file related, if there is one.
-            pcs (Optional[Set[int]]): Program counter values mapping to this check.
+            pcs (Optional[set[int]]): Program counter values mapping to this check.
         """
         pcs = pcs or set()
         closure = Closure(name=name, full_name=full_name or name)
         depth = self.last.depth - 1 if self.last else 0
         statement = Statement(type=_type, pcs=pcs)
         flow = ControlFlow(
             closure=closure, depth=depth, statements=[statement], source_path=source_path
         )
         self.append(flow)
 
     def _add(
         self,
-        asts: List[ASTNode],
+        asts: list[ASTNode],
         content: Content,
-        pcs: Set[int],
+        pcs: set[int],
         function: Function,
         depth: int,
         source_path: Optional[Path] = None,
     ):
         statement = SourceStatement(asts=asts, content=content, pcs=pcs)
         exec_sequence = ControlFlow(
             statements=[statement], source_path=source_path, closure=function, depth=depth
```

### Comparing `eth-ape-0.7.9/src/ape/utils/__init__.py` & `eth-ape-0.8.0/src/ape/utils/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -13,45 +13,53 @@
 from ape.utils.basemodel import (
     BaseInterface,
     BaseInterfaceModel,
     ExtraAttributesMixin,
     ExtraModelAttributes,
     ManagerAccessMixin,
     injected_before_use,
+    only_raise_attribute_error,
 )
-from ape.utils.github import GithubClient, github_client
 from ape.utils.misc import (
     DEFAULT_LIVE_NETWORK_BASE_FEE_MULTIPLIER,
     DEFAULT_LOCAL_TRANSACTION_ACCEPTANCE_TIMEOUT,
     DEFAULT_TRANSACTION_ACCEPTANCE_TIMEOUT,
     EMPTY_BYTES32,
+    SOURCE_EXCLUDE_PATTERNS,
     USER_AGENT,
     ZERO_ADDRESS,
     add_padding_to_strings,
     allow_disconnected,
     cached_property,
     extract_nested_value,
     gas_estimation_error_message,
     get_current_timestamp_ms,
     get_package_version,
     is_evm_precompile,
     is_zero_hex,
     load_config,
+    log_instead_of_fail,
     nonreentrant,
     pragma_str_to_specifier_set,
     raises_not_implemented,
     run_until_complete,
     singledispatchmethod,
     stream_response,
     to_int,
 )
 from ape.utils.os import (
+    clean_path,
+    create_tempdir,
     expand_environment_variables,
     get_all_files_in_directory,
+    get_full_extension,
     get_relative_path,
+    in_tempdir,
+    path_match,
+    run_in_tempdir,
     use_temp_sys_path,
 )
 from ape.utils.process import JoinableQueue, spawn
 from ape.utils.testing import (
     DEFAULT_NUMBER_OF_TEST_ACCOUNTS,
     DEFAULT_TEST_CHAIN_ID,
     DEFAULT_TEST_HD_PATH,
@@ -64,14 +72,16 @@
 __all__ = [
     "abstractmethod",
     "add_padding_to_strings",
     "allow_disconnected",
     "BaseInterface",
     "BaseInterfaceModel",
     "cached_property",
+    "clean_path",
+    "create_tempdir",
     "DEFAULT_LIVE_NETWORK_BASE_FEE_MULTIPLIER",
     "DEFAULT_LOCAL_TRANSACTION_ACCEPTANCE_TIMEOUT",
     "DEFAULT_NUMBER_OF_TEST_ACCOUNTS",
     "DEFAULT_TEST_CHAIN_ID",
     "DEFAULT_TEST_MNEMONIC",
     "DEFAULT_TEST_HD_PATH",
     "DEFAULT_TRANSACTION_ACCEPTANCE_TIMEOUT",
@@ -79,39 +89,44 @@
     "ExtraAttributesMixin",
     "expand_environment_variables",
     "extract_nested_value",
     "ExtraModelAttributes",
     "get_relative_path",
     "gas_estimation_error_message",
     "get_package_version",
-    "GithubClient",
-    "github_client",
     "GeneratedDevAccount",
     "generate_dev_accounts",
     "get_all_files_in_directory",
     "get_current_timestamp_ms",
+    "get_full_extension",
     "pragma_str_to_specifier_set",
+    "in_tempdir",
     "injected_before_use",
     "is_array",
     "is_dynamic_sized_type",
     "is_evm_precompile",
     "is_named_tuple",
     "is_struct",
     "is_zero_hex",
     "JoinableQueue",
     "load_config",
+    "log_instead_of_fail",
     "LogInputABICollection",
     "ManagerAccessMixin",
     "nonreentrant",
+    "only_raise_attribute_error",
     "parse_coverage_tables",
     "parse_gas_table",
+    "path_match",
     "raises_not_implemented",
     "returns_array",
+    "run_in_tempdir",
     "run_until_complete",
     "singledispatchmethod",
+    "SOURCE_EXCLUDE_PATTERNS",
     "spawn",
     "stream_response",
     "Struct",
     "StructParser",
     "to_int",
     "TraceStyles",
     "use_temp_sys_path",
```

### Comparing `eth-ape-0.7.9/src/ape/utils/abi.py` & `eth-ape-0.8.0/src/ape/utils/abi.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 import re
+from collections.abc import Sequence
 from dataclasses import make_dataclass
-from typing import Any, Dict, List, Optional, Sequence, Tuple, Union
+from typing import Any, Optional, Union
 
 from eth_abi import decode, grammar
 from eth_abi.exceptions import DecodingError, InsufficientDataBytes
 from eth_pydantic_types import HexBytes
 from eth_utils import decode_hex
 from ethpm_types.abi import ABIType, ConstructorABI, EventABI, EventABIType, MethodABI
 
@@ -59,104 +60,111 @@
         The default struct return name for unnamed structs.
         This value is also used for named tuples where the tuple does not have a name
         (but each item in the tuple does have a name).
         """
         name = self.abi.name if isinstance(self.abi, MethodABI) else "constructor"
         return f"{name}_return"
 
-    def encode_input(self, values: Union[List, Tuple, Dict]) -> Any:
+    def encode_input(self, values: Union[list, tuple, dict]) -> Any:
         """
         Convert dicts and other objects to struct inputs.
 
         Args:
-            values (Union[List, Tuple]): A list of of input values.
+            values (Union[list, ttuple]): A list of of input values.
 
         Returns:
             Any: The same input values only decoded into structs when applicable.
         """
 
         return [self._encode(ipt, v) for ipt, v in zip(self.abi.inputs, values)]
 
-    def decode_input(self, values: Union[Sequence, Dict[str, Any]]) -> Any:
+    def decode_input(self, values: Union[Sequence, dict[str, Any]]) -> Any:
         return (
             self._decode(self.abi.inputs, values)
             if isinstance(self.abi, (EventABI, MethodABI))
             else None
         )
 
     def _encode(self, _type: ABIType, value: Any):
         if (
             _type.type == "tuple"
             and _type.components
             and all(m.name for m in _type.components)
             and not isinstance(value, tuple)
         ):
             if isinstance(value, dict):
-                return tuple([value[m.name] for m in _type.components])
+                return tuple(
+                    (
+                        self._encode(m, value[m.name])
+                        if isinstance(value[m.name], dict)
+                        else value[m.name]
+                    )
+                    for m in _type.components
+                )
 
             elif isinstance(value, (list, tuple)):
                 # NOTE: Args must be passed in correct order.
                 return tuple(value)
 
             else:
                 arg = [getattr(value, m.name) for m in _type.components if m.name]
                 return tuple(arg)
 
         elif (
             str(_type.type).startswith("tuple[")
             and isinstance(value, (list, tuple))
             and len(_type.components or []) > 0
         ):
-            non_array_type_data = _type.model_dump(mode="json")
+            non_array_type_data = _type.model_dump()
             non_array_type_data["type"] = "tuple"
             non_array_type = ABIType(**non_array_type_data)
             return [self._encode(non_array_type, v) for v in value]
 
         return value
 
-    def decode_output(self, values: Union[List, Tuple]) -> Any:
+    def decode_output(self, values: Union[list, tuple]) -> Any:
         """
         Parse a list of output types and values into structs.
         Values are only altered when they are a struct.
         This method also handles structs within structs as well as arrays of structs.
 
         Args:
-            values (Union[List, Tuple]): A list of of output values.
+            values (Union[list, tuple]): A list of of output values.
 
         Returns:
             Any: The same input values only decoded into structs when applicable.
         """
 
         return self._decode(self.abi.outputs, values) if isinstance(self.abi, MethodABI) else None
 
     def _decode(
         self,
         _types: Union[Sequence[ABIType]],
-        values: Union[Sequence, Dict[str, Any]],
+        values: Union[Sequence, dict[str, Any]],
     ):
         if is_struct(_types):
             return self._create_struct(_types[0], values)
 
         elif isinstance(values, (list, tuple)) and is_named_tuple(_types, values):
             # Handle tuples. NOTE: unnamed output structs appear as tuples with named members
             return create_struct(self.default_name, _types, values)
 
-        return_values: List = []
+        return_values: list = []
         has_array_return = _is_array_return(_types)
         has_array_of_tuples_return = (
             has_array_return and len(_types) == 1 and "tuple" in _types[0].type
         )
         if has_array_return and not has_array_of_tuples_return:
             # Normal array
             return values
 
         elif has_array_of_tuples_return:
             item_type_str = str(_types[0].type).split("[")[0]
             data = {
-                **_types[0].model_dump(mode="json"),
+                **_types[0].model_dump(),
                 "type": item_type_str,
                 "internalType": item_type_str,
             }
             output_type = ABIType.model_validate(data)
 
             if isinstance(values, (list, tuple)) and not values[0]:
                 # Only returned an empty list.
@@ -170,15 +178,15 @@
         else:
             for output_type, value in zip(_types, values):
                 if isinstance(value, (tuple, list)):
                     item_type_str = str(output_type.type).split("[")[0]
                     if item_type_str == "tuple":
                         # Either an array of structs or nested structs.
                         item_type_data = {
-                            **output_type.model_dump(mode="json"),
+                            **output_type.model_dump(),
                             "type": item_type_str,
                             "internalType": item_type_str,
                         }
                         item_type = ABIType.model_validate(item_type_data)
 
                         if is_struct(output_type):
                             parsed_item = self._decode([item_type], [value])
@@ -219,15 +227,15 @@
         components = self._parse_components(out_abi.components, out_value[0])
         return create_struct(
             name,
             out_abi.components,
             components,
         )
 
-    def _parse_components(self, components: List[ABIType], values) -> List:
+    def _parse_components(self, components: list[ABIType], values) -> list:
         parsed_values = []
         for component, value in zip(components, values):
             if is_struct(component):
                 new_value = self._create_struct(component, (value,))
                 parsed_values.append(new_value)
             elif is_array(component.type) and "tuple" in component.type and component.components:
                 new_value = [self._decode(component.components, v) for v in value]
@@ -261,15 +269,15 @@
 
 
 class Struct:
     """
     A class for contract return values using the struct data-structure.
     """
 
-    def items(self) -> Dict:
+    def items(self) -> dict:
         """Override"""
         return {}
 
     def __setitem__(self, key, value):
         """Override"""
         pass
 
@@ -281,16 +289,16 @@
     numeric tuple access.
 
     **NOTE**: This method assumes you already know the values to give to the struct
     properties.
 
     Args:
         name (str): The name of the struct.
-        types (List[ABIType]: The types of values in the struct.
-        output_values (List[Any]): The struct property values.
+        types (list[ABIType]: The types of values in the struct.
+        output_values (list[Any]): The struct property values.
 
     Returns:
         Any: The struct dataclass.
     """
 
     def get_item(struct, key) -> Any:
         # NOTE: Allow struct to function as a tuple and dict as well
@@ -308,19 +316,19 @@
             field_to_set = struct_values[key]
             setattr(struct, field_to_set, value)
 
     def contains(struct, key):
         return key in struct.__dataclass_fields__
 
     def is_equal(struct, other) -> bool:
-        _len = len(other)
         if not hasattr(other, "__len__"):
             return NotImplemented
 
-        elif _len != len(struct):
+        _len = len(other)
+        if _len != len(struct):
             return False
 
         if hasattr(other, "items"):
             # Struct or dictionary.
             for key, value in other.items():
                 if key not in struct:
                     # Different object.
@@ -345,32 +353,45 @@
 
         else:
             return NotImplemented
 
     def length(struct) -> int:
         return len(struct.__dataclass_fields__)
 
-    def items(struct) -> List[Tuple]:
+    def items(struct) -> list[tuple]:
         return [(k, struct[k]) for k, v in struct.__dataclass_fields__.items()]
 
-    def values(struct) -> List[Any]:
+    def values(struct) -> list[Any]:
         return [x[1] for x in struct.items()]
 
+    def reduce(struct) -> tuple:
+        return (create_struct, (name, types, output_values))
+
     # NOTE: Should never be "_{i}", but mypy complains and we need a unique value
     properties = [m.name or f"_{i}" for i, m in enumerate(types)]
     methods = {
         "__eq__": is_equal,
         "__getitem__": get_item,
         "__setitem__": set_item,
         "__contains__": contains,
         "__len__": length,
+        "__reduce__": reduce,
         "items": items,
         "values": values,
     }
 
+    if conflicts := [p for p in properties if p in methods]:
+        conflicts_str = ", ".join(conflicts)
+        logger.debug(
+            "The following methods are unavailable on the struct "
+            f"due to having the same name as a field: {conflicts_str}"
+        )
+        for conflict in conflicts:
+            del methods[conflict]
+
     struct_def = make_dataclass(
         name,
         properties,
         namespace=methods,
         bases=(Struct,),  # We set a base class for subclass checking elsewhere.
     )
 
@@ -382,25 +403,25 @@
     return parsed.is_dynamic
 
 
 class LogInputABICollection:
     def __init__(self, abi: EventABI):
         self.abi = abi
         self.topic_abi_types = [i for i in abi.inputs if i.indexed]
-        self.data_abi_types: List[EventABIType] = [i for i in abi.inputs if not i.indexed]
+        self.data_abi_types: list[EventABIType] = [i for i in abi.inputs if not i.indexed]
 
         names = [i.name for i in abi.inputs]
         if len(set(names)) < len(names):
             raise ValueError("duplicate names found in log input", abi)
 
     @property
     def event_name(self):
         return self.abi.name
 
-    def decode(self, topics: List[str], data: str, use_hex_on_fail: bool = False) -> Dict:
+    def decode(self, topics: list[str], data: str, use_hex_on_fail: bool = False) -> dict:
         decoded = {}
         for abi, topic_value in zip(self.topic_abi_types, topics[1:]):
             # reference types as indexed arguments are written as a hash
             # https://docs.soliditylang.org/en/v0.8.15/contracts.html#events
             abi_type = "bytes32" if is_dynamic_sized_type(abi.type) else abi.canonical_type
             hex_value = decode_hex(topic_value)
```

### Comparing `eth-ape-0.7.9/src/ape/utils/basemodel.py` & `eth-ape-0.8.0/src/ape/utils/basemodel.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,42 +1,34 @@
+import inspect
 from abc import ABC
-from typing import (
-    TYPE_CHECKING,
-    Any,
-    Callable,
-    ClassVar,
-    Dict,
-    Iterator,
-    List,
-    Optional,
-    Sequence,
-    Union,
-    cast,
-)
+from collections.abc import Callable, Iterator, Sequence
+from sys import getrecursionlimit
+from typing import TYPE_CHECKING, Any, ClassVar, Optional, Union, cast
 
 from ethpm_types import BaseModel as EthpmTypesBaseModel
 from pydantic import BaseModel as RootBaseModel
 from pydantic import ConfigDict
 
 from ape.exceptions import ApeAttributeError, ApeIndexError, ProviderNotConnectedError
 from ape.logging import logger
+from ape.utils.misc import log_instead_of_fail, raises_not_implemented
 
 if TYPE_CHECKING:
     from pydantic.main import Model
 
     from ape.api.providers import ProviderAPI
     from ape.managers.accounts import AccountManager
     from ape.managers.chain import ChainManager
     from ape.managers.compilers import CompilerManager
     from ape.managers.config import ConfigManager
     from ape.managers.converters import ConversionManager
     from ape.managers.networks import NetworkManager
-    from ape.managers.project import DependencyManager, ProjectManager
+    from ape.managers.plugins import PluginManager
+    from ape.managers.project import ProjectManager
     from ape.managers.query import QueryManager
-    from ape.plugins import PluginManager
     from ape.pytest.runners import PytestApeRunner
 
 
 class classproperty(object):
     def __init__(self, fn: Callable):
         self.fn = fn
 
@@ -44,30 +36,35 @@
         return self.fn(owner)
 
 
 class _RecursionChecker:
     # A helper for preventing the recursion errors
     # that happen in custom __getattr__ methods.
 
-    THRESHOLD: int = 10
-    getattr_checking: Dict[str, int] = {}
-    getattr_errors: Dict[str, Exception] = {}
+    def __init__(self):
+        self.THRESHOLD: int = getrecursionlimit()
+        self.getattr_checking: dict[str, int] = {}
+        self.getattr_errors: dict[str, Exception] = {}
+
+    @log_instead_of_fail(default="<_RecursionChecker>")
+    def __repr__(self) -> str:
+        return repr(self.getattr_checking)
 
     def check(self, name: str) -> bool:
         return (self.getattr_checking.get(name, 0) or 0) >= self.THRESHOLD
 
     def add(self, name: str):
-        if name in self.getattr_errors:
+        if name in self.getattr_checking:
             self.getattr_checking[name] += 1
         else:
             self.getattr_checking[name] = 1
 
-    def reset(self):
-        self.getattr_checking = {}
-        self.getattr_errors = {}
+    def reset(self, name: str):
+        self.getattr_checking.pop(name, None)
+        self.getattr_errors.pop(name, None)
 
 
 _recursion_checker = _RecursionChecker()
 
 
 class injected_before_use(property):
     """
@@ -92,37 +89,49 @@
         if arg_strs:
             error_message = f"{error_message} (arguments={', '.join(arg_strs)})"
 
         error_message = f"{error_message}. Please inject this property before calling."
         raise ValueError(error_message)
 
 
+def only_raise_attribute_error(fn: Callable) -> Any:
+    def wrapper(*args, **kwargs):
+        try:
+            return fn(*args, **kwargs)
+        except AttributeError:
+            raise  # Don't modify or log attr errors.
+        except Exception as err:
+            # Wrap the exception in AttributeError
+            logger.log_debug_stack_trace()
+            raise ApeAttributeError(f"{err}") from err
+
+    return wrapper
+
+
 class ManagerAccessMixin:
     # NOTE: cast is used to update the class type returned to mypy
     account_manager: ClassVar["AccountManager"] = cast("AccountManager", injected_before_use())
 
     chain_manager: ClassVar["ChainManager"] = cast("ChainManager", injected_before_use())
 
     compiler_manager: ClassVar["CompilerManager"] = cast("CompilerManager", injected_before_use())
 
     config_manager: ClassVar["ConfigManager"] = cast("ConfigManager", injected_before_use())
 
     conversion_manager: ClassVar["ConversionManager"] = cast(
         "ConversionManager", injected_before_use()
     )
 
-    dependency_manager: ClassVar["DependencyManager"] = cast(
-        "DependencyManager", injected_before_use()
-    )
-
     network_manager: ClassVar["NetworkManager"] = cast("NetworkManager", injected_before_use())
 
     plugin_manager: ClassVar["PluginManager"] = cast("PluginManager", injected_before_use())
 
-    project_manager: ClassVar["ProjectManager"] = cast("ProjectManager", injected_before_use())
+    local_project: ClassVar["ProjectManager"] = cast("ProjectManager", injected_before_use())
+
+    Project: ClassVar[type["ProjectManager"]] = cast(type["ProjectManager"], injected_before_use())
 
     query_manager: ClassVar["QueryManager"] = cast("QueryManager", injected_before_use())
 
     _test_runner: ClassVar[Optional["PytestApeRunner"]] = None
 
     @classproperty
     def provider(self) -> "ProviderAPI":
@@ -156,15 +165,48 @@
         alt = name.replace("-", "_")
     elif "_" in name:
         alt = name.replace("_", "-")
 
     return alt
 
 
-_ATTR_TYPE = Union[Dict[str, Any], RootBaseModel]
+class _AttrLookup(dict):
+    """
+    Used when given extra attributes via a callback
+    that takes the attribute name.
+    """
+
+    def __init__(
+        self,
+        callback: Callable[
+            [
+                str,
+            ],
+            None,
+        ],
+    ):
+        self._callback = callback
+
+    def __contains__(self, item) -> bool:
+        return self._callback(item) is not None
+
+    @only_raise_attribute_error
+    def __getattr__(self, item):
+        res = self._callback(item)
+        if res is None:
+            # attr-lookups cannot return None!
+            raise AttributeError(item)
+
+        return res
+
+    def __getitem__(self, item):
+        return self._callback(item)
+
+    def get(self, item):
+        return self._callback(item)
 
 
 class ExtraModelAttributes(EthpmTypesBaseModel):
     """
     A class for defining extra model attributes.
     """
 
@@ -173,32 +215,51 @@
     name: str
     """
     The name of the attributes. This is important
     in instances such as when an attribute is missing,
     we can show a more accurate exception message.
     """
 
-    attributes: Union[_ATTR_TYPE, Callable[[], _ATTR_TYPE]]
-    """The attributes."""
+    attributes: Union[Any, Callable[[], Any], Callable[[str], Any]]
+    """The attributes. The following types are supported:
+
+    1. A model or dictionary to lookup attributes.
+    2. A callable with no arguments, for lazily evaluating a model or dictionary
+       for lookup.
+    3. A callable with a single argument that is the attribute name. This style
+       of lookup cannot be used for optionals.
+    """
 
     include_getattr: bool = True
     """Whether to use these in ``__getattr__``."""
 
     include_getitem: bool = False
     """Whether to use these in ``__getitem__``."""
 
     additional_error_message: Optional[str] = None
     """
     An additional error message to include at the end of
     the normal IndexError message.
     """
 
-    def __contains__(self, name: str) -> bool:
+    def __repr__(self) -> str:
+        try:
+            return f"<ExtraAttributes '{self.name}'>"
+        except Exception:
+            # Disallow exceptions in __repr__
+            return "<ExtraModelAttributes>"
+
+    def __contains__(self, name: Any) -> bool:
         attrs = self._attrs()
-        if name in attrs:
+        try:
+            name = str(name)
+        except Exception:
+            return False
+
+        if name in attrs or hasattr(attrs, name):
             return True
 
         elif alt := _get_alt(name):
             return alt in attrs
 
         return False
 
@@ -221,57 +282,63 @@
             res = self._get(alt)
             if res is not None:
                 return res
 
         return None
 
     def _get(self, name: str) -> Optional[Any]:
-        return self._attrs().get(name)
+        attrs = self._attrs()
+        return attrs.get(name) if hasattr(attrs, "get") else getattr(attrs, name, None)
 
-    def _attrs(self) -> dict:
-        if isinstance(self.attributes, dict):
+    def _attrs(self) -> Any:
+        if not isinstance(self.attributes, Callable):  # type: ignore
+            # Dict or model that can do a lookup.
             return self.attributes
-        elif isinstance(self.attributes, RootBaseModel):
-            return self.attributes.model_dump(by_alias=False)
 
-        # Lazy extras.
-        result = self.attributes()
-        return result if isinstance(result, dict) else result.model_dump(by_alias=False)
+        signature = inspect.signature(self.attributes)
+        if len(signature.parameters) == 0:
+            # Lazy-eval dict.
+            return self.attributes()  # type: ignore
+
+        # Callable lookup via name.
+        return _AttrLookup(self.attributes)  # type: ignore
 
 
 class BaseModel(EthpmTypesBaseModel):
     """
     An ape-pydantic BaseModel.
     """
 
     model_config = ConfigDict(arbitrary_types_allowed=True)
 
     def model_copy(
         self: "Model",
         *,
-        update: Optional[Dict[str, Any]] = None,
+        update: Optional[dict[str, Any]] = None,
         deep: bool = False,
         cache_clear: Optional[Sequence[str]] = None,
     ) -> "Model":
         result = super().model_copy(update=update, deep=deep)
 
         # Clear @cached_properties
         for cached_item in cache_clear or []:
             if cached_item in result.__dict__:
                 del result.__dict__[cached_item]
 
         return result
 
+    @raises_not_implemented
     def _repr_mimebundle_(self, include=None, exclude=None):
         # This works better than AttributeError for Ape.
-        raise NotImplementedError("This model does not implement '_repr_mimebundle_'.")
+        pass
 
+    @raises_not_implemented
     def _ipython_display_(self, include=None, exclude=None):
         # This works better than AttributeError for Ape.
-        raise NotImplementedError("This model does not implement '_ipython_display_'.")
+        pass
 
 
 def _assert_not_ipython_check(key):
     # Perf: IPython expects AttributeError here.
     if isinstance(key, str) and key == "_ipython_canary_method_should_not_exist_":
         raise AttributeError()
 
@@ -290,125 +357,152 @@
 
         Returns:
             Iterator[:class:`~ape.utils.basemodel.ExtraModelAttributes`]: A
             series of instances defining extra model attributes.
         """
         return iter(())
 
+    @only_raise_attribute_error
     def __getattr__(self, name: str) -> Any:
         """
         An overridden ``__getattr__`` implementation that takes into
         account :meth:`~ape.utils.basemodel.ExtraAttributesMixin.__ape_extra_attributes__`.
         """
         _assert_not_ipython_check(name)
-        private_attrs = self.__pydantic_private__ or {}
+        private_attrs = (self.__pydantic_private__ or {}) if isinstance(self, RootBaseModel) else {}
         if name in private_attrs:
-            _recursion_checker.reset()
+            _recursion_checker.reset(name)
             return private_attrs[name]
 
-        elif _recursion_checker.check(name):
-            # Prevent recursive error.
-            # First, attempt to get real error.
-            message = f"Failed trying to get {name}"
-            if real_error := _recursion_checker.getattr_errors.get(name):
-                message = f"{message}. {real_error}"
+        return get_attribute_with_extras(self, name)
 
-            _recursion_checker.reset()
-            raise AttributeError(message)
+    def __getitem__(self, name: Any) -> Any:
+        # For __getitem__, we first try the extra (unlike `__getattr__`).
+        return get_item_with_extras(self, name)
 
-        _recursion_checker.add(name)
 
-        try:
-            res = super().__getattribute__(name)
-        except AttributeError as err:
-            _recursion_checker.getattr_errors[name] = err
-            extras_checked = set()
-            for ape_extra in self.__ape_extra_attributes__():
-                if not ape_extra.include_getattr:
-                    continue
-
-                if name in ape_extra:
-                    # Attribute was found in one of the supplied
-                    # extra attributes mappings.
-                    _recursion_checker.reset()
-                    return ape_extra.get(name)
-
-                extras_checked.add(ape_extra.name)
-
-            # The error message mentions the alternative mappings,
-            # such as a contract-type map.
-            base_err = None
-            if name in _recursion_checker.getattr_errors:
-                # There was an error getting the value. Show that.
-                base_err = _recursion_checker.getattr_errors[name]
-                message = str(base_err)
-
-            else:
-                message = f"'{repr(self)}' has no attribute '{name}'"
-                if extras_checked:
-                    extras_str = ", ".join(extras_checked)
-                    message = f"{message}. Also checked '{extras_str}'"
-
-            _recursion_checker.reset()
-            attr_err = ApeAttributeError(message)
-            if base_err:
-                raise attr_err from base_err
-            else:
-                raise attr_err
+def get_attribute_with_extras(obj: Any, name: str) -> Any:
+    _assert_not_ipython_check(name)
+    if _recursion_checker.check(name):
+        # Prevent segfaults.
+        # First, attempt to get real error.
+        message = f"Failed trying to get {name}"
+        if real_error := _recursion_checker.getattr_errors.get(name):
+            message = f"{message}. {real_error}"
 
-        _recursion_checker.reset()
-        return res
+        _recursion_checker.reset(name)
+        raise AttributeError(message)
 
-    def __getitem__(self, name: Any) -> Any:
-        # For __getitem__, we first try the extra (unlike `__getattr__`).
-        extras_checked = set()
-        additional_error_messages = {}
-        for extra in self.__ape_extra_attributes__():
-            if not extra.include_getitem:
-                continue
+    _recursion_checker.add(name)
+
+    res = None
+
+    if not isinstance(obj, ExtraAttributesMixin):
+        name = getattr(type(obj), "__name__", "obj")
+        raise AttributeError(f"{name} must use the '{ExtraAttributesMixin.__name__}' mixin'")
 
-            if name in extra:
-                return extra.get(name)
+    try:
+        res = super(ExtraAttributesMixin, obj).__getattribute__(name)
+    except AttributeError as base_attr_err:
+        _recursion_checker.getattr_errors[name] = base_attr_err
 
-            extras_checked.add(extra.name)
+    if res is not None:
+        _recursion_checker.reset(name)
+        return res
+
+    # NOTE: Do not check extras within the error handler to avoid
+    #   errors occurring within an exception handler (Python shows that differently).
+    extras_checked = set()
+    for ape_extra in obj.__ape_extra_attributes__():
+        if not ape_extra.include_getattr:
+            continue
 
-            if extra.additional_error_message:
-                additional_error_messages[extra.name] = extra.additional_error_message
+        extras_checked.add(ape_extra.name)
+        try:
+            if name in ape_extra:
+                # Attribute was found in one of the supplied
+                # extra attributes mappings.
+                result = ape_extra.get(name)
+                # NOTE: Don't reset until _after_ we have the result.
+                _recursion_checker.reset(name)
+                return result
+
+        except Exception as err:
+            _recursion_checker.reset(name)
+            raise ApeAttributeError(f"{name} - {err}") from err
+
+    # The error message mentions the alternative mappings,
+    # such as a contract-type map.
+    base_err = None
+    if name in _recursion_checker.getattr_errors:
+        # There was an error getting the value. Show that.
+        base_err = _recursion_checker.getattr_errors[name]
+        message = str(base_err)
+    else:
+        message = f"'{repr(obj)}' has no attribute '{name}'"
+
+    if extras_checked:
+        extras_str = ", ".join(sorted(extras_checked))
+        message = f"{message}. Also checked extra(s) '{extras_str}'."
+
+    _recursion_checker.reset(name)
+    attr_err = ApeAttributeError(message)
+    if base_err:
+        raise attr_err from base_err
+    else:
+        raise attr_err
+
+
+def get_item_with_extras(obj: Any, name: str) -> Any:
+    # For __getitem__, we first try the extra (unlike `__getattr__`).
+    extras_checked = set()
+    additional_error_messages = {}
+    for extra in obj.__ape_extra_attributes__():
+        if not extra.include_getitem:
+            continue
+
+        if name in extra:
+            return extra.get(name)
+
+        extras_checked.add(extra.name)
+
+        if extra.additional_error_message:
+            additional_error_messages[extra.name] = extra.additional_error_message
+
+    # NOTE: If extras were supplied, the user was expecting it to be
+    #   there (unlike __getattr__).
+    if extras_checked:
+        prefix = f"Unable to find '{name}' in"
+        if not additional_error_messages:
+            extras_str = ", ".join(extras_checked)
+            message = f"{prefix} any of '{extras_str}'."
 
-        # NOTE: If extras were supplied, the user was expecting it to be
-        #   there (unlike __getattr__).
-        if extras_checked:
-            prefix = f"Unable to find '{name}' in"
-            if not additional_error_messages:
-                extras_str = ", ".join(extras_checked)
-                message = f"{prefix} any of '{extras_str}'."
-
-            else:
-                # The class is including additional error messages for the IndexError.
-                message = ""
-                for extra_checked in extras_checked:
-                    additional_message = additional_error_messages.get(extra_checked)
-                    suffix = f" {additional_message}" if additional_message else ""
-                    sub_message = f"{prefix} '{extra_checked}'.{suffix}"
-                    message = f"{message}\n{sub_message}" if message else sub_message
-
-            raise ApeIndexError(message)
-
-        # The user did not supply any extra __getitem__ attributes.
-        # Do what you would have normally done.
-        return super().__getitem__(name)  # type: ignore
+        else:
+            # The class is including additional error messages for the IndexError.
+            message = ""
+            for extra_checked in extras_checked:
+                additional_message = additional_error_messages.get(extra_checked)
+                suffix = f" {additional_message}" if additional_message else ""
+                sub_message = f"{prefix} '{extra_checked}'.{suffix}"
+                message = f"{message}\n{sub_message}" if message else sub_message
+
+        raise ApeIndexError(message)
+
+    # The user did not supply any extra __getitem__ attributes.
+    # Do what you would have normally done.
+    return super(ExtraAttributesMixin, obj).__getitem__(name)  # type: ignore
 
 
 class BaseInterfaceModel(BaseInterface, BaseModel):
     """
     An abstract base-class with manager access on a pydantic base model.
     """
 
     model_config = ConfigDict(arbitrary_types_allowed=True)
 
-    def __dir__(self) -> List[str]:
+    def __dir__(self) -> list[str]:
         """
         **NOTE**: Should integrate options in IPython tab-completion.
         https://ipython.readthedocs.io/en/stable/config/integrating.html
         """
         # Filter out protected/private members
         return [member for member in super().__dir__() if not member.startswith("_")]
```

### Comparing `eth-ape-0.7.9/src/ape/utils/github.py` & `eth-ape-0.8.0/src/ape/utils/_github.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,21 +1,18 @@
 import os
 import shutil
 import subprocess
 import tempfile
 import zipfile
 from io import BytesIO
 from pathlib import Path
-from typing import Dict, Optional, Set
+from typing import Any, Optional, Union
 
-from github import Github, UnknownObjectException
-from github.Auth import Token as GithubToken
-from github.GitRelease import GitRelease
-from github.Organization import Organization
-from github.Repository import Repository as GithubRepository
+from requests import Session
+from requests.adapters import HTTPAdapter
 from urllib3.util.retry import Retry
 
 from ape.exceptions import CompilerError, ProjectError, UnknownVersionError
 from ape.logging import logger
 from ape.utils.misc import USER_AGENT, cached_property, stream_response
 
 
@@ -53,72 +50,70 @@
 
             # Failed and we don't really know why.
             # Shouldn't really happen.
             # User will have to run command separately to debug.
             raise ProjectError(fail_msg)
 
 
-class GithubClient:
-    """
-    An HTTP client for the Github API.
-    """
-
+# NOTE: This client is only meant to be used internally for ApeWorX projects.
+class _GithubClient:
+    # Generic git/github client attributes.
     TOKEN_KEY = "GITHUB_ACCESS_TOKEN"
-    _repo_cache: Dict[str, GithubRepository] = {}
+    API_URL_PREFIX = "https://api.github.com"
     git: GitProcessWrapper = GitProcessWrapper()
 
-    def __init__(self):
-        token = os.environ[self.TOKEN_KEY] if self.TOKEN_KEY in os.environ else None
-        auth = GithubToken(token) if token else None
-        retry = Retry(total=10, backoff_factor=1.0, status_forcelist=[403])
-        self._client = Github(auth=auth, user_agent=USER_AGENT, retry=retry)
+    # ApeWorX-specific attributes.
+    ORGANIZATION_NAME = "ApeWorX"
+    FRAMEWORK_NAME = "ape"
+    _repo_cache: dict[str, dict] = {}
+
+    def __init__(self, session: Optional[Session] = None):
+        if session:
+            # NOTE: Mostly allowed for testing purposes.
+            self.__session = session
+
+        else:
+            headers = {"Content-Type": "application/json", "User-Agent": USER_AGENT}
+            if auth := os.environ[self.TOKEN_KEY] if self.TOKEN_KEY in os.environ else None:
+                headers["Authorization"] = f"token {auth}"
+
+            session = Session()
+            session.headers = {**session.headers, **headers}
+            adapter = HTTPAdapter(
+                max_retries=Retry(total=10, backoff_factor=1.0, status_forcelist=[403]),
+            )
+            session.mount("https://", adapter)
+            self.__session = session
 
     @cached_property
-    def ape_org(self) -> Organization:
+    def org(self) -> dict:
         """
-        The ``ApeWorX`` organization on ``Github`` (https://github.com/ApeWorX).
+        Our organization on ``Github``.
         """
-        return self.get_organization("ApeWorX")
+        return self.get_organization(self.ORGANIZATION_NAME)
 
     @cached_property
-    def available_plugins(self) -> Set[str]:
-        """
-        The available ``ape`` plugins, found from looking at the ``ApeWorX`` Github organization.
-
-        Returns:
-            Set[str]: The plugin names as ``'ape_plugin_name'`` (module-like).
-        """
+    def available_plugins(self) -> set[str]:
         return {
-            repo.name.replace("-", "_")
-            for repo in self.ape_org.get_repos()
-            if not repo.private and repo.name.startswith("ape-")
+            repo["name"].replace("-", "_")
+            for repo in self.get_org_repos()
+            if not repo.get("private", False) and repo["name"].startswith(f"{self.FRAMEWORK_NAME}-")
         }
 
-    def get_release(self, repo_path: str, version: str) -> GitRelease:
-        """
-        Get a release from Github.
-
-        Args:
-            repo_path (str): The path on Github to the repository,
-              e.g. ``OpenZeppelin/openzeppelin-contracts``.
-            version (str): The version of the release to get. Pass in ``"latest"``
-              to get the latest release.
-
-        Returns:
-            github.GitRelease.GitRelease
-        """
-        repo = self.get_repo(repo_path)
+    def get_org_repos(self) -> list[dict]:
+        return self._get(f"orgs/{self.ORGANIZATION_NAME}/repos")
 
+    def get_release(self, org_name: str, repo_name: str, version: str) -> dict:
         if version == "latest":
-            return repo.get_latest_release()
+            return self.get_latest_release(org_name, repo_name)
 
         def _try_get_release(vers):
             try:
-                return repo.get_release(vers)
-            except UnknownObjectException:
+                return self._get_release(org_name, repo_name, vers)
+            except Exception:
                 return None
 
         if release := _try_get_release(version):
             return release
         else:
             original_version = str(version)
             # Try an alternative tag style
@@ -126,101 +121,100 @@
                 version = version.lstrip("v")
             else:
                 version = f"v{version}"
 
             if release := _try_get_release(version):
                 return release
 
-            raise UnknownVersionError(original_version, repo.name)
+            raise UnknownVersionError(original_version, repo_name)
 
-    def get_repo(self, repo_path: str) -> GithubRepository:
-        """
-        Get a repository from GitHub.
-
-        Args:
-            repo_path (str): The path to the repository, such as
-              ``OpenZeppelin/openzeppelin-contracts``.
-
-        Returns:
-            github.Repository.Repository
-        """
+    def _get_release(self, org_name: str, repo_name: str, version: str) -> dict:
+        return self._get(f"repos/{org_name}/{repo_name}/releases/tags/{version}")
 
+    def get_repo(self, org_name: str, repo_name: str) -> dict:
+        repo_path = f"{org_name}/{repo_name}"
         if repo_path not in self._repo_cache:
             try:
-                self._repo_cache[repo_path] = self._client.get_repo(repo_path)
+                self._repo_cache[repo_path] = self._get_repo(org_name, repo_name)
                 return self._repo_cache[repo_path]
-            except UnknownObjectException as err:
+            except Exception as err:
                 raise ProjectError(f"Unknown repository '{repo_path}'") from err
 
         else:
             return self._repo_cache[repo_path]
 
-    def get_organization(self, name: str) -> Organization:
-        return self._client.get_organization(name)
+    def _get_repo(self, org_name: str, repo_name: str) -> dict:
+        return self._get(f"repos/{org_name}/{repo_name}")
+
+    def get_latest_release(self, org_name: str, repo_name: str) -> dict:
+        return self._get(f"repos/{org_name}/{repo_name}/releases/latest")
+
+    def get_organization(self, org_name: str) -> dict:
+        return self._get(f"orgs/{org_name}")
 
     def clone_repo(
         self,
-        repo_path: str,
-        target_path: Path,
+        org_name: str,
+        repo_name: str,
+        target_path: Union[str, Path],
         branch: Optional[str] = None,
         scheme: str = "http",
     ):
-        """
-        Clone a repository from Github.
-
-        Args:
-            repo_path (str): The path on Github to the repository,
-              e.g. ``OpenZeppelin/openzeppelin-contracts``.
-            target_path (Path): The local path to store the repo.
-            branch (Optional[str]): The branch to clone. Defaults to the default branch.
-            scheme (str): The git scheme to use when cloning. Defaults to `ssh`.
-        """
-
-        repo = self.get_repo(repo_path)
-        branch = branch or repo.default_branch
-        logger.info(f"Cloning branch '{branch}' from '{repo.name}'.")
-        url = repo.git_url
+        repo = self.get_repo(org_name, repo_name)
+        branch = branch or repo["default_branch"]
+        logger.info(f"Cloning branch '{branch}' from '{repo['name']}'.")
+        url = repo["git_url"]
 
         if "ssh" in scheme or "git" in scheme:
             url = url.replace("git://github.com/", "git@github.com:")
         elif "http" in scheme:
             url = url.replace("git://", "https://")
         else:
             raise ValueError(f"Scheme '{scheme}' not supported.")
 
-        self.git.clone(url, branch=branch, target_path=target_path)
+        target_path = Path(target_path)
+        target_path.parent.mkdir(parents=True, exist_ok=True)
+        if target_path.exists():
+            # Target repo cannot exist.
+            target_path = target_path / repo_name
 
-    def download_package(self, repo_path: str, version: str, target_path: Path):
-        """
-        Download a package from Github. This is useful for managing project dependencies.
+        self.git.clone(url, branch=branch, target_path=target_path)
 
-        Args:
-            repo_path (str): The path on ``Github`` to the repository,
-                                such as ``OpenZeppelin/openzeppelin-contracts``.
-            version (str): Number to specify update types
-                                to the downloaded package.
-            target_path (path): A path in your local filesystem to save the downloaded package.
-        """
+    def download_package(
+        self, org_name: str, repo_name: str, version: str, target_path: Union[Path, str]
+    ):
+        target_path = Path(target_path)  # Handles str
         if not target_path or not target_path.is_dir():
             raise ValueError(f"'target_path' must be a valid directory (got '{target_path}').")
 
-        release = self.get_release(repo_path, version)
-        description = f"Downloading {repo_path}@{version}"
-        release_content = stream_response(release.zipball_url, progress_bar_description=description)
+        release = self.get_release(org_name, repo_name, version)
+        description = f"Downloading {org_name}/{repo_name}@{version}"
+        release_content = stream_response(
+            release["zipball_url"], progress_bar_description=description
+        )
 
         # Use temporary path to isolate a package when unzipping
         with tempfile.TemporaryDirectory() as tmp:
             temp_path = Path(tmp)
             with zipfile.ZipFile(BytesIO(release_content)) as zf:
                 zf.extractall(temp_path)
 
             # Copy the directory contents into the target path.
             downloaded_packages = [f for f in temp_path.iterdir() if f.is_dir()]
             if len(downloaded_packages) < 1:
-                raise CompilerError(f"Unable to download package at '{repo_path}'.")
+                raise CompilerError(f"Unable to download package at '{org_name}/{repo_name}'.")
 
             package_path = temp_path / downloaded_packages[0]
             for source_file in package_path.iterdir():
                 shutil.move(str(source_file), str(target_path))
 
+    def _get(self, url: str) -> Any:
+        return self._request("GET", url)
+
+    def _request(self, method: str, url: str, **kwargs) -> Any:
+        url = f"{self.API_URL_PREFIX}/{url}"
+        response = self.__session.request(method, url, **kwargs)
+        response.raise_for_status()
+        return response.json()
+
 
-github_client = GithubClient()
+github_client = _GithubClient()
```

### Comparing `eth-ape-0.7.9/src/ape/utils/misc.py` & `eth-ape-0.8.0/src/ape/utils/misc.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,22 +1,24 @@
 import asyncio
+import functools
 import json
 import sys
 from asyncio import gather
-from datetime import datetime
+from collections.abc import Callable, Coroutine, Mapping
+from datetime import datetime, timezone
 from functools import cached_property, lru_cache, singledispatchmethod, wraps
+from importlib.metadata import PackageNotFoundError, distributions
+from importlib.metadata import version as version_metadata
 from pathlib import Path
-from typing import TYPE_CHECKING, Any, Callable, Coroutine, Dict, List, Mapping, Optional, cast
+from typing import TYPE_CHECKING, Any, Optional, cast
 
 import requests
 import yaml
 from eth_pydantic_types import HexBytes
 from eth_utils import is_0x_prefixed
-from importlib_metadata import PackageNotFoundError, distributions, packages_distributions
-from importlib_metadata import version as version_metadata
 from packaging.specifiers import SpecifierSet
 from tqdm.auto import tqdm  # type: ignore
 
 from ape.exceptions import APINotImplementedError, ProviderNotConnectedError
 from ape.logging import logger
 from ape.utils.os import expand_environment_variables
 
@@ -27,42 +29,54 @@
 EMPTY_BYTES32 = HexBytes("0x0000000000000000000000000000000000000000000000000000000000000000")
 ZERO_ADDRESS: "AddressType" = cast("AddressType", "0x0000000000000000000000000000000000000000")
 DEFAULT_TRANSACTION_ACCEPTANCE_TIMEOUT = 120
 DEFAULT_LOCAL_TRANSACTION_ACCEPTANCE_TIMEOUT = 20
 DEFAULT_LIVE_NETWORK_BASE_FEE_MULTIPLIER = 1.4
 DEFAULT_TRANSACTION_TYPE = 0
 DEFAULT_MAX_RETRIES_TX = 20
+SOURCE_EXCLUDE_PATTERNS = (
+    ".build",
+    ".cache",
+    ".DS_Store",
+    ".git",
+    ".gitkeep",
+    "*.adoc",
+    "*.css",
+    "*.html",
+    "*.md",
+    "*.pdf",
+    "*.py*",
+    "*.rst",
+    "*.txt",
+    "*package.json",
+    "*package-lock.json",
+    "*tsconfig.json",
+    "ape-config.yaml",
+    "py.typed",
+)
+
 
 _python_version = (
     f"{sys.version_info.major}.{sys.version_info.minor}"
     f".{sys.version_info.micro} {sys.version_info.releaselevel}"
 )
 
 
 @lru_cache(maxsize=None)
-def get_distributions():
-    """
-    Get a mapping of top-level packages to their distributions.
-    """
-
-    return packages_distributions()
-
-
-@lru_cache(maxsize=None)
-def _get_distributions(pkg_name: str) -> List:
+def _get_distributions(pkg_name: Optional[str] = None) -> list:
     """
     Get a mapping of top-level packages to their distributions.
     """
 
     distros = []
     all_distros = distributions()
     for dist in all_distros:
         package_names = (dist.read_text("top_level.txt") or "").split()
         for name in package_names:
-            if name == pkg_name:
+            if pkg_name is None or name == pkg_name:
                 distros.append(dist)
 
     return distros
 
 
 def pragma_str_to_specifier_set(pragma_str: str) -> Optional[SpecifierSet]:
     """
@@ -86,15 +100,15 @@
             return f"={item}"
 
         return item
 
     pragma_parts_fixed = []
     builder = ""
     for sub_part in pragma_parts:
-        parts_to_handle: List[str] = []
+        parts_to_handle: list[str] = []
         if "," in sub_part:
             sub_sub_parts = [x.strip() for x in sub_part.split(",")]
             if len(sub_sub_parts) > 2:
                 # Very rare case.
                 raise ValueError(f"Cannot handle pragma '{pragma_str}'.")
 
             if next_part := next(pragma_parts, None):
@@ -184,15 +198,15 @@
         return ""
 
 
 __version__ = get_package_version(__name__)
 USER_AGENT = f"Ape/{__version__} (Python/{_python_version})"
 
 
-def load_config(path: Path, expand_envars=True, must_exist=False) -> Dict:
+def load_config(path: Path, expand_envars=True, must_exist=False) -> dict:
     """
     Load a configuration file into memory.
     A file at the given path must exist or else it will throw ``OSError``.
     The configuration file must be a `.json` or `.yaml` or else it will throw ``TypeError``.
 
     Args:
         path (str): path to filesystem to find.
@@ -244,15 +258,15 @@
 
     return (
         f"Gas estimation failed: '{txn_error_text}'. This transaction will likely revert. "
         "If you wish to broadcast, you must set the gas limit manually."
     )
 
 
-def extract_nested_value(root: Mapping, *args: str) -> Optional[Dict]:
+def extract_nested_value(root: Mapping, *args: str) -> Optional[dict]:
     """
     Dig through a nested ``dict`` using the given keys and return the
     last-found object.
 
     Usage example::
 
             >>> extract_nested_value({"foo": {"bar": {"test": "VALUE"}}}, "foo", "bar", "test")
@@ -272,29 +286,29 @@
 
         current_value = current_value.get(arg)
 
     return current_value
 
 
 def add_padding_to_strings(
-    str_list: List[str],
+    str_list: list[str],
     extra_spaces: int = 0,
     space_character: str = " ",
-) -> List[str]:
+) -> list[str]:
     """
     Append spacing to each string in a list of strings such that
     they all have the same length.
 
     Args:
-        str_list (List[str]): The list of strings that need padding.
+        str_list (list[str]): The list of strings that need padding.
         extra_spaces (int): Optionally append extra spacing. Defaults to ``0``.
         space_character (str): The character to use in the padding. Defaults to ``" "``.
 
     Returns:
-        List[str]: A list of equal-length strings with padded spaces.
+        list[str]: A list of equal-length strings with padded spaces.
     """
 
     if not str_list:
         return []
 
     longest_item = len(max(str_list, key=len))
     spaced_items = []
@@ -442,15 +456,15 @@
 def get_current_timestamp_ms() -> int:
     """
     Get the current UNIX timestamp in milliseconds.
 
     Returns:
         int
     """
-    return round(datetime.utcnow().timestamp() * 1000)
+    return round(datetime.now(tz=timezone.utc).timestamp() * 1000)
 
 
 def is_evm_precompile(address: str) -> bool:
     """
     Returns ``True`` if the given address string is a known
     Ethereum pre-compile address.
 
@@ -486,38 +500,64 @@
             # "0x" counts as zero.
             return True
 
     except Exception:
         return False
 
 
-def _dict_overlay(mapping: Dict[str, Any], overlay: Dict[str, Any], depth: int = 0):
+def _dict_overlay(mapping: dict[str, Any], overlay: dict[str, Any], depth: int = 0):
     """Overlay given overlay structure on a dict"""
     for key, value in overlay.items():
         if isinstance(value, dict):
             if key not in mapping:
                 mapping[key] = dict()
             _dict_overlay(mapping[key], value, depth + 1)
         else:
             mapping[key] = value
     return mapping
 
 
+def log_instead_of_fail(default: Optional[Any] = None):
+    """
+    A decorator for logging errors instead of raising.
+    This is useful for methods like __repr__ which shouldn't fail.
+    """
+
+    def wrapper(fn):
+        @functools.wraps(fn)
+        def wrapped(*args, **kwargs):
+            try:
+                if args and isinstance(args[0], type):
+                    return fn(*args, **kwargs)
+                else:
+                    return fn(*args, **kwargs)
+
+            except Exception as err:
+                logger.error(str(err))
+                if default:
+                    return default
+
+        return wrapped
+
+    return wrapper
+
+
 __all__ = [
     "allow_disconnected",
     "cached_property",
     "_dict_overlay",
     "extract_nested_value",
     "gas_estimation_error_message",
     "get_current_timestamp_ms",
     "pragma_str_to_specifier_set",
     "get_package_version",
     "is_evm_precompile",
     "is_zero_hex",
     "load_config",
+    "log_instead_of_fail",
     "nonreentrant",
     "raises_not_implemented",
     "run_until_complete",
     "singledispatchmethod",
     "stream_response",
     "USER_AGENT",
 ]
```

### Comparing `eth-ape-0.7.9/src/ape/utils/process.py` & `eth-ape-0.8.0/src/ape/utils/process.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/src/ape/utils/testing.py` & `eth-ape-0.8.0/src/ape/utils/testing.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 from collections import namedtuple
-from typing import List
 
 from eth_account import Account
 from eth_account.hdaccount import HDPath
 from eth_account.hdaccount.mnemonic import Mnemonic
 from eth_pydantic_types import HexBytes
 
 DEFAULT_NUMBER_OF_TEST_ACCOUNTS = 10
@@ -26,30 +25,30 @@
 
 
 def generate_dev_accounts(
     mnemonic: str = DEFAULT_TEST_MNEMONIC,
     number_of_accounts: int = DEFAULT_NUMBER_OF_TEST_ACCOUNTS,
     hd_path: str = DEFAULT_TEST_HD_PATH,
     start_index: int = 0,
-) -> List[GeneratedDevAccount]:
+) -> list[GeneratedDevAccount]:
     """
     Create accounts from the given test mnemonic.
     Use these accounts (or the mnemonic) in chain-genesis
     for testing providers.
 
     Args:
         mnemonic (str): mnemonic phrase or seed words.
         number_of_accounts (int): Number of accounts. Defaults to ``10``.
         hd_path(str): Hard Wallets/HD Keys derivation path format.
           Defaults to ``"m/44'/60'/0'/0"``.
         start_index (int): The index to start from in the path. Defaults
           to 0.
 
     Returns:
-        List[:class:`~ape.utils.GeneratedDevAccount`]: List of development accounts.
+        list[:class:`~ape.utils.GeneratedDevAccount`]: List of development accounts.
     """
     seed = Mnemonic.to_seed(mnemonic)
     accounts = []
 
     if "{}" in hd_path or "{0}" in hd_path:
         hd_path_format = hd_path
     else:
```

### Comparing `eth-ape-0.7.9/src/ape/utils/validators.py` & `eth-ape-0.8.0/src/ape/utils/validators.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/src/ape_accounts/_cli.py` & `eth-ape-0.8.0/src/ape_accounts/_cli.py`

 * *Ordering differences only*

 * *Files 0% similar despite different names*

```diff
@@ -31,16 +31,16 @@
     Command-line helper for managing local accounts. You can unlock local accounts from
     scripts or the console using the accounts.load() method.
     """
 
 
 # Different name because `list` is a keyword
 @cli.command(name="list", short_help="List available local accounts")
-@click.option("--all", "show_all_plugins", help="Output accounts from all plugins", is_flag=True)
 @ape_cli_context()
+@click.option("--all", "show_all_plugins", help="Output accounts from all plugins", is_flag=True)
 def _list(cli_ctx, show_all_plugins):
     if "accounts" not in cli_ctx.account_manager.containers:
         cli_ctx.abort("Accounts plugin unexpectedly failed to load.")
 
     containers = (
         cli_ctx.account_manager.containers if show_all_plugins else {"accounts": _get_container()}
     )
@@ -71,14 +71,15 @@
             click.echo(f"  {account.address}{alias_display}")
 
         if index < num_containers - 1:
             click.echo()
 
 
 @cli.command(short_help="Create an account with a random mnemonic seed phrase")
+@ape_cli_context()
 @click.option(
     "--hide-mnemonic",
     help="Hide the newly generated mnemonic from the terminal",
     is_flag=True,
 )
 @click.option(
     "--word-count",
@@ -90,15 +91,14 @@
     "--hd-path",
     "custom_hd_path",
     help="Specify an HD path for deriving seed phrase",
     default=ETHEREUM_DEFAULT_PATH,
     show_default=True,
 )
 @non_existing_alias_argument()
-@ape_cli_context()
 def generate(cli_ctx, alias, hide_mnemonic, word_count, custom_hd_path):
     click.prompt(
         "Enhance the security of your account by adding additional random input",
         hide_input=True,
     )
 
     show_mnemonic = not hide_mnemonic and click.confirm("Show mnemonic?", default=True)
@@ -118,26 +118,26 @@
         f"A new account '{account.address}' with "
         + f"HDPath {custom_hd_path} has been added with the id '{alias}'"
     )
 
 
 # Different name because `import` is a keyword
 @cli.command(name="import", short_help="Import an account by private key or seed phrase")
+@ape_cli_context()
 @click.option(
     "--use-mnemonic", "import_from_mnemonic", help="Import a key from a mnemonic", is_flag=True
 )
 @click.option(
     "--hd-path",
     "custom_hd_path",
     help="Account HD path to use when importing by mnemonic",
     default=ETHEREUM_DEFAULT_PATH,
     show_default=True,
 )
 @non_existing_alias_argument()
-@ape_cli_context()
 def _import(cli_ctx, alias, import_from_mnemonic, custom_hd_path):
     account: Optional[KeyfileAccount] = None
 
     def ask_for_passphrase():
         return click.prompt(
             "Create Passphrase to encrypt account",
             hide_input=True,
@@ -179,24 +179,24 @@
     address = to_checksum_address(account["address"])
     cli_ctx.logger.success(
         f"Account {address} private key: {click.style(private_key.hex(), bold=True)})"
     )
 
 
 @cli.command(short_help="Change the password of an existing account")
-@existing_alias_argument(account_type=KeyfileAccount)
 @ape_cli_context()
+@existing_alias_argument(account_type=KeyfileAccount)
 def change_password(cli_ctx, alias):
     account = cli_ctx.account_manager.load(alias)
     assert isinstance(account, KeyfileAccount)
     account.change_password()
     cli_ctx.logger.success(f"Password has been changed for account '{alias}'")
 
 
 @cli.command(short_help="Delete an existing account")
-@existing_alias_argument(account_type=KeyfileAccount)
 @ape_cli_context()
+@existing_alias_argument(account_type=KeyfileAccount)
 def delete(cli_ctx, alias):
     account = cli_ctx.account_manager.load(alias)
     assert isinstance(account, KeyfileAccount)
     account.delete()
     cli_ctx.logger.success(f"Account '{alias}' has been deleted")
```

### Comparing `eth-ape-0.7.9/src/ape_accounts/accounts.py` & `eth-ape-0.8.0/src/ape_accounts/accounts.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,11 +1,13 @@
 import json
+import warnings
+from collections.abc import Iterator
 from os import environ
 from pathlib import Path
-from typing import Any, Dict, Iterator, Optional, Tuple
+from typing import Any, Optional
 
 import click
 from eip712.messages import EIP712Message
 from eth_account import Account as EthAccount
 from eth_account.hdaccount import ETHEREUM_DEFAULT_PATH
 from eth_account.messages import encode_defunct
 from eth_account.signers.local import LocalAccount
@@ -14,28 +16,29 @@
 from eth_utils import to_bytes
 
 from ape.api import AccountAPI, AccountContainerAPI, TransactionAPI
 from ape.exceptions import AccountsError
 from ape.logging import logger
 from ape.types import AddressType, MessageSignature, SignableMessage, TransactionSignature
 from ape.utils.basemodel import ManagerAccessMixin
+from ape.utils.misc import log_instead_of_fail
 from ape.utils.validators import _validate_account_alias, _validate_account_passphrase
 
 
 class InvalidPasswordError(AccountsError):
     """
     Raised when password to unlock an account is incorrect.
     """
 
     def __init__(self):
         super().__init__("Invalid password")
 
 
 class AccountContainer(AccountContainerAPI):
-    loaded_accounts: Dict[str, "KeyfileAccount"] = {}
+    loaded_accounts: dict[str, "KeyfileAccount"] = {}
 
     @property
     def _keyfiles(self) -> Iterator[Path]:
         return self.data_folder.glob("*.json")
 
     @property
     def aliases(self) -> Iterator[str]:
@@ -58,26 +61,19 @@
 # NOTE: `AccountAPI` is an BaseInterfaceModel
 class KeyfileAccount(AccountAPI):
     keyfile_path: Path
     locked: bool = True
     __autosign: bool = False
     __cached_key: Optional[HexBytes] = None
 
-    def __repr__(self):
+    @log_instead_of_fail(default="<KeyfileAccount>")
+    def __repr__(self) -> str:
         # NOTE: Prevent errors from preventing repr from working.
-        try:
-            address_str = f" address={self.address} "
-        except Exception:
-            address_str = ""
-
-        try:
-            alias_str = f" alias={self.alias} "
-        except Exception:
-            alias_str = ""
-
+        address_str = f" address={self.address} " if self.address else ""
+        alias_str = f" alias={self.alias} " if self.alias else ""
         return f"<{self.__class__.__name__}{address_str}{alias_str}>"
 
     @property
     def alias(self) -> str:
         return self.keyfile_path.stem
 
     @property
@@ -159,22 +155,25 @@
             f"Enter passphrase to delete '{self.alias}'", default=""
         )
         self.__decrypt_keyfile(passphrase)
         self.keyfile_path.unlink()
 
     def sign_message(self, msg: Any, **signer_options) -> Optional[MessageSignature]:
         if isinstance(msg, str):
-            user_approves = self.__autosign or click.confirm(f"Message: {msg}\n\nSign: ")
+            display_msg = f"Signing raw string: '{msg}'"
             msg = encode_defunct(text=msg)
+
         elif isinstance(msg, int):
-            user_approves = self.__autosign or click.confirm(f"Message: {msg}\n\nSign: ")
+            display_msg = f"Signing raw integer: {msg}"
             msg = encode_defunct(hexstr=HexBytes(msg).hex())
+
         elif isinstance(msg, bytes):
-            user_approves = self.__autosign or click.confirm(f"Message: {msg.hex()}\n\nSign: ")
+            display_msg = f"Signing raw bytes: '{msg.hex()}'"
             msg = encode_defunct(primitive=msg)
+
         elif isinstance(msg, EIP712Message):
             # Display message data to user
             display_msg = "Signing EIP712 Message\n"
 
             # Domain Data
             display_msg += "Domain\n"
             if msg._name_:
@@ -189,28 +188,30 @@
                 display_msg += f"\tSalt: 0x{msg._salt_.hex()}\n"
 
             # Message Data
             display_msg += "Message\n"
             for field, value in msg._body_["message"].items():
                 display_msg += f"\t{field}: {value}\n"
 
-            user_approves = self.__autosign or click.confirm(f"{display_msg}\nSign: ")
-
             # Convert EIP712Message to SignableMessage for handling below
             msg = msg.signable_message
+
         elif isinstance(msg, SignableMessage):
-            user_approves = self.__autosign or click.confirm(f"{msg}\n\nSign: ")
+            display_msg = str(msg)
+
         else:
             logger.warning("Unsupported message type, (type=%r, msg=%r)", type(msg), msg)
             return None
 
-        if not user_approves:
+        if self.__autosign or click.confirm(f"{display_msg}\n\nSign: "):
+            signed_msg = EthAccount.sign_message(msg, self.__key)
+
+        else:
             return None
 
-        signed_msg = EthAccount.sign_message(msg, self.__key)
         return MessageSignature(
             v=signed_msg.v,
             r=to_bytes(signed_msg.r),
             s=to_bytes(signed_msg.s),
         )
 
     def sign_transaction(self, txn: TransactionAPI, **signer_options) -> Optional[TransactionAPI]:
@@ -225,14 +226,36 @@
             v=signature.v,
             r=to_bytes(signature.r),
             s=to_bytes(signature.s),
         )
 
         return txn
 
+    def sign_raw_msghash(self, msghash: HexBytes) -> Optional[MessageSignature]:
+        logger.warning(
+            "Signing a raw hash directly is a dangerous action which could risk "
+            "substantial losses! Only confirm if you are 100% sure of the origin!"
+        )
+
+        # NOTE: Signing a raw hash is so dangerous, we don't want to allow autosigning it
+        if not click.confirm("Please confirm you wish to sign using `EthAccount.signHash`"):
+            return None
+
+        # Ignoring misleading deprecated warning from web3.py.
+        # Also, we have already warned the user about the safety.
+        with warnings.catch_warnings():
+            warnings.simplefilter("ignore")
+            signed_msg = EthAccount.signHash(msghash, self.__key)
+
+        return MessageSignature(
+            v=signed_msg.v,
+            r=to_bytes(signed_msg.r),
+            s=to_bytes(signed_msg.s),
+        )
+
     def set_autosign(self, enabled: bool, passphrase: Optional[str] = None):
         """
         Allow this account to automatically sign messages and transactions.
 
         Args:
             enabled (bool): ``True`` to enable, ``False`` to disable.
             passphrase (Optional[str]): Optionally provide the passphrase.
@@ -271,15 +294,15 @@
     path.write_text(json.dumps(EthAccount.encrypt(account.key, passphrase)))
 
     return KeyfileAccount(keyfile_path=path)
 
 
 def generate_account(
     alias: str, passphrase: str, hd_path: str = ETHEREUM_DEFAULT_PATH, word_count: int = 12
-) -> Tuple[KeyfileAccount, str]:
+) -> tuple[KeyfileAccount, str]:
     """
     Generate a new account.
 
     Args:
         alias (str): The alias name of the account.
         passphrase (str): Passphrase used to encrypt the account storage file.
         hd_path (str): The hierarchal deterministic path to use when generating the account.
```

### Comparing `eth-ape-0.7.9/src/ape_cache/_cli.py` & `eth-ape-0.8.0/src/ape_cache/_cli.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/src/ape_cache/models.py` & `eth-ape-0.8.0/src/ape_cache/models.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/src/ape_cache/query.py` & `eth-ape-0.8.0/src/ape_cache/query.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,10 @@
+from collections.abc import Iterator
 from pathlib import Path
-from typing import Any, Dict, Iterator, List, Optional, cast
+from typing import Any, Optional, cast
 
 from sqlalchemy import create_engine, func
 from sqlalchemy.engine import CursorResult
 from sqlalchemy.sql import column, insert, select
 from sqlalchemy.sql.expression import Insert, Select
 
 from ape.api import BlockAPI, QueryAPI, QueryType, TransactionAPI
@@ -322,15 +323,15 @@
                 raise QueryEngineError(f"Could not perform query:\n{query}")
 
             yield from map(
                 lambda row: self.provider.network.ecosystem.decode_block(dict(row.items())), result
             )
 
     @perform_query.register
-    def _perform_transaction_query(self, query: BlockTransactionQuery) -> Iterator[Dict]:
+    def _perform_transaction_query(self, query: BlockTransactionQuery) -> Iterator[dict]:
         with self.database_connection as conn:
             result = conn.execute(
                 select([Transactions]).where(Transactions.block_hash == query.block_id)
             )
 
             if not result:
                 # NOTE: Should be unreachable if estimated correctly
@@ -391,35 +392,35 @@
     @_cache_update_clause.register
     def _cache_update_events_clause(self, query: ContractEventQuery) -> Insert:
         return insert(ContractEvents)
 
     @singledispatchmethod
     def _get_cache_data(
         self, query: QueryType, result: Iterator[BaseInterfaceModel]
-    ) -> Optional[List[Dict[str, Any]]]:
+    ) -> Optional[list[dict[str, Any]]]:
         raise QueryEngineError(
             """
             Not a compatible QueryType. For more details see our docs
             https://docs.apeworx.io/ape/stable/methoddocs/exceptions.html#ape.exceptions.QueryEngineError
             """
         )
 
     @_get_cache_data.register
     def _get_block_cache_data(
         self, query: BlockQuery, result: Iterator[BaseInterfaceModel]
-    ) -> Optional[List[Dict[str, Any]]]:
+    ) -> Optional[list[dict[str, Any]]]:
         return [m.model_dump(mode="json", by_alias=False) for m in result]
 
     @_get_cache_data.register
     def _get_block_txns_data(
         self, query: BlockTransactionQuery, result: Iterator[BaseInterfaceModel]
-    ) -> Optional[List[Dict[str, Any]]]:
+    ) -> Optional[list[dict[str, Any]]]:
         new_result = []
         table_columns = [c.key for c in Transactions.__table__.columns]  # type: ignore
-        txns: List[TransactionAPI] = cast(List[TransactionAPI], result)
+        txns: list[TransactionAPI] = cast(list[TransactionAPI], result)
         for val in [m for m in txns]:
             new_dict = {
                 k: v
                 for k, v in val.model_dump(mode="json", by_alias=False).items()
                 if k in table_columns
             }
             for col in table_columns:
@@ -439,15 +440,15 @@
                     new_dict[col] = None
             new_result.append(new_dict)
         return new_result
 
     @_get_cache_data.register
     def _get_cache_events_data(
         self, query: ContractEventQuery, result: Iterator[BaseInterfaceModel]
-    ) -> Optional[List[Dict[str, Any]]]:
+    ) -> Optional[list[dict[str, Any]]]:
         return [m.model_dump(mode="json", by_alias=False) for m in result]
 
     def update_cache(self, query: QueryType, result: Iterator[BaseInterfaceModel]):
         try:
             clause = self._cache_update_clause(query)
         except QueryEngineError:
             # Cannot handle query type
```

### Comparing `eth-ape-0.7.9/src/ape_compile/_cli.py` & `eth-ape-0.8.0/src/ape_compile/_cli.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,21 +1,24 @@
+import sys
 from pathlib import Path
-from typing import Dict, Set
 
 import click
 from ethpm_types import ContractType
 
-from ape.cli import ape_cli_context, contract_file_paths_argument
+from ape.cli.arguments import contract_file_paths_argument
+from ape.cli.options import ape_cli_context, config_override_option, project_option
 
 
 def _include_dependencies_callback(ctx, param, value):
     return value or ctx.obj.config_manager.get_config("compile").include_dependencies
 
 
 @click.command(short_help="Compile select contract source files")
+@ape_cli_context()
+@project_option()
 @contract_file_paths_argument()
 @click.option(
     "-f",
     "--force",
     "use_cache",
     flag_value=False,
     default=True,
@@ -32,76 +35,75 @@
 )
 @click.option(
     "--include-dependencies",
     is_flag=True,
     help="Also compile dependencies",
     callback=_include_dependencies_callback,
 )
-@ape_cli_context()
-def cli(cli_ctx, file_paths: Set[Path], use_cache: bool, display_size: bool, include_dependencies):
+@config_override_option()
+def cli(
+    cli_ctx,
+    project,
+    file_paths: set[Path],
+    use_cache: bool,
+    display_size: bool,
+    include_dependencies,
+    config_override,
+):
     """
     Compiles the manifest for this project and saves the results
     back to the manifest.
 
     Note that ape automatically recompiles any changed contracts each time
     a project is loaded. You do not have to manually trigger a recompile.
     """
+    compiled = False
+    errored = False
 
-    sources_missing = cli_ctx.project_manager.sources_missing
-    if not file_paths and sources_missing and len(cli_ctx.project_manager.dependencies) == 0:
-        cli_ctx.logger.warning("Nothing to compile.")
-        return
+    if cfg := config_override:
+        project.reconfigure(**cfg)
 
-    ext_given = [p.suffix for p in file_paths if p]
+    if file_paths:
+        contracts = {
+            k: v.contract_type
+            for k, v in project.load_contracts(*file_paths, use_cache=use_cache).items()
+        }
+        cli_ctx.logger.success("'local project' compiled.")
+        compiled = True
+        if display_size:
+            _display_byte_code_sizes(cli_ctx, contracts)
+
+    if (include_dependencies or project.config.compile.include_dependencies) and len(
+        project.dependencies
+    ) > 0:
+        for dependency in project.dependencies:
+            # Even if compiling we failed, we at least tried
+            # and so we don't need to warn "Nothing to compile".
+            compiled = True
+
+            try:
+                contract_types = dependency.project.load_contracts(use_cache=use_cache)
+            except Exception as err:
+                cli_ctx.logger.log_error(err)
+                errored = True
+                continue
+
+            cli_ctx.logger.success(f"'{dependency.project.name}' compiled.")
+            if display_size:
+                _display_byte_code_sizes(cli_ctx, contract_types)
 
-    # Filter out common files that we know are not files you can compile anyway,
-    # like documentation files. NOTE: Nothing prevents a CompilerAPI from using these
-    # extensions, we just don't warn about missing compilers here. The warning is really
-    # meant to help guide users when the vyper, solidity, or cairo plugins are not installed.
-    general_extensions = {".md", ".rst", ".txt", ".py", ".html", ".css", ".adoc"}
-
-    ext_with_missing_compilers = {
-        x
-        for x in cli_ctx.project_manager.extensions_with_missing_compilers(ext_given)
-        if x not in general_extensions
-    }
-
-    if ext_with_missing_compilers:
-        if len(ext_with_missing_compilers) > 1:
-            # NOTE: `sorted` to increase reproducibility.
-            extensions_str = ", ".join(sorted(ext_with_missing_compilers))
-            message = f"Missing compilers for the following file types: '{extensions_str}'."
-        else:
-            message = f"Missing a compiler for {ext_with_missing_compilers.pop()} file types."
-
-        message = (
-            f"{message} "
-            f"Possibly, a compiler plugin is not installed "
-            f"or is installed but not loading correctly."
-        )
-        cli_ctx.logger.warning(message)
-
-    contract_types = cli_ctx.project_manager.load_contracts(
-        file_paths=file_paths, use_cache=use_cache
-    )
-
-    if include_dependencies:
-        for versions in cli_ctx.project_manager.dependencies.values():
-            for dependency in versions.values():
-                try:
-                    dependency.compile(use_cache=use_cache)
-                except Exception as err:
-                    # Log error and try to compile the remaining dependencies.
-                    cli_ctx.logger.error(err)
+    if not compiled:
+        cli_ctx.logger.warning("Nothing to compile.")
 
-    if display_size:
-        _display_byte_code_sizes(cli_ctx, contract_types)
+    if errored:
+        # Ensure exit code.
+        sys.exit(1)
 
 
-def _display_byte_code_sizes(cli_ctx, contract_types: Dict[str, ContractType]):
+def _display_byte_code_sizes(cli_ctx, contract_types: dict[str, ContractType]):
     # Display bytecode size for *all* contract types (not just ones we compiled)
     code_size = []
     for contract in contract_types.values():
         if not contract.deployment_bytecode:
             continue  # Skip if not bytecode to display
 
         bytecode = contract.deployment_bytecode.bytecode
```

### Comparing `eth-ape-0.7.9/src/ape_console/_cli.py` & `eth-ape-0.8.0/src/ape_console/_cli.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,40 +1,43 @@
 import faulthandler
 import inspect
 import logging
 import sys
 from importlib.machinery import SourceFileLoader
 from importlib.util import module_from_spec, spec_from_loader
-from os import environ, getcwd
+from os import environ
 from types import ModuleType
-from typing import Any, Dict, cast
+from typing import Any, Optional, cast
 
 import click
 import IPython
 from IPython.terminal.ipapp import Config as IPythonConfig
 
-from ape.cli import ConnectedProviderCommand, ape_cli_context
+from ape.cli.commands import ConnectedProviderCommand
+from ape.cli.options import ape_cli_context, project_option
+from ape.managers.project import ProjectManager
 from ape.utils.basemodel import ManagerAccessMixin
 from ape.utils.misc import _python_version
 from ape.version import version as ape_version
 from ape_console.config import ConsoleConfig
 
 CONSOLE_EXTRAS_FILENAME = "ape_console_extras.py"
 
 
 @click.command(
     cls=ConnectedProviderCommand,
     short_help="Load the console",
     context_settings=dict(ignore_unknown_options=True),
 )
 @ape_cli_context()
-def cli(cli_ctx):
+@project_option(hidden=True)  # Hidden as mostly used for test purposes.
+def cli(cli_ctx, project):
     """Opens a console for the local project."""
     verbose = cli_ctx.logger.level == logging.DEBUG
-    return console(verbose=verbose)
+    return console(project=project, verbose=verbose)
 
 
 def import_extras_file(file_path) -> ModuleType:
     """Import a module"""
     loader = SourceFileLoader(file_path.name[:-3], str(file_path))
     spec = spec_from_loader(loader.name, loader)
 
@@ -42,35 +45,34 @@
 
     module = module_from_spec(spec)
     loader.exec_module(module)
 
     return module
 
 
-def load_console_extras(**namespace: Any) -> Dict[str, Any]:
+def load_console_extras(**namespace: Any) -> dict[str, Any]:
     """load and return namespace updates from ape_console_extras.py  files if
     they exist"""
-    global_extras = ManagerAccessMixin.config_manager.DATA_FOLDER.joinpath(CONSOLE_EXTRAS_FILENAME)
-    project_extras = ManagerAccessMixin.config_manager.PROJECT_FOLDER.joinpath(
-        CONSOLE_EXTRAS_FILENAME
-    )
+    pm = namespace.get("project", ManagerAccessMixin.local_project)
+    global_extras = pm.config_manager.DATA_FOLDER.joinpath(CONSOLE_EXTRAS_FILENAME)
+    project_extras = pm.path.joinpath(CONSOLE_EXTRAS_FILENAME)
 
     for extras_file in [global_extras, project_extras]:
         if not extras_file.is_file():
             continue
 
         module = import_extras_file(extras_file)
         ape_init_extras = getattr(module, "ape_init_extras", None)
 
         # If found, execute ape_init_extras() function.
         if ape_init_extras is not None:
             # Figure out the kwargs the func is looking for and assemble
             # from the original namespace
             func_spec = inspect.getfullargspec(ape_init_extras)
-            init_kwargs: Dict[str, Any] = {k: namespace.get(k) for k in func_spec.args}
+            init_kwargs: dict[str, Any] = {k: namespace.get(k) for k in func_spec.args}
 
             # Execute functionality with existing console namespace as
             # kwargs.
             extras = ape_init_extras(**init_kwargs)
 
             # If ape_init_extras returned a dict expect it to be new symbols
             if isinstance(extras, dict):
@@ -84,21 +86,23 @@
                     continue
 
                 namespace[k] = getattr(module, k)
 
     return namespace
 
 
-def console(project=None, verbose=None, extra_locals=None, embed=False):
+def console(
+    project: Optional[ProjectManager] = None,
+    verbose: bool = False,
+    extra_locals: Optional[dict] = None,
+    embed: bool = False,
+):
     import ape
 
-    if not project:
-        # Use default project
-        project = ManagerAccessMixin.project_manager
-
+    project = project or ManagerAccessMixin.local_project
     banner = ""
     if verbose:
         banner = """
    Python:  {python_version}
   IPython:  {ipython_version}
       Ape:  {ape_version}
   Project:  {project_path}
@@ -111,20 +115,23 @@
             project_path=project.path,
         )
 
         if not environ.get("APE_TESTING"):
             faulthandler.enable()  # NOTE: In case we segfault
 
     namespace = {component: getattr(ape, component) for component in ape.__all__}
+    namespace["project"] = project  # Use the given project.
     namespace["ape"] = ape
 
+    # Allows modules relative to the project.
+    sys.path.insert(0, f"{project.path}")
+
     # NOTE: `ape_console_extras` only is meant to work with default namespace.
     #  Load extras before local namespace to avoid console extras receiving
     #  the wrong values for its arguments.
-    sys.path.insert(0, getcwd())
     console_extras = load_console_extras(**namespace)
 
     if extra_locals:
         namespace.update(extra_locals)
 
     if console_extras:
         namespace.update(console_extras)
@@ -136,15 +143,15 @@
 
         # Required for click.testing.CliRunner support.
         embed = True
 
     _launch_console(namespace, ipy_config, embed, banner)
 
 
-def _launch_console(namespace: Dict, ipy_config: IPythonConfig, embed: bool, banner: str):
+def _launch_console(namespace: dict, ipy_config: IPythonConfig, embed: bool, banner: str):
     ipython_kwargs = {"user_ns": namespace, "config": ipy_config}
     if embed:
         IPython.embed(**ipython_kwargs, colors="Neutral", banner1=banner)
     else:
         ipy_config.TerminalInteractiveShell.colors = "Neutral"
         ipy_config.TerminalInteractiveShell.banner1 = banner
         console_config = cast(ConsoleConfig, namespace["ape"].config.get_config("console"))
```

### Comparing `eth-ape-0.7.9/src/ape_console/plugin.py` & `eth-ape-0.8.0/src/ape_console/plugin.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,21 +1,25 @@
 import shlex
+from pathlib import Path
 
 import click
 from click.testing import CliRunner
 from eth_utils import is_hex
 from IPython import get_ipython
 from IPython.core.magic import Magics, line_magic, magics_class
+from rich import print as rich_print
 
 import ape
 from ape._cli import cli
 from ape.exceptions import Abort, ApeException, handle_ape_exception
 from ape.logging import logger
+from ape.managers.project import LocalProject
 from ape.types import AddressType
-from ape.utils import cached_property
+from ape.utils import ManagerAccessMixin, cached_property
+from ape.utils.os import clean_path
 
 
 @magics_class
 class ApeConsoleMagics(Magics):
     @cached_property
     def ipython(self):
         if ipython := get_ipython():
@@ -71,14 +75,28 @@
         decimals = ecosystem.fee_token_decimals
         symbol = ecosystem.fee_token_symbol
         balance = provider.get_balance(address)
         return f"{round(balance / 10 ** decimals, 8)} {symbol}"
 
 
 def custom_exception_handler(self, etype, value, tb, tb_offset=None):
-    if not handle_ape_exception(value, [self.user_ns["project"].path]):
+    project = self.user_ns["project"]
+    if isinstance(project, LocalProject):
+        path = project.path
+    else:
+        # This happens if assigned the variable `project` in your session
+        # to something other than ``ape.project``.
+        path = ManagerAccessMixin.local_project.path
+
+    if not handle_ape_exception(value, [path]):
         logger.error(Abort.from_ape_exception(value).format_message())
 
 
 def load_ipython_extension(ipython):
     ipython.register_magics(ApeConsoleMagics)
     ipython.set_custom_exc((ApeException,), custom_exception_handler)
+
+    # This prevents displaying a user's home directory
+    # ever when using `ape console`.
+    ipython.display_formatter.formatters["text/plain"].for_type(
+        Path, lambda x, *args, **kwargs: rich_print(clean_path(x))
+    )
```

### Comparing `eth-ape-0.7.9/src/ape_ethereum/__init__.py` & `eth-ape-0.8.0/src/ape_ethereum/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 from ape import plugins
 from ape.api import ForkedNetworkAPI, NetworkAPI, create_network_type
 from ape.api.networks import LOCAL_NETWORK_NAME
 
 from ._converters import WeiConversions
 from .ecosystem import NETWORKS, Ethereum, EthereumConfig
+from .query import EthereumQueryProvider
 
 
 @plugins.register(plugins.Config)
 def config_class():
     return EthereumConfig
 
 
@@ -25,7 +26,12 @@
 def networks():
     for network_name, network_params in NETWORKS.items():
         yield "ethereum", network_name, create_network_type(*network_params)
         yield "ethereum", f"{network_name}-fork", ForkedNetworkAPI
 
     # NOTE: This works for local providers, as they get chain_id from themselves
     yield "ethereum", LOCAL_NETWORK_NAME, NetworkAPI
+
+
+@plugins.register(plugins.QueryPlugin)
+def query_engines():
+    yield EthereumQueryProvider
```

### Comparing `eth-ape-0.7.9/src/ape_ethereum/_converters.py` & `eth-ape-0.8.0/src/ape_ethereum/_converters.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/src/ape_ethereum/ecosystem.py` & `eth-ape-0.8.0/src/ape_ethereum/ecosystem.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 import re
-from copy import deepcopy
+from collections.abc import Iterator, Sequence
+from decimal import Decimal
 from functools import cached_property
-from typing import Any, ClassVar, Dict, Iterator, List, Optional, Sequence, Tuple, Type, Union, cast
+from typing import Any, ClassVar, Optional, Union, cast
 
 from eth_abi import decode, encode
 from eth_abi.exceptions import InsufficientDataBytes, NonEmptyPaddingBytes
 from eth_pydantic_types import HexBytes
 from eth_typing import Hash32, HexStr
 from eth_utils import (
     encode_hex,
@@ -17,23 +18,29 @@
     to_checksum_address,
 )
 from ethpm_types import ContractType
 from ethpm_types.abi import ABIType, ConstructorABI, EventABI, MethodABI
 from pydantic import Field, computed_field, field_validator, model_validator
 from pydantic_settings import SettingsConfigDict
 
-from ape.api import BlockAPI, EcosystemAPI, PluginConfig, ReceiptAPI, TransactionAPI
+from ape.api import BlockAPI, EcosystemAPI, PluginConfig, ReceiptAPI, TraceAPI, TransactionAPI
 from ape.api.networks import LOCAL_NETWORK_NAME
 from ape.contracts.base import ContractCall
-from ape.exceptions import ApeException, APINotImplementedError, ConversionError, DecodingError
+from ape.exceptions import (
+    ApeException,
+    APINotImplementedError,
+    ConversionError,
+    CustomError,
+    DecodingError,
+    SignatureError,
+)
 from ape.managers.config import merge_configs
 from ape.types import (
     AddressType,
     AutoGasLimit,
-    CallTreeNode,
     ContractLog,
     GasLimit,
     RawAddress,
     TransactionSignature,
 )
 from ape.utils import (
     DEFAULT_LIVE_NETWORK_BASE_FEE_MULTIPLIER,
@@ -44,23 +51,24 @@
     LogInputABICollection,
     Struct,
     StructParser,
     is_array,
     returns_array,
     to_int,
 )
-from ape.utils.basemodel import _assert_not_ipython_check
+from ape.utils.basemodel import _assert_not_ipython_check, only_raise_attribute_error
 from ape.utils.misc import DEFAULT_MAX_RETRIES_TX, DEFAULT_TRANSACTION_TYPE
 from ape_ethereum.proxies import (
     IMPLEMENTATION_ABI,
     MASTER_COPY_ABI,
     PROXY_TYPE_ABI,
     ProxyInfo,
     ProxyType,
 )
+from ape_ethereum.trace import _REVERT_PREFIX, Trace, TransactionTrace
 from ape_ethereum.transactions import (
     AccessListTransaction,
     BaseTransaction,
     DynamicFeeTransaction,
     Receipt,
     SharedBlobReceipt,
     SharedBlobTransaction,
@@ -68,34 +76,55 @@
     TransactionStatusEnum,
     TransactionType,
 )
 
 NETWORKS = {
     # chain_id, network_id
     "mainnet": (1, 1),
-    "goerli": (5, 5),
     "sepolia": (11155111, 11155111),
 }
 BLUEPRINT_HEADER = HexBytes("0xfe71")
 
 
 class NetworkConfig(PluginConfig):
     required_confirmations: int = 0
+    """
+    The amount of blocks to wait before
+    considering a transaction 'confirmed'.
+    """
 
-    default_provider: Optional[str] = "geth"
+    default_provider: Optional[str] = "node"
     """
     The default provider to use. If set to ``None``, ape will rely on
     an external plugin supplying the provider implementation, such as
     ``ape-hardhat`` supplying forked-network providers.
     """
 
     block_time: int = 0
+    """
+    Approximate amount of time for a block to be
+    added to the network.
+    """
+
     transaction_acceptance_timeout: int = DEFAULT_TRANSACTION_ACCEPTANCE_TIMEOUT
+    """
+    The amount tof time before failing when sending a
+    transaction and it leaving the mempool.
+    """
+
     default_transaction_type: TransactionType = TransactionType.DYNAMIC
+    """
+    The default type of transaction to use.
+    """
+
     max_receipt_retries: int = DEFAULT_MAX_RETRIES_TX
+    """
+    Maximum number of retries when getting a receipt
+    from a transaction before failing.
+    """
 
     gas_limit: GasLimit = "auto"
     """
     The gas limit override to use for the network. If set to ``"auto"``, ape will
     estimate gas limits based on the transaction. If set to ``"max"`` the gas limit
     will be set to the maximum block gas limit for the network. Otherwise an ``int``
     can be used to specify an explicit gas limit amount (either base 10 or 16).
@@ -152,15 +181,15 @@
         **kwargs,
     )
 
 
 def create_network_config(
     required_confirmations: int = 2,
     base_fee_multiplier: float = DEFAULT_LIVE_NETWORK_BASE_FEE_MULTIPLIER,
-    cls: Type = NetworkConfig,
+    cls: type = NetworkConfig,
     **kwargs,
 ) -> NetworkConfig:
     return cls(
         base_fee_multiplier=base_fee_multiplier,
         required_confirmations=required_confirmations,
         **kwargs,
     )
@@ -169,48 +198,48 @@
 class BaseEthereumConfig(PluginConfig):
     """
     L2 plugins should use this as their config base-class.
     """
 
     DEFAULT_TRANSACTION_TYPE: ClassVar[int] = TransactionType.DYNAMIC.value
     DEFAULT_LOCAL_GAS_LIMIT: ClassVar[GasLimit] = "max"
-    NETWORKS: ClassVar[Dict[str, Tuple[int, int]]] = NETWORKS
+    NETWORKS: ClassVar[dict[str, tuple[int, int]]] = NETWORKS
 
     default_network: str = LOCAL_NETWORK_NAME
-    _forked_configs: Dict[str, ForkedNetworkConfig] = {}
-    _custom_networks: Dict[str, NetworkConfig] = {}
+    _forked_configs: dict[str, ForkedNetworkConfig] = {}
+    _custom_networks: dict[str, NetworkConfig] = {}
 
     model_config = SettingsConfigDict(extra="allow")
 
     @model_validator(mode="before")
     @classmethod
     def load_network_configs(cls, values):
-        cfg_forks: Dict[str, ForkedNetworkConfig] = {}
+        cfg_forks: dict[str, ForkedNetworkConfig] = {}
         custom_networks = {}
         for name, obj in values.items():
             if name.startswith("_"):
                 continue
 
             net_name = name.replace("-", "_")
             key = net_name.replace("_fork", "")
             if net_name.endswith("_fork"):
                 key = net_name.replace("_fork", "")
                 default_fork_model = create_local_network_config(
                     use_fork=True,
                     default_transaction_type=cls.DEFAULT_TRANSACTION_TYPE,
                     gas_limit=cls.DEFAULT_LOCAL_GAS_LIMIT,
-                ).model_dump(mode="json", by_alias=True)
+                ).model_dump(by_alias=True)
                 data = merge_configs(default_fork_model, obj)
                 cfg_forks[key] = ForkedNetworkConfig.model_validate(data)
 
             elif key != LOCAL_NETWORK_NAME and key not in cls.NETWORKS and isinstance(obj, dict):
                 # Custom network.
                 default_network_model = create_network_config(
                     default_transaction_type=cls.DEFAULT_TRANSACTION_TYPE
-                ).model_dump(mode="json", by_alias=True)
+                ).model_dump(by_alias=True)
                 data = merge_configs(default_network_model, obj)
                 custom_networks[name] = NetworkConfig.model_validate(data)
 
         values["_forked_configs"] = {**cfg_forks, **values.get("_forked_configs", {})}
         return {**values, **custom_networks}
 
     @computed_field  # type: ignore[misc]
@@ -218,14 +247,15 @@
     def local(self) -> NetworkConfig:
         return create_local_network_config(
             default_provider="test",
             default_transaction_type=self.DEFAULT_TRANSACTION_TYPE,
             gas_limit=self.DEFAULT_LOCAL_GAS_LIMIT,
         )
 
+    @only_raise_attribute_error
     def __getattr__(self, key: str) -> Any:
         _assert_not_ipython_check(key)
         net_key = key.replace("-", "_")
         if net_key.endswith("_fork"):
             return self._get_forked_config(net_key)
 
         try:
@@ -276,28 +306,28 @@
 
     def _get_custom_network(self, name: str) -> NetworkConfig:
         return self._custom_networks.get(name, NetworkConfig())
 
 
 class EthereumConfig(BaseEthereumConfig):
     mainnet: NetworkConfig = create_network_config(block_time=13)
-    goerli: NetworkConfig = create_network_config(block_time=15)
     sepolia: NetworkConfig = create_network_config(block_time=15)
 
 
 class Block(BlockAPI):
     """
     Class for representing a block on a chain.
     """
 
     gas_limit: int = Field(alias="gasLimit")
     gas_used: int = Field(alias="gasUsed")
     base_fee: int = Field(0, alias="baseFeePerGas")
     difficulty: int = 0
     total_difficulty: int = Field(0, alias="totalDifficulty")
+    uncles: list[HexBytes] = []
 
     # Type re-declares.
     hash: Optional[HexBytes] = None
     parent_hash: HexBytes = Field(
         EMPTY_BYTES32, alias="parentHash"
     )  # NOTE: genesis block has no parent hash
 
@@ -312,51 +342,75 @@
         "total_difficulty",
         mode="before",
     )
     @classmethod
     def validate_ints(cls, value):
         return to_int(value) if value else 0
 
+    @computed_field()  # type: ignore[misc]
+    @property
+    def size(self) -> int:
+        if self._size is not None:
+            # The size was provided with the rest of the model
+            # (normal).
+            return self._size
+
+        number = self.number
+        if number is None:
+            raise APINotImplementedError()
+
+        # Try to get it from the provider.
+        elif provider := self.network_manager.active_provider:
+            block = provider.get_block(number)
+            size = block._size
+            if size is not None and size > -1:
+                self._size = size
+                return size
+
+        raise APINotImplementedError()
+
 
 class Ethereum(EcosystemAPI):
     # NOTE: `default_transaction_type` should be overridden
     #   if the chain doesn't support EIP-1559.
 
-    name: str = "ethereum"
     fee_token_symbol: str = "ETH"
 
     @property
     def config(self) -> EthereumConfig:
-        return cast(EthereumConfig, self.config_manager.get_config(self.name))
+        return cast(EthereumConfig, super().config)
 
     @property
     def default_transaction_type(self) -> TransactionType:
         if provider := self.network_manager.active_provider:
             # Check connected network first.
             networks_to_check = [provider.network.name, self.default_network_name]
         else:
             networks_to_check = [self.default_network_name]
 
         for name in networks_to_check:
             network = self.get_network(name)
-            ecosystem_default = network.config.DEFAULT_TRANSACTION_TYPE
-            result: int = network._network_config.get("default_transaction_type", ecosystem_default)
+            ecosystem_config = network.ecosystem_config
+            ecosystem_default = ecosystem_config.get(
+                "default_transaction_type", DEFAULT_TRANSACTION_TYPE
+            )
+            result: int = network.config.get("default_transaction_type", ecosystem_default)
             return TransactionType(result)
 
         return TransactionType(DEFAULT_TRANSACTION_TYPE)
 
     @classmethod
     def decode_address(cls, raw_address: RawAddress) -> AddressType:
         return to_checksum_address(HexBytes(raw_address)[-20:].rjust(20, b"\x00"))
 
     @classmethod
     def encode_address(cls, address: AddressType) -> RawAddress:
         return str(address)
 
-    def decode_transaction_type(self, transaction_type_id: Any) -> Type[TransactionAPI]:
+    def decode_transaction_type(self, transaction_type_id: Any) -> type[TransactionAPI]:
         if isinstance(transaction_type_id, TransactionType):
             tx_type = transaction_type_id
         elif isinstance(transaction_type_id, int):
             tx_type = TransactionType(transaction_type_id)
         else:
             # Using hex or alike.
             tx_type = self.conversion_manager.convert(transaction_type_id, int)
@@ -476,15 +530,15 @@
                     return ProxyInfo(type=ProxyType.Delegate, target=target)
 
             except (ApeException, ValueError):
                 pass
 
         return None
 
-    def decode_receipt(self, data: Dict) -> ReceiptAPI:
+    def decode_receipt(self, data: dict) -> ReceiptAPI:
         status = data.get("status")
         if status is not None:
             status = self.conversion_manager.convert(status, int)
             status = TransactionStatusEnum(status)
 
         txn_hash = None
         hash_key_choices = ("hash", "txHash", "txnHash", "transactionHash", "transaction_hash")
@@ -515,28 +569,28 @@
             gas_used=data.get("gas_used", data.get("gasUsed")) or 0,
             logs=data.get("logs", []),
             status=status,
             txn_hash=txn_hash,
             transaction=self.create_transaction(**data),
         )
 
-        receipt_cls: Type[Receipt]
+        receipt_cls: type[Receipt]
         if any(
             x in data
             for x in ("blobGasPrice", "blobGasUsed", "blobVersionedHashes", "maxFeePerBlobGas")
         ):
             receipt_cls = SharedBlobReceipt
             receipt_kwargs["blob_gas_price"] = data.get("blob_gas_price", data.get("blobGasPrice"))
             receipt_kwargs["blob_gas_used"] = data.get("blob_gas_used", data.get("blobGasUsed"))
         else:
             receipt_cls = Receipt
 
         return receipt_cls.model_validate(receipt_kwargs)
 
-    def decode_block(self, data: Dict) -> BlockAPI:
+    def decode_block(self, data: dict) -> BlockAPI:
         data["hash"] = HexBytes(data["hash"]) if data.get("hash") else None
         if "gas_limit" in data:
             data["gasLimit"] = data.pop("gas_limit")
         if "gas_used" in data:
             data["gasUsed"] = data.pop("gas_used")
         if "parent_hash" in data:
             data["parentHash"] = HexBytes(data.pop("parent_hash"))
@@ -549,15 +603,15 @@
         elif "baseFee" in data:
             data["baseFeePerGas"] = data.pop("baseFee")
         if "transactions" in data:
             data["num_transactions"] = len(data["transactions"])
 
         return Block.model_validate(data)
 
-    def _python_type_for_abi_type(self, abi_type: ABIType) -> Union[Type, Sequence]:
+    def _python_type_for_abi_type(self, abi_type: ABIType) -> Union[type, Sequence]:
         # NOTE: An array can be an array of tuples, so we start with an array check
         if str(abi_type.type).endswith("]"):
             # remove one layer of the potential onion of array
             new_type = "[".join(str(abi_type.type).split("[")[:-1])
             # create a new type with the inner type of array
             new_abi_type = ABIType(type=new_type, **abi_type.model_dump(exclude={"type"}))
             # NOTE: type for static and dynamic array is a single item list
@@ -578,50 +632,53 @@
 
         elif "bytes" in abi_type.type:
             return bytes
 
         elif "int" in abi_type.type:
             return int
 
+        elif "fixed" in abi_type.type:
+            return Decimal
+
         raise ConversionError(f"Unable to convert '{abi_type}'.")
 
     def encode_calldata(self, abi: Union[ConstructorABI, MethodABI], *args) -> HexBytes:
         if not abi.inputs:
             return HexBytes("")
 
         parser = StructParser(abi)
         arguments = parser.encode_input(args)
         input_types = [i.canonical_type for i in abi.inputs]
         python_types = tuple(self._python_type_for_abi_type(i) for i in abi.inputs)
         converted_args = self.conversion_manager.convert(arguments, python_types)
         encoded_calldata = encode(input_types, converted_args)
         return HexBytes(encoded_calldata)
 
-    def decode_calldata(self, abi: Union[ConstructorABI, MethodABI], calldata: bytes) -> Dict:
+    def decode_calldata(self, abi: Union[ConstructorABI, MethodABI], calldata: bytes) -> dict:
         raw_input_types = [i.canonical_type for i in abi.inputs]
-        input_types = [parse_type(i.model_dump(mode="json")) for i in abi.inputs]
+        input_types = [parse_type(i.model_dump()) for i in abi.inputs]
 
         try:
             raw_input_values = decode(raw_input_types, calldata, strict=False)
-        except InsufficientDataBytes as err:
+        except (InsufficientDataBytes, OverflowError, NonEmptyPaddingBytes) as err:
             raise DecodingError(str(err)) from err
 
         input_values = [
             self.decode_primitive_value(v, t) for v, t in zip(raw_input_values, input_types)
         ]
         arguments = {}
         index = 0
         for i, v in zip(abi.inputs, input_values):
             name = i.name or f"{index}"
             arguments[name] = v
             index += 1
 
         return arguments
 
-    def decode_returndata(self, abi: MethodABI, raw_data: bytes) -> Tuple[Any, ...]:
+    def decode_returndata(self, abi: MethodABI, raw_data: bytes) -> tuple[Any, ...]:
         output_types_str_ls = [o.canonical_type for o in abi.outputs]
 
         if raw_data:
             try:
                 vm_return_values = decode(output_types_str_ls, raw_data, strict=False)
             except (InsufficientDataBytes, NonEmptyPaddingBytes) as err:
                 raise DecodingError(str(err)) from err
@@ -631,15 +688,15 @@
 
         if not vm_return_values:
             return vm_return_values
 
         elif not isinstance(vm_return_values, (tuple, list)):
             vm_return_values = (vm_return_values,)
 
-        output_types = [parse_type(o.model_dump(mode="json")) for o in abi.outputs]
+        output_types = [parse_type(o.model_dump()) for o in abi.outputs]
         output_values = [
             self.decode_primitive_value(v, t) for v, t in zip(vm_return_values, output_types)
         ]
         parser = StructParser(abi)
         output_values = parser.decode_output(output_values)
 
         if issubclass(type(output_values), Struct):
@@ -682,42 +739,46 @@
                 if is_hex_address(hex_str):
                     return self._enrich_value(hex_str, **kwargs)
 
                 return hex_str
 
         elif isinstance(value, str) and is_hex_address(value):
             address = self.decode_address(value)
-            return self._enrich_address(address, **kwargs)
+            return self._enrich_contract_id(address, **kwargs)
 
         elif isinstance(value, str):
             # Surround non-address strings with quotes.
             return f'"{value}"'
 
         elif isinstance(value, (list, tuple)):
             return [self._enrich_value(v, **kwargs) for v in value]
 
         elif isinstance(value, Struct):
             return {k: self._enrich_value(v, **kwargs) for k, v in value.items()}
 
         return value
 
     def decode_primitive_value(
-        self, value: Any, output_type: Union[str, Tuple, List]
-    ) -> Union[str, HexBytes, Tuple, List]:
+        self, value: Any, output_type: Union[str, tuple, list]
+    ) -> Union[str, HexBytes, tuple, list]:
         if output_type == "address":
             try:
                 return self.decode_address(value)
             except InsufficientDataBytes as err:
                 raise DecodingError() from err
 
         elif isinstance(value, bytes):
             return HexBytes(value)
 
         elif isinstance(output_type, str) and is_array(output_type):
             sub_type = "[".join(output_type.split("[")[:-1])
+
+            if not isinstance(value, (list, tuple)):
+                value = (value,)
+
             return [self.decode_primitive_value(v, sub_type) for v in value]
 
         elif isinstance(output_type, tuple):
             return tuple([self.decode_primitive_value(v, t) for v, t in zip(value, output_type)])
 
         elif (
             isinstance(output_type, list)
@@ -791,15 +852,15 @@
             tx_data["value"] = self.conversion_manager.convert(value, int)
 
         # None is not allowed, the user likely means `b""`.
         if "data" in tx_data and tx_data["data"] is None:
             tx_data["data"] = b""
 
         # Deduce the transaction type.
-        transaction_types: Dict[TransactionType, Type[TransactionAPI]] = {
+        transaction_types: dict[TransactionType, type[TransactionAPI]] = {
             TransactionType.STATIC: StaticFeeTransaction,
             TransactionType.ACCESS_LIST: AccessListTransaction,
             TransactionType.DYNAMIC: DynamicFeeTransaction,
             TransactionType.SHARED_BLOB: SharedBlobTransaction,
         }
         if "type" in tx_data:
             # May be None in data.
@@ -862,15 +923,15 @@
             )
 
         if "gas" not in tx_data:
             tx_data["gas"] = None
 
         return txn_class(**tx_data)
 
-    def decode_logs(self, logs: Sequence[Dict], *events: EventABI) -> Iterator["ContractLog"]:
+    def decode_logs(self, logs: Sequence[dict], *events: EventABI) -> Iterator["ContractLog"]:
         if not logs:
             return
 
         abi_inputs = {
             encode_hex(keccak(text=abi.selector)): LogInputABICollection(abi) for abi in events
         }
 
@@ -893,15 +954,15 @@
             if not (abi := get_abi(topics[0])):
                 continue
 
             event_arguments = abi.decode(topics, log["data"], use_hex_on_fail=True)
 
             # Since LogABICollection does not have access to the Ecosystem,
             # the rest of the decoding must happen here.
-            converted_arguments: Dict = {}
+            converted_arguments: dict = {}
 
             for item in abi.abi.inputs:
                 _type, key, value = item.canonical_type, item.name, event_arguments[item.name]
 
                 if isinstance(value, Struct):
                     struct_types = _type.lstrip("(").rstrip(")").split(",")
                     for struct_type, (struct_key, struct_val) in zip(struct_types, value.items()):
@@ -922,105 +983,158 @@
                     )
 
                 else:
                     # No change.
                     converted_arguments[key] = value
 
             yield ContractLog(
-                block_hash=log["blockHash"],
-                block_number=log["blockNumber"],
+                block_hash=log.get("blockHash") or log.get("block_hash") or "",
+                block_number=log.get("blockNumber") or log.get("block_number") or 0,
                 contract_address=self.decode_address(log["address"]),
                 event_arguments=converted_arguments,
                 event_name=abi.event_name,
-                log_index=log["logIndex"],
-                transaction_hash=log["transactionHash"],
-                transaction_index=log["transactionIndex"],
+                log_index=log.get("logIndex") or log.get("log_index") or 0,
+                transaction_hash=log.get("transactionHash") or log.get("transaction_hash") or "",
+                transaction_index=(
+                    log.get("transactionIndex")
+                    if "transactionIndex" in log
+                    else log.get("transaction_index")
+                ),
             )
 
-    def enrich_calltree(self, call: CallTreeNode, **kwargs) -> CallTreeNode:
-        kwargs["use_symbol_for_tokens"] = kwargs.get("use_symbol_for_tokens", False)
-        kwargs["in_place"] = kwargs.get("in_place", True)
-
-        if call.txn_hash:
-            receipt = self.chain_manager.get_receipt(call.txn_hash)
-            kwargs["sender"] = receipt.sender
-
-        # Enrich subcalls before any _return_ statement.
-        enriched_call = call if kwargs["in_place"] else deepcopy(call)
-        enriched_call.calls = [self.enrich_calltree(c, **kwargs) for c in enriched_call.calls]
+    def enrich_trace(self, trace: TraceAPI, **kwargs) -> TraceAPI:
+        kwargs["trace"] = trace
+        if not isinstance(trace, Trace):
+            return trace
 
-        not_address_type: bool = not self.conversion_manager.is_type(
-            enriched_call.contract_id, AddressType
-        )
-        if not_address_type and is_hex_address(enriched_call.contract_id):
-            enriched_call.contract_id = self.decode_address(enriched_call.contract_id)
+        elif trace._enriched_calltree is not None:
+            # Already enriched.
+            return trace
 
-        elif not_address_type:
+        if sender := trace.transaction.get("from"):
+            kwargs["sender"] = sender
+
+        # Get the un-enriched calltree.
+        data = trace.get_calltree().model_dump(mode="json", by_alias=True)
+
+        if isinstance(trace, TransactionTrace):
+            return_value = trace.__dict__.get("return_value") if data.get("depth", 0) == 0 else None
+            if return_value is not None:
+                # Return value was discovered already.
+                kwargs["return_value"] = return_value
+
+        enriched_calltree = self._enrich_calltree(data, **kwargs)
+
+        # Cache the result back on the trace.
+        trace._enriched_calltree = enriched_calltree
+
+        return trace
+
+    def _enrich_calltree(self, call: dict, **kwargs) -> dict:
+        if "contract_id" in call:
             # Already enriched.
-            return enriched_call
+            return call
+
+        if self._test_runner and self._test_runner.gas_tracker.enabled:
+            default_symbol_for_tokens = not self._test_runner.gas_tracker.enabled
+        else:
+            default_symbol_for_tokens = True
+
+        kwargs["use_symbol_for_tokens"] = kwargs.get(
+            "use_symbol_for_tokens", default_symbol_for_tokens
+        )
+        call_type = call.get("call_type", "")
+        is_create = "CREATE" in call_type
 
-        # Collapse pre-compile address calls
-        address = cast(AddressType, enriched_call.contract_id)
-        address_int = int(address, 16)
-        if 1 <= address_int <= 9:
-            sub_calls = [self.enrich_calltree(c, **kwargs) for c in enriched_call.calls]
-            if len(sub_calls) == 1:
-                return sub_calls[0]
-
-            intermediary_node = CallTreeNode(contract_id=f"{address_int}")
-            for sub_tree in sub_calls:
-                intermediary_node.add(sub_tree)
+        # Enrich sub-calls first.
+        if subcalls := call.get("calls"):
+            call["calls"] = [self._enrich_calltree(c, **kwargs) for c in subcalls]
 
-            return intermediary_node
+        # Figure out the contract.
+        address = call.pop("address", "")
+        try:
+            call["contract_id"] = address = kwargs["contract_address"] = str(
+                self.decode_address(address)
+            )
+        except Exception:
+            # Tx was made with a weird address.
+            call["contract_id"] = address
+
+        if calldata := call.get("calldata"):
+            calldata_bytes = HexBytes(calldata)
+            call["method_id"] = calldata_bytes[:4].hex()
+            call["calldata"] = calldata if is_create else calldata_bytes[4:].hex()
+
+        else:
+            call["method_id"] = "0x"
+
+        try:
+            address_int = int(address, 16)
+        except Exception:
+            pass
+        else:
+            # Collapse pre-compile address calls
+            if 1 <= address_int <= 9:
+                if len(call.get("calls", [])) == 1:
+                    return call["calls"][0]
+
+                return {"contract_id": f"{address_int}", "calls": call["calls"]}
+
+        depth = call.get("depth", 0)
+        if depth == 0 and address in self.account_manager:
+            call["contract_id"] = f"__{self.fee_token_symbol}_transfer__"
+        else:
+            call["contract_id"] = self._enrich_contract_id(call["contract_id"], **kwargs)
 
         if not (contract_type := self.chain_manager.contracts.get(address)):
-            return enriched_call
+            # Without a contract, we can enrich no further.
+            return call
 
-        enriched_call.contract_id = self._enrich_address(address, **kwargs)
         method_abi: Optional[Union[MethodABI, ConstructorABI]] = None
-        if "CREATE" in (enriched_call.call_type or ""):
+        if is_create:
             method_abi = contract_type.constructor
             name = "__new__"
 
-        elif enriched_call.method_id is None:
-            name = enriched_call.method_id or "0x"
-
-        else:
-            method_id_bytes = HexBytes(enriched_call.method_id)
+        elif call["method_id"] != "0x":
+            method_id_bytes = HexBytes(call["method_id"])
             if method_id_bytes in contract_type.methods:
                 method_abi = contract_type.methods[method_id_bytes]
                 assert isinstance(method_abi, MethodABI)  # For mypy
 
                 # Check if method name duplicated. If that is the case, use selector.
                 times = len([x for x in contract_type.methods if x.name == method_abi.name])
-                name = (
-                    method_abi.name if times == 1 else method_abi.selector
-                ) or enriched_call.method_id
-                enriched_call = self._enrich_calldata(
-                    enriched_call, method_abi, contract_type, **kwargs
-                )
+                name = (method_abi.name if times == 1 else method_abi.selector) or call["method_id"]
+                call = self._enrich_calldata(call, method_abi, contract_type, **kwargs)
+
             else:
-                name = enriched_call.method_id or "0x"
+                name = call["method_id"]
+        else:
+            name = call.get("method_id") or "0x"
 
-        enriched_call.method_id = name
+        call["method_id"] = name
 
         if method_abi:
-            enriched_call = self._enrich_calldata(
-                enriched_call, method_abi, contract_type, **kwargs
-            )
+            call = self._enrich_calldata(call, method_abi, contract_type, **kwargs)
 
-            if isinstance(method_abi, MethodABI):
-                enriched_call = self._enrich_returndata(enriched_call, method_abi, **kwargs)
+            if kwargs.get("return_value"):
+                # Return value was separately enriched.
+                call["returndata"] = kwargs["return_value"]
+            elif isinstance(method_abi, MethodABI):
+                call = self._enrich_returndata(call, method_abi, **kwargs)
             else:
                 # For constructors, don't include outputs, as it is likely a large amount of bytes.
-                enriched_call.outputs = None
+                call["returndata"] = None
+
+        elif "revert_message" not in call:
+            # Method not found but perhaps we still know the error.
+            call = self._enrich_revert_message(call)
 
-        return enriched_call
+        return call
 
-    def _enrich_address(self, address: AddressType, **kwargs) -> str:
+    def _enrich_contract_id(self, address: AddressType, **kwargs) -> str:
         if address and address == kwargs.get("sender"):
             return "tx.origin"
 
         elif address == ZERO_ADDRESS:
             return "ZERO_ADDRESS"
 
         if not (contract_type := self.chain_manager.contracts.get(address)):
@@ -1044,87 +1158,110 @@
             if isinstance(symbol, bytes):
                 try:
                     return symbol.rstrip(b"\x00").decode()
                 except UnicodeDecodeError:
                     return str(symbol)
 
         name = contract_type.name.strip() if contract_type.name else None
-        return name or self._get_contract_id_from_address(address)
-
-    def _get_contract_id_from_address(self, address: "AddressType") -> str:
-        if address in self.account_manager:
-            return f"Transferring {self.fee_token_symbol}"
-
-        return address
+        return name or address
 
     def _enrich_calldata(
         self,
-        call: CallTreeNode,
+        call: dict,
         method_abi: Union[MethodABI, ConstructorABI],
         contract_type: ContractType,
         **kwargs,
-    ) -> CallTreeNode:
-        calldata = call.inputs
+    ) -> dict:
+        calldata = call["calldata"]
         if isinstance(calldata, (str, bytes, int)):
             calldata_arg = HexBytes(calldata)
         else:
             # Not sure if we can get here.
             # Mostly for mypy's sake.
             return call
 
-        if call.call_type and "CREATE" in call.call_type:
+        if call.get("call_type") and "CREATE" in call.get("call_type", ""):
             # Strip off bytecode
             bytecode = (
                 contract_type.deployment_bytecode.to_bytes()
                 if contract_type.deployment_bytecode
                 else b""
             )
             # TODO: Handle Solidity Metadata (delegate to Compilers again?)
             calldata_arg = HexBytes(calldata_arg.split(bytecode)[-1])
 
         try:
-            call.inputs = self.decode_calldata(method_abi, calldata_arg)
+            call["calldata"] = self.decode_calldata(method_abi, calldata_arg)
         except DecodingError:
-            call.inputs = ["<?>" for _ in method_abi.inputs]
+            call["calldata"] = ["<?>" for _ in method_abi.inputs]
         else:
-            call.inputs = {k: self._enrich_value(v, **kwargs) for k, v in call.inputs.items()}
+            call["calldata"] = {
+                k: self._enrich_value(v, **kwargs) for k, v in call["calldata"].items()
+            }
 
         return call
 
-    def _enrich_returndata(
-        self, call: CallTreeNode, method_abi: MethodABI, **kwargs
-    ) -> CallTreeNode:
-        if call.call_type and "CREATE" in call.call_type:
-            call.outputs = ""
+    def _enrich_returndata(self, call: dict, method_abi: MethodABI, **kwargs) -> dict:
+        if "CREATE" in call.get("call_type", ""):
+            call["returndata"] = ""
+            return call
+
+        elif "revert_message" in call:
+            # Already enriched, in a sense..
             return call
 
         default_return_value = "<?>"
-        if (isinstance(call.outputs, str) and is_0x_prefixed(call.outputs)) or isinstance(
-            call.outputs, (int, bytes)
-        ):
-            return_value_bytes = HexBytes(call.outputs)
+        returndata = call.get("returndata", "")
+        is_hexstr = isinstance(returndata, str) and is_0x_prefixed(returndata)
+        return_value_bytes = None
+
+        # Check if return is only a revert string.
+        call = self._enrich_revert_message(call)
+        if "revert_message" in call:
+            return call
+
+        elif is_hexstr:
+            return_value_bytes = HexBytes(returndata)
+
+            # Check if custom-error.
+            if "trace" in kwargs and "contract_address" in kwargs:
+                address = kwargs["contract_address"]
+                try:
+                    instance = self.decode_custom_error(return_value_bytes, address, **kwargs)
+                except NotImplementedError:
+                    pass
+                else:
+                    if instance is not None:
+                        call["revert_message"] = repr(instance)
+                        return call
+
+        elif is_hexstr or isinstance(returndata, (int, bytes)):
+            return_value_bytes = HexBytes(returndata)
         else:
             return_value_bytes = None
 
         if return_value_bytes is None:
             values = tuple([default_return_value for _ in method_abi.outputs])
 
         else:
             return_values = None
             try:
                 return_values = (
                     self.decode_returndata(method_abi, return_value_bytes)
-                    if not call.failed
+                    if not call.get("failed")
                     else None
                 )
             except DecodingError:
                 if return_value_bytes == HexBytes("0x"):
                     # Empty result, but it failed decoding because of its length.
                     return_values = ("",)
 
+            # Cache un-enriched return_value in trace.
+            call["unenriched_return_values"] = return_values
+
             values = (
                 tuple([default_return_value for _ in method_abi.outputs])
                 if return_values is None
                 else tuple([self._enrich_value(v, **kwargs) for v in return_values or ()])
             )
 
         output_val = values[0] if len(values) == 1 else values
@@ -1132,30 +1269,94 @@
             isinstance(output_val, str)
             and is_0x_prefixed(output_val)
             and "." not in output_val
             and not int(output_val, 16)
         ):
             output_val = ""
 
-        call.outputs = output_val
+        call["returndata"] = output_val
         return call
 
-    def get_python_types(self, abi_type: ABIType) -> Union[Type, Sequence]:
+    def _enrich_revert_message(self, call: dict) -> dict:
+        returndata = call.get("returndata", "")
+        is_hexstr = isinstance(returndata, str) and is_0x_prefixed(returndata)
+        if is_hexstr and returndata.startswith(_REVERT_PREFIX):
+            # The returndata is the revert-str.
+            decoded_result = decode(("string",), HexBytes(returndata)[4:])
+            call["revert_message"] = decoded_result[0] if len(decoded_result) == 1 else ""
+
+        return call
+
+    def get_python_types(self, abi_type: ABIType) -> Union[type, Sequence]:
         return self._python_type_for_abi_type(abi_type)
 
+    def decode_custom_error(
+        self,
+        data: HexBytes,
+        address: AddressType,
+        **kwargs,
+    ) -> Optional[CustomError]:
+        # Use an instance (required for proper error caching).
+        try:
+            contract = self.chain_manager.contracts.instance_at(address)
+        except Exception:
+            return None
+
+        selector = data[:4]
+        input_data = data[4:]
+
+        if selector in contract.contract_type.errors:
+            abi = contract.contract_type.errors[selector]
+            error_cls = contract.get_error_by_signature(abi.signature)
+            inputs = self.decode_calldata(abi, input_data)
+            kwargs["contract_address"] = address
+            error_kwargs = {
+                k: v
+                for k, v in kwargs.items()
+                if k in ("trace", "txn", "contract_address", "source_traceback")
+            }
+            return error_cls(abi, inputs, **error_kwargs)
+
+        # ABI not found. Try looking at the "last" contract.
+        if not (tx := kwargs.get("txn")) or not self.network_manager.active_provider:
+            return None
+
+        try:
+            tx_hash = tx.txn_hash
+        except SignatureError:
+            return None
+
+        trace = kwargs.get("trace") or self.provider.get_transaction_trace(tx_hash)
+        if not (last_addr := next(trace.get_addresses_used(reverse=True), None)):
+            return None
+
+        if last_addr == address:
+            # Avoid checking same address twice.
+            return None
+
+        try:
+            if cerr := self.decode_custom_error(data, last_addr, **kwargs):
+                return cerr
+
+        except NotImplementedError:
+            return None
+
+        # error never found.
+        return None
+
 
-def parse_type(type_: Dict[str, Any]) -> Union[str, Tuple, List]:
+def parse_type(type_: dict[str, Any]) -> Union[str, tuple, list]:
     if "tuple" not in type_["type"]:
         return type_["type"]
 
     result = tuple([parse_type(c) for c in type_["components"]])
     return [result] if is_array(type_["type"]) else result
 
 
-def _correct_key(key: str, data: Dict, alt_keys: Tuple[str, ...]) -> Dict:
+def _correct_key(key: str, data: dict, alt_keys: tuple[str, ...]) -> dict:
     if key in data:
         return data
 
     # Check for alternative.
     for possible_key in alt_keys:
         if possible_key not in data:
             continue
```

### Comparing `eth-ape-0.7.9/src/ape_ethereum/multicall/constants.py` & `eth-ape-0.8.0/src/ape_ethereum/multicall/constants.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/src/ape_ethereum/multicall/exceptions.py` & `eth-ape-0.8.0/src/ape_ethereum/multicall/exceptions.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/src/ape_ethereum/multicall/handlers.py` & `eth-ape-0.8.0/src/ape_ethereum/multicall/handlers.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,10 @@
+from collections.abc import Iterator
 from types import ModuleType
-from typing import Any, Dict, Iterator, List, Optional, Tuple, Union
+from typing import Any, Optional, Union
 
 from ape.api import ReceiptAPI, TransactionAPI
 from ape.contracts.base import (
     ContractCallHandler,
     ContractInstance,
     ContractMethodHandler,
     ContractTransactionHandler,
@@ -17,29 +18,29 @@
 
 from .constants import (
     MULTICALL3_ADDRESS,
     MULTICALL3_CODE,
     MULTICALL3_CONTRACT_TYPE,
     SUPPORTED_CHAINS,
 )
-from .exceptions import InvalidOption, NotExecutedError, UnsupportedChainError, ValueRequired
+from .exceptions import InvalidOption, UnsupportedChainError, ValueRequired
 
 
 class BaseMulticall(ManagerAccessMixin):
     def __init__(
         self,
         address: AddressType = MULTICALL3_ADDRESS,
-        supported_chains: Optional[List[int]] = None,
+        supported_chains: Optional[list[int]] = None,
     ) -> None:
         """
         Initialize a new Multicall session object. By default, there are no calls to make.
         """
         self.address = address
         self.supported_chains = supported_chains or SUPPORTED_CHAINS
-        self.calls: List[Dict] = []
+        self.calls: list[dict] = []
 
     @classmethod
     def inject(cls) -> ModuleType:
         """
         Create the multicall module contract on-chain, so we can use it.
         Must use a provider that supports ``debug_setCode``.
 
@@ -83,53 +84,54 @@
         return contract
 
     @property
     def handler(self) -> ContractTransactionHandler:
         if any(call["value"] > 0 for call in self.calls):
             return self.contract.aggregate3Value
 
-        elif any(call["allowFailure"] for call in self.calls):
-            return self.contract.aggregate3
-
-        else:
-            return self.contract.aggregate
+        return self.contract.aggregate3
 
     def add(
         self,
         call: ContractMethodHandler,
         *args,
-        allowFailure: bool = False,
+        allowFailure: bool = True,
         value: int = 0,
-    ):
+    ) -> "BaseMulticall":
         """
         Adds a call to the Multicall session object.
 
         Raises:
             :class:`~ape_ethereum.multicall.exceptions.InvalidOption`: If one
               of the kwarg modifiers is not able to be used.
 
         Args:
             call (:class:`~ape_ethereum.multicall.handlers.ContractMethodHandler`):
               The method to call.
             *args: The arguments to invoke the method with.
             allowFailure (bool): Whether the call is allowed to fail.
             value (int): The amount of ether to forward with the call.
+
+        Returns:
+            :class:`~ape_ethereum.multicall.handlers.BaseMulticall`: returns itself
+              to emulate a builder pattern.
         """
 
         # Append call dict to the list
         # NOTE: Depending upon `_handler_method_abi` at time when `__call__` is triggered,
         #       some of these properties will be unused
         self.calls.append(
             {
                 "target": call.contract.address,
                 "allowFailure": allowFailure,
                 "value": value,
                 "callData": call.encode_input(*args),
             }
         )
+        return self
 
 
 class Call(BaseMulticall):
     """
     Create a sequence of calls to execute at once using ``eth_call`` via the Multicall3 contract.
 
     Usage example::
@@ -138,64 +140,54 @@
 
         call = multicall.Call()
         call.add(contract.myMethod, *call_args)
         call.add(contract.myMethod, *call_args)
         ...  # Add as many calls as desired
         call.add(contract.myMethod, *call_args)
         a, b, ..., z = call()  # Performs multicall
+        # or, using a builder pattern:
+        call = multicall.Call()
+            .add(contract.myMethod, *call_args)
+            .add(contract.myMethod, *call_args)
+            ...  # Add as many calls as desired
+            .add(contract.myMethod, *call_args)
+        a, b, ..., z = call()  # Performs multicall
     """
 
     def __init__(
         self,
         address: AddressType = MULTICALL3_ADDRESS,
-        supported_chains: Optional[List[int]] = None,
+        supported_chains: Optional[list[int]] = None,
     ) -> None:
         super().__init__(address=address, supported_chains=supported_chains)
 
-        self.abis: List[MethodABI] = []
-        self._result: Union[None, Tuple[int, List[HexBytes]], List[Tuple[bool, HexBytes]]] = None
-        self._failed_results: List[HexBytes] = []
+        self.abis: list[MethodABI] = []
+        self._result: Union[None, list[tuple[bool, HexBytes]]] = None
 
     @property
     def handler(self) -> ContractCallHandler:  # type: ignore[override]
         return super().handler.call  # NOTE: all Multicall3 methods are mutable calls by default
 
     def add(self, call: ContractMethodHandler, *args, **kwargs):
         if "value" in kwargs:
             raise InvalidOption("value")
 
         super().add(call, *args, **kwargs)
         self.abis.append(_select_method_abi(call.abis, args))
+        return self
 
     @property
-    def returnData(self) -> List[HexBytes]:
+    def returnData(self) -> list[HexBytes]:
+        # NOTE: this property is kept camelCase to align with the raw EVM struct
         result = self._result  # Declare for typing reasons.
-        if not result:
-            raise NotExecutedError()
-
-        elif (
-            isinstance(result, (tuple, list))
-            and len(result) >= 2
-            and type(result[0]) is bool
-            and isinstance(result[1], bytes)
-        ):
-            # Call3[] or Call3Value[] when only single call.
-            return [result[1]]
-
-        elif isinstance(result, tuple):
-            # Call3[] or Call3Value[] when multiple calls.
-            return list(r[1] for r in self._result)  # type: ignore
-
-        else:
-            # blockNumber: uint256, returnData: Call[]
-            return result.returnData  # type: ignore
+        return [res.returnData if res.success else None for res in result]  # type: ignore
 
     def _decode_results(self) -> Iterator[Any]:
         for abi, data in zip(self.abis, self.returnData):
-            if data in self._failed_results:
+            if data is None:
                 # The call failed.
                 yield data
                 continue
 
             try:
                 result = self.provider.network.ecosystem.decode_returndata(abi, data)
             except DecodingError as err:
@@ -249,15 +241,22 @@
         from ape_ethereum.multicall import Transaction
 
         txn = Transaction()
         txn.add(contract.myMethod, *call_args)
         txn.add(contract.myMethod, *call_args)
         ...  # Add as many calls as desired to execute
         txn.add(contract.myMethod, *call_args)
-        a, b, ..., z = txn(sender=my_signer)  # Sends the multicall transaction
+        a, b, ..., z = txn(sender=my_signer).return_data  # Sends the multicall transaction
+        # or, using a builder pattern:
+        txn = Transaction()
+            .add(contract.myMethod, *call_args)
+            .add(contract.myMethod, *call_args)
+            ...  # Add as many calls as desired to execute
+            .add(contract.myMethod, *call_args)
+        a, b, ..., z = txn(sender=my_signer).return_data  # Sends the multicall transaction
     """
 
     def _validate_calls(self, **txn_kwargs) -> None:
         required_value = sum(call["value"] for call in self.calls)
         if required_value > 0:
             if "value" not in txn_kwargs:
                 raise ValueRequired(required_value)
```

### Comparing `eth-ape-0.7.9/src/ape_ethereum/provider.py` & `eth-ape-0.8.0/src/ape_ethereum/provider.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,34 +1,27 @@
 import os
 import re
 import sys
 import time
 from abc import ABC
+from collections.abc import Iterable, Iterator
 from concurrent.futures import ThreadPoolExecutor
 from copy import copy
-from functools import cached_property
-from itertools import tee
+from functools import cached_property, wraps
 from pathlib import Path
-from typing import Any, Dict, Iterator, List, Optional, Union, cast
+from typing import Any, Optional, Union, cast
 
 import ijson  # type: ignore
 import requests
 from eth_pydantic_types import HexBytes
 from eth_typing import BlockNumber, HexStr
-from eth_utils import add_0x_prefix, to_hex
+from eth_utils import add_0x_prefix, is_hex, to_hex
 from ethpm_types import EventABI
-from evm_trace import CallTreeNode as EvmCallTreeNode
-from evm_trace import ParityTraceList
-from evm_trace import TraceFrame as EvmTraceFrame
-from evm_trace import (
-    create_trace_frames,
-    get_calltree_from_geth_call_trace,
-    get_calltree_from_parity_trace,
-)
 from pydantic.dataclasses import dataclass
+from requests import HTTPError
 from web3 import HTTPProvider, IPCProvider, Web3
 from web3.exceptions import ContractLogicError as Web3ContractLogicError
 from web3.exceptions import (
     ExtraDataLengthError,
     MethodUnavailable,
     TimeExhausted,
     TransactionNotFound,
@@ -36,16 +29,15 @@
 from web3.gas_strategies.rpc import rpc_gas_price_strategy
 from web3.middleware import geth_poa_middleware
 from web3.middleware.validation import MAX_EXTRADATA_LENGTH
 from web3.providers import AutoProvider
 from web3.providers.auto import load_provider_from_environment
 from web3.types import FeeHistory, RPCEndpoint, TxParams
 
-from ape.api import BlockAPI, ProviderAPI, ReceiptAPI, TransactionAPI
-from ape.api.networks import LOCAL_NETWORK_NAME
+from ape.api import Address, BlockAPI, ProviderAPI, ReceiptAPI, TraceAPI, TransactionAPI
 from ape.exceptions import (
     ApeException,
     APINotImplementedError,
     BlockNotFoundError,
     ConfigError,
     ContractLogicError,
     ContractNotFoundError,
@@ -57,54 +49,119 @@
     VirtualMachineError,
 )
 from ape.logging import logger, sanitize_url
 from ape.types import (
     AddressType,
     AutoGasLimit,
     BlockID,
-    CallTreeNode,
     ContractCode,
     ContractLog,
     LogFilter,
     SourceTraceback,
-    TraceFrame,
 )
-from ape.utils import gas_estimation_error_message, run_until_complete, to_int
+from ape.utils import gas_estimation_error_message, to_int
 from ape.utils.misc import DEFAULT_MAX_RETRIES_TX
+from ape_ethereum._print import CONSOLE_ADDRESS, console_contract
+from ape_ethereum.trace import CallTrace, TraceApproach, TransactionTrace
 from ape_ethereum.transactions import AccessList, AccessListTransaction
 
 DEFAULT_PORT = 8545
 DEFAULT_HOSTNAME = "localhost"
 DEFAULT_SETTINGS = {"uri": f"http://{DEFAULT_HOSTNAME}:{DEFAULT_PORT}"}
 
 
 def _sanitize_web3_url(msg: str) -> str:
-    if "URI: " not in msg:
+    """Sanitize RPC URI from given log string"""
+
+    # `auto` used by some providers to figure it out automatically
+    if "URI: " not in msg or "URI: auto" in msg:
         return msg
 
     parts = msg.split("URI: ")
     prefix = parts[0].strip()
     rest = parts[1].split(" ")
 
     # * To remove the `,` from the url http://127.0.0.1:8545,
     if "," in rest[0]:
         rest[0] = rest[0].rstrip(",")
     sanitized_url = sanitize_url(rest[0])
     return f"{prefix} URI: {sanitized_url} {' '.join(rest[1:])}"
 
 
+WEB3_PROVIDER_URI_ENV_VAR_NAME = "WEB3_PROVIDER_URI"
+
+
+def assert_web3_provider_uri_env_var_not_set():
+    """
+    Environment variable $WEB3_PROVIDER_URI causes problems
+    when used with Ape (ignores Ape's networks). Use
+    this validator to eliminate the concern.
+
+    Raises:
+          :class:`~ape.exceptions.ProviderError`: If environment variable
+            WEB3_PROVIDER_URI exists in ``os.environ``.
+    """
+    if WEB3_PROVIDER_URI_ENV_VAR_NAME not in os.environ:
+        return
+
+    # NOTE: This was the source of confusion for user when they noticed
+    #  Ape would only connect to RPC URL set by an environment variable
+    #  named $WEB3_PROVIDER_URI instead of whatever network they were telling Ape.
+    raise ProviderError(
+        "Ape does not support Web3.py's environment variable "
+        f"${WEB3_PROVIDER_URI_ENV_VAR_NAME}. If you are using this environment "
+        "variable name incidentally, please use a different name. If you are "
+        "trying to set the network in Web3.py, please use Ape's `ape-config.yaml` "
+        "or `--network` option instead."
+    )
+
+
 class Web3Provider(ProviderAPI, ABC):
     """
     A base provider mixin class that uses the
     `web3.py <https://web3py.readthedocs.io/en/stable/>`__ python package.
     """
 
     _web3: Optional[Web3] = None
     _client_version: Optional[str] = None
 
+    _call_trace_approach: Optional[TraceApproach] = None
+    """
+    Is ``None`` until known.
+    NOTE: This gets set in `ape_ethereum.trace.Trace`.
+    """
+
+    _supports_debug_trace_call: Optional[bool] = None
+
+    def __new__(cls, *args, **kwargs):
+        assert_web3_provider_uri_env_var_not_set()
+
+        # Post-connection ops
+        def post_connect_hook(connect):
+            @wraps(connect)
+            def connect_wrapper(self):
+                connect(self)
+                self._post_connect()
+
+            return connect_wrapper
+
+        # Patching the provider to call a post send_transaction() hook
+        def post_tx_hook(send_tx):
+            @wraps(send_tx)
+            def send_tx_wrapper(self, txn: TransactionAPI) -> ReceiptAPI:
+                receipt = send_tx(self, txn)
+                self._post_send_transaction(txn, receipt)
+                return receipt
+
+            return send_tx_wrapper
+
+        setattr(cls, "send_transaction", post_tx_hook(cls.send_transaction))
+        setattr(cls, "connect", post_connect_hook(cls.connect))
+        return super().__new__(cls)  # pydantic v2 doesn't want args
+
     def __init__(self, *args, **kwargs):
         logger.create_logger("web3.RequestManager", handlers=(_sanitize_web3_url,))
         logger.create_logger("web3.providers.HTTPProvider", handlers=(_sanitize_web3_url,))
         super().__init__(*args, **kwargs)
 
     @property
     def web3(self) -> Web3:
@@ -198,41 +255,42 @@
         raise APINotImplementedError("No base fee found in block.")
 
     @property
     def is_connected(self) -> bool:
         if self._web3 is None:
             return False
 
-        return run_until_complete(self._web3.is_connected())
+        return self._web3.is_connected()
 
     @property
     def max_gas(self) -> int:
         block = self.web3.eth.get_block("latest")
         return block["gasLimit"]
 
     @cached_property
     def supports_tracing(self) -> bool:
         try:
             # NOTE: Txn hash is purposely not a real hash.
-            # If we get any exception besides not implemented error,
-            # then we support tracing on this provider.
-            self.get_call_tree("__CHECK_IF_SUPPORTS_TRACING__")
-        except APINotImplementedError:
+            self.make_request("debug_traceTransaction", ["__CHECK_IF_SUPPORTS_TRACING__"])
+        except NotImplementedError:
             return False
+
         except Exception:
+            # We know tracing works because we didn't get a NotImplementedError.
             return True
 
         return True
 
     def update_settings(self, new_settings: dict):
         self.disconnect()
         self.provider_settings.update(new_settings)
         self.connect()
 
     def estimate_gas_cost(self, txn: TransactionAPI, block_id: Optional[BlockID] = None) -> int:
+        # NOTE: Using JSON mode since used as request data.
         txn_dict = txn.model_dump(by_alias=True, mode="json")
 
         # Force the use of hex values to support a wider range of nodes.
         if isinstance(txn_dict.get("type"), int):
             txn_dict["type"] = HexBytes(txn_dict["type"]).hex()
 
         # NOTE: "auto" means to enter this method, so remove it from dict
@@ -244,37 +302,44 @@
             txn_dict.pop("maxFeePerGas", None)
             txn_dict.pop("maxPriorityFeePerGas", None)
 
         txn_params = cast(TxParams, txn_dict)
         try:
             return self.web3.eth.estimate_gas(txn_params, block_identifier=block_id)
         except (ValueError, Web3ContractLogicError) as err:
-            tx_error = self.get_virtual_machine_error(err, txn=txn)
+            # NOTE: Try to use debug_traceCall to obtain a trace.
+            #  And the RPC can be very picky with inputs.
+            tx_to_trace: dict = {}
+            for key, val in txn_params.items():
+                if isinstance(val, int):
+                    tx_to_trace[key] = hex(val)
+                else:
+                    tx_to_trace[key] = val
+
+            trace = CallTrace(tx=txn)
+            tx_error = self.get_virtual_machine_error(
+                err,
+                txn=txn,
+                trace=trace,
+            )
 
             # If this is the cause of a would-be revert,
             # raise ContractLogicError so that we can confirm tx-reverts.
             if isinstance(tx_error, ContractLogicError):
                 raise tx_error from err
 
             message = gas_estimation_error_message(tx_error)
             raise TransactionError(
                 message, base_err=tx_error, txn=txn, source_traceback=tx_error.source_traceback
             ) from err
 
     @cached_property
     def chain_id(self) -> int:
         default_chain_id = None
-        if (
-            self.network.name
-            not in (
-                "custom",
-                LOCAL_NETWORK_NAME,
-            )
-            and not self.network.is_fork
-        ):
+        if self.network.name != "custom" and not self.network.is_dev:
             # If using a live network, the chain ID is hardcoded.
             default_chain_id = self.network.chain_id
 
         try:
             if hasattr(self.web3, "eth"):
                 return self.web3.eth.chain_id
 
@@ -335,123 +400,128 @@
             return HexBytes(self.web3.eth.get_storage_at(address, slot, block_identifier=block_id))
         except ValueError as err:
             if "RPC Endpoint has not been implemented" in str(err):
                 raise APINotImplementedError(str(err)) from err
 
             raise  # Raise original error
 
+    def get_transaction_trace(self, transaction_hash: str, **kwargs) -> TraceAPI:
+        if "call_trace_approach" not in kwargs:
+            kwargs["call_trace_approach"] = self._call_trace_approach
+
+        return TransactionTrace(transaction_hash=transaction_hash, **kwargs)
+
     def send_call(
         self,
         txn: TransactionAPI,
         block_id: Optional[BlockID] = None,
-        state: Optional[Dict] = None,
-        **kwargs,
+        state: Optional[dict] = None,
+        **kwargs: Any,
     ) -> HexBytes:
-        if kwargs.pop("skip_trace", False):
-            return self._send_call(txn, **kwargs)
-        elif self._test_runner is not None:
+        if block_id is not None:
+            kwargs["block_identifier"] = block_id
+
+        if state is not None:
+            kwargs["state_override"] = state
+
+        skip_trace = kwargs.pop("skip_trace", False)
+        arguments = self._prepare_call(txn, **kwargs)
+        if skip_trace:
+            return self._eth_call(arguments)
+
+        show_gas = kwargs.pop("show_gas_report", False)
+        show_trace = kwargs.pop("show_trace", False)
+
+        if self._test_runner is not None:
             track_gas = self._test_runner.gas_tracker.enabled
             track_coverage = self._test_runner.coverage_tracker.enabled
         else:
             track_gas = False
             track_coverage = False
 
-        show_trace = kwargs.pop("show_trace", False)
-        show_gas = kwargs.pop("show_gas_report", False)
-        needs_trace = track_gas or track_coverage or show_trace or show_gas
-        if not needs_trace or not self.provider.supports_tracing or not txn.receiver:
-            return self._send_call(txn, **kwargs)
+        needs_trace = track_gas or track_coverage or show_gas or show_trace
+        if not needs_trace:
+            return self._eth_call(arguments)
 
         # The user is requesting information related to a call's trace,
         # such as gas usage data.
-        try:
-            with self.chain_manager.isolate():
-                return self._send_call_as_txn(
-                    txn,
-                    track_gas=track_gas,
-                    track_coverage=track_coverage,
-                    show_trace=show_trace,
-                    show_gas=show_gas,
-                    **kwargs,
-                )
 
-        except APINotImplementedError:
-            return self._send_call(txn, **kwargs)
+        # When looking at gas, we cannot use token symbols in enrichment.
+        # Else, the table is difficult to understand.
+        use_symbol_for_tokens = track_gas or show_gas
+
+        trace = CallTrace(
+            tx=arguments[0],
+            arguments=arguments[1:],
+            use_symbol_for_tokens=use_symbol_for_tokens,
+            supports_debug_trace_call=self._supports_debug_trace_call,
+        )
 
-    def _send_call_as_txn(
-        self,
-        txn: TransactionAPI,
-        track_gas: bool = False,
-        track_coverage: bool = False,
-        show_trace: bool = False,
-        show_gas: bool = False,
-        **kwargs,
-    ) -> HexBytes:
-        account = self.account_manager.test_accounts[0]
-        receipt = account.call(txn, **kwargs)
-        if not (call_tree := receipt.call_tree):
-            return self._send_call(txn, **kwargs)
-
-        # Grab raw returndata before enrichment
-        returndata = call_tree.outputs
-
-        if (track_gas or track_coverage) and show_gas and not show_trace:
-            # Optimization to enrich early and in_place=True.
-            call_tree.enrich()
-
-        if track_gas:
-            # in_place=False in case show_trace is True
-            receipt.track_gas()
+        if track_gas and self._test_runner is not None and txn.receiver:
+            self._test_runner.gas_tracker.append_gas(trace, txn.receiver)
 
-        if track_coverage:
-            receipt.track_coverage()
+        if track_coverage and self._test_runner is not None and txn.receiver:
+            if contract_type := self.chain_manager.contracts.get(txn.receiver):
+                if contract_src := self.local_project._create_contract_source(contract_type):
+                    method_id = HexBytes(txn.data)
+                    selector = (
+                        contract_type.methods[method_id].selector
+                        if method_id in contract_type.methods
+                        else None
+                    )
+                    source_traceback = SourceTraceback.create(contract_src, trace, method_id)
+                    self._test_runner.coverage_tracker.cover(
+                        source_traceback, function=selector, contract=contract_type.name
+                    )
 
         if show_gas:
-            # in_place=False in case show_trace is True
-            self.chain_manager._reports.show_gas(call_tree.enrich(in_place=False))
+            trace.show_gas_report()
 
         if show_trace:
-            call_tree = call_tree.enrich(use_symbol_for_tokens=True)
-            self.chain_manager._reports.show_trace(call_tree)
-
-        return HexBytes(returndata)
-
-    def _send_call(self, txn: TransactionAPI, **kwargs) -> HexBytes:
-        arguments = self._prepare_call(txn, **kwargs)
-        try:
-            return self._eth_call(arguments)
-        except TransactionError as err:
-            if not err.txn:
-                err.txn = txn
+            trace.show()
 
-            raise  # The tx error
+        return HexBytes(trace.return_value)
 
-    def _eth_call(self, arguments: List) -> HexBytes:
+    def _eth_call(self, arguments: list) -> HexBytes:
         # Force the usage of hex-type to support a wider-range of nodes.
         txn_dict = copy(arguments[0])
         if isinstance(txn_dict.get("type"), int):
             txn_dict["type"] = HexBytes(txn_dict["type"]).hex()
 
         # Remove unnecessary values to support a wider-range of nodes.
         txn_dict.pop("chainId", None)
 
         arguments[0] = txn_dict
+
         try:
-            result = self._make_request("eth_call", arguments)
+            result = self.make_request("eth_call", arguments)
         except Exception as err:
-            receiver = txn_dict["to"]
-            raise self.get_virtual_machine_error(err, contract_address=receiver) from err
+            trace = CallTrace(tx=arguments[0], arguments=arguments[1:], use_tokens_for_symbols=True)
+            contract_address = arguments[0]["to"]
+            contract_type = self.chain_manager.contracts.get(contract_address)
+            method_id = arguments[0].get("data", "")[:10] or None
+            tb = None
+            if contract_type and method_id:
+                if contract_src := self.local_project._create_contract_source(contract_type):
+                    tb = SourceTraceback.create(contract_src, trace, method_id)
+
+            raise self.get_virtual_machine_error(
+                err, trace=trace, contract_address=contract_address, source_traceback=tb
+            ) from err
 
         if "error" in result:
             raise ProviderError(result["error"]["message"])
 
         return HexBytes(result)
 
-    def _prepare_call(self, txn: TransactionAPI, **kwargs) -> List:
-        txn_dict = txn.model_dump(by_alias=True, mode="json")
+    def _prepare_call(self, txn: Union[dict, TransactionAPI], **kwargs) -> list:
+        # NOTE: Using mode="json" because used in request data.
+        txn_dict = (
+            txn.model_dump(by_alias=True, mode="json") if isinstance(txn, TransactionAPI) else txn
+        )
         fields_to_convert = ("data", "chainId", "value")
         for field in fields_to_convert:
             value = txn_dict.get(field)
             if value is not None and not isinstance(value, str):
                 txn_dict[field] = to_hex(value)
 
         # Remove unneeded properties
@@ -485,18 +555,24 @@
             timeout if timeout is not None else self.provider.network.transaction_acceptance_timeout
         )
 
         hex_hash = HexBytes(txn_hash)
         try:
             receipt_data = self.web3.eth.wait_for_transaction_receipt(hex_hash, timeout=timeout)
         except TimeExhausted as err:
-            raise TransactionNotFoundError(txn_hash, error_messsage=str(err)) from err
+            msg_str = str(err)
+            if f"HexBytes('{txn_hash}')" in msg_str:
+                msg_str = msg_str.replace(f"HexBytes('{txn_hash}')", f"'{txn_hash}'")
+
+            raise TransactionNotFoundError(
+                transaction_hash=txn_hash, error_message=msg_str
+            ) from err
 
-        ecosystem_config = self.network.config.model_dump(by_alias=True, mode="json")
-        network_config: Dict = ecosystem_config.get(self.network.name, {})
+        ecosystem_config = self.network.ecosystem_config.model_dump(by_alias=True)
+        network_config: dict = ecosystem_config.get(self.network.name, {})
         max_retries = network_config.get("max_get_transaction_retries", DEFAULT_MAX_RETRIES_TX)
         txn = {}
         for attempt in range(max_retries):
             try:
                 txn = dict(self.web3.eth.get_transaction(HexStr(txn_hash)))
                 break
             except TransactionNotFound:
@@ -518,15 +594,15 @@
     def get_transactions_by_block(self, block_id: BlockID) -> Iterator[TransactionAPI]:
         if isinstance(block_id, str):
             block_id = HexStr(block_id)
 
             if block_id.isnumeric():
                 block_id = add_0x_prefix(block_id)
 
-        block = cast(Dict, self.web3.eth.get_block(block_id, full_transactions=True))
+        block = cast(dict, self.web3.eth.get_block(block_id, full_transactions=True))
         for transaction in block.get("transactions", []):
             yield self.network.ecosystem.create_transaction(**transaction)
 
     def get_transactions_by_account_nonce(
         self,
         account: AddressType,
         start_nonce: int = 0,
@@ -624,15 +700,15 @@
             number: int
             time: float
 
         # Pretend we _did_ yield the last confirmed item, for logic's sake.
         fake_last_block = self.get_block(self.web3.eth.block_number - required_confirmations)
         last_num = fake_last_block.number or 0
         last_hash = fake_last_block.hash or HexBytes(0)
-        last = YieldAction(number=last_num, hash=last_hash, time=time.time())
+        last: YieldAction = YieldAction(number=last_num, hash=last_hash, time=time.time())
 
         # A helper method for various points of ensuring we didn't timeout.
         def assert_chain_activity():
             time_waiting = time.time() - last.time
             if time_waiting > timeout:
                 raise ProviderError("Timed out waiting for next block.")
 
@@ -642,15 +718,15 @@
             next_block = last.number + 1
 
             head = self.get_block("latest")
 
             try:
                 if head.number is None or head.hash is None:
                     raise ProviderError("Head block has no number or hash.")
-                # Use an "adjused" head, based on the required confirmations.
+                # Use an "adjusted" head, based on the required confirmations.
                 adjusted_head = self.get_block(head.number - required_confirmations)
                 if adjusted_head.number is None or adjusted_head.hash is None:
                     raise ProviderError("Adjusted head block has no number or hash.")
             except Exception:
                 # TODO: I did encounter this sometimes in a re-org, needs better handling
                 # and maybe bubbling up the block number/hash exceptions above.
                 assert_chain_activity()
@@ -698,32 +774,32 @@
                 # Set the last action, used for checking timeouts and re-orgs.
                 last = YieldAction(number=block.number, hash=block.hash, time=time.time())
 
     def poll_logs(
         self,
         stop_block: Optional[int] = None,
         address: Optional[AddressType] = None,
-        topics: Optional[List[Union[str, List[str]]]] = None,
+        topics: Optional[list[Union[str, list[str]]]] = None,
         required_confirmations: Optional[int] = None,
         new_block_timeout: Optional[int] = None,
-        events: Optional[List[EventABI]] = None,
+        events: Optional[list[EventABI]] = None,
     ) -> Iterator[ContractLog]:
         events = events or []
         if required_confirmations is None:
             required_confirmations = self.network.required_confirmations
 
         if stop_block is not None:
             if stop_block <= (self.provider.get_block("latest").number or 0):
                 raise ValueError("'stop' argument must be in the future.")
 
         for block in self.poll_blocks(stop_block, required_confirmations, new_block_timeout):
             if block.number is None:
                 raise ValueError("Block number cannot be None")
 
-            log_params: Dict[str, Any] = {
+            log_params: dict[str, Any] = {
                 "start_block": block.number,
                 "stop_block": block.number,
                 "events": events,
             }
             if address is not None:
                 log_params["addresses"] = [address]
             if topics is not None:
@@ -738,103 +814,48 @@
         if page is None:
             page = self.block_page_size
 
         for start_block in range(start, stop + 1, page):
             stop_block = min(stop, start_block + page - 1)
             yield start_block, stop_block
 
-    def get_contract_creation_receipts(
-        self,
-        address: AddressType,
-        start_block: int = 0,
-        stop_block: Optional[int] = None,
-        contract_code: Optional[HexBytes] = None,
-    ) -> Iterator[ReceiptAPI]:
-        if stop_block is None:
-            stop_block = self.chain_manager.blocks.height
-
-        if contract_code is None:
-            contract_code = HexBytes(self.get_code(address))
-
-        mid_block = (stop_block - start_block) // 2 + start_block
-        # NOTE: biased towards mid_block == start_block
-
-        if start_block == mid_block:
-            for tx in self.chain_manager.blocks[mid_block].transactions:
-                if (receipt := tx.receipt) and receipt.contract_address == address:
-                    yield receipt
-
-            if mid_block + 1 <= stop_block:
-                yield from self.get_contract_creation_receipts(
-                    address,
-                    start_block=mid_block + 1,
-                    stop_block=stop_block,
-                    contract_code=contract_code,
-                )
-
-        # TODO: Handle when code is nonzero but doesn't match
-        # TODO: Handle when code is empty after it's not (re-init)
-        elif HexBytes(self.get_code(address, block_id=mid_block)) == contract_code:
-            # If the code exists, we need to look backwards.
-            yield from self.get_contract_creation_receipts(
-                address,
-                start_block=start_block,
-                stop_block=mid_block,
-                contract_code=contract_code,
-            )
-
-        elif mid_block + 1 <= stop_block:
-            # The code does not exist yet, we need to look ahead.
-            yield from self.get_contract_creation_receipts(
-                address,
-                start_block=mid_block + 1,
-                stop_block=stop_block,
-                contract_code=contract_code,
-            )
-
     def get_contract_logs(self, log_filter: LogFilter) -> Iterator[ContractLog]:
         height = self.chain_manager.blocks.height
         start_block = log_filter.start_block
         stop_block_arg = log_filter.stop_block if log_filter.stop_block is not None else height
         stop_block = min(stop_block_arg, height)
         block_ranges = self.block_ranges(start_block, stop_block, self.block_page_size)
 
         def fetch_log_page(block_range):
             start, stop = block_range
             update = {"start_block": start, "stop_block": stop}
             page_filter = log_filter.model_copy(update=update)
-            # eth-tester expects a different format, let web3 handle the conversions for it.
-            raw = "EthereumTester" not in self.client_version
-            logs = self._get_logs(page_filter.model_dump(mode="json"), raw)
+
+            # NOTE: Using JSON mode since used as request data.
+            filter_params = page_filter.model_dump(mode="json")
+            logs = self.make_request("eth_getLogs", [filter_params])
             return self.network.ecosystem.decode_logs(logs, *log_filter.events)
 
         with ThreadPoolExecutor(self.concurrency) as pool:
             for page in pool.map(fetch_log_page, block_ranges):
                 yield from page
 
-    def _get_logs(self, filter_params, raw=True) -> List[Dict]:
-        if not raw:
-            return [vars(d) for d in self.web3.eth.get_logs(filter_params)]
-
-        return self._make_request("eth_getLogs", [filter_params])
-
     def prepare_transaction(self, txn: TransactionAPI) -> TransactionAPI:
         # NOTE: Use "expected value" for Chain ID, so if it doesn't match actual, we raise
         txn.chain_id = self.network.chain_id
 
         from ape_ethereum.transactions import StaticFeeTransaction, TransactionType
 
         txn_type = TransactionType(txn.type)
         if (
             txn_type in (TransactionType.STATIC, TransactionType.ACCESS_LIST)
             and isinstance(txn, StaticFeeTransaction)
             and txn.gas_price is None
         ):
             txn.gas_price = self.gas_price
-
         elif txn_type in (TransactionType.DYNAMIC, TransactionType.SHARED_BLOB):
             if txn.max_priority_fee is None:
                 txn.max_priority_fee = self.priority_fee
 
             if txn.max_fee is None:
                 multiplier = self.network.base_fee_multiplier
                 txn.max_fee = int(self.base_fee * multiplier + txn.max_priority_fee)
@@ -879,14 +900,15 @@
         try:
             if txn.signature or not txn.sender:
                 txn_hash = self.web3.eth.send_raw_transaction(txn.serialize_transaction())
             else:
                 if txn.sender not in self.web3.eth.accounts:
                     self.chain_manager.provider.unlock_account(txn.sender)
 
+                # NOTE: Using JSON mode since used as request data.
                 txn_data = cast(TxParams, txn.model_dump(by_alias=True, mode="json"))
                 txn_hash = self.web3.eth.send_transaction(txn_data)
 
         except (ValueError, Web3ContractLogicError) as err:
             vm_err = self.get_virtual_machine_error(err, txn=txn)
             raise vm_err from err
 
@@ -896,123 +918,117 @@
                 txn.required_confirmations
                 if txn.required_confirmations is not None
                 else self.network.required_confirmations
             ),
         )
 
         # NOTE: Ensure to cache even the failed receipts.
+        # NOTE: Caching must happen before error enrichment.
         self.chain_manager.history.append(receipt)
 
         if receipt.failed:
+            # NOTE: Using JSON mode since used as request data.
             txn_dict = receipt.transaction.model_dump(by_alias=True, mode="json")
+
             txn_params = cast(TxParams, txn_dict)
 
             # Replay txn to get revert reason
             try:
                 self.web3.eth.call(txn_params)
             except Exception as err:
                 vm_err = self.get_virtual_machine_error(err, txn=txn)
                 raise vm_err from err
 
             # If we get here, for some reason the tx-replay did not produce
             # a VM error.
             receipt.raise_for_status()
 
-        logger.info(f"Confirmed {receipt.txn_hash} (total fees paid = {receipt.total_fees_paid})")
         return receipt
 
-    def _create_call_tree_node(
-        self, evm_call: EvmCallTreeNode, txn_hash: Optional[str] = None
-    ) -> CallTreeNode:
-        address = evm_call.address
-        try:
-            contract_id = str(self.provider.network.ecosystem.decode_address(address))
-        except ValueError:
-            # Use raw value since it is not a real address.
-            contract_id = address.hex()
-
-        call_type = evm_call.call_type.value
-        return CallTreeNode(
-            calls=[self._create_call_tree_node(x, txn_hash=txn_hash) for x in evm_call.calls],
-            call_type=call_type,
-            contract_id=contract_id,
-            failed=evm_call.failed,
-            gas_cost=evm_call.gas_cost,
-            inputs=evm_call.calldata if "CREATE" in call_type else evm_call.calldata[4:].hex(),
-            method_id=evm_call.calldata[:4].hex(),
-            outputs=evm_call.returndata.hex(),
-            raw=evm_call.model_dump(by_alias=True, mode="json"),
-            txn_hash=txn_hash,
-        )
+    def _post_send_transaction(self, tx: TransactionAPI, receipt: ReceiptAPI):
+        """Execute post-transaction ops"""
 
-    def _create_trace_frame(self, evm_frame: EvmTraceFrame) -> TraceFrame:
-        address_bytes = evm_frame.address
-        try:
-            address = (
-                self.network.ecosystem.decode_address(address_bytes.hex())
-                if address_bytes
-                else None
-            )
-        except ValueError:
-            # Might not be a real address.
-            address = cast(AddressType, address_bytes.hex()) if address_bytes else None
-
-        return TraceFrame(
-            pc=evm_frame.pc,
-            op=evm_frame.op,
-            gas=evm_frame.gas,
-            gas_cost=evm_frame.gas_cost,
-            depth=evm_frame.depth,
-            contract_address=address,
-            raw=evm_frame.model_dump(by_alias=True, mode="json"),
-        )
+        # TODO: Optional configuration?
+        if tx.receiver and Address(tx.receiver).is_contract:
+            # Look for and print any contract logging
+            receipt.show_debug_logs()
 
-    def _make_request(self, endpoint: str, parameters: Optional[List] = None) -> Any:
+        logger.info(f"Confirmed {receipt.txn_hash} (total fees paid = {receipt.total_fees_paid})")
+
+    def _post_connect(self):
+        # Register the console contract for trace enrichment
+        self.chain_manager.contracts._cache_contract_type(CONSOLE_ADDRESS, console_contract)
+
+    def make_request(self, rpc: str, parameters: Optional[Iterable] = None) -> Any:
         parameters = parameters or []
-        coroutine = self.web3.provider.make_request(RPCEndpoint(endpoint), parameters)
-        result = run_until_complete(coroutine)
+
+        try:
+            result = self.web3.provider.make_request(RPCEndpoint(rpc), parameters)
+        except HTTPError as err:
+            if "method not allowed" in str(err).lower():
+                raise APINotImplementedError(
+                    f"RPC method '{rpc}' is not implemented by this node instance."
+                )
+
+            raise ProviderError(str(err)) from err
 
         if "error" in result:
             error = result["error"]
             message = (
                 error["message"] if isinstance(error, dict) and "message" in error else str(error)
             )
 
             if (
                 "does not exist/is not available" in str(message)
                 or re.match(r"Method .*?not found", message)
                 or message.startswith("Unknown RPC Endpoint")
                 or "RPC Endpoint has not been implemented" in message
             ):
                 raise APINotImplementedError(
-                    f"RPC method '{endpoint}' is not implemented by this node instance."
+                    f"RPC method '{rpc}' is not implemented by this node instance."
                 )
 
             raise ProviderError(message)
 
         elif "result" in result:
             return result.get("result", {})
 
         return result
 
+    def stream_request(self, method: str, params: Iterable, iter_path: str = "result.item"):
+        if not (uri := self.http_uri):
+            raise ProviderError("This provider has no HTTP URI and is unable to stream requests.")
+
+        payload = {"jsonrpc": "2.0", "id": 1, "method": method, "params": params}
+        results = ijson.sendable_list()
+        coroutine = ijson.items_coro(results, iter_path)
+        resp = requests.post(uri, json=payload, stream=True)
+        resp.raise_for_status()
+
+        for chunk in resp.iter_content(chunk_size=2**17):
+            coroutine.send(chunk)
+            yield from results
+            del results[:]
+
     def create_access_list(
         self, transaction: TransactionAPI, block_id: Optional[BlockID] = None
-    ) -> List[AccessList]:
+    ) -> list[AccessList]:
         """
         Get the access list for a transaction use ``eth_createAccessList``.
 
         Args:
             transaction (:class:`~ape.api.transactions.TransactionAPI`): The
               transaction to check.
             block_id (:class:`~ape.types.BlockID`): Optionally specify a block
               ID. Defaults to using the latest block.
 
         Returns:
-            List[:class:`~ape_ethereum.transactions.AccessList`]
+            list[:class:`~ape_ethereum.transactions.AccessList`]
         """
+        # NOTE: Using JSON mode since used in request data.
         tx_dict = transaction.model_dump(by_alias=True, mode="json", exclude=("chain_id",))
         tx_dict_converted = {}
         for key, val in tx_dict.items():
             if isinstance(val, int):
                 # This RPC requires hex-str values.
                 if val > 0:
                     tx_dict_converted[key] = to_hex(val)
@@ -1025,15 +1041,15 @@
             # Contract creation with no data, can skip.
             return []
 
         arguments: list = [tx_dict_converted]
         if block_id is not None:
             arguments.append(block_id)
 
-        result = self._make_request("eth_createAccessList", arguments)
+        result = self.make_request("eth_createAccessList", arguments)
         return [AccessList.model_validate(x) for x in result.get("accessList", [])]
 
     def get_virtual_machine_error(self, exception: Exception, **kwargs) -> VirtualMachineError:
         txn = kwargs.get("txn")
         if isinstance(exception, Web3ContractLogicError):
             # This happens from `assert` or `require` statements.
             return self._handle_execution_reverted(exception, **kwargs)
@@ -1063,86 +1079,89 @@
 
         return VirtualMachineError(str(err_msg), code=(err_data or {}).get("code"), **kwargs)
 
     def _handle_execution_reverted(
         self,
         exception: Union[Exception, str],
         txn: Optional[TransactionAPI] = None,
-        trace: Optional[Iterator[TraceFrame]] = None,
+        trace: Optional[TraceAPI] = None,
         contract_address: Optional[AddressType] = None,
         source_traceback: Optional[SourceTraceback] = None,
     ) -> ContractLogicError:
-        message = str(exception).split(":")[-1].strip()
-        params: Dict = {
+        if hasattr(exception, "args") and len(exception.args) == 2:
+            message = exception.args[0].replace("execution reverted: ", "")
+            data = exception.args[1]
+        else:
+            message = str(exception).split(":")[-1].strip()
+            data = None
+
+        params: dict = {
             "trace": trace,
             "contract_address": contract_address,
             "source_traceback": source_traceback,
         }
         no_reason = message == "execution reverted"
 
         if isinstance(exception, Web3ContractLogicError) and no_reason:
             # Check for custom exception data and use that as the message instead.
             # This allows compiler exception enrichment to function.
-            err_trace = None
-            try:
-                if trace:
-                    trace, err_trace = tee(trace)
-                elif txn:
-                    err_trace = self.provider.get_transaction_trace(txn.txn_hash.hex())
+            if data != "no data" and is_hex(data):
+                message = add_0x_prefix(data)
 
-                try:
-                    trace_ls: List[TraceFrame] = list(err_trace) if err_trace else []
-                except Exception as err:
-                    logger.error(f"Failed getting traceback: {err}")
-                    trace_ls = []
-
-                data = trace_ls[-1].raw if len(trace_ls) > 0 else {}
-                memory = data.get("memory", [])
-                return_value = "".join([x[2:] for x in memory[4:]])
-                if return_value:
-                    message = f"0x{return_value}"
-                    no_reason = False
+            else:
+                if trace is None and txn is not None:
+                    trace = self.provider.get_transaction_trace(txn.txn_hash.hex())
 
-            except (ApeException, NotImplementedError):
-                # Either provider does not support or isn't a custom exception.
-                pass
+                if trace is not None and (revert_message := trace.revert_message):
+                    message = revert_message
+                    no_reason = False
+                    if revert_message := trace.revert_message:
+                        message = revert_message
+                        no_reason = False
 
         result = (
             ContractLogicError(txn=txn, **params)
             if no_reason
             else ContractLogicError(
                 base_err=exception if isinstance(exception, Exception) else None,
                 revert_message=message,
                 txn=txn,
                 **params,
             )
         )
-        return self.compiler_manager.enrich_error(result)
+        enriched = self.compiler_manager.enrich_error(result)
+
+        # Show call trace if available
+        if enriched.txn:
+            # Unlikely scenario where a transaction is on the error even though a receipt exists.
+            if isinstance(enriched.txn, TransactionAPI) and enriched.txn.receipt:
+                enriched.txn.receipt.show_trace()
+            elif isinstance(enriched.txn, ReceiptAPI):
+                enriched.txn.show_trace()
+
+        return enriched
 
 
 class EthereumNodeProvider(Web3Provider, ABC):
     # optimal values for geth
     block_page_size: int = 5000
     concurrency: int = 16
 
-    name: str = "geth"
-
-    """Is ``None`` until known."""
-    can_use_parity_traces: Optional[bool] = None
+    name: str = "node"
 
     @property
     def uri(self) -> str:
         if "url" in self.provider_settings:
             raise ConfigError("Unknown provider setting 'url'. Did you mean 'uri'?")
 
         elif "uri" in self.provider_settings:
             # Use adhoc, scripted value
             return self.provider_settings["uri"]
 
-        config = self.config.model_dump(mode="json").get(self.network.ecosystem.name, None)
+        config = self.config.model_dump().get(self.network.ecosystem.name, None)
         if config is None:
             return DEFAULT_SETTINGS["uri"]
 
         # Use value from config file
         network_config = config.get(self.network.name) or DEFAULT_SETTINGS
 
         if "url" in network_config:
@@ -1178,15 +1197,15 @@
 
         return _get_default_data_dir()
 
     @cached_property
     def _ots_api_level(self) -> Optional[int]:
         # NOTE: Returns None when OTS namespace is not enabled.
         try:
-            result = self._make_request("ots_getApiLevel")
+            result = self.make_request("ots_getApiLevel")
         except (NotImplementedError, ApeException, ValueError):
             return None
 
         if isinstance(result, int):
             return result
 
         elif isinstance(result, str) and result.isnumeric():
@@ -1224,16 +1243,14 @@
         except ValueError as err:
             raise ProviderError(
                 err.args[0].get("message")
                 if all((hasattr(err, "args"), err.args, isinstance(err.args[0], dict)))
                 else "Error getting chain id."
             )
 
-        is_likely_poa = False
-
         # NOTE: We have to check both earliest and latest
         #   because if the chain was _ever_ PoA, we need
         #   this middleware.
         for option in ("earliest", "latest"):
             try:
                 block = self.web3.eth.get_block(option)  # type: ignore[arg-type]
             except ExtraDataLengthError:
@@ -1249,106 +1266,45 @@
 
         if is_likely_poa and geth_poa_middleware not in self.web3.middleware_onion:
             self.web3.middleware_onion.inject(geth_poa_middleware, layer=0)
 
         self.network.verify_chain_id(chain_id)
 
     def disconnect(self):
-        self.can_use_parity_traces = None
+        self._call_trace_approach = None
         self._web3 = None
         self._client_version = None
 
-    def get_transaction_trace(self, txn_hash: str) -> Iterator[TraceFrame]:
-        frames = self._stream_request(
-            "debug_traceTransaction", [txn_hash, {"enableMemory": True}], "result.structLogs.item"
-        )
-        for frame in create_trace_frames(frames):
-            yield self._create_trace_frame(frame)
-
-    def _get_transaction_trace_using_call_tracer(self, txn_hash: str) -> Dict:
-        return self._make_request(
-            "debug_traceTransaction", [txn_hash, {"enableMemory": True, "tracer": "callTracer"}]
-        )
-
-    def get_call_tree(self, txn_hash: str) -> CallTreeNode:
-        if self.can_use_parity_traces is True:
-            return self._get_parity_call_tree(txn_hash)
-
-        elif self.can_use_parity_traces is False:
-            return self._get_geth_call_tree(txn_hash)
-
-        elif "erigon" in self.client_version.lower():
-            tree = self._get_parity_call_tree(txn_hash)
-            self.can_use_parity_traces = True
-            return tree
-
-        try:
-            # Try the Parity traces first, in case node client supports it.
-            tree = self._get_parity_call_tree(txn_hash)
-        except (ValueError, APINotImplementedError, ProviderError):
-            self.can_use_parity_traces = False
-            return self._get_geth_call_tree(txn_hash)
-
-        # Parity style works.
-        self.can_use_parity_traces = True
-        return tree
-
-    def _get_parity_call_tree(self, txn_hash: str) -> CallTreeNode:
-        result = self._make_request("trace_transaction", [txn_hash])
-        if not result:
-            raise ProviderError(f"Failed to get trace for '{txn_hash}'.")
-
-        traces = ParityTraceList.model_validate(result)
-        evm_call = get_calltree_from_parity_trace(traces)
-        return self._create_call_tree_node(evm_call, txn_hash=txn_hash)
-
-    def _get_geth_call_tree(self, txn_hash: str) -> CallTreeNode:
-        calls = self._get_transaction_trace_using_call_tracer(txn_hash)
-        evm_call = get_calltree_from_geth_call_trace(calls)
-        return self._create_call_tree_node(evm_call, txn_hash=txn_hash)
-
     def _log_connection(self, client_name: str):
         msg = f"Connecting to existing {client_name.strip()} node at"
         suffix = (
             self.ipc_path.as_posix().replace(Path.home().as_posix(), "$HOME")
             if self.ipc_path.exists()
             else self._clean_uri
         )
         logger.info(f"{msg} {suffix}.")
 
-    def ots_get_contract_creator(self, address: AddressType) -> Optional[Dict]:
+    def ots_get_contract_creator(self, address: AddressType) -> Optional[dict]:
         if self._ots_api_level is None:
             return None
 
-        result = self._make_request("ots_getContractCreator", [address])
+        result = self.make_request("ots_getContractCreator", [address])
         if result is None:
             # NOTE: Skip the explorer part of the error message via `has_explorer=True`.
             raise ContractNotFoundError(address, has_explorer=True, provider_name=self.name)
 
         return result
 
     def _get_contract_creation_receipt(self, address: AddressType) -> Optional[ReceiptAPI]:
         if result := self.ots_get_contract_creator(address):
             tx_hash = result["hash"]
             return self.get_receipt(tx_hash)
 
         return None
 
-    def _stream_request(self, method: str, params: List, iter_path="result.item"):
-        payload = {"jsonrpc": "2.0", "id": 1, "method": method, "params": params}
-        results = ijson.sendable_list()
-        coroutine = ijson.items_coro(results, iter_path)
-        resp = requests.post(self.uri, json=payload, stream=True)
-        resp.raise_for_status()
-
-        for chunk in resp.iter_content(chunk_size=2**17):
-            coroutine.send(chunk)
-            yield from results
-            del results[:]
-
     def connect(self):
         self._set_web3()
         if not self.is_connected:
             uri = self._clean_uri
             message = f"No (supported) node found on '{uri}'."
             raise ProviderError(message)
```

### Comparing `eth-ape-0.7.9/src/ape_ethereum/proxies.py` & `eth-ape-0.8.0/src/ape_ethereum/proxies.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/src/ape_ethereum/transactions.py` & `eth-ape-0.8.0/src/ape_ethereum/transactions.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,30 +1,31 @@
 import sys
 from enum import Enum, IntEnum
 from functools import cached_property
-from typing import IO, Dict, List, Optional, Union
+from typing import IO, Any, Optional, Union
 
 from eth_abi import decode
 from eth_account import Account as EthAccount
 from eth_account._utils.legacy_transactions import (
     encode_transaction,
     serializable_unsigned_transaction_from_dict,
 )
 from eth_pydantic_types import HexBytes
-from eth_utils import decode_hex, encode_hex, keccak, to_hex, to_int
+from eth_utils import decode_hex, encode_hex, keccak, to_int
 from ethpm_types import ContractType
 from ethpm_types.abi import EventABI, MethodABI
 from pydantic import BaseModel, Field, field_validator, model_validator
 
 from ape.api import ReceiptAPI, TransactionAPI
 from ape.contracts import ContractEvent
 from ape.exceptions import OutOfGasError, SignatureError, TransactionError
 from ape.logging import logger
-from ape.types import AddressType, CallTreeNode, ContractLog, ContractLogContainer, SourceTraceback
+from ape.types import AddressType, ContractLog, ContractLogContainer, SourceTraceback
 from ape.utils import ZERO_ADDRESS
+from ape_ethereum.trace import Trace
 
 
 class TransactionStatusEnum(IntEnum):
     """
     An ``Enum`` class representing the status of a transaction.
     """
 
@@ -48,15 +49,15 @@
     ACCESS_LIST = 1  # EIP-2930
     DYNAMIC = 2  # EIP-1559
     SHARED_BLOB = 3  # EIP-4844
 
 
 class AccessList(BaseModel):
     address: AddressType
-    storage_keys: List[HexBytes] = Field(default_factory=list, alias="storageKeys")
+    storage_keys: list[HexBytes] = Field(default_factory=list, alias="storageKeys")
 
 
 class BaseTransaction(TransactionAPI):
     def serialize_transaction(self) -> bytes:
         if not self.signature:
             message = "The transaction is not signed."
             if not self.sender:
@@ -117,15 +118,15 @@
     gas_price: Optional[int] = Field(None, alias="gasPrice")
     max_priority_fee: Optional[int] = Field(None, exclude=True)  # type: ignore
     type: int = Field(TransactionType.STATIC.value, exclude=True)
     max_fee: Optional[int] = Field(None, exclude=True)  # type: ignore
 
     @model_validator(mode="before")
     @classmethod
-    def calculate_read_only_max_fee(cls, values) -> Dict:
+    def calculate_read_only_max_fee(cls, values) -> dict:
         # NOTE: Work-around, Pydantic doesn't handle calculated fields well.
         values["max_fee"] = cls.conversion_manager.convert(
             values.get("gas_limit", 0), int
         ) * cls.conversion_manager.convert(values.get("gas_price", 0), int)
         return values
 
 
@@ -133,15 +134,15 @@
     """
     `EIP-2930 <https://eips.ethereum.org/EIPS/eip-2930>`__
     transactions are similar to legacy transaction with an added access list functionality.
     """
 
     gas_price: Optional[int] = Field(None, alias="gasPrice")
     type: int = Field(TransactionType.ACCESS_LIST.value)
-    access_list: List[AccessList] = Field(default_factory=list, alias="accessList")
+    access_list: list[AccessList] = Field(default_factory=list, alias="accessList")
 
     @field_validator("type")
     @classmethod
     def check_type(cls, value):
         return value.value if isinstance(value, TransactionType) else value
 
 
@@ -150,29 +151,29 @@
     Transactions that are post-EIP-1559 and use the ``maxFeePerGas``
     and ``maxPriorityFeePerGas`` fields.
     """
 
     max_priority_fee: Optional[int] = Field(None, alias="maxPriorityFeePerGas")  # type: ignore
     max_fee: Optional[int] = Field(None, alias="maxFeePerGas")  # type: ignore
     type: int = Field(TransactionType.DYNAMIC.value)
-    access_list: List[AccessList] = Field(default_factory=list, alias="accessList")
+    access_list: list[AccessList] = Field(default_factory=list, alias="accessList")
 
     @field_validator("type")
     @classmethod
     def check_type(cls, value):
         return value.value if isinstance(value, TransactionType) else value
 
 
 class SharedBlobTransaction(DynamicFeeTransaction):
     """
     `EIP-4844 <https://eips.ethereum.org/EIPS/eip-4844>`__ transactions.
     """
 
     max_fee_per_blob_gas: int = Field(0, alias="maxFeePerBlobGas")
-    blob_versioned_hashes: List[HexBytes] = Field([], alias="blobVersionedHashes")
+    blob_versioned_hashes: list[HexBytes] = Field([], alias="blobVersionedHashes")
 
     """
     Overridden because EIP-4844 states it cannot be nil.
     """
     receiver: AddressType = Field(ZERO_ADDRESS, alias="to")
 
     @field_validator("max_fee_per_blob_gas", mode="before")
@@ -200,16 +201,30 @@
         return self.gas_used * self.gas_price
 
     @property
     def failed(self) -> bool:
         return self.status != TransactionStatusEnum.NO_ERROR
 
     @cached_property
-    def call_tree(self) -> Optional[CallTreeNode]:
-        return self.provider.get_call_tree(self.txn_hash)
+    def debug_logs_typed(self) -> list[tuple[Any]]:
+        """
+        Extract messages to console outputted by contracts via print() or console.log() statements
+        """
+        try:
+            trace = self.trace
+        # Some providers do not implement this, so skip.
+        except NotImplementedError:
+            logger.debug("Call tree not available, skipping debug log extraction")
+            return []
+
+        # If the trace is not available, no logs are available.
+        if trace is None or not isinstance(trace, Trace):
+            return []
+
+        return list(trace.debug_logs)
 
     @cached_property
     def contract_type(self) -> Optional[ContractType]:
         if address := (self.receiver or self.contract_address):
             return self.chain_manager.contracts.get(address)
 
         return None
@@ -224,102 +239,59 @@
             return None
 
         return self.contract_type.methods[method_id]
 
     @cached_property
     def source_traceback(self) -> SourceTraceback:
         if contract_type := self.contract_type:
-            try:
-                return SourceTraceback.create(contract_type, self.trace, HexBytes(self.data))
-            except Exception as err:
-                # Failing to get a traceback should not halt an Ape application.
-                # Sometimes, a node crashes and we are left with nothing.
-                logger.error(f"Problem retrieving traceback: {err}")
-                pass
+            if contract_src := self.local_project._create_contract_source(contract_type):
+                try:
+                    return SourceTraceback.create(contract_src, self.trace, HexBytes(self.data))
+                except Exception as err:
+                    # Failing to get a traceback should not halt an Ape application.
+                    # Sometimes, a node crashes and we are left with nothing.
+                    logger.error(f"Problem retrieving traceback: {err}")
+                    pass
 
         return SourceTraceback.model_validate([])
 
     def raise_for_status(self):
         if self.gas_limit is not None and self.ran_out_of_gas:
             raise OutOfGasError(txn=self)
 
         elif self.status != TransactionStatusEnum.NO_ERROR:
             txn_hash = HexBytes(self.txn_hash).hex()
             raise TransactionError(f"Transaction '{txn_hash}' failed.", txn=self)
 
     def show_trace(self, verbose: bool = False, file: IO[str] = sys.stdout):
-        if not (call_tree := self.call_tree):
-            return
-
-        call_tree.enrich(use_symbol_for_tokens=True)
-        revert_message = None
-
-        if call_tree.failed:
-            default_message = "reverted without message"
-            returndata = HexBytes(call_tree.raw["returndata"])
-            if not to_hex(returndata).startswith(
-                "0x08c379a00000000000000000000000000000000000000000000000000000000000000020"
-            ):
-                revert_message = default_message
-            else:
-                decoded_result = decode(("string",), returndata[4:])
-                if len(decoded_result) == 1:
-                    revert_message = f'reverted with message: "{decoded_result[0]}"'
-                else:
-                    revert_message = default_message
-
-        self.chain_manager._reports.show_trace(
-            call_tree,
-            sender=self.sender,
-            transaction_hash=self.txn_hash,
-            revert_message=revert_message,
-            verbose=verbose,
-            file=file,
-        )
+        self.trace.show(verbose=verbose, file=file)
 
     def show_gas_report(self, file: IO[str] = sys.stdout):
-        if not (call_tree := self.call_tree):
-            return
-
-        call_tree.enrich()
-
-        # Enrich transfers.
-        if (
-            call_tree.contract_id.startswith("Transferring ")
-            and self.receiver is not None
-            and self.receiver in self.account_manager
-        ):
-            receiver_id = self.account_manager[self.receiver].alias or self.receiver
-            call_tree.method_id = f"to:{receiver_id}"
-
-        elif call_tree.contract_id.startswith("Transferring "):
-            call_tree.method_id = f"to:{self.receiver}"
-
-        self.chain_manager._reports.show_gas(call_tree, file=file)
+        self.trace.show_gas_report(file=file)
 
     def show_source_traceback(self, file: IO[str] = sys.stdout):
         self.chain_manager._reports.show_source_traceback(
             self.source_traceback, file=file, failing=self.failed
         )
 
     def decode_logs(
         self,
         abi: Optional[
-            Union[List[Union[EventABI, "ContractEvent"]], Union[EventABI, "ContractEvent"]]
+            Union[list[Union[EventABI, "ContractEvent"]], Union[EventABI, "ContractEvent"]]
         ] = None,
     ) -> ContractLogContainer:
         if not self.logs:
             # Short circuit.
             return ContractLogContainer([])
 
         elif abi is not None:
             if not isinstance(abi, (list, tuple)):
                 abi = [abi]
 
-            event_abis: List[EventABI] = [a.abi if not isinstance(a, EventABI) else a for a in abi]
+            event_abis: list[EventABI] = [a.abi if not isinstance(a, EventABI) else a for a in abi]
             return ContractLogContainer(
                 self.provider.network.ecosystem.decode_logs(self.logs, *event_abis)
             )
 
         else:
             # If ABI is not provided, decode all events
             addresses = {x["address"] for x in self.logs}
@@ -327,15 +299,15 @@
             # address  selector  abi
             selectors = {
                 address: {encode_hex(keccak(text=abi.selector)): abi for abi in contract.events}
                 for address, contract in contract_types.items()
             }
 
             def get_default_log(
-                _log: Dict, logs: ContractLogContainer, evt_name: Optional[str] = None
+                _log: dict, logs: ContractLogContainer, evt_name: Optional[str] = None
             ) -> ContractLog:
                 log_index = _log.get("logIndex", logs[-1].log_index + 1 if logs else 0)
 
                 # NOTE: Happens when decoding fails.
                 evt_name = evt_name or f"UnknownLog_WithIndex_{log_index}"
 
                 return ContractLog(
@@ -385,15 +357,15 @@
 
                 else:
                     obj = get_default_log(log, decoded_logs)
                     decoded_logs.append(obj)
 
             return decoded_logs
 
-    def _decode_ds_note(self, log: Dict) -> Optional[ContractLog]:
+    def _decode_ds_note(self, log: dict) -> Optional[ContractLog]:
         # The first topic encodes the function selector
         selector, tail = log["topics"][0][:4], log["topics"][0][4:]
         if sum(tail):
             # non-zero bytes found after selector
             return None
 
         if not (contract_type := self.chain_manager.contracts.get(log["address"])):
@@ -423,14 +395,30 @@
             log_index=log["logIndex"],
             transaction_hash=log["transactionHash"],
             transaction_index=log["transactionIndex"],
         )
 
 
 class SharedBlobReceipt(Receipt):
+    """
+    An `EIP-4844 <https://eips.ethereum.org/EIPS/eip-4844#blob-transaction>`__"
+    blob transaction.
+    """
+
     blob_gas_used: int
+    """
+    The total amount of blob gas consumed by the transactions within the block.
+    """
+
     blob_gas_price: int
+    """
+    The blob-gas price, independent from regular gas price.
+    """
 
     @field_validator("blob_gas_used", "blob_gas_price", mode="before")
     @classmethod
-    def hex_to_int(cls, value):
+    def validate_hex(cls, value):
+        return cls._hex_to_int(value or 0)
+
+    @classmethod
+    def _hex_to_int(cls, value) -> int:
         return value if isinstance(value, int) else int(HexBytes(value).hex(), 16)
```

### Comparing `eth-ape-0.7.9/src/ape_geth/__init__.py` & `eth-ape-0.8.0/src/ape_node/__init__.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,26 +1,25 @@
 from ape import plugins
 from ape.api.networks import LOCAL_NETWORK_NAME
 
-from .provider import Geth as GethProvider
-from .provider import GethConfig, GethDev, GethNetworkConfig
-from .query import OTSQueryEngine
+from .provider import EthereumNetworkConfig, EthereumNodeConfig, GethDev, Node
+from .query import OtterscanQueryEngine
 
 
 @plugins.register(plugins.Config)
 def config_class():
-    return GethConfig
+    return EthereumNodeConfig
 
 
 @plugins.register(plugins.ProviderPlugin)
 def providers():
-    networks_dict = GethNetworkConfig().model_dump(mode="json")
+    networks_dict = EthereumNetworkConfig().model_dump()
     networks_dict.pop(LOCAL_NETWORK_NAME)
     for network_name in networks_dict:
-        yield "ethereum", network_name, GethProvider
+        yield "ethereum", network_name, Node
 
     yield "ethereum", LOCAL_NETWORK_NAME, GethDev
 
 
 @plugins.register(plugins.QueryPlugin)
 def query_engines():
-    yield OTSQueryEngine
+    yield OtterscanQueryEngine
```

### Comparing `eth-ape-0.7.9/src/ape_geth/provider.py` & `eth-ape-0.8.0/src/ape_node/provider.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,41 +1,37 @@
 import atexit
 import shutil
-from itertools import tee
 from pathlib import Path
 from subprocess import DEVNULL, PIPE, Popen
-from typing import Any, Dict, Iterator, List, Optional, Tuple, Union
+from typing import Optional, Union
 
 from eth_pydantic_types import HexBytes
 from eth_typing import HexStr
 from eth_utils import add_0x_prefix, to_hex, to_wei
-from evm_trace import CallType
-from evm_trace import TraceFrame as EvmTraceFrame
-from evm_trace import create_trace_frames, get_calltree_from_geth_trace
 from evmchains import get_random_rpc
 from geth.accounts import ensure_account_exists  # type: ignore
 from geth.chain import initialize_chain  # type: ignore
 from geth.process import BaseGethProcess  # type: ignore
 from geth.wrapper import construct_test_chain_kwargs  # type: ignore
 from pydantic_settings import SettingsConfigDict
 from requests.exceptions import ConnectionError
 from web3.middleware import geth_poa_middleware
 from yarl import URL
 
-from ape.api import PluginConfig, SubprocessProvider, TestProviderAPI, TransactionAPI
-from ape.exceptions import ProviderError
+from ape.api import PluginConfig, SubprocessProvider, TestProviderAPI
 from ape.logging import LogLevel, logger
-from ape.types import BlockID, CallTreeNode, SnapshotID, SourceTraceback
+from ape.types import SnapshotID
 from ape.utils import (
     DEFAULT_NUMBER_OF_TEST_ACCOUNTS,
     DEFAULT_TEST_CHAIN_ID,
     DEFAULT_TEST_HD_PATH,
     DEFAULT_TEST_MNEMONIC,
     JoinableQueue,
     generate_dev_accounts,
+    log_instead_of_fail,
     raises_not_implemented,
     spawn,
 )
 from ape_ethereum.provider import (
     DEFAULT_HOSTNAME,
     DEFAULT_PORT,
     DEFAULT_SETTINGS,
@@ -55,20 +51,20 @@
         port: int = DEFAULT_PORT,
         mnemonic: str = DEFAULT_TEST_MNEMONIC,
         number_of_accounts: int = DEFAULT_NUMBER_OF_TEST_ACCOUNTS,
         chain_id: int = DEFAULT_TEST_CHAIN_ID,
         initial_balance: Union[str, int] = to_wei(10000, "ether"),
         executable: Optional[str] = None,
         auto_disconnect: bool = True,
-        extra_funded_accounts: Optional[List[str]] = None,
+        extra_funded_accounts: Optional[list[str]] = None,
         hd_path: Optional[str] = DEFAULT_TEST_HD_PATH,
     ):
         executable = executable or "geth"
         if not shutil.which(executable):
-            raise GethNotInstalledError()
+            raise NodeSoftwareNotInstalledError()
 
         self.data_dir = data_dir
         self._hostname = hostname
         self._port = port
         self.data_dir.mkdir(exist_ok=True, parents=True)
         self.is_running = False
         self._auto_disconnect = auto_disconnect
@@ -94,15 +90,15 @@
         accounts = generate_dev_accounts(
             mnemonic, number_of_accounts=number_of_accounts, hd_path=hd_path or DEFAULT_TEST_HD_PATH
         )
         addresses = [a.address for a in accounts]
         addresses.extend(extra_funded_accounts or [])
         bal_dict = {"balance": str(initial_balance)}
         alloc = {a: bal_dict for a in addresses}
-        genesis_data: Dict = {
+        genesis_data: dict = {
             "overwrite": True,
             "coinbase": "0x0000000000000000000000000000000000000000",
             "difficulty": "0x0",
             "extraData": f"0x{'0' * 64}{sealer}{'0' * 130}",
             "config": {
                 "chainId": chain_id,
                 "gasLimit": 0,
@@ -192,94 +188,100 @@
     def wait(self, *args, **kwargs):
         if self.proc is None:
             return
 
         self.proc.wait(*args, **kwargs)
 
 
-class GethNetworkConfig(PluginConfig):
+class EthereumNetworkConfig(PluginConfig):
     # Make sure you are running the right networks when you try for these
-    mainnet: Dict = {"uri": get_random_rpc("ethereum", "mainnet")}
-    goerli: Dict = {"uri": get_random_rpc("ethereum", "goerli")}
-    sepolia: Dict = {"uri": get_random_rpc("ethereum", "sepolia")}
+    mainnet: dict = {"uri": get_random_rpc("ethereum", "mainnet")}
+    sepolia: dict = {"uri": get_random_rpc("ethereum", "sepolia")}
     # Make sure to run via `geth --dev` (or similar)
-    local: Dict = {**DEFAULT_SETTINGS.copy(), "chain_id": DEFAULT_TEST_CHAIN_ID}
+    local: dict = {**DEFAULT_SETTINGS.copy(), "chain_id": DEFAULT_TEST_CHAIN_ID}
 
     model_config = SettingsConfigDict(extra="allow")
 
 
-class GethConfig(PluginConfig):
-    ethereum: GethNetworkConfig = GethNetworkConfig()
+class EthereumNodeConfig(PluginConfig):
+    ethereum: EthereumNetworkConfig = EthereumNetworkConfig()
     executable: Optional[str] = None
     ipc_path: Optional[Path] = None
     data_dir: Optional[Path] = None
 
     model_config = SettingsConfigDict(extra="allow")
 
 
-# TODO: 0.8 rename exception.
-class GethNotInstalledError(ConnectionError):
+class NodeSoftwareNotInstalledError(ConnectionError):
     def __init__(self):
         super().__init__(
-            "No node found and 'ape-geth' is unable to start one.\n"
+            "No node found and 'ape-node' is unable to start one.\n"
             "Things you can do:\n"
             "\t1. Check your connection URL, if trying to connect remotely.\n"
             "\t2. Install node software (geth), if trying to run a local node.\n"
             "\t3. Use and configure a different provider plugin, such as 'ape-foundry'."
         )
 
 
 # NOTE: Using EthereumNodeProvider because of it's geth-derived default behavior.
 class GethDev(EthereumNodeProvider, TestProviderAPI, SubprocessProvider):
     _process: Optional[GethDevProcess] = None
-    name: str = "geth"
-    can_use_parity_traces: Optional[bool] = False
+    name: str = "node"
 
     @property
     def process_name(self) -> str:
         return self.name
 
     @property
     def chain_id(self) -> int:
         return self.settings.ethereum.local.get("chain_id", DEFAULT_TEST_CHAIN_ID)
 
     @property
     def data_dir(self) -> Path:
-        # Overridden from BaseGeth class for placing debug logs in ape data folder.
-        return self.settings.data_dir or self.data_folder / self.name
+        # Overridden from base class for placing debug logs in ape data folder.
+        return self.settings.data_dir or self.config_manager.DATA_FOLDER / self.name
 
-    def __repr__(self):
-        try:
-            return f"<geth chain_id={self.chain_id}>"
-        except Exception:
-            return "<geth>"
+    @log_instead_of_fail(default="<node>")
+    def __repr__(self) -> str:
+        client_version = self.client_version
+        client_version_str = f" ({client_version}) " if client_version else " "
+        return f"<Node{client_version_str}chain_id={self.chain_id}>"
+
+    @property
+    def auto_mine(self) -> bool:
+        return self.make_request("eth_mining", [])
+
+    @auto_mine.setter
+    def auto_mine(self, value):
+        raise NotImplementedError("'auto_mine' setter not implemented.")
 
     def connect(self):
         self._set_web3()
         if self.is_connected:
             self._complete_connect()
         else:
             self.start()
 
     def start(self, timeout: int = 20):
+        # NOTE: Using JSON mode to ensure types can be passed as CLI args.
         test_config = self.config_manager.get_config("test").model_dump(mode="json")
 
         # Allow configuring a custom executable besides your $PATH geth.
         if self.settings.executable is not None:
             test_config["executable"] = self.settings.executable
 
         test_config["ipc_path"] = self.ipc_path
         test_config["auto_disconnect"] = self._test_runner is None or test_config.get(
             "disconnect_providers_after", True
         )
 
         # Include extra accounts to allocated funds to at genesis.
         extra_accounts = self.settings.ethereum.local.get("extra_funded_accounts", [])
         extra_accounts.extend(self.provider_settings.get("extra_funded_accounts", []))
-        extra_accounts = list(set([HexBytes(a).hex().lower() for a in extra_accounts]))
+        extra_accounts = list({HexBytes(a).hex().lower() for a in extra_accounts})
         test_config["extra_funded_accounts"] = extra_accounts
 
         process = GethDevProcess.from_uri(self.uri, self.data_dir, **test_config)
         process.connect(timeout=timeout)
         if not self.web3.is_connected():
             process.disconnect()
             raise ConnectionError("Unable to connect to locally running geth.")
@@ -312,15 +314,15 @@
         self.process = None  # type: ignore[assignment]
 
         super().disconnect()
 
     def snapshot(self) -> SnapshotID:
         return self.get_block("latest").number or 0
 
-    def revert(self, snapshot_id: SnapshotID):
+    def restore(self, snapshot_id: SnapshotID):
         if isinstance(snapshot_id, int):
             block_number_int = snapshot_id
             block_number_hex_str = str(to_hex(snapshot_id))
         elif isinstance(snapshot_id, bytes):
             block_number_hex_str = add_0x_prefix(HexStr(snapshot_id.hex()))
             block_number_int = int(block_number_hex_str, 16)
         else:
@@ -331,149 +333,30 @@
         if block_number_int == current_block:
             # Head is already at this block.
             return
         elif block_number_int > block_number_int:
             logger.error("Unable to set head to future block.")
             return
 
-        self._make_request("debug_setHead", [block_number_hex_str])
+        self.make_request("debug_setHead", [block_number_hex_str])
 
     @raises_not_implemented
     def set_timestamp(self, new_timestamp: int):
         pass
 
     @raises_not_implemented
     def mine(self, num_blocks: int = 1):
         pass
 
-    def send_call(
-        self,
-        txn: TransactionAPI,
-        block_id: Optional[BlockID] = None,
-        state: Optional[Dict] = None,
-        **kwargs: Any,
-    ) -> HexBytes:
-        if block_id is not None:
-            kwargs["block_identifier"] = block_id
-
-        if state is not None:
-            kwargs["state_override"] = state
-
-        skip_trace = kwargs.pop("skip_trace", False)
-        arguments = self._prepare_call(txn, **kwargs)
-        if skip_trace:
-            return self._eth_call(arguments)
-
-        show_gas = kwargs.pop("show_gas_report", False)
-        show_trace = kwargs.pop("show_trace", False)
-
-        if self._test_runner is not None:
-            track_gas = self._test_runner.gas_tracker.enabled
-            track_coverage = self._test_runner.coverage_tracker.enabled
-        else:
-            track_gas = False
-            track_coverage = False
-
-        needs_trace = track_gas or track_coverage or show_gas or show_trace
-        if not needs_trace:
-            return self._eth_call(arguments)
-
-        # The user is requesting information related to a call's trace,
-        # such as gas usage data.
-
-        result, trace_frames = self._trace_call(arguments)
-        trace_frames, frames_copy = tee(trace_frames)
-        return_value = HexBytes(result["returnValue"])
-        root_node_kwargs = {
-            "gas_cost": result.get("gas", 0),
-            "address": txn.receiver,
-            "calldata": txn.data,
-            "value": txn.value,
-            "call_type": CallType.CALL,
-            "failed": False,
-            "returndata": return_value,
-        }
-
-        evm_call_tree = get_calltree_from_geth_trace(trace_frames, **root_node_kwargs)
-
-        # NOTE: Don't pass txn_hash here, as it will fail (this is not a real txn).
-        call_tree = self._create_call_tree_node(evm_call_tree)
-
-        if track_gas and show_gas and not show_trace and call_tree:
-            # Optimization to enrich early and in_place=True.
-            call_tree.enrich()
-
-        if track_gas and call_tree and self._test_runner is not None and txn.receiver:
-            # Gas report being collected, likely for showing a report
-            # at the end of a test run.
-            # Use `in_place=False` in case also `show_trace=True`
-            enriched_call_tree = call_tree.enrich(in_place=False)
-            self._test_runner.gas_tracker.append_gas(enriched_call_tree, txn.receiver)
-
-        if track_coverage and self._test_runner is not None and txn.receiver:
-            contract_type = self.chain_manager.contracts.get(txn.receiver)
-            if contract_type:
-                traceframes = (self._create_trace_frame(x) for x in frames_copy)
-                method_id = HexBytes(txn.data)
-                selector = (
-                    contract_type.methods[method_id].selector
-                    if method_id in contract_type.methods
-                    else None
-                )
-                source_traceback = SourceTraceback.create(contract_type, traceframes, method_id)
-                self._test_runner.coverage_tracker.cover(
-                    source_traceback, function=selector, contract=contract_type.name
-                )
-
-        if show_gas:
-            enriched_call_tree = call_tree.enrich(in_place=False)
-            self.chain_manager._reports.show_gas(enriched_call_tree)
-
-        if show_trace:
-            call_tree = call_tree.enrich(use_symbol_for_tokens=True)
-            self.chain_manager._reports.show_trace(call_tree)
-
-        return return_value
-
-    def _trace_call(self, arguments: List[Any]) -> Tuple[Dict, Iterator[EvmTraceFrame]]:
-        result = self._make_request("debug_traceCall", arguments)
-        trace_data = result.get("structLogs", [])
-        return result, create_trace_frames(trace_data)
-
-    def _eth_call(self, arguments: List) -> HexBytes:
-        try:
-            result = self._make_request("eth_call", arguments)
-        except Exception as err:
-            trace, trace2 = tee(self._create_trace_frame(x) for x in self._trace_call(arguments)[1])
-            contract_address = arguments[0]["to"]
-            contract_type = self.chain_manager.contracts.get(contract_address)
-            method_id = arguments[0].get("data", "")[:10] or None
-            tb = (
-                SourceTraceback.create(contract_type, trace, method_id)
-                if method_id and contract_type
-                else None
-            )
-            raise self.get_virtual_machine_error(
-                err, trace=trace2, contract_address=contract_address, source_traceback=tb
-            ) from err
-
-        if "error" in result:
-            raise ProviderError(result["error"]["message"])
-
-        return HexBytes(result)
-
-    def get_call_tree(self, txn_hash: str, **root_node_kwargs) -> CallTreeNode:
-        return self._get_geth_call_tree(txn_hash, **root_node_kwargs)
-
-    def build_command(self) -> List[str]:
+    def build_command(self) -> list[str]:
         return self._process.command if self._process else []
 
 
 # NOTE: The default behavior of EthereumNodeBehavior assumes geth.
-class Geth(EthereumNodeProvider):
+class Node(EthereumNodeProvider):
     @property
     def uri(self) -> str:
         if "uri" in self.provider_settings:
             # If specifying in Python, use no matter what.
             return self.provider_settings["uri"]
 
         uri = super().uri
```

### Comparing `eth-ape-0.7.9/src/ape_geth/query.py` & `eth-ape-0.8.0/src/ape_node/query.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,35 +1,43 @@
+from collections.abc import Iterator
 from functools import singledispatchmethod
-from typing import Iterator, Optional
+from typing import Optional
 
-from ape.api import ReceiptAPI
-from ape.api.query import ContractCreationQuery, QueryAPI, QueryType
+from ape.api.query import ContractCreation, ContractCreationQuery, QueryAPI, QueryType
 from ape.exceptions import QueryEngineError
+from ape.types.address import AddressType
 from ape_ethereum.provider import EthereumNodeProvider
 
 
-class OTSQueryEngine(QueryAPI):
+class OtterscanQueryEngine(QueryAPI):
     @singledispatchmethod
     def estimate_query(self, query: QueryType) -> Optional[int]:  # type: ignore[override]
         return None
 
     @singledispatchmethod
     def perform_query(self, query: QueryType) -> Iterator:  # type: ignore[override]
         raise QueryEngineError(
             f"{self.__class__.__name__} cannot handle {query.__class__.__name__} queries."
         )
 
     @estimate_query.register
     def estimate_contract_creation_query(self, query: ContractCreationQuery) -> Optional[int]:
-        if provider := self.network_manager.active_provider:
-            if not isinstance(provider, EthereumNodeProvider):
-                return None
-            elif uri := provider.http_uri:
-                return 225 if uri.startswith("http://") else 600
-
+        if getattr(self.provider, "_ots_api_level", None) is not None:
+            return 250
         return None
 
     @perform_query.register
-    def get_contract_creation_receipt(self, query: ContractCreationQuery) -> Iterator[ReceiptAPI]:
+    def get_contract_creation_receipt(
+        self, query: ContractCreationQuery
+    ) -> Iterator[ContractCreation]:
         if self.network_manager.active_provider and isinstance(self.provider, EthereumNodeProvider):
-            if receipt := self.provider._get_contract_creation_receipt(query.contract):
-                yield receipt
+            ots = self.provider.make_request("ots_getContractCreator", [query.contract])
+            if ots is None:
+                return None
+            creator = self.conversion_manager.convert(ots["creator"], AddressType)
+            receipt = self.provider.get_receipt(ots["hash"])
+            yield ContractCreation(
+                txn_hash=ots["hash"],
+                block=receipt.block_number,
+                deployer=receipt.sender,
+                factory=creator if creator != receipt.sender else None,
+            )
```

### Comparing `eth-ape-0.7.9/src/ape_networks/__init__.py` & `eth-ape-0.8.0/src/ape_networks/__init__.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,37 +1,37 @@
-from typing import Dict, List, Optional
+from typing import Optional
 
 from ape import plugins
 from ape.api import PluginConfig
 
 
 class CustomNetwork(PluginConfig):
     """
     A custom network config.
     """
 
-    """Name of the network e.g. mainnet."""
     name: str
+    """Name of the network e.g. mainnet."""
 
-    """Chain ID (required)."""
     chain_id: int
+    """Chain ID (required)."""
 
-    """The name of the ecosystem."""
     ecosystem: str
+    """The name of the ecosystem."""
 
-    """The base ecosystem plugin to use, when applicable. Defaults to the default ecosystem."""
     base_ecosystem_plugin: Optional[str] = None
+    """The base ecosystem plugin to use, when applicable. Defaults to the default ecosystem."""
 
+    default_provider: str = "node"
     """The default provider plugin to use. Default is the default node provider."""
-    default_provider: str = "geth"
 
+    request_header: dict = {}
     """The HTTP request header."""
-    request_header: Dict = {}
 
 
 class NetworksConfig(PluginConfig):
-    custom: List[CustomNetwork] = []
+    custom: list[CustomNetwork] = []
 
 
 @plugins.register(plugins.Config)
 def config_class():
     return NetworksConfig
```

### Comparing `eth-ape-0.7.9/src/ape_networks/_cli.py` & `eth-ape-0.8.0/src/ape_networks/_cli.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 import json
-from typing import Callable, Dict
+from collections.abc import Callable
 
 import click
 import yaml
 from rich import print as echo_rich_text
 from rich.tree import Tree
 
 from ape.api import SubprocessProvider
@@ -58,15 +58,15 @@
     )
 
     if output_format == OutputFormat.TREE:
         default_suffix = "[dim default]  (default)"
         ecosystems = network_data["ecosystems"]
         ecosystems = sorted(ecosystems, key=lambda e: e["name"])
 
-        def make_sub_tree(data: Dict, create_tree: Callable) -> Tree:
+        def make_sub_tree(data: dict, create_tree: Callable) -> Tree:
             name = f"[bold green]{data['name']}"
             if "isDefault" in data and data["isDefault"]:
                 name += default_suffix
 
             sub_tree = create_tree(name)
             return sub_tree
 
@@ -103,15 +103,15 @@
             raise NetworkError(
                 f"Network data did not dump to YAML: {data_str}\nActual err: {err}"
             ) from err
 
 
 @cli.command(short_help="Start a node process")
 @ape_cli_context()
-@network_option(default="ethereum:local:geth")
+@network_option(default="ethereum:local:node")
 def run(cli_ctx, provider):
     """
     Start a subprocess node as if running independently
     and stream stdout and stderr.
     """
     # Ignore extra loggers, such as web3 loggers.
     cli_ctx.logger._extra_loggers = {}
```

### Comparing `eth-ape-0.7.9/src/ape_plugins/_cli.py` & `eth-ape-0.8.0/src/ape_plugins/_cli.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,27 +1,28 @@
 import subprocess
 import sys
 from pathlib import Path
-from typing import Any, Dict, List, Tuple
+from typing import Any
 
 import click
 from packaging.version import Version
 
 from ape.cli import ape_cli_context, skip_confirmation_option
 from ape.logging import logger
 from ape.managers.config import CONFIG_FILE_NAME
 from ape.plugins._utils import (
+    PIP_COMMAND,
     ModifyPluginResultHandler,
     PluginMetadata,
     PluginMetadataList,
     PluginType,
-    _pip_freeze,
+    _filter_plugins_from_dists,
     ape_version,
 )
-from ape.utils import load_config
+from ape.utils.misc import _get_distributions, load_config
 
 
 @click.group(short_help="Manage ape plugins")
 def cli():
     """
     Command-line helper for managing plugins.
     """
@@ -29,52 +30,42 @@
 
 def plugins_argument():
     """
     An argument that is either the given list of plugins
     or plugins loaded from the local config file.
     """
 
-    def load_from_file(ctx, file_path: Path) -> List[PluginMetadata]:
+    def load_from_file(ctx, file_path: Path) -> list[PluginMetadata]:
         if file_path.is_dir() and (file_path / CONFIG_FILE_NAME).is_file():
             file_path = file_path / CONFIG_FILE_NAME
 
         if file_path.is_file():
             config = load_config(file_path)
             if plugins := config.get("plugins"):
-                res = [PluginMetadata.model_validate(d) for d in plugins]
-                for itm in res:
-                    itm._use_subprocess_pip_freeze = True
-
-                return res
+                return [PluginMetadata.model_validate(d) for d in plugins]
 
         ctx.obj.logger.warning(f"No plugins found at '{file_path}'.")
         return []
 
-    def callback(ctx, param, value: Tuple[str]):
+    def callback(ctx, param, value: tuple[str]):
         res = []
         if not value:
             ctx.obj.abort("You must give at least one requirement to install.")
 
         elif len(value) == 1:
             # User passed in a path to a file.
             file_path = Path(value[0]).expanduser().resolve()
             res = (
                 load_from_file(ctx, file_path)
                 if file_path.exists()
-                else [
-                    PluginMetadata(name=v, _use_subprocess_pip_freeze=True)
-                    for v in value[0].split(" ")
-                ]
+                else [PluginMetadata(name=v) for v in value[0].split(" ")]
             )
 
         else:
-            res = [PluginMetadata(name=v, _use_subprocess_pip_freeze=True) for v in value]
-
-        for itm in res:
-            itm._use_subprocess_pip_freeze = True
+            res = [PluginMetadata(name=v) for v in value]
 
         return res
 
     return click.argument(
         "plugins",
         callback=callback,
         nargs=-1,
@@ -98,24 +89,24 @@
         (PluginType.CORE, PluginType.INSTALLED, PluginType.THIRD_PARTY, PluginType.AVAILABLE)
         if value
         else (PluginType.INSTALLED, PluginType.THIRD_PARTY)
     )
 
 
 @cli.command(name="list", short_help="Display plugins")
+@ape_cli_context()
 @click.option(
     "-a",
     "--all",
     "to_display",
     default=False,
     is_flag=True,
     callback=_display_all_callback,
     help="Display all plugins installed and available (including Core)",
 )
-@ape_cli_context()
 def _list(cli_ctx, to_display):
     metadata = PluginMetadataList.load(cli_ctx.plugin_manager)
     if output := metadata.to_str(include=to_display):
         click.echo(output)
         if not metadata.installed and not metadata.third_party:
             click.echo("No plugins installed (besides core plugins).")
 
@@ -124,22 +115,22 @@
 
 
 @cli.command()
 @ape_cli_context()
 @plugins_argument()
 @skip_confirmation_option("Don't ask for confirmation to install the plugins")
 @upgrade_option(help="Upgrade the plugin to the newest available version")
-def install(cli_ctx, plugins: List[PluginMetadata], skip_confirmation: bool, upgrade: bool):
+def install(cli_ctx, plugins: list[PluginMetadata], skip_confirmation: bool, upgrade: bool):
     """Install plugins"""
 
     failures_occurred = False
 
     # Track the operations until the end. This way, if validation
     # fails on one, we can error-out before installing anything.
-    install_list: List[Dict[str, Any]] = []
+    install_list: list[dict[str, Any]] = []
 
     for plugin in plugins:
         result = plugin._prepare_install(upgrade=upgrade, skip_confirmation=skip_confirmation)
         if result:
             install_list.append(result)
         else:
             failures_occurred = True
@@ -161,16 +152,16 @@
             failures_occurred = not failures_occurred and success
 
     if failures_occurred:
         sys.exit(1)
 
 
 @cli.command()
-@plugins_argument()
 @ape_cli_context()
+@plugins_argument()
 @skip_confirmation_option("Don't ask for confirmation to install the plugins")
 def uninstall(cli_ctx, plugins, skip_confirmation):
     """Uninstall plugins"""
 
     failures_occurred = False
     did_warn_about_version = False
     for plugin in plugins:
@@ -196,20 +187,20 @@
             continue
 
         # if plugin is installed and 2nd class. We should uninstall it
         if plugin.is_installed and (
             skip_confirmation or click.confirm(f"Remove plugin '{plugin}'?")
         ):
             cli_ctx.logger.info(f"Uninstalling '{plugin.name}'...")
-            args = [sys.executable, "-m", "pip", "uninstall", "-y", plugin.package_name, "--quiet"]
+            arguments = plugin._get_uninstall_args()
 
             # NOTE: Be *extremely careful* with this command, as it modifies the user's
             #       installed packages, to potentially catastrophic results
             # NOTE: This is not abstracted into another function *on purpose*
-            result = subprocess.call(args)
+            result = subprocess.call(arguments)
             failures_occurred = not result_handler.handle_uninstall_result(result)
 
     if failures_occurred:
         sys.exit(1)
 
 
 @cli.command()
@@ -233,32 +224,72 @@
     """
     Change ape and all plugins version
     """
 
     _change_version(version)
 
 
+def _install(name, spec, exit_on_fail: bool = True) -> int:
+    """
+    Helper function to install or update a Python package using pip.
+
+    Args:
+      name (str): The package name.
+      spec (str): Version specifier, e.g., '==1.0.0', '>=1.0.0', etc.
+      exit_on_fail (bool): Set to ``False`` to not exit on fail.
+
+    Returns:
+        The process return-code.
+    """
+    arguments = [*PIP_COMMAND, "install", f"{name}{spec}", "--quiet"]
+
+    # Run the installation process and capture output for error checking
+    completed_process = subprocess.run(
+        arguments,
+        capture_output=True,
+        text=True,  # Output as string
+        check=False,  # Allow manual error handling
+    )
+
+    # Check for installation errors
+    if completed_process.returncode != 0:
+        message = f"Failed to install/update {name}"
+        if completed_process.stdout:
+            message += f": {completed_process.stdout}"
+        if completed_process.stderr:
+            message += f": {completed_process.stderr}"
+
+        logger.error(message)
+        if exit_on_fail:
+            sys.exit(completed_process.returncode)
+    else:
+        logger.info(f"Successfully installed/updated {name}")
+
+    return completed_process.returncode
+
+
 def _change_version(spec: str):
     # Update all the plugins.
     # This will also update core Ape.
     # NOTE: It is possible plugins may depend on each other and may update in
     #   an order causing some error codes to pop-up, so we ignore those for now.
-    for plugin in _pip_freeze.get_plugins(use_process=True):
+    plugin_retcode = 0
+    for plugin in _filter_plugins_from_dists(_get_distributions()):
         logger.info(f"Updating {plugin} ...")
         name = plugin.split("=")[0].strip()
-        subprocess.call([sys.executable, "-m", "pip", "install", f"{name}{spec}", "--quiet"])
+        retcode = _install(name, spec, exit_on_fail=False)
+        if retcode != 0:
+            plugin_retcode = retcode
+        # else: errors logged in _install separately
 
     # This check is for verifying the update and shouldn't actually do anything.
     logger.info("Updating Ape core ...")
-    completed_process = subprocess.run(
-        [sys.executable, "-m", "pip", "install", f"eth-ape{spec}", "--quiet"]
-    )
-    if completed_process.returncode != 0:
-        message = "Update failed"
-        if output := completed_process.stdout:
-            message = f"{message}: {output.decode('utf8')}"
+    ape_retcode = _install("eth-ape", spec)
+    if ape_retcode == 0 and plugin_retcode == 0:
+        prefix = "Ape"
+        if plugin_retcode == 0:
+            prefix = f"{prefix} and plugins"
 
-        logger.error(message)
-        sys.exit(completed_process.returncode)
+        logger.success(f"{prefix} have successfully upgraded.")
+    # else: _install logs errors already.
 
-    else:
-        logger.success("Ape and all plugins have successfully upgraded.")
+    sys.exit(ape_retcode | plugin_retcode)
```

### Comparing `eth-ape-0.7.9/src/ape_pm/_cli.py` & `eth-ape-0.8.0/src/ape_pm/_cli.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,81 +1,56 @@
-import json
+import sys
 from pathlib import Path
-from typing import Tuple
+from typing import Optional
 
 import click
 
-from ape.cli import ape_cli_context
+from ape.cli.options import ape_cli_context, config_override_option
+from ape.exceptions import ProjectError
+from ape.logging import logger
+from ape.managers.project import Dependency
 
 
 @click.group()
 def cli():
     """
     Package management tools
     """
 
 
-def _echo_no_packages(project: bool):
-    message = "No packages installed"
-    if project:
-        message = f"{message} for this project"
-
-    click.echo(f"{message}.")
-
-
 @cli.command("list")
 @ape_cli_context()
-@click.option(
-    "_all", "--all", is_flag=True, help="Include packages not referenced by the local project"
-)
-def _list(cli_ctx, _all):
+@click.option("--all", "list_all", help="List all installed dependencies", is_flag=True)
+def _list(cli_ctx, list_all):
     """
     List installed packages
     """
 
+    pm = cli_ctx.local_project
     packages = []
-    packages_folder = cli_ctx.dependency_manager.DATA_FOLDER / "packages"
-    if _all:
-        if not packages_folder.is_dir():
-            _echo_no_packages(False)
-            return
-
-        for dependency in packages_folder.iterdir():
-            base_item = {"name": dependency.name}
-            for version_dir in dependency.iterdir():
-                item = {
-                    "version": version_dir.name,
-                    **base_item,
-                    "compiled": _check_compiled(version_dir),
-                }
-                packages.append(item)
-
-    else:
-        # Limit to local project.
-        for dependency in cli_ctx.config_manager.dependencies:
-            item = {"name": dependency.name, "version": dependency.version_id, "compiled": False}
-
-            # Check if compiled.
-            if packages_folder.is_dir():
-                for package_dir in packages_folder.iterdir():
-                    if package_dir.is_dir() and package_dir.name == dependency.name:
-                        for version_dir in package_dir.iterdir():
-                            versions = [dependency.version_id]
-                            if versions[0].startswith("v"):
-                                versions.append(dependency.version_id[1:])
-                            else:
-                                versions.append(f"v{dependency.version_id}")
+    dependencies = [*list(pm.dependencies.specified)]
+    if list_all:
+        dependencies = list(set([*dependencies, *pm.dependencies.installed]))
 
-                            if version_dir.is_dir() and version_dir.name in versions:
-                                item["compiled"] = _check_compiled(version_dir)
-
-            packages.append(item)
+    for dependency in dependencies:
+        try:
+            is_compiled = dependency.project.is_compiled
+        except ProjectError:
+            # Project may not even be installed right.
+            is_compiled = False
+
+        item = {
+            "name": dependency.name,
+            "version": dependency.version,
+            "compiled": is_compiled,
+        }
+        packages.append(item)
 
     if not packages:
-        _echo_no_packages(not _all)
+        click.echo("No packages installed.")
         return
 
     # Output gathered packages.
     longest_name = max([4, *[len(p["name"]) for p in packages]])
     longest_version = max([7, *[len(p["version"]) for p in packages]])
     tab = "  "
 
@@ -90,273 +65,257 @@
         )
         spacing_name = ((longest_name - len(_package["name"])) + len(tab)) * " "
         spacing_version = ((longest_version - len(version)) + len(tab)) * " "
         return f"{name}{spacing_name}{version}{spacing_version + compiled}"
 
     def rows():
         yield f"NAME{header_name_space}VERSION{version_name_space}COMPILED\n"
-        for _package in packages:
+        for _package in sorted(packages, key=lambda p: f"{p['name']}{p['version']}"):
             yield f"{get_package_str(_package)}\n"
 
     if len(packages) > 16:
         click.echo_via_pager(rows())
     else:
         for row in rows():
             click.echo(row.strip())
 
 
-def _check_compiled(version_dir: Path) -> bool:
-    file = next(version_dir.iterdir(), None)
-    return (
-        bool(json.loads(file.read_text()).get("contractTypes"))
-        if file and file.is_file()
-        else False
-    )
+def _handle_package_path(path: Path, original_value: Optional[str] = None) -> dict:
+    if not path.exists():
+        value = original_value or path.as_posix()
+        raise click.BadArgumentUsage(f"Unknown package '{value}'.")
+
+    elif path.is_file() and path.name == "ape-config.yaml":
+        path = path.parent
+
+    path = path.resolve().absolute()
+    return {"local": path.as_posix()}
 
 
 def _package_callback(ctx, param, value):
     if value is None:
         # Install all packages from local project.
         return None
 
+    elif isinstance(value, Path):
+        return _handle_package_path(value)
+
     elif value.startswith("gh:"):
         # Is a GitHub style dependency
         return {"github": value[3:]}
 
     elif value.startswith("npm:"):
         # Is an NPM style dependency
-        return {"npm:": value[4:]}
+        return {"npm": value[4:]}
 
     elif value == ".":
         return value
 
     # Check if is a local package.
     try:
         path = Path(value).absolute()
     except Exception:
-        path = None
-
-    if path is not None and path.exists():
-        # Is a local package somewhere.
-        if path.is_file() and path.name == "ape-config.yaml":
-            path = path.parent
-
-        return {"local": path.as_posix()}
+        pass
+    else:
+        return _handle_package_path(path, original_value=value)
 
-    elif ":" in value:
+    if isinstance(value, str) and ":" in value:
         # Catch-all for unknown dependency types that may exist.
         parts = value.split(":")
         return {parts[0]: parts[1]}
 
     raise click.BadArgumentUsage(f"Unknown package '{value}'.")
 
 
 @cli.command()
 @ape_cli_context()
-@click.argument("package", nargs=1, required=False, callback=_package_callback)
+@click.argument("package", required=False, callback=_package_callback)
 @click.option("--name", help="The name of the dependency", metavar="NAME")
 @click.option("--version", help="The dependency's version", metavar="VERSION")
 @click.option(
     "--ref",
     help="A reference flag, used for GitHub branches or tags instead of version",
     metavar="REF",
 )
 @click.option("--force", "-f", help="Force a re-install", is_flag=True)
-def install(cli_ctx, package, name, version, ref, force):
+@config_override_option()
+def install(cli_ctx, package, name, version, ref, force, config_override):
     """
     Download and cache packages
     """
 
-    log_name = None
-
+    pm = cli_ctx.local_project
     if not package or package == ".":
-        # `ape pm install`: Load all dependencies from current package.
-        try:
-            cli_ctx.project_manager.load_dependencies(use_cache=not force)
-        except Exception as err:
-            cli_ctx.logger.log_debug_stack_trace()
-            cli_ctx.abort(f"Failed loading dependencies: {err}")
+        if version:
+            cli_ctx.abort("Cannot specify version when installing from config.")
 
-    elif name:
-        # `ape pm install <package>`: Is a specific package.
-        data = {"name": name, **package}
-        if version is not None:
-            data["version"] = version
-        if ref is not None:
-            data["ref"] = ref
+        pm.dependencies.install(use_cache=not force)
+        message = "All project packages installed."
+        if not force:
+            message = f"{message} Use `--force` to re-install."
 
-        try:
-            dependency_obj = cli_ctx.dependency_manager.decode_dependency(data)
-        except Exception as err:
-            try:
-                data_str = ", ".join([f"{k}={v}" for k, v in data.items()])
-            except Exception:
-                try:
-                    data_str = f"{data}"
-                except Exception:
-                    data_str = ""
-
-            message = "Issue with dependency data"
-            if data_str:
-                message = f"{message}: {data_str}"
-
-            message = f"{message}. Err={err}"
-            cli_ctx.abort(message)
-
-        else:
-            dependency_obj.extract_manifest(use_cache=not force)
-            log_name = f"{dependency_obj.name}@{dependency_obj.version_id}"
+        cli_ctx.logger.success(message)
+        return
 
-    else:
-        # This is **not** the local project, but no --name was given.
-        # NOTE: `--version` is not required when using local dependencies.
-        cli_ctx.abort("Must provide --name")
+    if name:
+        package["name"] = name
+    if ref:
+        package["ref"] = ref
+    if version:
+        package["version"] = version
+    if config_override:
+        package["config_override"] = config_override
 
-    if log_name:
-        cli_ctx.logger.success(f"Package '{log_name}' installed.")
+    try:
+        dependency = pm.dependencies.install(**package, use_cache=not force)
+    except Exception as err:
+        cli_ctx.logger.log_error(err)
     else:
-        cli_ctx.logger.success("All project packages installed.")
+        assert isinstance(dependency, Dependency)  # for mypy
+        cli_ctx.logger.success(f"Package '{dependency.name}@{dependency.version}' installed.")
 
 
 @cli.command()
 @ape_cli_context()
-@click.argument("package", nargs=1, required=True)
+@click.argument("name", required=False)
 @click.argument("versions", nargs=-1, required=False)
 @click.option(
     "-y", "--yes", is_flag=True, help="Automatically confirm the removal of the package(s)"
 )
-def remove(cli_ctx, package, versions, yes):
+def uninstall(cli_ctx, name, versions, yes):
     """
-    Remove a package
+    Uninstall a package
 
     This command removes a package from the installed packages.
 
     If specific versions are provided, only those versions of the package will be
     removed. If no versions are provided, the command will prompt you to choose
     versions to remove. You can also choose to remove all versions of the package.
 
     Examples:\n
     - Remove specific versions: ape pm remove <PackageName> "1.0.0" "2.0.0"\n
     - Prompt to choose versions: ape pm remove <PackageName>\n
     - Remove all versions: ape pm remove <PackageName> -y
     """
-    package_dir = cli_ctx.dependency_manager.DATA_FOLDER / "packages" / package
-    if not package_dir.is_dir():
-        cli_ctx.abort(f"Package '{package}' is not installed.")
-
-    # Remove multiple versions if no version is specified
-    versions_to_remove = versions if versions else []
-    if len(versions_to_remove) == 1 and versions_to_remove[0] == "all":
-        versions_to_remove = [d.name for d in package_dir.iterdir() if d.is_dir()]
-
-    elif not versions_to_remove:
-        available_versions = [d.name for d in package_dir.iterdir() if d.is_dir()]
-        if not available_versions:
-            cli_ctx.abort(f"No installed versions of package '{package}' found.")
-
-        # If there is only one version, use that.
-        if len(available_versions) == 1 or yes:
-            versions_to_remove = available_versions
 
+    pm = cli_ctx.local_project
+
+    # NOTE: Purposely don't call `get_dependency` or anything so we for sure
+    #   are only checking the installed.
+    installed = {d for d in pm.dependencies.installed}
+
+    did_error = False
+    did_find = False
+
+    if not name or name == ".":
+        if versions:
+            cli_ctx.abort("Cannot specify version when uninstalling from config.")
+
+        # Uninstall all dependencies from the config.
+        for cfg in pm.config.dependencies:
+            api = pm.dependencies.decode_dependency(**cfg)
+            for dependency in installed:
+                if dependency.name != api.name or dependency.version != api.version_id:
+                    continue
+
+                did_find = True
+                res = _uninstall(dependency, yes=yes)
+                if res is False:
+                    did_error = True
+
+    else:
+        deps_to_remove = {
+            d for d in installed if d.name == name and (d.version in versions if versions else True)
+        }
+        for dependency in deps_to_remove:
+            did_find = True
+            res = _uninstall(dependency, yes=yes)
+            if res is False:
+                did_error = True
+
+    if not did_find:
+        if name:
+            name = ", ".join([f"{name}={v}" for v in versions]) if versions else name
+            cli_ctx.logger.error(f"Package(s) '{name}' not installed.")
         else:
-            version_prompt = (
-                f"Which versions of package '{package}' do you want to remove? "
-                f"{available_versions} (separate multiple versions with comma, or 'all')"
+            cli_ctx.logger.error(
+                "No package(s) installed in local project. "
+                "Please specify a package to uninstall or go to a local project."
             )
-            versions_input = click.prompt(version_prompt)
-            if versions_input.strip() == "all":
-                versions_to_remove = available_versions
-            else:
-                versions_to_remove = [v.strip() for v in versions_input.split(",") if v.strip()]
 
-            # Prevents a double-prompt.
-            yes = True
+        did_error = True
 
-    if not versions_to_remove:
-        cli_ctx.logger.info("No versions selected for removal.")
-        return
+    sys.exit(int(did_error))
 
-    # Remove all the versions specified
-    for version in versions_to_remove:
-        if not (package_dir / version).is_dir() and not (package_dir / f"v{version}").is_dir():
-            cli_ctx.logger.warning(
-                f"Version '{version}' of package '{package_dir.name}' is not installed."
-            )
-            continue
 
-        elif yes or click.confirm(
-            f"Are you sure you want to remove version '{version}' of package '{package}'?"
-        ):
-            cli_ctx.project_manager.remove_dependency(package_dir.name, versions=[version])
-            cli_ctx.logger.success(f"Version '{version}' of package '{package_dir.name}' removed.")
+def _uninstall(dependency: Dependency, yes: bool = False) -> bool:
+    key = f"{dependency.name}={dependency.version}"
+    if not yes and not click.confirm(f"Remove '{key}'"):
+        return True  # Not an error.
+
+    try:
+        dependency.uninstall()
+    except Exception as err:
+        logger.error(f"Failed uninstalling '{key}': {err}")
+        return False
+
+    logger.success(f"Uninstalled '{key}'.")
+    return True
 
 
 @cli.command()
 @ape_cli_context()
-@click.argument("name", nargs=1, required=False)
+@click.argument("name", required=False)
 @click.option("--version", help="The dependency version", metavar="VERSION")
 @click.option("--force", "-f", help="Force a re-compile", is_flag=True)
-def compile(cli_ctx, name, version, force):
+@config_override_option()
+def compile(cli_ctx, name, version, force, config_override):
     """
     Compile a package
     """
+    pm = cli_ctx.local_project
+    if not name or name == ".":
+        if version:
+            cli_ctx.abort("Cannot specify 'version' without 'name'.")
+
+        # Compile all from config.
+        did_error = False
+        for cfg in pm.config.dependencies:
+            if config_override:
+                cfg["config_override"] = config_override
+
+            dependency = pm.dependencies.install(**cfg)
+            try:
+                dependency.compile(use_cache=not force)
+            except Exception as err:
+                cli_ctx.logger.error(str(err))
+                continue
+            else:
+                cli_ctx.logger.success(
+                    f"Package '{dependency.name}@{dependency.version}' compiled."
+                )
 
-    if not name:
-        # Compile all local project dependencies.
-        for dep_name, versions in cli_ctx.project_manager.dependencies.items():
-            for version, dependency in versions.items():
-                log_line = dep_name
-                if version != "local":
-                    log_line += f"@{version}"
-
-                try:
-                    dependency.compile(use_cache=not force)
-                except Exception as err:
-                    cli_ctx.logger.error(err)
-                else:
-                    cli_ctx.logger.success(f"Package '{log_line}' compiled.")
+        if did_error:
+            sys.exit(1)
 
         return
 
-    elif name not in cli_ctx.project_manager.dependencies:
-        cli_ctx.abort(f"Dependency '{name}' unknown. Is it installed?")
-
-    if not (versions := cli_ctx.project_manager.dependencies[name]):
-        # This shouldn't happen.
-        cli_ctx.abort("No versions.")
-
-    if not version and len(versions) == 1:
-        # Version is not specified but we can use the only existing version.
-        version = list(versions.keys())[0]
-
-    elif not version:
-        cli_ctx.abort("Please specify --version.")
-
-    version_opts: Tuple
-    if version == "local":
-        version_opts = (version,)
-    elif version.startswith("v"):
-        version_opts = (f"v{version}", str(version))
+    if version:
+        to_compile = [pm.dependencies.get_dependency(name, version)]
     else:
-        version_opts = (str(version), str(version[1:]))
-
-    version_found = None
-    for version_i in version_opts:
-        if version_i in versions:
-            version_found = version_i
-            break
+        to_compile = [d for d in pm.dependencies.get_versions(name)]
 
-    if not version_found:
-        cli_ctx.abort(f"Version '{version}' for dependency '{name}' not found. Is it installed?")
+    if not to_compile:
+        key = f"{name}@{version}" if version else name
+        cli_ctx.abort(f"Dependency '{key}' unknown. Is it installed?")
+
+    for dependency in to_compile:
+        if config_override:
+            dependency.api.config_override = config_override
 
-    dependency = versions[version_found]
-
-    try:
-        dependency.compile(use_cache=not force)
-    except Exception as err:
-        cli_ctx.logger.error(err)
-    else:
-        log_line = name
-        if version_found and version_found != "local":
-            log_line = f"{log_line}@{version_found}"
-
-        cli_ctx.logger.success(f"Package '{log_line}' compiled.")
+        try:
+            dependency.compile(use_cache=not force)
+        except Exception as err:
+            cli_ctx.logger.error(str(err))
+            continue
+        else:
+            cli_ctx.logger.success(f"Package '{dependency.name}@{dependency.version}' compiled.")
```

### Comparing `eth-ape-0.7.9/src/ape_pm/compiler.py` & `eth-ape-0.8.0/src/ape_pm/compiler.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,83 +1,99 @@
 import json
+from collections.abc import Iterable, Iterator
+from json import JSONDecodeError
 from pathlib import Path
-from typing import List, Optional, Sequence, Set
+from typing import Optional
 
 from eth_pydantic_types import HexBytes
 from eth_utils import is_0x_prefixed
 from ethpm_types import ContractType
 
-from ape.api import CompilerAPI
+from ape.api.compiler import CompilerAPI
 from ape.exceptions import CompilerError, ContractLogicError
 from ape.logging import logger
-from ape.utils import get_relative_path
+from ape.managers.project import ProjectManager
+from ape.utils.os import get_relative_path
 
 
 class InterfaceCompiler(CompilerAPI):
+    """
+    A compiler plugin for interface JSONs (ABIs). Also, this
+    compiler can "compile" already-compiled ``ContractType``
+    JSON files.
+    """
+
     @property
     def name(self) -> str:
         return "ethpm"
 
-    def get_versions(self, all_paths: Sequence[Path]) -> Set[str]:
+    def get_versions(self, all_paths: Iterable[Path]) -> set[str]:
         # NOTE: This bypasses the serialization of this compiler into the package manifest's
         #       ``compilers`` field. You should not do this with a real compiler plugin.
         return set()
 
     def compile(
-        self, filepaths: Sequence[Path], base_path: Optional[Path] = None
-    ) -> List[ContractType]:
-        contract_types: List[ContractType] = []
-        for path in filepaths:
-            source_path = (
-                get_relative_path(path, base_path) if base_path and path.is_absolute() else path
-            )
-            source_id = str(source_path)
-            code = path.read_text()
-            if not code:
-                continue
+        self,
+        contract_filepaths: Iterable[Path],
+        project: Optional["ProjectManager"],
+        settings: Optional[dict] = None,
+    ) -> Iterator[ContractType]:
+        project = project or self.local_project
+        source_ids = {
+            p: f"{get_relative_path(p, project.path.absolute())}" if p.is_absolute() else str(p)
+            for p in contract_filepaths
+        }
+        logger.info(f"Compiling {', '.join(source_ids.values())}.")
+        for path in contract_filepaths:
+            if not path.is_file() and (project.path / path).is_file():
+                # Was given a relative path.
+                src_path = project.path / path
+            elif not path.is_file():
+                raise CompilerError(f"'{path}' is not a file.")
+            else:
+                src_path = path
 
+            code = src_path.read_text()
+            source_id = source_ids[path]
             try:
                 # NOTE: Always set the source ID to the source of the JSON file
                 #   to avoid manifest corruptions later on.
-                contract_type = self.compile_code(
-                    code,
-                    base_path=base_path,
-                    sourceId=source_id,
+                contract_type = self.compile_code(code, project=project, sourceId=source_id)
+            except CompilerError as err:
+                logger.warning(
+                    f"Unable to parse {ContractType.__name__} from '{source_id}'. Reason: {err}"
                 )
-
-                # NOTE: Try getting name/ ID from code-JSON first.
-                #   That's why this is not part of `contract_type_overrides`.
-                if not contract_type.name:
-                    contract_type.name = path.stem
-
-            except CompilerError:
-                logger.warning(f"Unable to parse {ContractType.__name__} from '{source_id}'.")
                 continue
 
-            contract_types.append(contract_type)
-
-        return contract_types
+            # NOTE: Try getting name/ ID from code-JSON first.
+            #   That's why this is not part of `**kwargs` in `compile_code()`.
+            contract_type.name = contract_type.name or src_path.stem
+            yield contract_type
 
     def compile_code(
         self,
         code: str,
-        base_path: Optional[Path] = None,
+        project: Optional[ProjectManager] = None,
         **kwargs,
     ) -> ContractType:
-        data = json.loads(code)
+        code = code or "[]"
+        try:
+            data = json.loads(code)
+        except JSONDecodeError as err:
+            raise CompilerError(str(err)) from err
+
         if isinstance(data, list):
             # ABI JSON list
             contract_type_data = {"abi": data, **kwargs}
 
         elif isinstance(data, dict) and (
             "contractName" in data or "abi" in data or "sourceId" in data
         ):
             # Raw contract type JSON or raw compiler output.
             contract_type_data = {**data, **kwargs}
-
             if (
                 "deploymentBytecode" not in contract_type_data
                 or "runtimeBytecode" not in contract_type_data
             ):
                 if "bin" in contract_type_data:
                     # Handle raw Solidity output.
                     deployment_bytecode = data["bin"]
```

### Comparing `eth-ape-0.7.9/src/ape_run/_cli.py` & `eth-ape-0.8.0/src/ape_run/_cli.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import inspect
 import os
 import sys
 import traceback
 from contextlib import contextmanager
 from pathlib import Path
 from runpy import run_module
-from typing import Any, Dict, Union
+from typing import Any, Union
 
 import click
 from click import Command, Context, Option
 
 from ape.cli import ConnectedProviderCommand, verbosity_option
 from ape.cli.options import _VERBOSITY_VALUES, _create_verbosity_kwargs
 from ape.exceptions import ApeException, handle_ape_exception
@@ -78,27 +78,27 @@
                 # Attempt to use source-traceback style printing.
                 network_value = (
                     ctx.params.get("network") or self.network_manager.default_ecosystem.name
                 )
                 with self.network_manager.parse_network_choice(
                     network_value, disconnect_on_exit=False
                 ):
-                    if not isinstance(err, ApeException) or not handle_ape_exception(
-                        err, [ctx.obj.project_manager.path]
-                    ):
+                    path = ctx.obj.local_project.path
+                    assert isinstance(path, Path)  # For mypy.
+                    if not isinstance(err, ApeException) or not handle_ape_exception(err, (path,)):
                         err_info = traceback.format_exc()
                         click.echo(err_info)
 
                     self._launch_console()
             else:
                 # Don't handle error - raise exception as normal.
                 raise
 
     def _get_command(self, filepath: Path) -> Union[click.Command, click.Group, None]:
-        relative_filepath = get_relative_path(filepath, ManagerAccessMixin.project_manager.path)
+        relative_filepath = get_relative_path(filepath, ManagerAccessMixin.local_project.path)
 
         # First load the code module by compiling it
         # NOTE: This does not execute the module
         logger.debug(f"Parsing module: {relative_filepath}")
         try:
             code = compile(filepath.read_text(), filepath, "exec")
         except SyntaxError as e:
@@ -167,22 +167,22 @@
 
                 # Nothing to call, everything executes on loading
                 self._namespace[filepath.stem] = empty_ns
 
             return call
 
     @property
-    def commands(self) -> Dict[str, Union[click.Command, click.Group]]:
-        if not self.project_manager.scripts_folder.is_dir():
+    def commands(self) -> dict[str, Union[click.Command, click.Group]]:
+        if not self.local_project.scripts_folder.is_dir():
             return {}
 
-        return self._get_cli_commands(self.project_manager.scripts_folder)
+        return self._get_cli_commands(self.local_project.scripts_folder)
 
-    def _get_cli_commands(self, base_path: Path) -> Dict:
-        commands: Dict[str, Command] = {}
+    def _get_cli_commands(self, base_path: Path) -> dict:
+        commands: dict[str, Command] = {}
 
         for filepath in base_path.iterdir():
             if filepath.stem.startswith("_"):
                 continue  # Ignore any "private" files
 
             elif filepath.is_dir():
                 group = click.Group(
@@ -218,15 +218,15 @@
             return self._launch_console()
 
         return result
 
     def _launch_console(self):
         trace = inspect.trace()
         trace_frames = [
-            x for x in trace if x.filename.startswith(str(self.project_manager.scripts_folder))
+            x for x in trace if x.filename.startswith(str(self.local_project.scripts_folder))
         ]
         if not trace_frames:
             # Error from Ape internals; avoid launching console.
             sys.exit(1)
 
         # Use most recently matching frame.
         frame = trace_frames[-1].frame
@@ -240,15 +240,15 @@
             }
 
         finally:
             # Avoid keeping a reference to a frame to avoid reference cycles.
             if frame:
                 del frame
 
-        return console(project=self.project_manager, extra_locals=extra_locals, embed=True)
+        return console(project=self.local_project, extra_locals=extra_locals, embed=True)
 
 
 @click.command(
     cls=ScriptCommand,
     short_help="Run scripts from the `scripts/` folder",
 )
 @click.option(
```

### Comparing `eth-ape-0.7.9/src/ape_test/__init__.py` & `eth-ape-0.8.0/src/ape_test/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-from typing import Dict, List, NewType, Optional, Union
+from typing import NewType, Optional, Union
 
-from pydantic import NonNegativeInt
+from pydantic import NonNegativeInt, field_validator
 
 from ape import plugins
 from ape.api import PluginConfig
 from ape.api.networks import LOCAL_NETWORK_NAME
 from ape.utils import DEFAULT_NUMBER_OF_TEST_ACCOUNTS, DEFAULT_TEST_HD_PATH, DEFAULT_TEST_MNEMONIC
 from ape_test.accounts import TestAccount, TestAccountContainer
 from ape_test.provider import EthTesterProviderConfig, LocalProvider
@@ -19,31 +19,47 @@
 
 
 class GasConfig(PluginConfig):
     """
     Configuration related to test gas reports.
     """
 
-    show: bool = False
-    """
-    Set to ``True`` to always show gas.
-    """
-
-    exclude: List[GasExclusion] = []
+    exclude: list[GasExclusion] = []
     """
     Contract methods patterns to skip. Specify ``contract_name:`` and not
     ``method_name:`` to skip all methods in the contract. Only specify
     ``method_name:`` to skip all methods across all contracts. Specify
     both to skip methods in a certain contracts. Entries use glob-rules;
     use ``prefix_*`` to skip all items with a certain prefix.
     """
 
+    reports: list[str] = []
+    """
+    Report-types to use. Currently, only supports `terminal`.
+    """
+
+    @field_validator("reports", mode="before")
+    @classmethod
+    def validate_reports(cls, values):
+        values = list(set(values or []))
+        valid = ("terminal",)
+        for val in values:
+            if val not in valid:
+                valid_str = ", ".join(valid)
+                raise ValueError(f"Invalid gas-report format '{val}'. Valid: {valid_str}")
+
+        return values
+
+    @property
+    def show(self) -> bool:
+        return "terminal" in self.reports
+
 
+_ReportType = Union[bool, dict]
 """Dict is for extra report settings."""
-_ReportType = Union[bool, Dict]
 
 
 class CoverageReportsConfig(PluginConfig):
     """
     Enable reports.
     """
 
@@ -79,15 +95,15 @@
     """
 
     reports: CoverageReportsConfig = CoverageReportsConfig()
     """
     Enable reports.
     """
 
-    exclude: List[CoverageExclusion] = []
+    exclude: list[CoverageExclusion] = []
     """
     Contract methods patterns to skip. Specify ``contract_name:`` and not
     ``method_name:`` to skip all methods in the contract. Only specify
     ``method_name:`` to skip all methods across all contracts. Specify
     both to skip methods in a certain contracts. Entries use glob-rules;
     use ``prefix_*`` to skip all items with a certain prefix.
     """
```

### Comparing `eth-ape-0.7.9/src/ape_test/_cli.py` & `eth-ape-0.8.0/src/ape_test/_cli.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 import subprocess
 import sys
 import threading
 import time
+from collections.abc import Sequence
 from datetime import datetime, timedelta
 from pathlib import Path
-from typing import List, Sequence
 
 import click
 import pytest
 from watchdog import events
 from watchdog.observers import Observer
 
 from ape.cli import ape_cli_context
@@ -39,15 +39,15 @@
     )
 
     def dispatch(self, event: events.FileSystemEvent) -> None:
         if event.event_type in self.EVENTS_WATCHED:
             self.process_event(event)
 
     @cached_property
-    def _extensions_to_watch(self) -> List[str]:
+    def _extensions_to_watch(self) -> list[str]:
         return [".py", *self.compiler_manager.registered_compilers.keys()]
 
     def _is_path_watched(self, filepath: str) -> bool:
         """
         Check if file should trigger pytest run
         """
         return any(map(filepath.endswith, self._extensions_to_watch))
```

### Comparing `eth-ape-0.7.9/src/ape_test/accounts.py` & `eth-ape-0.8.0/src/ape_test/accounts.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,26 +1,29 @@
-from typing import Any, Iterator, List, Optional
+import warnings
+from collections.abc import Iterator
+from typing import Any, Optional
 
+from eip712.messages import EIP712Message
 from eth_account import Account as EthAccount
 from eth_account.messages import SignableMessage, encode_defunct
+from eth_pydantic_types import HexBytes
 from eth_utils import to_bytes
-from hexbytes import HexBytes
 
 from ape.api import TestAccountAPI, TestAccountContainerAPI, TransactionAPI
 from ape.exceptions import SignatureError
 from ape.types import AddressType, MessageSignature, TransactionSignature
 from ape.utils import GeneratedDevAccount, generate_dev_accounts
 
 
 class TestAccountContainer(TestAccountContainerAPI):
     num_generated: int = 0
     mnemonic: str = ""
     num_of_accounts: int = 0
     hd_path: str = ""
-    _accounts: List["TestAccount"] = []
+    _accounts: list["TestAccount"] = []
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         self.init()
 
     def init(self):
         self.mnemonic = self.config["mnemonic"]
@@ -39,15 +42,15 @@
         return self.num_of_accounts
 
     @property
     def config(self):
         return self.config_manager.get_config("test")
 
     @property
-    def _dev_accounts(self) -> List[GeneratedDevAccount]:
+    def _dev_accounts(self) -> list[GeneratedDevAccount]:
         return generate_dev_accounts(
             self.mnemonic,
             number_of_accounts=self.num_of_accounts,
             hd_path=self.hd_path,
         )
 
     @property
@@ -67,16 +70,15 @@
         )
 
     @property
     def accounts(self) -> Iterator["TestAccount"]:
         # As TestAccountManager only uses accounts property this works!
         if self._is_config_changed:
             self.init()
-        for account in self._accounts:
-            yield account
+        yield from self._accounts
 
     def generate_account(self) -> "TestAccountAPI":
         new_index = self.num_of_accounts + self.num_generated
         self.num_generated += 1
         generated_account = generate_dev_accounts(
             self.mnemonic, 1, hd_path=self.hd_path, start_index=new_index
         )[0]
@@ -106,27 +108,31 @@
     def sign_message(self, msg: Any, **signer_options) -> Optional[MessageSignature]:
         # Convert str and int to SignableMessage if needed
         if isinstance(msg, str):
             msg = encode_defunct(text=msg)
         elif isinstance(msg, int):
             msg = HexBytes(msg).hex()
             msg = encode_defunct(hexstr=msg)
+        elif isinstance(msg, EIP712Message):
+            # Convert EIP712Message to SignableMessage for handling below
+            msg = msg.signable_message
 
         # Process SignableMessage
         if isinstance(msg, SignableMessage):
             signed_msg = EthAccount.sign_message(msg, self.private_key)
             return MessageSignature(
                 v=signed_msg.v,
                 r=to_bytes(signed_msg.r),
                 s=to_bytes(signed_msg.s),
             )
         return None
 
     def sign_transaction(self, txn: TransactionAPI, **signer_options) -> Optional[TransactionAPI]:
         # Signs anything that's given to it
+        # NOTE: Using JSON mode since used as request data.
         tx_data = txn.model_dump(mode="json", by_alias=True)
 
         try:
             signature = EthAccount.sign_transaction(tx_data, self.private_key)
         except TypeError as err:
             # Occurs when missing properties on the txn that are needed to sign.
             raise SignatureError(str(err)) from err
@@ -134,7 +140,18 @@
         txn.signature = TransactionSignature(
             v=signature.v,
             r=to_bytes(signature.r),
             s=to_bytes(signature.s),
         )
 
         return txn
+
+    def sign_raw_msghash(self, msghash: HexBytes) -> MessageSignature:
+        with warnings.catch_warnings():
+            warnings.simplefilter("ignore")
+            signed_msg = EthAccount.signHash(msghash, self.private_key)
+
+        return MessageSignature(
+            v=signed_msg.v,
+            r=to_bytes(signed_msg.r),
+            s=to_bytes(signed_msg.s),
+        )
```

### Comparing `eth-ape-0.7.9/src/ape_test/provider.py` & `eth-ape-0.8.0/src/ape_test/provider.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 import re
 from ast import literal_eval
+from collections.abc import Iterator
 from functools import cached_property
 from re import Pattern
-from typing import Dict, Optional, cast
+from typing import Any, Optional, cast
 
 from eth.exceptions import HeaderNotFound
 from eth_pydantic_types import HexBytes
 from eth_tester.backends import PyEVMBackend  # type: ignore
 from eth_tester.exceptions import TransactionFailed  # type: ignore
 from eth_utils import is_0x_prefixed
 from eth_utils.exceptions import ValidationError
@@ -21,21 +22,22 @@
     ContractLogicError,
     ProviderError,
     ProviderNotConnectedError,
     TransactionError,
     UnknownSnapshotError,
     VirtualMachineError,
 )
-from ape.types import BlockID, SnapshotID
+from ape.types import BlockID, ContractLog, LogFilter, SnapshotID
 from ape.utils import DEFAULT_TEST_CHAIN_ID, DEFAULT_TEST_HD_PATH, gas_estimation_error_message
 from ape_ethereum.provider import Web3Provider
 
 
 class EthTesterProviderConfig(PluginConfig):
     chain_id: int = DEFAULT_TEST_CHAIN_ID
+    auto_mine: bool = True
 
 
 class LocalProvider(TestProviderAPI, Web3Provider):
     _evm_backend: Optional[PyEVMBackend] = None
     _CANNOT_AFFORD_GAS_PATTERN: Pattern = re.compile(
         r"Sender b'[\\*|\w]*' cannot afford txn gas (\d+) with account balance (\d+)"
     )
@@ -46,67 +48,95 @@
     @property
     def evm_backend(self) -> PyEVMBackend:
         if self._evm_backend is None:
             raise ProviderNotConnectedError()
 
         return self._evm_backend
 
-    def connect(self):
+    @cached_property
+    def tester(self):
         chain_id = self.settings.chain_id
         if self._web3 is not None:
-            connected_chain_id = self._make_request("eth_chainId")
+            connected_chain_id = self.make_request("eth_chainId")
             if connected_chain_id == chain_id:
                 # Is already connected and settings have not changed.
                 return
 
         hd_path = (self.config.hd_path or DEFAULT_TEST_HD_PATH).rstrip("/")
         self._evm_backend = PyEVMBackend.from_mnemonic(
             mnemonic=self.config.mnemonic,
             num_accounts=self.config.number_of_accounts,
             hd_path=hd_path,
         )
         endpoints = {**API_ENDPOINTS}
         endpoints["eth"] = merge(endpoints["eth"], {"chainId": static_return(chain_id)})
-        tester = EthereumTesterProvider(ethereum_tester=self._evm_backend, api_endpoints=endpoints)
-        self._web3 = Web3(tester)
+        return EthereumTesterProvider(ethereum_tester=self._evm_backend, api_endpoints=endpoints)
+
+    @property
+    def auto_mine(self) -> bool:
+        return self.tester.ethereum_tester.auto_mine_transactions
+
+    @auto_mine.setter
+    def auto_mine(self, value: Any) -> None:
+        if value is True:
+            self.tester.ethereum_tester.enable_auto_mine_transactions()
+        elif value is False:
+            self.tester.ethereum_tester.disable_auto_mine_transactions()
+        else:
+            raise TypeError("Expecting bool-value for auto_mine setter.")
+
+    def connect(self):
+        if "tester" in self.__dict__:
+            del self.__dict__["tester"]
+
+        self._web3 = Web3(self.tester)
+        # Handle disabling auto-mine if the user requested via config.
+        if self.config.provider.auto_mine is False:
+            self.auto_mine = False  # type: ignore[misc]
 
     def disconnect(self):
         # NOTE: This type ignore seems like a bug in pydantic.
         self._web3 = None
         self._evm_backend = None
         self.provider_settings = {}
 
-    def update_settings(self, new_settings: Dict):
+    def update_settings(self, new_settings: dict):
         self.provider_settings = {**self.provider_settings, **new_settings}
         self.disconnect()
         self.connect()
 
     def estimate_gas_cost(
         self, txn: TransactionAPI, block_id: Optional[BlockID] = None, **kwargs
     ) -> int:
         if isinstance(self.network.gas_limit, int):
             return self.network.gas_limit
 
         estimate_gas = self.web3.eth.estimate_gas
+
+        # NOTE: Using JSON mode since used as request data.
         txn_dict = txn.model_dump(mode="json")
+
         txn_dict.pop("gas", None)
         txn_data = cast(TxParams, txn_dict)
 
         try:
             return estimate_gas(txn_data, block_identifier=block_id)
         except (ValidationError, TransactionFailed) as err:
             ape_err = self.get_virtual_machine_error(err, txn=txn)
             gas_match = self._INVALID_NONCE_PATTERN.match(str(ape_err))
             if gas_match:
                 # Sometimes, EthTester is confused about the sender nonce
                 # during gas estimation. Retry using the "expected" gas
                 # and then set it back.
                 expected_nonce, actual_nonce = gas_match.groups()
                 txn.nonce = int(expected_nonce)
+
+                # NOTE: Using JSON mode since used as request data.
                 txn_params: TxParams = cast(TxParams, txn.model_dump(by_alias=True, mode="json"))
+
                 value = estimate_gas(txn_params, block_identifier=block_id)
                 txn.nonce = int(actual_nonce)
                 return value
 
             elif isinstance(ape_err, ContractLogicError):
                 raise ape_err from err
             else:
@@ -114,21 +144,25 @@
                 raise TransactionError(
                     message, base_err=ape_err, txn=txn, source_traceback=ape_err.source_traceback
                 ) from ape_err
 
     @property
     def settings(self) -> EthTesterProviderConfig:
         return EthTesterProviderConfig.model_validate(
-            {**self.config.provider.model_dump(mode="json"), **self.provider_settings}
+            {**self.config.provider.model_dump(), **self.provider_settings}
         )
 
+    @property
+    def supports_tracing(self) -> bool:
+        return False
+
     @cached_property
     def chain_id(self) -> int:
         try:
-            result = self._make_request("eth_chainId")
+            result = self.make_request("eth_chainId")
         except ProviderNotConnectedError:
             result = self.settings.chain_id
 
         return result
 
     @property
     def gas_price(self) -> int:
@@ -147,20 +181,22 @@
         """
         return self._get_last_base_fee()
 
     def send_call(
         self,
         txn: TransactionAPI,
         block_id: Optional[BlockID] = None,
-        state: Optional[Dict] = None,
+        state: Optional[dict] = None,
         **kwargs,
     ) -> HexBytes:
+        # NOTE: Using JSON mode since used as request data.
         data = txn.model_dump(mode="json", exclude_none=True)
+
         state = kwargs.pop("state_override", None)
-        call_kwargs: Dict = {"block_identifier": block_id, "state_override": state}
+        call_kwargs: dict = {"block_identifier": block_id, "state_override": state}
 
         # Remove unneeded properties
         data.pop("gas", None)
         data.pop("gasLimit", None)
         data.pop("maxFeePerGas", None)
         data.pop("maxPriorityFeePerGas", None)
 
@@ -187,15 +223,17 @@
             txn_hash.hex(), required_confirmations=txn.required_confirmations or 0
         )
 
         # NOTE: Caching must happen before error enrichment.
         self.chain_manager.history.append(receipt)
 
         if receipt.failed:
+            # NOTE: Using JSON mode since used as request data.
             txn_dict = txn.model_dump(mode="json")
+
             txn_dict["nonce"] += 1
             txn_params = cast(TxParams, txn_dict)
 
             # Replay txn to get revert reason
             try:
                 self.web3.eth.call(txn_params)
             except (ValidationError, TransactionFailed) as err:
@@ -207,15 +245,15 @@
             receipt.raise_for_status()
 
         return receipt
 
     def snapshot(self) -> SnapshotID:
         return self.evm_backend.take_snapshot()
 
-    def revert(self, snapshot_id: SnapshotID):
+    def restore(self, snapshot_id: SnapshotID):
         if snapshot_id:
             current_hash = self.get_block("latest").hash
             if current_hash != snapshot_id:
                 try:
                     return self.evm_backend.revert_to_snapshot(snapshot_id)
                 except HeaderNotFound:
                     raise UnknownSnapshotError(snapshot_id)
@@ -241,14 +279,35 @@
                         return
 
             raise ProviderError(f"Failed to time travel: {err}") from err
 
     def mine(self, num_blocks: int = 1):
         self.evm_backend.mine_blocks(num_blocks)
 
+    def get_contract_logs(self, log_filter: LogFilter) -> Iterator[ContractLog]:
+        from_block = max(0, log_filter.start_block)
+
+        if log_filter.stop_block is None:
+            to_block = None
+        else:
+            latest_block = self.get_block("latest").number
+            to_block = (
+                min(latest_block, log_filter.stop_block)
+                if latest_block is not None
+                else log_filter.stop_block
+            )
+
+        log_gen = self.tester.ethereum_tester.get_logs(
+            address=log_filter.addresses,
+            from_block=from_block,
+            to_block=to_block,
+            topics=log_filter.topic_filter,
+        )
+        yield from self.network.ecosystem.decode_logs(log_gen, *log_filter.events)
+
     def get_virtual_machine_error(self, exception: Exception, **kwargs) -> VirtualMachineError:
         if isinstance(exception, ValidationError):
             match = self._CANNOT_AFFORD_GAS_PATTERN.match(str(exception))
             if match:
                 txn_gas, bal = match.groups()
                 sender = getattr(kwargs["txn"], "sender")
                 new_message = (
```

### Comparing `eth-ape-0.7.9/src/eth_ape.egg-info/PKG-INFO` & `eth-ape-0.8.0/src/eth_ape.egg-info/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: eth-ape
-Version: 0.7.9
+Version: 0.8.0
 Summary: Ape Ethereum Framework
 Home-page: https://apeworx.io
 Author: ApeWorX Ltd.
 Author-email: admin@apeworx.io
 License: Apache-2.0
 Project-URL: Documentation, https://docs.apeworx.io/ape/
 Project-URL: Funding, https://gitcoin.co/grants/5958/ape-maintenance-fund
@@ -15,19 +15,19 @@
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Developers
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Natural Language :: English
 Classifier: Operating System :: MacOS
 Classifier: Operating System :: POSIX
 Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
-Requires-Python: >=3.8,<4
+Classifier: Programming Language :: Python :: 3.12
+Requires-Python: >=3.9,<4
 Description-Content-Type: text/markdown
 Provides-Extra: test
 Provides-Extra: lint
 Provides-Extra: doc
 Provides-Extra: release
 Provides-Extra: dev
 Provides-Extra: recommended-plugins
@@ -58,15 +58,15 @@
 Read our [academic platform](https://academy.apeworx.io/) will help you master Ape Framework with tutorials and challenges.
 
 ## Prerequisite
 
 In the latest release, Ape requires:
 
 - Linux or macOS
-- Python 3.8 up to 3.11
+- Python 3.9 up to 3.12
 - **Windows**: Install Windows Subsystem Linux [(WSL)](https://docs.microsoft.com/en-us/windows/wsl/install)
 
 Check your python version in a terminal with `python3 --version`.
 
 ## Installation
 
 There are three ways to install ape: `pipx`, `pip`, or `Docker`.
```

### Comparing `eth-ape-0.7.9/src/eth_ape.egg-info/SOURCES.txt` & `eth-ape-0.8.0/src/eth_ape.egg-info/SOURCES.txt`

 * *Files 4% similar despite different names*

```diff
@@ -41,14 +41,16 @@
 docs/commands/networks.rst
 docs/commands/plugins.rst
 docs/commands/pm.rst
 docs/commands/run.rst
 docs/commands/test.rst
 docs/methoddocs/ape.md
 docs/methoddocs/ape_accounts.md
+docs/methoddocs/ape_compile.md
+docs/methoddocs/ape_pm.md
 docs/methoddocs/api.md
 docs/methoddocs/cli.md
 docs/methoddocs/contracts.md
 docs/methoddocs/exceptions.md
 docs/methoddocs/managers.md
 docs/methoddocs/plugins.md
 docs/methoddocs/types.md
@@ -68,17 +70,17 @@
 docs/userguides/networks.md
 docs/userguides/projects.md
 docs/userguides/proxy.md
 docs/userguides/publishing.md
 docs/userguides/quickstart.md
 docs/userguides/scripts.md
 docs/userguides/testing.md
+docs/userguides/trace.md
 docs/userguides/transactions.md
 src/ape/__init__.py
-src/ape/__modules__.py
 src/ape/_cli.py
 src/ape/exceptions.py
 src/ape/harambe.py
 src/ape/logging.py
 src/ape/py.typed
 src/ape/version.py
 src/ape/api/__init__.py
@@ -88,14 +90,15 @@
 src/ape/api/config.py
 src/ape/api/convert.py
 src/ape/api/explorers.py
 src/ape/api/networks.py
 src/ape/api/projects.py
 src/ape/api/providers.py
 src/ape/api/query.py
+src/ape/api/trace.py
 src/ape/api/transactions.py
 src/ape/cli/__init__.py
 src/ape/cli/arguments.py
 src/ape/cli/choices.py
 src/ape/cli/commands.py
 src/ape/cli/options.py
 src/ape/cli/paramtype.py
@@ -105,19 +108,17 @@
 src/ape/managers/accounts.py
 src/ape/managers/base.py
 src/ape/managers/chain.py
 src/ape/managers/compilers.py
 src/ape/managers/config.py
 src/ape/managers/converters.py
 src/ape/managers/networks.py
+src/ape/managers/plugins.py
+src/ape/managers/project.py
 src/ape/managers/query.py
-src/ape/managers/project/__init__.py
-src/ape/managers/project/dependency.py
-src/ape/managers/project/manager.py
-src/ape/managers/project/types.py
 src/ape/plugins/__init__.py
 src/ape/plugins/_utils.py
 src/ape/plugins/account.py
 src/ape/plugins/compiler.py
 src/ape/plugins/config.py
 src/ape/plugins/converter.py
 src/ape/plugins/network.py
@@ -135,17 +136,17 @@
 src/ape/pytest/runners.py
 src/ape/types/__init__.py
 src/ape/types/address.py
 src/ape/types/coverage.py
 src/ape/types/signatures.py
 src/ape/types/trace.py
 src/ape/utils/__init__.py
+src/ape/utils/_github.py
 src/ape/utils/abi.py
 src/ape/utils/basemodel.py
-src/ape/utils/github.py
 src/ape/utils/misc.py
 src/ape/utils/os.py
 src/ape/utils/process.py
 src/ape/utils/testing.py
 src/ape/utils/trace.py
 src/ape/utils/validators.py
 src/ape_accounts/__init__.py
@@ -161,38 +162,43 @@
 src/ape_compile/_cli.py
 src/ape_compile/py.typed
 src/ape_console/__init__.py
 src/ape_console/_cli.py
 src/ape_console/config.py
 src/ape_console/plugin.py
 src/ape_ethereum/__init__.py
+src/ape_ethereum/_console_log_abi.py
 src/ape_ethereum/_converters.py
+src/ape_ethereum/_print.py
 src/ape_ethereum/ecosystem.py
 src/ape_ethereum/provider.py
 src/ape_ethereum/proxies.py
 src/ape_ethereum/py.typed
+src/ape_ethereum/query.py
+src/ape_ethereum/trace.py
 src/ape_ethereum/transactions.py
 src/ape_ethereum/multicall/__init__.py
 src/ape_ethereum/multicall/constants.py
 src/ape_ethereum/multicall/exceptions.py
 src/ape_ethereum/multicall/handlers.py
-src/ape_geth/__init__.py
-src/ape_geth/provider.py
-src/ape_geth/py.typed
-src/ape_geth/query.py
 src/ape_init/__init__.py
 src/ape_init/_cli.py
 src/ape_networks/__init__.py
 src/ape_networks/_cli.py
+src/ape_node/__init__.py
+src/ape_node/provider.py
+src/ape_node/py.typed
+src/ape_node/query.py
 src/ape_plugins/__init__.py
 src/ape_plugins/_cli.py
-src/ape_plugins/exceptions.py
 src/ape_pm/__init__.py
 src/ape_pm/_cli.py
 src/ape_pm/compiler.py
+src/ape_pm/dependency.py
+src/ape_pm/projects.py
 src/ape_pm/py.typed
 src/ape_run/__init__.py
 src/ape_run/_cli.py
 src/ape_run/py.typed
 src/ape_test/__init__.py
 src/ape_test/_cli.py
 src/ape_test/accounts.py
@@ -208,14 +214,15 @@
 tests/README.md
 tests/__init__.py
 tests/conftest.py
 tests/functional/__init__.py
 tests/functional/conftest.py
 tests/functional/test_accounts.py
 tests/functional/test_address.py
+tests/functional/test_base_manager.py
 tests/functional/test_block.py
 tests/functional/test_block_container.py
 tests/functional/test_chain.py
 tests/functional/test_cli.py
 tests/functional/test_compilers.py
 tests/functional/test_config.py
 tests/functional/test_console.py
@@ -228,33 +235,37 @@
 tests/functional/test_contracts_cache.py
 tests/functional/test_coverage.py
 tests/functional/test_default_sender_context_manager.py
 tests/functional/test_dependencies.py
 tests/functional/test_ecosystem.py
 tests/functional/test_exceptions.py
 tests/functional/test_fixtures.py
+tests/functional/test_gas_tracker.py
 tests/functional/test_history.py
 tests/functional/test_logging.py
 tests/functional/test_multicall.py
 tests/functional/test_network_api.py
 tests/functional/test_network_manager.py
 tests/functional/test_plugins.py
 tests/functional/test_project.py
 tests/functional/test_provider.py
 tests/functional/test_proxy.py
 tests/functional/test_query.py
 tests/functional/test_receipt.py
 tests/functional/test_receipt_capture.py
 tests/functional/test_reverts_context_manager.py
+tests/functional/test_trace.py
 tests/functional/test_transaction.py
 tests/functional/test_types.py
 tests/functional/conversion/test_address.py
+tests/functional/conversion/test_decimal.py
 tests/functional/conversion/test_encode_structs.py
 tests/functional/conversion/test_ether.py
 tests/functional/conversion/test_hex.py
+tests/functional/conversion/test_misc.py
 tests/functional/conversion/test_timestamp.py
 tests/functional/data/__init__.py
 tests/functional/data/contracts/ethereum/abi/contract_abi.json
 tests/functional/data/contracts/ethereum/local/BeaconProxy.json
 tests/functional/data/contracts/ethereum/local/ContractA.json
 tests/functional/data/contracts/ethereum/local/ContractB.json
 tests/functional/data/contracts/ethereum/local/ContractC.json
@@ -267,23 +278,27 @@
 tests/functional/data/contracts/ethereum/local/SolidityContract.json
 tests/functional/data/contracts/ethereum/local/SubReverts.json
 tests/functional/data/contracts/ethereum/local/VyDefault.json
 tests/functional/data/contracts/ethereum/local/VyperContract.json
 tests/functional/data/contracts/ethereum/local/VyperFactory.json
 tests/functional/data/contracts/ethereum/local/beacon.json
 tests/functional/data/contracts/ethereum/local/eip1967.json
+tests/functional/data/contracts/ethereum/local/printing.json
 tests/functional/data/contracts/ethereum/local/proxy.json
-tests/functional/data/manifests/OpenZeppelin/v3.1.0/OpenZeppelin.json
-tests/functional/data/manifests/OpenZeppelin/v4.4.2/OpenZeppelin.json
+tests/functional/data/manifests/openzeppelin/3.1.0/openzeppelin.json
+tests/functional/data/manifests/openzeppelin/4.4.2/openzeppelin.json
 tests/functional/data/projects/ApeProject/ape-config.yaml
 tests/functional/data/projects/ApeProject/contracts/ApeContract0.json
 tests/functional/data/projects/ApeProject/contracts/ApeContract1.json
 tests/functional/data/projects/ApeProject/contracts/Contract.json
+tests/functional/data/projects/ApeProject/contracts/Exclude.json
+tests/functional/data/projects/ApeProject/contracts/subdir/ApeContractNested.json
+tests/functional/data/projects/ApeProject/contracts/subdir/ExcludeNested.json
 tests/functional/data/projects/BrownieProject/brownie-config.yaml
-tests/functional/data/projects/BrownieProject/contracts/brownie.json
+tests/functional/data/projects/BrownieProject/contractsrenamed/brownie.json
 tests/functional/data/projects/LongContractsFolder/source/v0.1/long_contracts_folder.json
 tests/functional/data/python/__init__.py
 tests/functional/data/sources/ContractA.sol
 tests/functional/data/sources/ContractB.sol
 tests/functional/data/sources/ContractC.sol
 tests/functional/data/sources/HasError.sol
 tests/functional/data/sources/Proxy.sol
@@ -294,26 +309,29 @@
 tests/functional/data/sources/VyDefault.vy
 tests/functional/data/sources/VyperContract.vy
 tests/functional/data/sources/VyperFactory.vy
 tests/functional/data/sources/interfaces/ISubReverts.vy
 tests/functional/geth/__init__.py
 tests/functional/geth/conftest.py
 tests/functional/geth/test_contract.py
+tests/functional/geth/test_contract_event.py
 tests/functional/geth/test_ecosystem.py
+tests/functional/geth/test_gas_tracker.py
+tests/functional/geth/test_network_manager.py
 tests/functional/geth/test_provider.py
 tests/functional/geth/test_query.py
+tests/functional/geth/test_receipt.py
 tests/functional/geth/test_trace.py
 tests/functional/geth/text_proxy.py
 tests/functional/utils/__init__.py
 tests/functional/utils/test_abi.py
 tests/functional/utils/test_basemodel.py
 tests/functional/utils/test_github.py
 tests/functional/utils/test_misc.py
 tests/functional/utils/test_os.py
-tests/functional/utils/test_trace.py
 tests/integration/__init__.py
 tests/integration/cli/__init__.py
 tests/integration/cli/conftest.py
 tests/integration/cli/test_accounts.py
 tests/integration/cli/test_cache.py
 tests/integration/cli/test_compile.py
 tests/integration/cli/test_console.py
@@ -341,14 +359,15 @@
 tests/integration/cli/projects/geth/tests/test_using_local_geth.py
 tests/integration/cli/projects/multiple-interfaces/contracts/Interface-with-hyphens.json
 tests/integration/cli/projects/multiple-interfaces/contracts/Interface.exclude.json
 tests/integration/cli/projects/multiple-interfaces/contracts/Interface.json
 tests/integration/cli/projects/multiple-interfaces/contracts/InterfaceWithNumber123.json
 tests/integration/cli/projects/multiple-interfaces/contracts/Interface_with_underscores.json
 tests/integration/cli/projects/no-config/.gitkeep
+tests/integration/cli/projects/only-dependencies/__init__.py
 tests/integration/cli/projects/only-dependencies/ape-config.yaml
 tests/integration/cli/projects/only-dependencies/dependency_in_project_only/__init__.py
 tests/integration/cli/projects/only-dependencies/dependency_in_project_only/importme.py
 tests/integration/cli/projects/only-dependencies/dependency_in_project_only/sources/DependencyInProjectOnly.json
 tests/integration/cli/projects/only-script-subdirs/scripts/subdirectory/subdirectory_click_print.py
 tests/integration/cli/projects/only-script-subdirs/scripts/subdirectory/subdirectory_main_print.py
 tests/integration/cli/projects/script/contracts/VyperContract.json
@@ -372,14 +391,15 @@
 tests/integration/cli/projects/with-contracts/contracts/Exclude.json
 tests/integration/cli/projects/with-contracts/contracts/RawSolidityOutput.json
 tests/integration/cli/projects/with-contracts/contracts/RawVyperOutput.json
 tests/integration/cli/projects/with-contracts/contracts/hyphen-Contract.json
 tests/integration/cli/projects/with-contracts/contracts/DirectoryWithJSONExtension.json/.gitkeep
 tests/integration/cli/projects/with-contracts/contracts/exclude_dir/UnwantedContract.json
 tests/integration/cli/projects/with-contracts/dep/contracts/RawVyperOutputDep.json
+tests/integration/cli/projects/with-contracts/dep_contracts_folder_root/RawVyperOutputDepNoContractsFolder.json
 tests/integration/cli/projects/with-contracts/scripts/txerr.py
 tests/integration/cli/projects/with-contracts/tests/conftest.py
 tests/integration/cli/projects/with-contracts/tests/test_contract.py
 tests/integration/cli/projects/with-dependencies/ape-config.yaml
 tests/integration/cli/projects/with-dependencies/manifest_dependency.json
 tests/integration/cli/projects/with-dependencies/containing_sub_dependencies/ape-config.yaml
 tests/integration/cli/projects/with-dependencies/containing_sub_dependencies/contracts/containing_sub_dependencies.json
```

### Comparing `eth-ape-0.7.9/src/eth_ape.egg-info/requires.txt` & `eth-ape-0.8.0/src/eth_ape.egg-info/requires.txt`

 * *Files 16% similar despite different names*

```diff
@@ -1,58 +1,59 @@
 click<9,>=8.1.6
 ijson<4,>=3.1.4
-importlib-metadata
-ipython<9,>=8.5.0
+ipython<9,>=8.18.1
 lazyasd>=0.1.4
 packaging<24,>=23.0
 pandas<2,>=1.3.0
 pluggy<2,>=1.3
-pydantic<3,>=2.5.2
+pydantic<3,>=2.6.4
 pydantic-settings<3,>=2.0.3
-PyGithub<2,>=1.59
-pytest<8.0,>=6.0
+pytest<9.0,>=8.0
 python-dateutil<3,>=2.8.2
 PyYAML<7,>=5.0
 requests<3,>=2.28.1
 rich<14,>=12.5.1
 SQLAlchemy>=1.4.35
 tqdm<5.0,>=4.62.3
 traitlets>=5.3.0
 urllib3<3,>=2.0.0
 watchdog<4,>=3.0
-eth-abi<5,>=4.2.1
-eth-account<0.11,>=0.10.0
+eth-abi<6,>=5.1.0
+eth-account<0.12,>=0.11.2
 eth-typing<4,>=3.5.2
 eth-utils<3,>=2.3.1
-py-geth<5,>=4.2.0
-web3[tester]<7,>=6.15.1
-eip712<0.4,>=0.2.3
-ethpm-types<0.7,>=0.6.7
-eth_pydantic_types<0.2,>=0.1.0a5
-evmchains<0.1,>=0.0.2
-evm-trace>=0.1.2
+hexbytes
+py-geth<5,>=4.4.0
+trie<4,>=3.0.0
+web3[tester]<7,>=6.17.2
+eip712<0.3,>=0.2.7
+ethpm-types<0.7,>=0.6.9
+eth_pydantic_types<0.2,>=0.1.0
+evmchains<0.1,>=0.0.7
+evm-trace<0.2,>=0.1.5
 
 [dev]
-pytest-xdist<4,>=3.5.0
+pytest-xdist<4,>=3.6.1
 pytest-cov<5,>=4.0.0
 pytest-mock
-pytest-timeout~=2.2.0
+pytest-timeout<3,>=2.2.0
 hypothesis<7.0,>=6.2.0
 hypothesis-jsonschema==0.19.0
-black<25,>=24.1.1
-mypy<2,>=1.8.0
+black<25,>=24.4.2
+mypy<2,>=1.10.0
 types-PyYAML
 types-requests
 types-setuptools
-pandas-stubs==1.2.0.62
+pandas-stubs>=2.2.1.240316
 types-SQLAlchemy>=1.4.49
+types-python-dateutil
 flake8<8,>=7.0.0
 flake8-breakpoint<2,>=1.1.0
 flake8-print<5,>=4.0.1
-isort<6,>=5.10.1
+isort<6,>=5.13.2
 mdformat>=0.7.17
 mdformat-gfm>=0.3.5
 mdformat-frontmatter>=0.4.1
 mdformat-pyproject>=0.0.1
 pygments<3,>=2.17.0
 myst-parser<2,>=1.0.0
 sphinx-click<5,>=4.4.0
@@ -74,25 +75,26 @@
 sphinx-click<5,>=4.4.0
 Sphinx<7,>=6.1.3
 sphinx_rtd_theme<2,>=1.2.0
 sphinxcontrib-napoleon>=0.7
 sphinx-plausible<0.2,>=0.1.2
 
 [lint]
-black<25,>=24.1.1
-mypy<2,>=1.8.0
+black<25,>=24.4.2
+mypy<2,>=1.10.0
 types-PyYAML
 types-requests
 types-setuptools
-pandas-stubs==1.2.0.62
+pandas-stubs>=2.2.1.240316
 types-SQLAlchemy>=1.4.49
+types-python-dateutil
 flake8<8,>=7.0.0
 flake8-breakpoint<2,>=1.1.0
 flake8-print<5,>=4.0.1
-isort<6,>=5.10.1
+isort<6,>=5.13.2
 mdformat>=0.7.17
 mdformat-gfm>=0.3.5
 mdformat-frontmatter>=0.4.1
 mdformat-pyproject>=0.0.1
 
 [recommended-plugins]
 ape-alchemy
@@ -108,13 +110,13 @@
 
 [release]
 setuptools
 wheel
 twine==3.8.0
 
 [test]
-pytest-xdist<4,>=3.5.0
+pytest-xdist<4,>=3.6.1
 pytest-cov<5,>=4.0.0
 pytest-mock
-pytest-timeout~=2.2.0
+pytest-timeout<3,>=2.2.0
 hypothesis<7.0,>=6.2.0
 hypothesis-jsonschema==0.19.0
```

### Comparing `eth-ape-0.7.9/tests/README.md` & `eth-ape-0.8.0/tests/README.md`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/conftest.py` & `eth-ape-0.8.0/tests/conftest.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,43 +1,42 @@
 import json
+import os
 import shutil
 import subprocess
 import sys
 import tempfile
 import time
+from collections.abc import Callable, Sequence
 from contextlib import contextmanager
 from pathlib import Path
-from tempfile import mkdtemp
-from typing import Any, Callable, Dict, Optional, Sequence
+from typing import Any, Optional, Union
 
 import pytest
-import yaml
 from click.testing import CliRunner
 
 import ape
-from ape.exceptions import APINotImplementedError, UnknownSnapshotError
+from ape.exceptions import APINotImplementedError, ProviderNotConnectedError, UnknownSnapshotError
 from ape.logging import LogLevel, logger
-from ape.managers.config import CONFIG_FILE_NAME
+from ape.pytest.config import ConfigWrapper
+from ape.pytest.gas import GasTracker
 from ape.types import AddressType
 from ape.utils import DEFAULT_TEST_CHAIN_ID, ZERO_ADDRESS
-
-# NOTE: Ensure that we don't use local paths for these
-DATA_FOLDER = Path(mkdtemp()).resolve()
-ape.config.DATA_FOLDER = DATA_FOLDER
-ape.config.dependency_manager.DATA_FOLDER = DATA_FOLDER
-PROJECT_FOLDER = Path(mkdtemp()).resolve()
-ape.config.PROJECT_FOLDER = PROJECT_FOLDER
+from ape.utils.basemodel import only_raise_attribute_error
 
 # Needed to test tracing support in core `ape test` command.
 pytest_plugins = ["pytester"]
 GETH_URI = "http://127.0.0.1:5550"
 ALIAS = "__FUNCTIONAL_TESTS_ALIAS__"
 geth_process_test = pytest.mark.xdist_group(name="geth-tests")
 explorer_test = pytest.mark.xdist_group(name="explorer-tests")
 
+# Ensure we don't persist any .ape data or using existing.
+DATA_FOLDER = Path(tempfile.mkdtemp()).resolve()
+ape.config.DATA_FOLDER = DATA_FOLDER
+
 
 def pytest_addoption(parser):
     parser.addoption(
         "--includepip", action="store_true", help="run tests that depend on pip install operations"
     )
 
 
@@ -53,30 +52,75 @@
 
     With this variable set fault handling and IPython command history logging
     will be disabled in the ape console.
     """
     monkeypatch.setenv("APE_TESTING", "1")
 
 
+@pytest.fixture(scope="session", autouse=True)
+def clean_temp_data_folder():
+    yield
+    shutil.rmtree(DATA_FOLDER)
+
+
+@pytest.fixture(scope="session", autouse=True)
+def start_dir():
+    return os.getcwd()
+
+
+@pytest.fixture(autouse=True)
+def validate_cwd(start_dir):
+    # Handle weird issues with cwd breaking everything.
+    # Possibly dur to chdir to a tempdir and then it gets deleted. my guess.
+    # TODO: Find root cause and fix there.
+    try:
+        os.getcwd()
+    except Exception:
+        # Change back to project root, hopefully.
+        os.chdir(start_dir)
+
+
+@pytest.fixture(scope="session")
+def project(config):
+    path = "functional/data/contracts/local"
+    with ape.project.temp_config(contracts_folder=path):
+        yield ape.project
+
+
 @pytest.fixture(scope="session")
 def config():
     return ape.config
 
 
 @pytest.fixture(scope="session")
-def convert(chain):
-    return chain.conversion_manager.convert
+def conversion_manager(chain):
+    return chain.conversion_manager
+
+
+@pytest.fixture(scope="session")
+def convert(conversion_manager):
+    return conversion_manager.convert
 
 
 @pytest.fixture(scope="session")
 def data_folder(config):
     return DATA_FOLDER
 
 
 @pytest.fixture(scope="session")
+def projects_path():
+    return Path(__file__).parent / "integration" / "cli" / "projects"
+
+
+@pytest.fixture(scope="session")
+def with_dependencies_project_path(projects_path):
+    return projects_path / "with-dependencies"
+
+
+@pytest.fixture(scope="session")
 def plugin_manager():
     return ape.networks.plugin_manager
 
 
 @pytest.fixture(scope="session")
 def accounts():
     return ape.accounts
@@ -94,19 +138,14 @@
 
 @pytest.fixture(scope="session")
 def chain():
     return ape.chain
 
 
 @pytest.fixture(scope="session")
-def project_folder():
-    return PROJECT_FOLDER
-
-
-@pytest.fixture(scope="session")
 def test_accounts(accounts):
     return accounts.test_accounts
 
 
 @pytest.fixture(scope="session")
 def owner(test_accounts):
     return test_accounts[0]
@@ -143,26 +182,14 @@
 
 
 @pytest.fixture
 def geth_second_account(test_accounts):
     return test_accounts[7]
 
 
-@pytest.fixture
-def project(config, project_folder):
-    project_folder.mkdir(parents=True, exist_ok=True)
-    with config.using_project(project_folder) as project:
-        yield project
-
-
-@pytest.fixture
-def dependency_manager(project):
-    return project.dependency_manager
-
-
 @pytest.fixture(scope="session")
 def keyparams():
     # NOTE: password is 'asdf1234'
     return {
         "address": "f39Fd6e51aad88F6F4ce6aB8827279cffFb92266",
         "crypto": {
             "cipher": "aes-128-ctr",
@@ -179,25 +206,14 @@
             "mac": "10ee5db98f1a653c9bda7657f3b3b8bd55dd2fec93936e6b1783af912f9167c2",
         },
         "id": "1af390c5-c4cf-46d0-9341-5374e1a84959",
         "version": 3,
     }
 
 
-@pytest.fixture(scope="session")
-def temp_accounts_path(config):
-    path = Path(config.DATA_FOLDER) / "accounts"
-    path.mkdir(exist_ok=True, parents=True)
-
-    yield path
-
-    if path.is_dir():
-        shutil.rmtree(path)
-
-
 @pytest.fixture
 def runner():
     return CliRunner()
 
 
 @pytest.fixture
 def networks_disconnected():
@@ -237,21 +253,21 @@
     return eth_tester_provider.network_manager
 
 
 @pytest.fixture
 def geth_provider(networks):
     if (
         not networks.active_provider
-        or networks.provider.name != "geth"
+        or networks.provider.name != "node"
         or not networks.provider.is_connected
         or getattr(networks.provider, "uri", "") != GETH_URI
     ):
         test_acct_100 = "0x63c7f11162dBFC374DC6f5C0B3Aa26C618846a85"
         with networks.ethereum.local.use_provider(
-            "geth", provider_settings={"uri": GETH_URI, "extra_funded_accounts": [test_acct_100]}
+            "node", provider_settings={"uri": GETH_URI, "extra_funded_accounts": [test_acct_100]}
         ) as provider:
             yield provider
     else:
         yield networks.provider
 
 
 @contextmanager
@@ -260,15 +276,15 @@
         raise AssertionError("Isolation should only be used with a connected provider.")
 
     init_network_name = ape.chain.provider.network.name
     init_provider_name = ape.chain.provider.name
 
     try:
         snapshot = ape.chain.snapshot()
-    except APINotImplementedError:
+    except (APINotImplementedError, ProviderNotConnectedError):
         # Provider not used or connected in test.
         snapshot = None
 
     yield
 
     if (
         snapshot is None
@@ -276,94 +292,75 @@
         or ape.chain.provider.network.name != init_network_name
         or ape.chain.provider.name != init_provider_name
     ):
         return
 
     try:
         ape.chain.restore(snapshot)
-    except UnknownSnapshotError:
+    except (UnknownSnapshotError, ProviderNotConnectedError):
         # Assume snapshot removed for testing reasons
         # or the provider was not needed to be connected for the test.
         pass
 
 
 @pytest.fixture(autouse=True)
 def eth_tester_isolation(eth_tester_provider):
     with _isolation():
         yield
 
 
-@pytest.fixture(scope="session")
-def temp_config(config):
-    @contextmanager
-    def func(data: Optional[Dict] = None):
-        data = data or {}
-        with tempfile.TemporaryDirectory() as temp_dir_str:
-            temp_dir = Path(temp_dir_str)
-            config._cached_configs = {}
-            config_file = temp_dir / CONFIG_FILE_NAME
-            config_file.touch()
-            config_file.write_text(yaml.dump(data))
-
-            with config.using_project(temp_dir) as temp_project:
-                yield temp_project
-
-            config_file.unlink()
-            config._cached_configs = {}
-
-    return func
-
-
 @pytest.fixture
 def empty_data_folder():
-    current_data_folder = ape.config.DATA_FOLDER
-    ape.config.DATA_FOLDER = Path(mkdtemp()).resolve()
-    ape.config.dependency_manager.DATA_FOLDER = ape.config.DATA_FOLDER
+    # Avoid user's global ape-config data.
+    if "global_config" in (ape.config.__dict__ or {}):
+        del ape.config.__dict__["global_config"]
+
+    shutil.rmtree(DATA_FOLDER, ignore_errors=True)
+    DATA_FOLDER.mkdir(parents=True, exist_ok=True)
     yield
-    ape.config.DATA_FOLDER = current_data_folder
-    ape.config.dependency_manager.DATA_FOLDER = ape.config.DATA_FOLDER
 
 
 @pytest.fixture
-def keyfile_account(owner, keyparams, temp_accounts_path, temp_keyfile_account_ctx):
-    with temp_keyfile_account_ctx(temp_accounts_path, ALIAS, keyparams, owner) as account:
+def keyfile_account(owner, keyparams, temp_keyfile_account_ctx):
+    with temp_keyfile_account_ctx(ALIAS, keyparams, owner) as account:
         # Ensure starts off locked.
         account.lock()
         yield account
 
 
 @pytest.fixture
 def temp_keyfile_account_ctx():
     @contextmanager
-    def _temp_keyfile_account(base_path: Path, alias: str, keyparams, sender):
-        test_keyfile_path = base_path / f"{alias}.json"
+    def _temp_keyfile_account(alias: str, keyparams, sender):
+        accts_folder = DATA_FOLDER / "accounts"
+        accts_folder.mkdir(parents=True, exist_ok=True)
+        test_keyfile_path = accts_folder / f"{alias}.json"
 
-        if not test_keyfile_path.is_file():
-            account = _make_keyfile_account(base_path, alias, keyparams, sender)
-        else:
+        if test_keyfile_path.is_file():
             account = ape.accounts.load(ALIAS)
+        else:
+            account = _make_keyfile_account(accts_folder, alias, keyparams, sender)
 
         try:
             yield account
         finally:
             if test_keyfile_path.is_file():
                 test_keyfile_path.unlink()
 
     return _temp_keyfile_account
 
 
-def _make_keyfile_account(base_path: Path, alias: str, params: Dict, funder):
+def _make_keyfile_account(base_path: Path, alias: str, params: dict, funder):
     test_keyfile_path = base_path / f"{alias}.json"
 
     if test_keyfile_path.is_file():
         # Corrupted from a previous test
         test_keyfile_path.unlink()
 
     test_keyfile_path.write_text(json.dumps(params))
-
     acct = ape.accounts.load(alias)
     funder.transfer(acct, "25 ETH")  # Auto-fund this account
     return acct
 
 
 def skip_if_plugin_installed(*plugin_names: str):
     """
@@ -410,20 +407,29 @@
     return ZERO_ADDRESS
 
 
 @pytest.fixture
 def ape_caplog(caplog):
     class ApeCaplog:
         def __init__(self, caplog_level: LogLevel = LogLevel.WARNING):
+            self.level = caplog_level
             self.messages_at_start = list(caplog.messages)
             self.set_levels(caplog_level=caplog_level)
 
+        @only_raise_attribute_error
         def __getattr__(self, name: str) -> Any:
             return getattr(caplog, name)
 
+        @contextmanager
+        def at_level(self, level: LogLevel):
+            original = self.level
+            self.set_levels(level)
+            yield
+            self.set_levels(original)
+
         @property
         def fail_message(self) -> str:
             if caplog.messages:
                 last_message = caplog.messages[-1]
                 return f"Actual last message: {last_message}"
 
             elif self.messages_at_start:
@@ -440,16 +446,16 @@
         def head(self) -> str:
             """
             A str representing the latest logged line.
             Initialized to empty str.
             """
             return caplog.messages[-1] if len(caplog.messages) else ""
 
-        @classmethod
-        def set_levels(cls, caplog_level: LogLevel = LogLevel.WARNING):
+        def set_levels(self, caplog_level: LogLevel = LogLevel.WARNING):
+            self.level = caplog_level
             logger.set_level(LogLevel.INFO)
             caplog.set_level(caplog_level)
 
         def assert_last_log(self, message: str):
             assert message in self.head, self.fail_message
 
         def assert_last_log_with_retries(
@@ -492,32 +498,72 @@
     """
     Same CLI commands are better tested using a python subprocess,
     such as `ape test` commands because duplicate pytest main methods
     do not run well together, or `ape plugins` commands, which may
     modify installed plugins.
     """
 
-    def __init__(self, root_cmd: Optional[Sequence[str]] = None):
+    def __init__(
+        self, root_cmd: Optional[Sequence[str]] = None, data_folder: Optional[Path] = None
+    ):
         self.root_cmd = root_cmd or []
+        self.data_folder = data_folder
 
-    def invoke(self, subcommand: Optional[Sequence[str]] = None):
-        subcommand = subcommand or []
+    def invoke(self, *subcommand: str, input=None, timeout: int = 40):
+        subcommand = subcommand or ()
         cmd_ls = [*self.root_cmd, *subcommand]
-        completed_process = subprocess.run(cmd_ls, capture_output=True, text=True)
-        return SubprocessResult(completed_process)
+
+        env = dict(os.environ)
+        if self.data_folder:
+            env["APE_DATA_FOLDER"] = str(self.data_folder)
+
+        completed_process = subprocess.run(
+            cmd_ls, capture_output=True, env=env, input=input, text=True, timeout=timeout
+        )
+        result = SubprocessResult(completed_process)
+        sys.stdin = sys.__stdin__
+        return result
 
 
 class ApeSubprocessRunner(SubprocessRunner):
     """
     Subprocess runner for Ape-specific commands.
     """
 
-    def __init__(self, root_cmd: Optional[Sequence[str]] = None):
+    def __init__(
+        self,
+        root_cmd: Optional[Union[str, Sequence[str]]] = None,
+        data_folder: Optional[Path] = None,
+    ):
         ape_path = Path(sys.executable).parent / "ape"
-        super().__init__([str(ape_path), *(root_cmd or [])])
+
+        root = root_cmd or ()
+        if isinstance(root, str):
+            root = (root,)
+
+        super().__init__([str(ape_path), *root], data_folder=data_folder)
+        self.project = None
+
+    def invoke(self, *subcommand: str, input=None, timeout: int = 40):
+        if self.project:
+            try:
+                here = os.getcwd()
+            except Exception:
+                here = None
+
+            os.chdir(f"{self.project.path}")
+
+        else:
+            here = None
+
+        result = super().invoke(*subcommand, input=input, timeout=timeout)
+        if here:
+            os.chdir(here)
+
+        return result
 
 
 class SubprocessResult:
     def __init__(self, completed_process: subprocess.CompletedProcess):
         self._completed_process = completed_process
 
     @property
@@ -532,15 +578,15 @@
 CUSTOM_NETWORK_0 = "apenet"
 CUSTOM_NETWORK_CHAIN_ID_0 = 944898498948934528628
 CUSTOM_NETWORK_1 = "apenet1"
 CUSTOM_NETWORK_CHAIN_ID_1 = 944898498948934528629
 CUSTOM_BLOCK_TIME = 123
 
 
-def _make_net(name: str, chain_id: int, **kwargs) -> Dict:
+def _make_net(name: str, chain_id: int, **kwargs) -> dict:
     return {"name": name, "chain_id": chain_id, "ecosystem": "ethereum", **kwargs}
 
 
 CUSTOM_NETWORKS_CONFIG = {
     "networks": {
         "custom": [
             _make_net(CUSTOM_NETWORK_0, CUSTOM_NETWORK_CHAIN_ID_0),
@@ -552,20 +598,14 @@
 
 @pytest.fixture(scope="session")
 def custom_networks_config_dict():
     return CUSTOM_NETWORKS_CONFIG
 
 
 @pytest.fixture(scope="session")
-def custom_networks_config(temp_config, custom_networks_config_dict):
-    with temp_config(custom_networks_config_dict):
-        yield custom_networks_config_dict
-
-
-@pytest.fixture(scope="session")
 def custom_network_name_0():
     return CUSTOM_NETWORK_0
 
 
 @pytest.fixture(scope="session")
 def custom_network_name_1():
     return CUSTOM_NETWORK_1
@@ -578,9 +618,20 @@
 
 @pytest.fixture(scope="session")
 def custom_network_chain_id_1():
     return CUSTOM_NETWORK_CHAIN_ID_1
 
 
 @pytest.fixture
-def custom_network(ethereum, custom_networks_config):
-    return ethereum.apenet
+def custom_network(ethereum, project, custom_networks_config_dict):
+    with project.temp_config(**custom_networks_config_dict):
+        yield ethereum.apenet
+
+
+@pytest.fixture
+def config_wrapper(mocker):
+    return ConfigWrapper(mocker.MagicMock())
+
+
+@pytest.fixture
+def gas_tracker(config_wrapper):
+    return GasTracker(config_wrapper)
```

### Comparing `eth-ape-0.7.9/tests/functional/conftest.py` & `eth-ape-0.8.0/tests/functional/conftest.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,18 @@
 import threading
 import time
 from contextlib import contextmanager
-from distutils.dir_util import copy_tree
 from pathlib import Path
+from shutil import copytree
 from typing import Optional, cast
 
 import pytest
 from eth_pydantic_types import HexBytes
-from ethpm_types import ContractType, MethodABI
+from ethpm_types import ContractType, ErrorABI, MethodABI
+from ethpm_types.abi import ABIType
 
 import ape
 from ape.api.networks import LOCAL_NETWORK_NAME
 from ape.contracts import ContractContainer, ContractInstance
 from ape.contracts.base import ContractCallHandler
 from ape.exceptions import ChainError, ContractLogicError, ProviderError
 from ape.logging import LogLevel
@@ -172,16 +173,16 @@
 
 @pytest.fixture(scope="session")
 def address():
     return TEST_ADDRESS
 
 
 @pytest.fixture
-def second_keyfile_account(sender, keyparams, temp_accounts_path, temp_keyfile_account_ctx):
-    with temp_keyfile_account_ctx(temp_accounts_path, ALIAS_2, keyparams, sender) as account:
+def second_keyfile_account(sender, keyparams, temp_keyfile_account_ctx):
+    with temp_keyfile_account_ctx(ALIAS_2, keyparams, sender) as account:
         # Ensure starts off locked.
         account.lock()
         yield account
 
 
 @pytest.fixture(scope="session")
 def solidity_contract_type(get_contract_type) -> ContractType:
@@ -300,53 +301,56 @@
 @pytest.fixture
 def ds_note_test_contract(eth_tester_provider, vyper_contract_type, owner, get_contract_type):
     contract_type = get_contract_type("DsNoteTest")
     contract_container = ContractContainer(contract_type=contract_type)
     return contract_container.deploy(sender=owner)
 
 
-@pytest.fixture
-def project_with_contract(temp_config):
-    with temp_config() as project:
-        copy_tree(str(APE_PROJECT_FOLDER), str(project.path))
+@pytest.fixture(scope="session")
+def project_with_contract():
+    with ape.Project(APE_PROJECT_FOLDER).isolate_in_tempdir() as project:
         yield project
 
 
-@pytest.fixture
-def project_with_source_files_contract(temp_config):
+@pytest.fixture(scope="session")
+def project_with_source_files_contract(project_with_contract):
     bases_source_dir = BASE_SOURCES_DIRECTORY
-    project_source_dir = APE_PROJECT_FOLDER
+    project_source_dir = project_with_contract.path
 
-    with temp_config() as project:
-        copy_tree(str(project_source_dir), str(project.path))
-        copy_tree(str(bases_source_dir), f"{project.path}/contracts/")
-        yield project
+    with ape.Project.create_temporary_project() as tmp_project:
+        copytree(project_source_dir, str(tmp_project.path), dirs_exist_ok=True)
+        copytree(bases_source_dir, tmp_project.path / "contracts", dirs_exist_ok=True)
+        yield tmp_project
 
 
 @pytest.fixture
 def clean_contracts_cache(chain):
     original_cached_contracts = chain.contracts._local_contract_types
     chain.contracts._local_contract_types = {}
     yield
     chain.contracts._local_contract_types = original_cached_contracts
 
 
 @pytest.fixture
-def project_with_dependency_config(temp_config):
+def project_with_dependency_config(project):
     dependencies_config = {
+        "contracts_folder": "functional/data/contracts/local",
         "dependencies": [
             {
                 "local": str(PROJECT_WITH_LONG_CONTRACTS_FOLDER),
                 "name": "testdependency",
-                "contracts_folder": "source/v0.1",
+                "config_override": {
+                    "contracts_folder": "source/v0.1",
+                },
+                "version": "releases/v6",  # Testing having a slash in version.
             }
-        ]
+        ],
     }
-    with temp_config(dependencies_config) as project:
-        yield project
+    with project.isolate_in_tempdir(**dependencies_config) as tmp_project:
+        yield tmp_project
 
 
 @pytest.fixture(scope="session")
 def base_projects_directory():
     return BASE_PROJECTS_DIRECTORY
 
 
@@ -508,15 +512,15 @@
     yield
     logger.set_level(initial_level)
 
 
 @pytest.fixture
 def dummy_live_network(chain):
     original_network = chain.provider.network.name
-    chain.provider.network.name = "goerli"
+    chain.provider.network.name = "sepolia"
     yield chain.provider.network
     chain.provider.network.name = original_network
 
 
 @pytest.fixture(scope="session")
 def proxy_contract_container(get_contract_type):
     return ContractContainer(get_contract_type("proxy"))
@@ -593,14 +597,19 @@
 
 @pytest.fixture
 def vyper_factory(owner, get_contract_type):
     return owner.deploy(ContractContainer(get_contract_type("VyperFactory")))
 
 
 @pytest.fixture
+def vyper_printing(owner, get_contract_type):
+    return owner.deploy(ContractContainer(get_contract_type("printing")))
+
+
+@pytest.fixture
 def vyper_blueprint(owner, vyper_contract_container):
     receipt = owner.declare(vyper_contract_container)
     return receipt.contract_address
 
 
 @pytest.fixture
 def minimal_proxy_container():
@@ -666,27 +675,29 @@
 
 
 @pytest.fixture
 def mock_compiler(mocker):
     mock = mocker.MagicMock()
     mock.name = "mock"
     mock.ext = ".__mock__"
+    mock.tracked_settings = []
 
-    def mock_compile(paths, base_path=None):
-        mock.tracked_settings.append(mock.compiler_settings)
+    def mock_compile(paths, project=None, settings=None):
+        settings = settings or {}
+        mock.tracked_settings.append(settings)
         result = []
         for path in paths:
             if path.suffix == mock.ext:
                 name = path.stem
                 code = HexBytes(123).hex()
                 data = {
                     "contractName": name,
                     "abi": [],
                     "deploymentBytecode": code,
-                    "sourceId": path.name,
+                    "sourceId": f"{project.contracts_folder.name}/{path.name}",
                 }
 
                 # Check for mocked overrides
                 overrides = mock.overrides
                 if isinstance(overrides, dict):
                     data = {**data, **overrides}
 
@@ -703,15 +714,15 @@
 def mock_sepolia(ethereum, eth_tester_provider, vyper_contract_instance):
     """
     Temporarily tricks Ape into thinking the local network
     is Sepolia so we can test features that require a live
     network.
     """
     # Ensuring contract exists before hack.
-    # This allow the nework to be past genesis which is more realistic.
+    # This allow the network to be past genesis which is more realistic.
     _ = vyper_contract_instance
     eth_tester_provider.network.name = "sepolia"
     yield eth_tester_provider.network
     eth_tester_provider.network.name = LOCAL_NETWORK_NAME
 
 
 @pytest.fixture
@@ -725,40 +736,76 @@
     ethereum.sepolia_fork.__dict__["providers"] = {}
     yield
     if actual:
         ethereum.sepolia_fork.__dict__["providers"] = actual
 
 
 @pytest.fixture
-def mock_fork_provider(mocker, ethereum):
+def mock_fork_provider(mocker, ethereum, mock_sepolia):
     """
     A fake provider representing something like ape-foundry
     that can fork networks (only uses sepolia-fork).
     """
-    actual = ethereum.sepolia_fork.__dict__.pop("providers", {})
+    initial_providers = ethereum.sepolia_fork.__dict__.pop("providers", {})
+    initial_default = ethereum.sepolia_fork._default_provider
     mock_provider = mocker.MagicMock()
     mock_provider.name = "mock"
     mock_provider.network = ethereum.sepolia_fork
 
     # Have to do this because providers are partials.
     def fake_partial(*args, **kwargs):
         mock_provider.partial_call = (args, kwargs)
         return mock_provider
 
+    ethereum.sepolia_fork._default_provider = "mock"
     ethereum.sepolia_fork.__dict__["providers"] = {"mock": fake_partial}
-
     yield mock_provider
-
-    if actual:
-        ethereum.sepolia_fork.__dict__["providers"] = actual
+    if initial_providers:
+        ethereum.sepolia_fork.__dict__["providers"] = initial_providers
+    if initial_default:
+        ethereum.sepolia_fork._default_provider = initial_default
 
 
 @pytest.fixture
 def delete_account_after(project_path):
     @contextmanager
     def delete_account_context(alias: str):
         yield
         account_path = ape.config.DATA_FOLDER / "accounts" / f"{alias}.json"
         if account_path.exists():
             account_path.unlink()
 
     return delete_account_context
+
+
+@pytest.fixture
+def setup_custom_error(chain):
+    def fn(addr: AddressType):
+        abi = [
+            ErrorABI(
+                type="error",
+                name="AllowanceExpired",
+                inputs=[
+                    ABIType(
+                        name="deadline", type="uint256", components=None, internal_type="uint256"
+                    )
+                ],
+            ),
+            MethodABI(
+                type="function",
+                name="execute",
+                stateMutability="payable",
+                inputs=[
+                    ABIType(name="commands", type="bytes", components=None, internal_type="bytes"),
+                    ABIType(
+                        name="inputs", type="bytes[]", components=None, internal_type="bytes[]"
+                    ),
+                ],
+                outputs=[],
+            ),
+        ]
+        contract_type = ContractType(abi=abi)
+
+        # Hack in contract-type.
+        chain.contracts._local_contract_types[addr] = contract_type
+
+    return fn
```

### Comparing `eth-ape-0.7.9/tests/functional/conversion/test_encode_structs.py` & `eth-ape-0.8.0/tests/functional/conversion/test_encode_structs.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-from typing import Dict, Tuple, cast
+from typing import cast
 
 import pytest
 from eth_pydantic_types import HexBytes
 from ethpm_types import BaseModel
 from ethpm_types.abi import MethodABI
 
 from ape.types import AddressType
@@ -60,23 +60,23 @@
 def test_encode_structs(data_type, ethereum):
     data = DATA_BY_TYPE_KEY[data_type]
     encode_calldata = ethereum.encode_calldata
     assert encode_calldata(ABI, data) == EXPECTED
 
 
 def test_encode_structs_as_tuple_with_unconverted(sender, ethereum):
-    normal_data: Tuple = DATA_BY_TYPE_KEY["tuple"]  # type: ignore[assignment]
+    normal_data: tuple = DATA_BY_TYPE_KEY["tuple"]  # type: ignore[assignment]
     data = list(normal_data)
     data[-1] = sender
     actual = ethereum.encode_calldata(ABI, normal_data)
     assert actual == EXPECTED
 
 
 def test_encode_structs_as_dict_with_unconverted(sender, ethereum):
-    normal_data: Dict = DATA_BY_TYPE_KEY["dict"]  # type: ignore[assignment]
+    normal_data: dict = DATA_BY_TYPE_KEY["dict"]  # type: ignore[assignment]
     data = dict(normal_data)
     data["d"] = sender
     actual = ethereum.encode_calldata(ABI, normal_data)
     assert actual == EXPECTED
 
 
 def test_encode_structs_as_object_with_unconverted(sender, ethereum):
@@ -84,15 +84,15 @@
     data = normal_data.model_copy()
     data.d = sender
     actual = ethereum.encode_calldata(ABI, normal_data)
     assert actual == EXPECTED
 
 
 def test_encode_struct_using_dict_with_more_fields(sender, ethereum):
-    normal_data: Dict = DATA_BY_TYPE_KEY["dict"]  # type: ignore[assignment]
+    normal_data: dict = DATA_BY_TYPE_KEY["dict"]  # type: ignore[assignment]
     data = dict(normal_data)
     data["extra"] = "foobar"  # Should be ignored since not in ABI.
     actual = ethereum.encode_calldata(ABI, normal_data)
     assert actual == EXPECTED
 
 
 def test_encode_struct_using_object_with_more_fields(sender, ethereum):
```

### Comparing `eth-ape-0.7.9/tests/functional/conversion/test_ether.py` & `eth-ape-0.8.0/tests/functional/conversion/test_ether.py`

 * *Files 7% similar despite different names*

```diff
@@ -14,27 +14,27 @@
         max_value=2**256 - 1,
         allow_infinity=False,
         allow_nan=False,
     ),
     unit=st.sampled_from(list(ETHER_UNITS.keys())),
 )
 def test_ether_conversions(value, unit, convert):
-    actual = convert(value=f"{value} {unit}", type=int)
+    actual = convert(f"{value} {unit}", int)
     expected = int(value * ETHER_UNITS[unit])
     assert actual == expected
 
 
 def test_bad_type(convert):
     with pytest.raises(ConversionError) as err:
-        convert(value="something", type=float)
+        convert("something", float)
 
     expected = (
         "Type '<class 'float'>' must be one of " "[AddressType, bytes, int, Decimal, bool, str]."
     )
     assert str(err.value) == expected
 
 
 def test_no_registered_converter(convert):
     with pytest.raises(ConversionError) as err:
-        convert(value="something", type=ChecksumAddress)
+        convert("something", ChecksumAddress)
 
     assert str(err.value) == "No conversion registered to handle 'something'."
```

### Comparing `eth-ape-0.7.9/tests/functional/conversion/test_timestamp.py` & `eth-ape-0.8.0/tests/functional/conversion/test_timestamp.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/contracts/ethereum/abi/contract_abi.json` & `eth-ape-0.8.0/tests/functional/data/contracts/ethereum/abi/contract_abi.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/BeaconProxy.json` & `eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/BeaconProxy.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/ContractA.json` & `eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/ContractA.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/ContractB.json` & `eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/ContractB.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/ContractC.json` & `eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/ContractC.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/DsNoteTest.json` & `eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/DsNoteTest.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/HasError.json` & `eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/HasError.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/InterfaceImplementation.json` & `eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/InterfaceImplementation.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/RevertsContract.json` & `eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/RevertsContract.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/SolFallbackAndReceive.json` & `eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/SolFallbackAndReceive.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/SolidityContract.json` & `eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/SolidityContract.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/SubReverts.json` & `eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/SubReverts.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/VyDefault.json` & `eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/VyDefault.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/VyperContract.json` & `eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/VyperContract.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/VyperFactory.json` & `eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/VyperFactory.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/beacon.json` & `eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/beacon.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/eip1967.json` & `eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/eip1967.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/contracts/ethereum/local/proxy.json` & `eth-ape-0.8.0/tests/functional/data/contracts/ethereum/local/proxy.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/projects/ApeProject/contracts/Contract.json` & `eth-ape-0.8.0/tests/functional/data/projects/ApeProject/contracts/Contract.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/sources/ContractA.sol` & `eth-ape-0.8.0/tests/functional/data/sources/ContractA.sol`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/sources/ContractB.sol` & `eth-ape-0.8.0/tests/functional/data/sources/ContractB.sol`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/sources/ContractC.sol` & `eth-ape-0.8.0/tests/functional/data/sources/ContractC.sol`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/sources/HasError.sol` & `eth-ape-0.8.0/tests/functional/data/sources/HasError.sol`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/sources/RevertsContract.vy` & `eth-ape-0.8.0/tests/functional/data/sources/RevertsContract.vy`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/sources/SolidityContract.sol` & `eth-ape-0.8.0/tests/functional/data/sources/SolidityContract.sol`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/data/sources/VyperContract.vy` & `eth-ape-0.8.0/tests/functional/data/sources/VyperContract.vy`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/geth/conftest.py` & `eth-ape-0.8.0/tests/functional/geth/conftest.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,23 +1,18 @@
 import copy
 from pathlib import Path
 
 import pytest
 
 from ape.contracts import ContractContainer
-from ape_geth.provider import Geth
+from ape_node.provider import Node
 from tests.functional.data.python import TRACE_RESPONSE
 
 
 @pytest.fixture
-def txn_hash():
-    return "0x053cba5c12172654d894f66d5670bab6215517a94189a9ffc09bc40a589ec04d"
-
-
-@pytest.fixture
 def parity_trace_response():
     return TRACE_RESPONSE
 
 
 @pytest.fixture
 def geth_contract(geth_account, vyper_contract_container, geth_provider):
     return geth_account.deploy(vyper_contract_container, 0)
@@ -58,16 +53,16 @@
     """
     ct = get_contract_type("ContractB")
     return owner.deploy(ContractContainer(ct), leaf_contract_geth)
 
 
 @pytest.fixture
 def mock_geth(geth_provider, mock_web3):
-    provider = Geth(
-        name="geth",
+    provider = Node(
+        name="node",
         network=geth_provider.network,
         provider_settings={},
         data_folder=Path("."),
         request_header={},
     )
     original_web3 = provider._web3
     provider._web3 = mock_web3
@@ -85,28 +80,28 @@
     return geth_vyper_contract.setNumber(44, sender=owner)
 
 
 @pytest.fixture
 def custom_network_connection(
     geth_provider,
     ethereum,
-    temp_config,
+    project,
     custom_network_name_0,
     custom_networks_config_dict,
     networks,
 ):
     data = copy.deepcopy(custom_networks_config_dict)
     data["networks"]["custom"][0]["chain_id"] = geth_provider.chain_id
     config = {
         ethereum.name: {custom_network_name_0: {"default_transaction_type": 0}},
         geth_provider.name: {ethereum.name: {custom_network_name_0: {"uri": geth_provider.uri}}},
         **data,
     }
     actual = geth_provider.network
-    with temp_config(config):
+    with project.temp_config(**config):
         geth_provider.network = ethereum.apenet
         try:
-            with networks.ethereum.apenet.use_provider("geth"):
+            with networks.ethereum.apenet.use_provider("node"):
                 yield
 
         finally:
             geth_provider.network = actual
```

### Comparing `eth-ape-0.7.9/tests/functional/geth/test_contract.py` & `eth-ape-0.8.0/tests/functional/geth/test_contract.py`

 * *Files 8% similar despite different names*

```diff
@@ -25,15 +25,27 @@
     assert geth_contract.myNumber() == 102
 
     # Verify the estimate gas RPC was not used (since we are using max_gas).
     assert estimate_gas_spy.call_count == 0
 
 
 @geth_process_test
-def test_revert(accounts, not_owner, geth_contract):
+def test_contract_call_show_trace(geth_contract, geth_account):
+    """
+    Show the `show_trace=True` does not corrupt the value.
+    Note: The provider uses `debug_traceCall` to get the result instead of
+    `eth_call`.
+    """
+    geth_contract.setNumber(203, sender=geth_account)
+    actual = geth_contract.myNumber(show_trace=True)
+    assert actual == 203
+
+
+@geth_process_test
+def test_tx_revert(accounts, not_owner, geth_contract):
     # 'sender' is not the owner so it will revert (with a message)
     with pytest.raises(ContractLogicError, match="!authorized") as err:
         geth_contract.setNumber(5, sender=not_owner)
 
     assert err.value.txn is not None
```

### Comparing `eth-ape-0.7.9/tests/functional/geth/test_provider.py` & `eth-ape-0.8.0/tests/functional/geth/test_provider.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,34 +1,39 @@
 from pathlib import Path
 from typing import cast
 
 import pytest
 from eth_pydantic_types import HashBytes32
 from eth_typing import HexStr
+from eth_utils import keccak
 from evmchains import PUBLIC_CHAIN_META
 from hexbytes import HexBytes
+from web3.exceptions import ContractLogicError as Web3ContractLogicError
 from web3.exceptions import ExtraDataLengthError
 from web3.middleware import geth_poa_middleware
 
 from ape.exceptions import (
     APINotImplementedError,
     BlockNotFoundError,
+    ContractLogicError,
     NetworkMismatchError,
     TransactionError,
     TransactionNotFoundError,
 )
+from ape.utils import to_int
 from ape_ethereum.ecosystem import Block
-from ape_ethereum.provider import DEFAULT_SETTINGS
+from ape_ethereum.provider import DEFAULT_SETTINGS, EthereumNodeProvider
 from ape_ethereum.transactions import (
     AccessList,
     AccessListTransaction,
+    DynamicFeeTransaction,
     TransactionStatusEnum,
     TransactionType,
 )
-from ape_geth.provider import GethDevProcess, GethNotInstalledError
+from ape_node.provider import GethDevProcess, NodeSoftwareNotInstalledError
 from tests.conftest import GETH_URI, geth_process_test
 
 
 @pytest.fixture
 def web3_factory(mocker):
     return mocker.patch("ape_ethereum.provider._create_web3")
 
@@ -38,59 +43,72 @@
     assert geth_provider.http_uri == GETH_URI
     assert not geth_provider.ws_uri
     assert geth_provider.uri == GETH_URI
 
 
 @geth_process_test
 def test_uri_localhost_not_running_uses_random_default(config):
-    cfg = config.get_config("geth").ethereum.mainnet
+    cfg = config.get_config("node").ethereum.mainnet
     assert cfg["uri"] in PUBLIC_CHAIN_META["ethereum"]["mainnet"]["rpc"]
-    cfg = config.get_config("geth").ethereum.sepolia
+    cfg = config.get_config("node").ethereum.sepolia
     assert cfg["uri"] in PUBLIC_CHAIN_META["ethereum"]["sepolia"]["rpc"]
 
 
 @geth_process_test
-def test_uri_when_configured(geth_provider, temp_config, ethereum):
+def test_uri_when_configured(geth_provider, project, ethereum):
     settings = geth_provider.provider_settings
     geth_provider.provider_settings = {}
     value = "https://value/from/config"
-    config = {"geth": {"ethereum": {"local": {"uri": value}, "mainnet": {"uri": value}}}}
+    config = {"node": {"ethereum": {"local": {"uri": value}, "mainnet": {"uri": value}}}}
     expected = DEFAULT_SETTINGS["uri"]
     network = ethereum.get_network("mainnet")
 
     try:
-        with temp_config(config):
+        with project.temp_config(**config):
             # Assert we use the config value.
             actual_local_uri = geth_provider.uri
             # Assert provider settings takes precedence.
-            provider = network.get_provider("geth", provider_settings={"uri": expected})
+            provider = network.get_provider("node", provider_settings={"uri": expected})
             actual_mainnet_uri = provider.uri
 
     finally:
         geth_provider.provider_settings = settings
 
     assert actual_local_uri == value
     assert actual_mainnet_uri == expected
 
 
 @geth_process_test
 def test_repr_connected(geth_provider):
-    assert repr(geth_provider) == "<geth chain_id=1337>"
+    actual = repr(geth_provider)
+    expected = f"<Node ({geth_provider.client_version}) chain_id=1337>"
+    assert actual == expected
 
 
 @geth_process_test
 def test_repr_on_local_network_and_disconnected(networks):
-    geth = networks.get_provider_from_choice("ethereum:local:geth")
-    assert repr(geth) == "<geth chain_id=1337>"
+    node = networks.get_provider_from_choice("ethereum:local:node")
+    # Ensure disconnected.
+    if w3 := node._web3:
+        node._web3 = None
+
+    actual = repr(node)
+    expected = "<Node chain_id=1337>"
+    assert actual == expected
+
+    if w3:
+        node._web3 = w3
 
 
 @geth_process_test
 def test_repr_on_live_network_and_disconnected(networks):
-    geth = networks.get_provider_from_choice("ethereum:goerli:geth")
-    assert repr(geth) == "<geth chain_id=5>"
+    node = networks.get_provider_from_choice("ethereum:sepolia:node")
+    actual = repr(node)
+    expected = "<Node chain_id=11155111>"
+    assert actual == expected
 
 
 @geth_process_test
 def test_get_logs(geth_contract, geth_account):
     geth_contract.setNumber(101010, sender=geth_account)
     actual = geth_contract.NumberChange[-1]
     assert actual.event_name == "NumberChange"
@@ -101,16 +119,16 @@
 @geth_process_test
 def test_chain_id_when_connected(geth_provider):
     assert geth_provider.chain_id == 1337
 
 
 @geth_process_test
 def test_chain_id_live_network_not_connected(networks):
-    geth = networks.get_provider_from_choice("ethereum:goerli:geth")
-    assert geth.chain_id == 5
+    node = networks.get_provider_from_choice("ethereum:sepolia:node")
+    assert node.chain_id == 11155111
 
 
 @geth_process_test
 def test_chain_id_live_network_connected_uses_web3_chain_id(mocker, geth_provider):
     mock_network = mocker.MagicMock()
     mock_network._chain_id = 999999999  # Shouldn't use hardcoded network
     mock_network.name = "mock"
@@ -127,42 +145,42 @@
 
 
 @geth_process_test
 def test_connect_wrong_chain_id(ethereum, geth_provider, web3_factory):
     start_network = geth_provider.network
     expected_error_message = (
         f"Provider connected to chain ID '{geth_provider._web3.eth.chain_id}', "
-        "which does not match network chain ID '5'. "
-        "Are you connected to 'goerli'?"
+        "which does not match network chain ID '11155111'. "
+        "Are you connected to 'sepolia'?"
     )
 
     try:
-        geth_provider.network = ethereum.get_network("goerli")
+        geth_provider.network = ethereum.get_network("sepolia")
 
         # Ensure when reconnecting, it does not use HTTP
         web3_factory.return_value = geth_provider._web3
         with pytest.raises(NetworkMismatchError, match=expected_error_message):
             geth_provider.connect()
     finally:
         geth_provider.network = start_network
 
 
 @geth_process_test
 def test_connect_to_chain_that_started_poa(mock_web3, web3_factory, ethereum):
     """
     Ensure that when connecting to a chain that
-    started out as PoA, such as Goerli, we include
+    started out as PoA, such as Sepolia, we include
     the right middleware. Note: even if the chain
     is no longer PoA, we still need the middleware
     to fetch blocks during the PoA portion of the chain.
     """
     mock_web3.eth.get_block.side_effect = ExtraDataLengthError
-    mock_web3.eth.chain_id = ethereum.goerli.chain_id
+    mock_web3.eth.chain_id = ethereum.sepolia.chain_id
     web3_factory.return_value = mock_web3
-    provider = ethereum.goerli.get_provider("geth")
+    provider = ethereum.sepolia.get_provider("node")
     provider.provider_settings = {"uri": "http://node.example.com"}  # fake
     provider.connect()
 
     # Verify PoA middleware was added.
     assert mock_web3.middleware_onion.inject.call_args[0] == (geth_poa_middleware,)
     assert mock_web3.middleware_onion.inject.call_args[1] == {"layer": 0}
 
@@ -183,18 +201,41 @@
     latest_block = geth_provider.get_block("latest")
     block_id = latest_block.number + 1000
     with pytest.raises(BlockNotFoundError, match=f"Block with ID '{block_id}' not found."):
         geth_provider.get_block(block_id)
 
 
 @geth_process_test
-def test_get_receipt_not_exists_with_timeout(geth_provider, txn_hash):
+def test_get_block_pending(geth_provider, geth_account, geth_second_account, accounts):
+    """
+    Pending timestamps can be weird.
+    This ensures we can check those are various strange states of geth.
+    """
+    actual = geth_provider.get_block("latest")
+    assert isinstance(actual, Block)
+
+    snap = geth_provider.snapshot()
+
+    # Transact to increase block
+    geth_account.transfer(geth_second_account, "1 gwei")
+    actual = geth_provider.get_block("latest")
+    assert isinstance(actual, Block)
+
+    # Restore state before transaction
+    geth_provider.restore(snap)
+    actual = geth_provider.get_block("latest")
+    assert isinstance(actual, Block)
+
+
+@geth_process_test
+def test_get_receipt_not_exists_with_timeout(geth_provider):
+    txn_hash = "0x0123"
     expected = (
         f"Transaction '{txn_hash}' not found. "
-        rf"Error: Transaction HexBytes\('{txn_hash}'\) "
+        rf"Error: Transaction '{txn_hash}' "
         "is not in the chain after 0 seconds"
     )
     with pytest.raises(TransactionNotFoundError, match=expected):
         geth_provider.get_receipt(txn_hash, timeout=0)
 
 
 @geth_process_test
@@ -214,15 +255,15 @@
     actual_block_number = geth_provider.get_block("latest").number
     expected_block_number = snapshot + 1
     actual_nonce = geth_account.nonce
     expected_nonce = start_nonce + 1
     assert actual_block_number == expected_block_number
     assert actual_nonce == expected_nonce
 
-    geth_provider.revert(snapshot)
+    geth_provider.restore(snapshot)
 
     actual_block_number = geth_provider.get_block("latest").number
     expected_block_number = snapshot
     actual_nonce = geth_account.nonce
     expected_nonce = start_nonce
     assert actual_block_number == expected_block_number
     assert actual_nonce == expected_nonce
@@ -272,15 +313,15 @@
 
     # Transact to increase block
     geth_account.transfer(geth_second_account, "1 gwei")
     actual = geth_provider.get_block("latest")
     assert isinstance(actual, Block)
 
     # Restore state before transaction
-    geth_provider.revert(snap)
+    geth_provider.restore(snap)
     actual = geth_provider.get_block("latest")
     assert isinstance(actual, Block)
 
 
 @geth_process_test
 def test_isolate(chain, geth_contract, geth_account):
     number_at_start = 444
@@ -344,17 +385,34 @@
             geth_provider.send_transaction(mock_transaction)
 
     finally:
         geth_provider._web3 = start_web3
 
 
 @geth_process_test
+def test_send_call(geth_provider, ethereum, geth_contract):
+    txn = DynamicFeeTransaction.model_validate(
+        {
+            "chainId": 1337,
+            "to": geth_contract.address,
+            "gas": 4716984,
+            "value": 0,
+            "data": HexBytes(keccak(text="myNumber()")[:4]),
+            "type": 2,
+            "accessList": [],
+        }
+    )
+    actual = geth_provider.send_call(txn)
+    assert to_int(actual) == 0
+
+
+@geth_process_test
 def test_network_choice(geth_provider):
     actual = geth_provider.network_choice
-    expected = "ethereum:local:geth"
+    expected = "ethereum:local:node"
     assert actual == expected
 
 
 @geth_process_test
 def test_network_choice_when_custom(geth_provider):
     name = geth_provider.network.name
     geth_provider.network.name = "custom"
@@ -368,20 +426,20 @@
 
 @geth_process_test
 def test_make_request_not_exists(geth_provider):
     with pytest.raises(
         APINotImplementedError,
         match="RPC method 'ape_thisDoesNotExist' is not implemented by this node instance.",
     ):
-        geth_provider._make_request("ape_thisDoesNotExist")
+        geth_provider.make_request("ape_thisDoesNotExist")
 
 
-def test_geth_not_found():
+def test_geth_bin_not_found():
     bin_name = "__NOT_A_REAL_EXECUTABLE_HOPEFULLY__"
-    with pytest.raises(GethNotInstalledError):
+    with pytest.raises(NodeSoftwareNotInstalledError):
         _ = GethDevProcess(Path.cwd(), executable=bin_name)
 
 
 @geth_process_test
 def test_base_fee(geth_provider, mocker):
     # NOTE: Only mocked to guarantee we are in a state
     #   with history.
@@ -413,28 +471,35 @@
     finally:
         geth_provider._web3.eth.fee_history = orig
 
     assert actual == expected
 
 
 @geth_process_test
-def test_estimate_gas(geth_contract, geth_provider, geth_account):
+def test_estimate_gas_cost(geth_contract, geth_provider, geth_account):
     txn = geth_contract.setNumber.as_transaction(900, sender=geth_account)
     estimate = geth_provider.estimate_gas_cost(txn)
     assert estimate > 0
 
 
 @geth_process_test
-def test_estimate_gas_of_static_fee_txn(geth_contract, geth_provider, geth_account):
+def test_estimate_gas_cost_of_static_fee_txn(geth_contract, geth_provider, geth_account):
     txn = geth_contract.setNumber.as_transaction(900, sender=geth_account, type=0)
     estimate = geth_provider.estimate_gas_cost(txn)
     assert estimate > 0
 
 
 @geth_process_test
+def test_estimate_gas_cost_reverts(geth_contract, geth_provider, geth_second_account):
+    txn = geth_contract.setNumber.as_transaction(900, sender=geth_second_account, type=0)
+    with pytest.raises(ContractLogicError):
+        geth_provider.estimate_gas_cost(txn)
+
+
+@geth_process_test
 @pytest.mark.parametrize("tx_type", TransactionType)
 def test_prepare_transaction_with_max_gas(tx_type, geth_provider, ethereum, geth_account):
     tx = ethereum.create_transaction(type=tx_type.value, sender=geth_account.address)
     tx.gas_limit = None  # Undo set from validator
     assert tx.gas_limit is None, "Test setup failed - couldn't clear tx gas limit."
 
     # NOTE: The local network by default uses max_gas.
@@ -459,7 +524,41 @@
 @geth_process_test
 def test_create_access_list(geth_provider, geth_contract, geth_account):
     tx = geth_contract.setNumber.as_transaction(123, sender=geth_account, type=1)
     actual = geth_provider.create_access_list(tx)
     assert len(actual) > 0
     assert isinstance(actual[0], AccessList)
     assert len(actual[0].storage_keys) > 0
+
+
+@geth_process_test
+def test_send_call_base_class_block_id(networks, ethereum, mocker):
+    """
+    Testing a case where was a bug in the base class for most providers.
+    Note: can't use ape-node as-is, as it overrides `send_call()`.
+    """
+
+    provider = mocker.MagicMock()
+    provider.network.name = "mainnet"
+
+    def hacked_send_call(*args, **kwargs):
+        return EthereumNodeProvider.send_call(provider, *args, **kwargs)
+
+    provider.send_call = hacked_send_call
+    tx = ethereum.create_transaction()
+    block_id = 567
+
+    orig = networks.active_provider
+    networks.active_provider = provider
+    _ = provider.send_call(tx, block_id=block_id, skip_trace=True) == HexStr("0x")
+    networks.active_provider = orig  # put back ASAP
+
+    actual = provider._prepare_call.call_args[-1]["block_identifier"]
+    assert actual == block_id
+
+
+@geth_process_test
+def test_get_virtual_machine_error(geth_provider):
+    expected = "__EXPECTED__"
+    error = Web3ContractLogicError(f"execution reverted: {expected}", "0x08c379a")
+    actual = geth_provider.get_virtual_machine_error(error)
+    assert actual.message == expected
```

### Comparing `eth-ape-0.7.9/tests/functional/geth/text_proxy.py` & `eth-ape-0.8.0/tests/functional/geth/text_proxy.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/test_accounts.py` & `eth-ape-0.8.0/tests/functional/test_accounts.py`

 * *Files 3% similar despite different names*

```diff
@@ -91,17 +91,16 @@
 def test_recover_signer(signer, message):
     signature = signer.sign_message(message)
     assert recover_signer(message, signature) == signer
 
 
 def test_sign_eip712_message(signer):
     foo = Foo(signer.address)  # type: ignore[call-arg]
-    message = foo.signable_message
-    signature = signer.sign_message(message)
-    assert signer.check_signature(message, signature)
+    signature = signer.sign_message(foo)
+    assert signer.check_signature(foo, signature)
 
 
 def test_sign_message_with_prompts(runner, keyfile_account, message):
     # "y\na\ny": yes sign, password, yes keep unlocked
     start_nonce = keyfile_account.nonce
     with runner.isolation(input=f"y\n{PASSPHRASE}\ny"):
         signature = keyfile_account.sign_message(message)
@@ -113,14 +112,29 @@
         assert signature is None
 
     # Nonce should not change from signing messages.
     end_nonce = keyfile_account.nonce
     assert start_nonce == end_nonce
 
 
+def test_sign_raw_hash(runner, keyfile_account):
+    # NOTE: `message` is a 32 byte raw hash, which is treated specially
+    message = b"\xAB" * 32
+
+    # "y\na\ny": yes sign raw hash, password, yes keep unlocked
+    with runner.isolation(input=f"y\n{PASSPHRASE}\ny"):
+        signature = keyfile_account.sign_raw_msghash(message)
+        assert keyfile_account.check_signature(message, signature, recover_using_eip191=False)
+
+    # "n\nn": no sign raw hash: don't sign
+    with runner.isolation(input="n"):
+        signature = keyfile_account.sign_message(message)
+        assert signature is None
+
+
 def test_transfer(sender, receiver, eth_tester_provider, convert):
     initial_receiver_balance = receiver.balance
     initial_sender_balance = sender.balance
     value_str = "24 gwei"
     value_int = convert(value_str, int)
 
     receipt = sender.transfer(receiver, value_str)
@@ -353,37 +367,37 @@
 
 def test_accounts_address_access(owner, accounts):
     assert accounts[owner.address] == owner
 
 
 def test_accounts_address_access_conversion_fail(accounts):
     with pytest.raises(
-        IndexError,
+        KeyError,
         match=(
             r"No account with ID 'FAILS'\. "
             r"Do you have the necessary conversion plugins installed?"
         ),
     ):
         _ = accounts["FAILS"]
 
 
 def test_accounts_address_access_not_found(accounts):
     address = "0x1222262222222922222222222222222222222222"
-    with pytest.raises(IndexError, match=rf"No account with address '{address}'\."):
+    with pytest.raises(KeyError, match=rf"No account with address '{address}'\."):
         _ = accounts[address]
 
 
 def test_test_accounts_address_access_conversion_fail(test_accounts):
-    with pytest.raises(IndexError, match=r"No account with ID 'FAILS'"):
+    with pytest.raises(KeyError, match=r"No account with ID 'FAILS'"):
         _ = test_accounts["FAILS"]
 
 
 def test_test_accounts_address_access_not_found(test_accounts):
     address = "0x1222262222222922222222222222222222222222"
-    with pytest.raises(IndexError, match=rf"No account with address '{address}'\."):
+    with pytest.raises(KeyError, match=rf"No account with address '{address}'\."):
         _ = test_accounts[address]
 
 
 def test_accounts_contains(accounts, owner):
     assert owner.address in accounts
 
 
@@ -407,18 +421,18 @@
     keyfile_account.set_autosign(False)
     with runner.isolation(input=f"y\n{PASSPHRASE}\n"):
         assert keyfile_account.transfer(receiver, "1 gwei")
 
 
 def test_impersonate_not_implemented(accounts, address):
     expected_err_msg = (
-        "Your provider does not support impersonating accounts:\n"
-        f"No account with address '{address}'."
+        r"Your provider does not support impersonating accounts:\\n"
+        rf"No account with address '{address}'\."
     )
-    with pytest.raises(IndexError, match=expected_err_msg):
+    with pytest.raises(KeyError, match=expected_err_msg):
         _ = accounts[address]
 
 
 def test_impersonated_account_ignores_signature_check_on_txn(accounts, address):
     account = ImpersonatedAccount(raw_address=address)
 
     # Impersonate hack, since no providers in core actually support it.
@@ -434,18 +448,18 @@
     # Normally, you'd get a signature error here, but since the account is registered
     # as impersonated, ape lets it slide because it knows it won't match.
     assert isinstance(actual, bytes)
 
 
 def test_contract_as_sender_non_fork_network(contract_instance):
     expected_err_msg = (
-        "Your provider does not support impersonating accounts:\n"
-        f"No account with address '{contract_instance}'."
+        r"Your provider does not support impersonating accounts:\\n"
+        rf"No account with address '{contract_instance}'\."
     )
-    with pytest.raises(IndexError, match=expected_err_msg):
+    with pytest.raises(KeyError, match=expected_err_msg):
         contract_instance.setNumber(5, sender=contract_instance)
 
 
 def test_unlock_with_passphrase_and_sign_message(runner, keyfile_account, message):
     keyfile_account.unlock(passphrase=PASSPHRASE)
 
     # y: yes, sign (note: unlocking makes the key available but is not the same as autosign).
@@ -526,25 +540,25 @@
 
     # y: yes, sign (note: unlocking makes the key available but is not the same as autosign).
     with runner.isolation(input="y\n"):
         signature = reloaded_account.sign_message(message)
         assert keyfile_account.check_signature(message, signature)
 
 
-def test_custom_num_of_test_accounts_config(test_accounts, temp_config):
+def test_custom_num_of_test_accounts_config(test_accounts, project):
     custom_number_of_test_accounts = 20
     test_config = {
         "test": {
             "number_of_accounts": custom_number_of_test_accounts,
         }
     }
 
     assert len(test_accounts) == DEFAULT_NUMBER_OF_TEST_ACCOUNTS
 
-    with temp_config(test_config):
+    with project.temp_config(**test_config):
         assert len(test_accounts) == custom_number_of_test_accounts
 
 
 def test_test_accounts_repr(test_accounts):
     actual = repr(test_accounts)
     assert all(a.address in actual for a in test_accounts)
 
@@ -586,36 +600,36 @@
 
 
 def test_is_not_contract(owner, keyfile_account):
     assert not owner.is_contract
     assert not keyfile_account.is_contract
 
 
-def test_using_different_hd_path(test_accounts, temp_config):
+def test_using_different_hd_path(test_accounts, project):
     test_config = {
         "test": {
             "hd_path": "m/44'/60'/0'/{}",
         }
     }
 
     old_first_account = test_accounts[0]
-    with temp_config(test_config):
+    with project.temp_config(**test_config):
         new_first_account = test_accounts[0]
         assert old_first_account.address != new_first_account.address
 
 
-def test_using_random_mnemonic(test_accounts, temp_config):
+def test_using_random_mnemonic(test_accounts, project):
     test_config = {
         "test": {
             "mnemonic": "test_mnemonic_for_ape",
         }
     }
 
     old_first_account = test_accounts[0]
-    with temp_config(test_config):
+    with project.temp_config(**test_config):
         new_first_account = test_accounts[0]
         assert old_first_account.address != new_first_account.address
 
 
 def test_iter_test_accounts(test_accounts):
     actual = list(iter(test_accounts))
     assert len(actual) == len(test_accounts)
```

### Comparing `eth-ape-0.7.9/tests/functional/test_address.py` & `eth-ape-0.8.0/tests/functional/test_address.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/test_block_container.py` & `eth-ape-0.8.0/tests/functional/test_block_container.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,9 @@
 import time
 from queue import Queue
-from typing import List
 
 import pytest
 from eth_pydantic_types import HexBytes
 
 from ape.exceptions import ChainError, ProviderError
 
 
@@ -131,15 +130,15 @@
         "Chain has reorganized since returning the last block. "
         "Try adjusting the required network confirmations."
     )
     assert ape_caplog.records, "Didn't detect re-org"
     ape_caplog.assert_last_log(expected_error)
 
     # Show that there are duplicate blocks
-    block_numbers: List[int] = [blocks.get().number for _ in range(6)]
+    block_numbers: list[int] = [blocks.get().number for _ in range(6)]
     assert len(set(block_numbers)) < len(block_numbers)
 
 
 def test_poll_blocks_timeout(
     vyper_contract_instance, chain_that_mined_5, eth_tester_provider, owner, PollDaemon
 ):
     poller = chain_that_mined_5.blocks.poll_blocks(new_block_timeout=1)
```

### Comparing `eth-ape-0.7.9/tests/functional/test_chain.py` & `eth-ape-0.8.0/tests/functional/test_chain.py`

 * *Ordering differences only*

 * *Files 1% similar despite different names*

```diff
@@ -77,16 +77,16 @@
     start_head = chain.blocks.height
 
     with chain.isolate():
         vyper_contract_instance.setNumber(333, sender=owner)
         assert vyper_contract_instance.myNumber() == 333
         assert chain.blocks.height == start_head + 1
 
-    assert vyper_contract_instance.myNumber() == number_at_start
     assert chain.blocks.height == start_head
+    assert vyper_contract_instance.myNumber() == number_at_start
 
 
 def test_get_receipt_uses_cache(mocker, eth_tester_provider, chain, vyper_contract_instance, owner):
     expected = vyper_contract_instance.setNumber(3, sender=owner)
     eth = eth_tester_provider.web3.eth
     rpc_spy = mocker.spy(eth, "get_transaction")
     actual = chain.get_receipt(expected.txn_hash)
```

### Comparing `eth-ape-0.7.9/tests/functional/test_cli.py` & `eth-ape-0.8.0/tests/functional/test_cli.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,65 +1,67 @@
 import copy
 import shutil
+from pathlib import Path
 
 import click
 import pytest
 
 from ape.cli import (
     AccountAliasPromptChoice,
     ConnectedProviderCommand,
-    NetworkBoundCommand,
     NetworkChoice,
     PromptChoice,
     account_option,
+    config_override_option,
     contract_file_paths_argument,
     existing_alias_argument,
     network_option,
     non_existing_alias_argument,
+    project_option,
     select_account,
     verbosity_option,
 )
 from ape.cli.choices import _NONE_NETWORK, _get_networks_sequence_from_cache
 from ape.cli.commands import get_param_from_ctx, parse_network
 from ape.exceptions import AccountsError
 from ape.logging import logger
-from tests.conftest import geth_process_test
+from tests.conftest import geth_process_test, skip_if_plugin_installed
 
 OUTPUT_FORMAT = "__TEST__{0}:{1}:{2}_"
 OTHER_OPTION_VALUE = "TEST_OTHER_OPTION"
 other_option = click.option("--other", default=OTHER_OPTION_VALUE)
 
 
 @pytest.fixture
 def keyfile_swap_paths(config):
     return config.DATA_FOLDER / "accounts", config.DATA_FOLDER.parent / "temp_accounts"
 
 
 @pytest.fixture
-def one_keyfile_account(keyfile_swap_paths, keyfile_account, temp_config):
+def one_keyfile_account(keyfile_swap_paths, keyfile_account, project):
     src_path, dest_path = keyfile_swap_paths
     existing_keyfiles = [x for x in src_path.iterdir() if x.is_file()]
     test_data = {"test": {"number_of_accounts": 0}}
     if existing_keyfiles == [keyfile_account.keyfile_path]:
         # Already only has the 1 account
-        with temp_config(test_data):
+        with project.temp_config(**test_data):
             yield keyfile_account
 
     else:
         if dest_path.is_file():
             dest_path.unlink()
         elif dest_path.is_dir():
             shutil.rmtree(dest_path)
 
         dest_path.mkdir()
         for keyfile in [x for x in existing_keyfiles if x != keyfile_account.keyfile_path]:
             shutil.copy(keyfile, dest_path / keyfile.name)
             keyfile.unlink()
 
-        with temp_config(test_data):
+        with project.temp_config(**test_data):
             yield keyfile_account
 
         for file in dest_path.iterdir():
             shutil.copy(file, src_path / file.name)
 
 
 @pytest.fixture
@@ -69,14 +71,29 @@
     def cmd(ecosystem, network, provider):
         output = OUTPUT_FORMAT.format(ecosystem.name, network.name, provider.name)
         click.echo(output)
 
     return cmd
 
 
+@pytest.fixture
+def contracts_paths_cmd():
+    expected = "EXPECTED {}"
+
+    @click.command()
+    @contract_file_paths_argument()
+    @project_option()
+    def cmd(file_paths, project):
+        _ = project  # used in `contract_file_paths_argument`
+        output = ", ".join(x.name for x in sorted(file_paths))
+        click.echo(expected.format(output))
+
+    return cmd
+
+
 def _setup_temp_acct_number_change(accounts, num_accounts: int):
     if "containers" in accounts.__dict__:
         del accounts.__dict__["containers"]
 
     installed_account_types = {str(type(a)) for a in accounts}
     if installed_account_types:
         accounts_str = ", ".join(installed_account_types)
@@ -87,26 +104,26 @@
 
 def _teardown_numb_acct_change(accounts):
     if "containers" in accounts.__dict__:
         del accounts.__dict__["containers"]
 
 
 @pytest.fixture
-def no_accounts(accounts, empty_data_folder, temp_config):
+def no_accounts(accounts, empty_data_folder, project):
     data = _setup_temp_acct_number_change(accounts, 0)
-    with temp_config(data):
+    with project.temp_config(**data):
         yield
 
     _teardown_numb_acct_change(accounts)
 
 
 @pytest.fixture
-def one_account(accounts, empty_data_folder, temp_config, test_accounts):
+def one_account(accounts, empty_data_folder, project, test_accounts):
     data = _setup_temp_acct_number_change(accounts, 1)
-    with temp_config(data):
+    with project.temp_config(**data):
         yield test_accounts[0]
 
     _teardown_numb_acct_change(accounts)
 
 
 def get_expected_account_str(acct):
     return f"__expected_output__: {acct.address}"
@@ -206,15 +223,15 @@
     @network_option()
     @other_option
     def with_net(network, other):
         click.echo(network.name)
         click.echo(other)
 
     def run(cmd, fail_msg=None):
-        res = runner.invoke(cmd, [], catch_exceptions=False)
+        res = runner.invoke(cmd, (), catch_exceptions=False)
         fail_msg = f"{fail_msg}\n{res.output}" if fail_msg else res.output
         assert res.exit_code == 0, fail_msg
         assert OTHER_OPTION_VALUE in res.output, fail_msg
         return res
 
     run(solo_option, fail_msg="Failed when used without network kwargs")
     result = run(with_net, fail_msg="Failed when used with network kwargs")
@@ -251,15 +268,15 @@
 
 def test_network_option_make_required(runner):
     @click.command()
     @network_option(required=True)
     def cmd(network):
         click.echo(OUTPUT_FORMAT.format(network))
 
-    result = runner.invoke(cmd, [])
+    result = runner.invoke(cmd, ())
     assert result.exit_code == 2
     assert "Error: Missing option '--network'." in result.output
 
 
 def test_network_option_default_none(runner):
     @click.command()
     @network_option(default=None)
@@ -277,41 +294,43 @@
         click.echo(f"Value is '{network}'")
 
     result = runner.invoke(cmd, ("--network", "None"))
     assert "Value is 'None'" in result.output
 
 
 @pytest.mark.parametrize("network_name", ("apenet", "apenet1"))
-def test_network_option_specify_custom_network(runner, custom_networks_config, network_name):
-    network_part = ("--network", f"ethereum:{network_name}:geth")
-
-    # NOTE: Also testing network filter with a custom network
-    #  But this is also required to work around LRU cache
-    #  giving us the wrong networks because click is running
-    #  the tester in-process after re-configuring networks,
-    #  which shouldn't happen IRL.
-
-    @click.command()
-    @network_option(network=network_name)
-    def cmd(network):
-        click.echo(f"Value is '{network.name}'")
+def test_network_option_specify_custom_network(
+    runner, project, custom_networks_config_dict, network_name
+):
+    network_part = ("--network", f"ethereum:{network_name}:node")
+    with project.temp_config(**custom_networks_config_dict):
+        # NOTE: Also testing network filter with a custom network
+        #  But this is also required to work around LRU cache
+        #  giving us the wrong networks because click is running
+        #  the tester in-process after re-configuring networks,
+        #  which shouldn't happen IRL.
+
+        @click.command()
+        @network_option(network=network_name)
+        def cmd(network):
+            click.echo(f"Value is '{network.name}'")
 
-    result = runner.invoke(cmd, network_part)
-    assert f"Value is '{network_name}'" in result.output
+        result = runner.invoke(cmd, network_part)
+        assert f"Value is '{network_name}'" in result.output
 
 
 def test_account_option(runner, keyfile_account):
     @click.command()
     @account_option()
     def cmd(account):
         _expected = get_expected_account_str(account)
         click.echo(_expected)
 
     expected = get_expected_account_str(keyfile_account)
-    result = runner.invoke(cmd, ["--account", keyfile_account.alias])
+    result = runner.invoke(cmd, ("--account", keyfile_account.alias))
     assert expected in result.output
 
 
 def test_account_option_uses_single_account_as_default(runner, one_account):
     """
     When there is only 1 test account, that is the default
     when no option is given.
@@ -320,15 +339,15 @@
     @click.command()
     @account_option(account_type=[one_account])
     def cmd(account):
         _expected = get_expected_account_str(account)
         click.echo(_expected)
 
     expected = get_expected_account_str(one_account)
-    result = runner.invoke(cmd, [])
+    result = runner.invoke(cmd, ())
     assert expected in result.output
 
 
 def test_account_prompts_when_more_than_one_keyfile_account(
     runner, keyfile_account, second_keyfile_account
 ):
     @click.command()
@@ -336,15 +355,15 @@
     def cmd(account):
         _expected = get_expected_account_str(account)
         click.echo(_expected)
 
     expected = get_expected_account_str(keyfile_account)
 
     # Requires user input.
-    result = runner.invoke(cmd, [], input="0\n")
+    result = runner.invoke(cmd, (), input="0\n")
 
     assert expected in result.output
 
 
 def test_account_option_can_use_test_account(runner, test_accounts):
     index = 7
     test_account = test_accounts[index]
@@ -352,15 +371,15 @@
     @click.command()
     @account_option()
     def cmd(account):
         _expected = get_expected_account_str(account)
         click.echo(_expected)
 
     expected = get_expected_account_str(test_account)
-    result = runner.invoke(cmd, ["--account", f"TEST::{index}"])
+    result = runner.invoke(cmd, ("--account", f"TEST::{index}"))
     assert expected in result.output
 
 
 @pytest.mark.parametrize("opt", (0, "foo"))
 def test_prompt_choice(runner, opt):
     """
     This demonstrates how to use ``PromptChoice``,
@@ -407,71 +426,187 @@
     """
     option = AccountAliasPromptChoice()
     assert option.name == "account"
     option = AccountAliasPromptChoice(name="account_z")
     assert option.name == "account_z"
 
 
-def test_contract_file_paths_argument(runner):
-    @click.command()
-    @contract_file_paths_argument()
-    def cmd(file_paths):
-        pass
+def test_contract_file_paths_argument_given_source_id(
+    project_with_source_files_contract, runner, contracts_paths_cmd
+):
+    pm = project_with_source_files_contract
+    src_id = next(x for x in pm.sources if Path(x).suffix == ".json")
+    arguments = (src_id, "--project", f"{pm.path}")
+    result = runner.invoke(contracts_paths_cmd, arguments)
 
-    result = runner.invoke(cmd, ["path0", "path1"])
-    assert "Contract 'path0' not found" in result.output
+    assert f"EXPECTED {src_id.split('/')[-1]}" in result.output
+
+
+def test_contract_file_paths_argument_given_name(
+    project_with_source_files_contract, runner, contracts_paths_cmd
+):
+    pm = project_with_source_files_contract
+    src_stem = next(x for x in pm.sources if Path(x).suffix == ".json").split(".")[0]
+    arguments = (src_stem, "--project", f"{pm.path}")
+    result = runner.invoke(contracts_paths_cmd, arguments)
+
+    assert f"EXPECTED {src_stem.split('/')[-1]}" in result.output
+
+
+def test_contract_file_paths_argument_given_contracts_folder(
+    project_with_contract, runner, contracts_paths_cmd
+):
+    pm = project_with_contract
+    contracts_dirname = pm.contracts_folder.as_posix()
+    arguments = (contracts_dirname, "--project", f"{pm.path}")
+    result = runner.invoke(contracts_paths_cmd, arguments)
+    all_paths = ", ".join(x.name for x in sorted(pm.sources.paths))
+
+    assert f"EXPECTED {all_paths}" in result.output
+
+
+def test_contract_file_paths_argument_given_contracts_folder_name(
+    project_with_contract, runner, contracts_paths_cmd
+):
+    pm = project_with_contract
+    arguments = ("contracts", "--project", f"{pm.path}")
+    result = runner.invoke(contracts_paths_cmd, arguments)
+    all_paths = ", ".join(x.name for x in sorted(pm.sources.paths))
+
+    assert f"EXPECTED {all_paths}" in result.output
+
+
+def test_contract_file_paths_argument_handles_exclude(
+    project_with_contract, runner, contracts_paths_cmd
+):
+    pm = project_with_contract
+    cfg = pm.config.get_config("compile")
+    failmsg = "Setup failed - missing exclude config (set in ape-config.yaml)."
+    assert "*Excl*" in cfg.exclude, failmsg
+
+    # make a .cache file to show it is ignored.
+    cache_file = project_with_contract.contracts_folder / ".cache" / "thing.json"
+    cache_file.parent.mkdir(parents=True, exist_ok=True)
+    cache_file.write_text("FAILS IF LOADED")
+
+    result = runner.invoke(contracts_paths_cmd, "contracts")
+    assert "Exclude.json" not in result.output
+    assert "ExcludeNested.json" not in result.output
+    # Ensure .cache always ignored!
+    assert ".cache" not in result.output
+
+
+@pytest.mark.parametrize("name", ("contracts/subdir", "subdir"))
+def test_contract_file_paths_argument_given_subdir_relative_to_path(
+    project_with_contract, runner, contracts_paths_cmd, name
+):
+    pm = project_with_contract
+    arguments = (name, "--project", f"{pm.path}")
+    result = runner.invoke(contracts_paths_cmd, arguments)
+    paths = sorted(pm.sources.paths)
+
+    all_paths = ", ".join(x.name for x in paths if x.parent.name == "subdir")
+    assert f"EXPECTED {all_paths}" in result.output
+
+
+@skip_if_plugin_installed("vyper")
+def test_contract_file_paths_argument_missing_vyper(
+    project_with_source_files_contract, runner, contracts_paths_cmd
+):
+    name = "VyperContract"
+    pm = project_with_source_files_contract
+    arguments = (name, "--project", f"{pm.path}")
+    result = runner.invoke(contracts_paths_cmd, arguments)
+
+    expected = (
+        "Missing compilers for the following file types: '.vy'. "
+        "Possibly, a compiler plugin is not installed or is installed "
+        "but not loading correctly. Is 'ape-vyper' installed?"
+    )
+    assert expected in result.output
+
+
+@skip_if_plugin_installed("solidity")
+def test_contract_file_paths_argument_missing_solidity(
+    project_with_source_files_contract, runner, contracts_paths_cmd
+):
+    name = "SolidityContract"
+    pm = project_with_source_files_contract
+    with pm.isolate_in_tempdir() as tmp_project:
+        arguments = (name, "--project", f"{tmp_project.path}")
+        result = runner.invoke(contracts_paths_cmd, arguments)
+
+    expected = (
+        "Missing compilers for the following file types: '.sol'. "
+        "Possibly, a compiler plugin is not installed or is installed "
+        "but not loading correctly. Is 'ape-solidity' installed?"
+    )
+    assert expected in result.output
+
+
+def test_contract_file_paths_argument_contract_does_not_exist(
+    project_with_source_files_contract, runner, contracts_paths_cmd
+):
+    name = "MadeUp"
+    pm = project_with_source_files_contract
+    with pm.isolate_in_tempdir() as tmp_project:
+        arguments = (name, "--project", f"{tmp_project.path}")
+        result = runner.invoke(contracts_paths_cmd, arguments)
+
+    expected = f"Source file '{name}' not found."
+    assert expected in result.output
 
 
 def test_existing_alias_option(runner):
     @click.command()
     @existing_alias_argument()
     def cmd(alias):
         click.echo(alias)
 
-    result = runner.invoke(cmd, ["TEST::0"])
+    result = runner.invoke(cmd, "TEST::0")
     assert "TEST::0" in result.output
 
 
 def test_existing_alias_option_custom_callback(runner):
     magic_value = "THIS IS A TEST"
 
     def custom_callback(*args, **kwargs):
         return magic_value
 
     @click.command()
     @existing_alias_argument(callback=custom_callback)
     def cmd(alias):
         click.echo(alias)
 
-    result = runner.invoke(cmd, ["TEST::0"])
+    result = runner.invoke(cmd, "TEST::0")
     assert magic_value in result.output
 
 
 def test_non_existing_alias_option(runner):
     @click.command()
     @non_existing_alias_argument()
     def cmd(alias):
         click.echo(alias)
 
-    result = runner.invoke(cmd, ["non-exists"])
+    result = runner.invoke(cmd, "non-exists")
     assert "non-exists" in result.output
 
 
 def test_non_existing_alias_option_custom_callback(runner):
     magic_value = "THIS IS A TEST"
 
     def custom_callback(*args, **kwargs):
         return magic_value
 
     @click.command()
     @non_existing_alias_argument(callback=custom_callback)
     def cmd(alias):
         click.echo(alias)
 
-    result = runner.invoke(cmd, ["non-exists"])
+    result = runner.invoke(cmd, "non-exists")
     assert magic_value in result.output
 
 
 def test_connected_provider_command_no_args_or_network_specified(runner):
     @click.command(cls=ConnectedProviderCommand)
     def cmd():
         from ape import chain
@@ -484,15 +619,15 @@
 
 
 def test_connected_provider_command_invalid_value(runner):
     @click.command(cls=ConnectedProviderCommand)
     def cmd():
         pass
 
-    result = runner.invoke(cmd, ["--network", "OOGA_BOOGA"], catch_exceptions=False)
+    result = runner.invoke(cmd, ("--network", "OOGA_BOOGA"), catch_exceptions=False)
     assert result.exit_code != 0
     assert "Invalid value for '--network'" in result.output
 
 
 def test_connected_provider_command_use_provider(runner):
     @click.command(cls=ConnectedProviderCommand)
     def cmd(provider):
@@ -579,53 +714,47 @@
 
     @click.command(cls=ConnectedProviderCommand)
     @network_option()
     def cmd(provider):
         click.echo(provider.name)
 
     # NOTE: Must use a network that is not the default.
-    spec = ("--network", "ethereum:local:geth")
+    spec = ("--network", "ethereum:local:node")
+    res = runner.invoke(cmd, spec, catch_exceptions=False)
+    assert res.exit_code == 0, res.output
+    assert "node" in res.output
+
+
+@geth_process_test
+def test_connected_provider_command_with_network_option_and_cls_types_false(runner, geth_provider):
+    _ = geth_provider  # Ensure already running, to avoid clashing later on.
+
+    @click.command(cls=ConnectedProviderCommand, use_cls_types=False)
+    @network_option()
+    def cmd(network):
+        assert isinstance(network, str)
+        assert network == "ethereum:local:node"
+
+    # NOTE: Must use a network that is not the default.
+    spec = ("--network", "ethereum:local:node")
     res = runner.invoke(cmd, spec, catch_exceptions=False)
     assert res.exit_code == 0, res.output
-    assert "geth" in res.output
 
 
 def test_connected_provider_command_none_network(runner):
     @click.command(cls=ConnectedProviderCommand)
     def cmd(network, provider):
         click.echo(network)
         click.echo(provider)
 
     spec = ("--network", "None")
     res = runner.invoke(cmd, spec, catch_exceptions=False)
     assert res.exit_code == 0, res.output
 
 
-# TODO: Delete for 0.8.
-def test_deprecated_network_bound_command(runner):
-    with pytest.warns(
-        DeprecationWarning,
-        match=r"'NetworkBoundCommand' is deprecated\. Use 'ConnectedProviderCommand'\.",
-    ):
-
-        @click.command(cls=NetworkBoundCommand)
-        @network_option()
-        # NOTE: Must also make sure can use other options with this combo!
-        #   (was issue where could not).
-        @click.option("--other", default=OTHER_OPTION_VALUE)
-        def cmd(network, other):
-            click.echo(network)
-            click.echo(other)
-
-    result = runner.invoke(cmd, ["--network", "ethereum:local:test"], catch_exceptions=False)
-    assert result.exit_code == 0, result.output
-    assert "ethereum:local:test" in result.output, result.output
-    assert OTHER_OPTION_VALUE in result.output
-
-
 def test_get_param_from_ctx(mocker):
     mock_ctx = mocker.MagicMock()
     mock_ctx.params = {"foo": "bar"}
     mock_ctx.parent = mocker.MagicMock()
     mock_ctx.parent.params = {"interactive": True}
     actual = get_param_from_ctx(mock_ctx, "interactive")
     assert actual is True
@@ -678,24 +807,24 @@
     network_choice = NetworkChoice()
     uri = "https://example.com"
     actual = network_choice.convert(f"{prefix}{uri}", None, None)
     assert actual.uri == uri
     assert actual.network.name == "custom"
 
 
-def test_network_choice_custom_config_network(custom_networks_config_dict, temp_config):
+def test_network_choice_custom_config_network(custom_networks_config_dict, project):
     data = copy.deepcopy(custom_networks_config_dict)
 
     # Was a bug where couldn't have this name.
     data["networks"]["custom"][0]["name"] = "custom"
 
     _get_networks_sequence_from_cache.cache_clear()
 
     network_choice = NetworkChoice()
-    with temp_config(data):
+    with project.temp_config(**data):
         actual = network_choice.convert("ethereum:custom", None, None)
 
     assert actual.network.name == "custom"
 
 
 def test_network_choice_when_custom_local_network():
     network_choice = NetworkChoice()
@@ -705,7 +834,19 @@
     assert actual.network.name == "local"
 
 
 def test_network_choice_explicit_none():
     network_choice = NetworkChoice()
     actual = network_choice.convert("None", None, None)
     assert actual == _NONE_NETWORK
+
+
+def test_config_override_option(runner):
+    @click.command()
+    @config_override_option()
+    def cli(config_override):
+        assert isinstance(config_override, dict)
+        assert config_override["foo"] == "bar"
+
+    result = runner.invoke(cli, ("--config-override", '{"foo": "bar"}'))
+    assert result.exit_code == 0
+    assert not result.exception
```

### Comparing `eth-ape-0.7.9/tests/functional/test_config.py` & `eth-ape-0.8.0/tests/functional/test_config.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,204 +1,214 @@
-import tempfile
 from pathlib import Path
-from typing import Dict, Optional, Union
+from typing import Optional, Union
 
 import pytest
 from pydantic_settings import SettingsConfigDict
 
-from ape.api import ConfigEnum, PluginConfig
-from ape.api.networks import LOCAL_NETWORK_NAME
-from ape.managers.config import (
-    CONFIG_FILE_NAME,
-    ConfigManager,
-    DeploymentConfigCollection,
-    merge_configs,
-)
+from ape.api.config import ApeConfig, ConfigEnum, PluginConfig
+from ape.exceptions import ConfigError
+from ape.managers.config import CONFIG_FILE_NAME, merge_configs
 from ape.types import GasLimit
 from ape_ethereum.ecosystem import NetworkConfig
 from ape_networks import CustomNetwork
 from tests.functional.conftest import PROJECT_WITH_LONG_CONTRACTS_FOLDER
 
 
-def test_deployments(networks_connected_to_tester, owner, vyper_contract_container, config):
-    networks = networks_connected_to_tester  # Connection needs to lookup config.
+def test_model_validate_empty():
+    data: dict = {}
+    cfg = ApeConfig.model_validate(data)
+    assert cfg.contracts_folder is None
+
+
+def test_model_validate():
+    data = {"contracts_folder": "src"}
+    cfg = ApeConfig.model_validate(data)
+    assert cfg.contracts_folder == "src"
+
+
+def test_model_validate_none_contracts_folder():
+    data = {"contracts_folder": None}
+    cfg = ApeConfig.model_validate(data)
+    assert cfg.contracts_folder is None
+
+
+def test_model_validate_path_contracts_folder():
+    path = Path.home() / "contracts"
+    data = {"contracts_folder": path}
+    cfg = ApeConfig.model_validate(data)
+    assert cfg.contracts_folder == str(path)
+
+
+def test_deployments(networks_connected_to_tester, owner, vyper_contract_container, project):
+    _ = networks_connected_to_tester  # Connection needs to lookup config.
 
     # First, obtain a "previously-deployed" contract.
     instance = vyper_contract_container.deploy(1000200000, sender=owner)
     address = instance.address
 
     # Create a config using this new contract for a "later time".
-    data = {
+    deploys = {
         **_create_deployments(address=address, contract_name=instance.contract_type.name),
-        "valid_ecosystems": {"ethereum": networks.ethereum},
-        "valid_networks": [LOCAL_NETWORK_NAME],
     }
-    deploy_config = DeploymentConfigCollection(root=data)
-    assert deploy_config.root["ethereum"]["local"][0]["address"] == address
-
-    orig = config.deployments
-    config.deployments = deploy_config
-    try:
-        # Ensure we can reference the deployment on the contract.
+    with project.temp_config(**{"deployments": deploys}):
+        deploy_config = project.config.deployments
+        assert deploy_config["ethereum"]["local"][0]["address"] == address
         deployment = vyper_contract_container.deployments[0]
-    finally:
-        config.deployments = orig
 
     assert deployment.address == instance.address
 
 
-def test_deployments_integer_type_addresses(networks):
-    data = {
+def test_deployments_integer_type_addresses(networks, project):
+    deploys = {
         **_create_deployments(address=0x0C25212C557D00024B7CA3DF3238683A35541354),
-        "valid_ecosystems": {"ethereum": networks.ethereum},
-        "valid_networks": [LOCAL_NETWORK_NAME],
     }
-    config = DeploymentConfigCollection(root=data)
-    assert (
-        config.root["ethereum"]["local"][0]["address"]
-        == "0x0c25212c557d00024b7Ca3df3238683A35541354"
-    )
-
-
-@pytest.mark.parametrize(
-    "ecosystem_names,network_names,err_part",
-    [(["ERRORS"], ["mainnet"], "ecosystem"), (["ethereum"], ["ERRORS"], "network")],
-)
-def test_deployments_bad_value(
-    ecosystem_names, network_names, err_part, ape_caplog, plugin_manager
-):
-    deployments = _create_deployments()
-    all_ecosystems = dict(plugin_manager.ecosystems)
-    ecosystem_dict = {e: all_ecosystems[e] for e in ecosystem_names if e in all_ecosystems}
-    data = {**deployments, "valid_ecosystems": ecosystem_dict, "valid_networks": network_names}
-    ape_caplog.assert_last_log_with_retries(
-        lambda: DeploymentConfigCollection(root=data),
-        f"Invalid {err_part}",
-    )
+    with project.temp_config(**{"deployments": deploys}):
+        deploy_config = project.config.deployments
+        assert (
+            deploy_config["ethereum"]["local"][0]["address"]
+            == "0x0c25212c557d00024b7Ca3df3238683A35541354"
+        )
+
+
+def test_deployments_bad_ecosystem(project):
+    deployments = _create_deployments(ecosystem_name="madeup")
+    with project.temp_config(deployments=deployments):
+        with pytest.raises(
+            ConfigError, match=r"Invalid ecosystem 'madeup' in deployments config\."
+        ):
+            _ = project.config.deployments
+
+
+def test_deployments_bad_network(project):
+    deployments = _create_deployments(network_name="madeup")
+    with project.temp_config(deployments=deployments):
+        with pytest.raises(
+            ConfigError, match=r"Invalid network 'ethereum:madeup' in deployments config\."
+        ):
+            _ = project.config.deployments
 
 
 def _create_deployments(
     ecosystem_name: str = "ethereum",
     network_name: str = "local",
     address: Union[int, str] = "0x0C25212C557D00024B7CA3DF3238683A35541354",
     contract_name: Optional[str] = "MyContract",
-) -> Dict:
+) -> dict:
     return {
         ecosystem_name: {
             network_name: [
                 {
                     "address": address,
                     "contract_type": contract_name,
                 }
             ]
         }
     }
 
 
-def test_ethereum_network_configs(config, temp_config):
-    eth_config = {"ethereum": {"goerli": {"default_provider": "test"}}}
-    with temp_config(eth_config):
+def test_ethereum_network_configs(config, project):
+    eth_config = {"ethereum": {"sepolia": {"default_provider": "test"}}}
+    with project.temp_config(**eth_config):
         actual = config.get_config("ethereum")
-        assert actual.goerli.default_provider == "test"
+        assert actual.sepolia.default_provider == "test"
 
         # Ensure that non-updated fields remain unaffected
-        assert actual.goerli.block_time == 15
+        assert actual.sepolia.block_time == 15
 
 
 def test_network_gas_limit_default(config):
     eth_config = config.get_config("ethereum")
 
-    assert eth_config.goerli.gas_limit == "auto"
+    assert eth_config.sepolia.gas_limit == "auto"
     assert eth_config.local.gas_limit == "max"
 
 
-def _goerli_with_gas_limit(gas_limit: GasLimit) -> dict:
+def _sepolia_with_gas_limit(gas_limit: GasLimit) -> dict:
     return {
         "ethereum": {
-            "goerli": {
+            "sepolia": {
                 "default_provider": "test",
                 "gas_limit": gas_limit,
             }
         }
     }
 
 
 @pytest.mark.parametrize("gas_limit", ("auto", "max"))
-def test_network_gas_limit_string_config(gas_limit, config, temp_config):
-    eth_config = _goerli_with_gas_limit(gas_limit)
+def test_network_gas_limit_string_config(gas_limit, project):
+    eth_config = _sepolia_with_gas_limit(gas_limit)
 
-    with temp_config(eth_config):
-        actual = config.get_config("ethereum")
+    with project.temp_config(**eth_config):
+        actual = project.config.get_config("ethereum")
 
-        assert actual.goerli.gas_limit == gas_limit
+        assert actual.sepolia.gas_limit == gas_limit
 
         # Local configuration is unaffected
         assert actual.local.gas_limit == "max"
 
 
 @pytest.mark.parametrize("gas_limit", (1234, "1234", 0x4D2, "0x4D2"))
-def test_network_gas_limit_numeric_config(gas_limit, config, temp_config):
-    eth_config = _goerli_with_gas_limit(gas_limit)
-
-    with temp_config(eth_config):
-        actual = config.get_config("ethereum")
-
-        assert actual.goerli.gas_limit == 1234
+def test_network_gas_limit_numeric_config(gas_limit, project):
+    eth_config = _sepolia_with_gas_limit(gas_limit)
+    with project.temp_config(**eth_config):
+        actual = project.config.get_config("ethereum")
+        assert actual.sepolia.gas_limit == 1234
 
         # Local configuration is unaffected
         assert actual.local.gas_limit == "max"
 
 
-def test_network_gas_limit_invalid_numeric_string(config, temp_config):
+def test_network_gas_limit_invalid_numeric_string(project):
     """
     Test that using hex strings for a network's gas_limit config must be
     prefixed with '0x'
     """
-    eth_config = _goerli_with_gas_limit("4D2")
-    with pytest.raises(ValueError, match="Gas limit hex str must include '0x' prefix."):
-        with temp_config(eth_config):
-            pass
+    eth_config = _sepolia_with_gas_limit("4D2")
+    with project.temp_config(**eth_config):
+        with pytest.raises(AttributeError, match="Gas limit hex str must include '0x' prefix."):
+            _ = project.config.ethereum
 
 
-def test_dependencies(project_with_dependency_config, config):
+def test_dependencies(project_with_dependency_config):
+    config = project_with_dependency_config.config
     assert len(config.dependencies) == 1
-    assert config.dependencies[0].name == "testdependency"
-    assert config.dependencies[0].contracts_folder == "source/v0.1"
-    assert config.dependencies[0].local == str(PROJECT_WITH_LONG_CONTRACTS_FOLDER)
+    assert config.dependencies[0]["name"] == "testdependency"
+    assert config.dependencies[0]["config_override"]["contracts_folder"] == "source/v0.1"
+    assert config.dependencies[0]["local"] == str(PROJECT_WITH_LONG_CONTRACTS_FOLDER)
 
 
 def test_config_access():
     config = NetworkConfig()
     assert "default_provider" in config
     assert (
         config.default_provider
         == config["default_provider"]
         == getattr(config, "default-provider")
-        == "geth"
+        == "node"
     )
 
 
 def test_plugin_config_updates_when_default_is_empty_dict():
     class SubConfig(PluginConfig):
         foo: int = 0
         bar: int = 1
 
     class MyConfig(PluginConfig):
-        sub: Dict[str, Dict[str, SubConfig]] = {}
+        sub: dict[str, dict[str, SubConfig]] = {}
 
     overrides = {"sub": {"baz": {"test": {"foo": 5}}}}
     actual = MyConfig.from_overrides(overrides)
     assert actual.sub == {"baz": {"test": SubConfig(foo=5, bar=1)}}
 
 
 @pytest.mark.parametrize("override_0,override_1", [(True, {"foo": 0}), ({"foo": 0}, True)])
 def test_plugin_config_with_union_dicts(override_0, override_1):
     class SubConfig(PluginConfig):
-        bool_or_dict: Union[bool, Dict] = True
-        dict_or_bool: Union[Dict, bool] = {}
+        bool_or_dict: Union[bool, dict] = True
+        dict_or_bool: Union[dict, bool] = {}
 
     config = SubConfig.from_overrides({"bool_or_dict": override_0, "dict_or_bool": override_1})
     assert config.bool_or_dict == override_0
     assert config.dict_or_bool == override_1
 
 
 def test_global_config(data_folder, config):
@@ -206,48 +216,48 @@
     config_file.unlink(missing_ok=True)
     config_file.touch()
     config_content = """
 test:
   number_of_accounts: 11
 """.strip()
     config_file.write_text(config_content)
-    config.load(force_reload=True)
-    assert config.get_config("test").number_of_accounts == 11
+    global_config = config.load_global_config()
+    assert global_config.get_config("test").number_of_accounts == 11
     config_file.unlink(missing_ok=True)
 
 
 def test_merge_configs():
     """
     The test covers most cases in `merge_config()`. See comment below explaining
     `expected`.
     """
     global_config = {
         "ethereum": {
-            "mainnet": {"default_provider": "geth"},
+            "mainnet": {"default_provider": "node"},
             "local": {"default_provider": "test", "required_confirmations": 5},
         }
     }
     project_config = {
         "ethereum": {
-            "local": {"default_provider": "geth"},
+            "local": {"default_provider": "node"},
             "sepolia": {"default_provider": "alchemy"},
         },
         "test": "foo",
     }
     actual = merge_configs(global_config, project_config)
 
     # Expected case `key only in global`: "mainnet"
     # Expected case `non-primitive override from project`: local -> default_provider, which
     #  is `test` in global but `geth` in project; thus it is `geth` in expected.
     # Expected case `merge sub-dictionaries`: `ethereum` is being merged.
     # Expected case `add missing project keys`: `test` is added, so is `sepolia` (nested-example).
     expected = {
         "ethereum": {
-            "local": {"default_provider": "geth", "required_confirmations": 5},
-            "mainnet": {"default_provider": "geth"},
+            "local": {"default_provider": "node", "required_confirmations": 5},
+            "mainnet": {"default_provider": "node"},
             "sepolia": {"default_provider": "alchemy"},
         },
         "test": "foo",
     }
     assert actual == expected
 
 
@@ -284,47 +294,16 @@
     class MyConfig(PluginConfig):
         my_enum: MyEnum
 
     actual = MyConfig(my_enum="FOO")
     assert actual.my_enum == MyEnum.FOO
 
 
-def test_config_manager_loads_on_init(config):
-    """
-    This is needed or else tools may interact with the config manager
-    before it has processed the config file.
-    """
-    name = "nametestvalidate"
-
-    with tempfile.TemporaryDirectory() as temp_dir:
-        config = f"name: {name}"
-        path = Path(temp_dir)
-        (path / "ape-config.yaml").write_text(config)
-        manager = ConfigManager(REQUEST_HEADER={}, DATA_FOLDER=Path.cwd(), PROJECT_FOLDER=path)
-        assert manager.name == name
-
-
-def test_load_does_not_call_project_manager(temp_config, config):
-    """
-    It is highly critical that `load()` does not call anything from
-    `project_manager` as it is not loaded yet in the manager access mixin.
-    """
-    orig = config.project_manager.path
-    path = Path("_should_not_be_in_parents_")
-    try:
-        with temp_config({"contracts_folder": "src"}):
-            config.project_manager.path = path
-            assert config.load(force_reload=True)
-            assert path.name not in [x.name for x in config.contracts_folder.parents]
-    finally:
-        config.project_manager.path = orig
-
-
-def test_contracts_folder_with_hyphen(temp_config):
-    with temp_config({"contracts-folder": "src"}) as project:
+def test_contracts_folder_with_hyphen(project):
+    with project.temp_config(**{"contracts-folder": "src"}):
         assert project.contracts_folder.name == "src"
 
 
 def test_custom_network():
     chain_id = 11191919191991918223773
     data = {
         "name": "mytestnet",
```

### Comparing `eth-ape-0.7.9/tests/functional/test_contract.py` & `eth-ape-0.8.0/tests/functional/test_contract.py`

 * *Files 8% similar despite different names*

```diff
@@ -5,42 +5,38 @@
 
 from ape import Contract
 from ape.contracts import ContractInstance
 from ape.exceptions import ChainError
 
 """NOTE: This is testing Contract with a capital C."""
 
-"""NOTE: This is testing contract with a capital C."""
-
 
 def test_Contract_from_abi(contract_instance):
     contract = Contract(contract_instance.address, abi=contract_instance.contract_type.abi)
     assert isinstance(contract, ContractInstance)
     assert contract.address == contract_instance.address
     assert contract.myNumber() == 0
     assert contract.balance == 0
 
 
 def test_Contract_from_abi_list(contract_instance):
     contract = Contract(
         contract_instance.address,
-        abi=[abi.model_dump(mode="json") for abi in contract_instance.contract_type.abi],
+        abi=[abi.model_dump() for abi in contract_instance.contract_type.abi],
     )
 
     assert isinstance(contract, ContractInstance)
     assert contract.address == contract_instance.address
     assert contract.myNumber() == 0
 
 
 def test_Contract_from_json_str(contract_instance):
     contract = Contract(
         contract_instance.address,
-        abi=json.dumps(
-            [abi.model_dump(mode="json") for abi in contract_instance.contract_type.abi]
-        ),
+        abi=json.dumps([abi.model_dump() for abi in contract_instance.contract_type.abi]),
     )
 
     assert isinstance(contract, ContractInstance)
     assert contract.address == contract_instance.address
     assert contract.myNumber() == 0
```

### Comparing `eth-ape-0.7.9/tests/functional/test_contract_container.py` & `eth-ape-0.8.0/tests/functional/test_contract_container.py`

 * *Files 3% similar despite different names*

```diff
@@ -117,19 +117,17 @@
 
     # Show we get the implementation contract type using the proxy address
     implementation = chain.contracts.instance_at(proxy.address)
     assert implementation.contract_type == vyper_contract_instance.contract_type
 
 
 def test_source_path_in_project(project_with_contract):
-    contracts_folder = project_with_contract.contracts_folder
     contract = project_with_contract.contracts["Contract"]
     contract_container = project_with_contract.get_contract("Contract")
-    expected = contracts_folder / contract.source_id
-
+    expected = project_with_contract.path / contract.source_id
     assert contract_container.source_path.is_file()
     assert contract_container.source_path == expected
 
 
 def test_source_path_out_of_project(contract_container, project_with_contract):
     assert not contract_container.source_path
 
@@ -154,7 +152,14 @@
     expected = "setNumber(uint256)", {"num": 222}
     assert actual == expected
 
 
 def test_declare(contract_container, sender):
     receipt = contract_container.declare(sender=sender)
     assert not receipt.failed
+
+
+def test_source_id(contract_container):
+    actual = contract_container.source_id
+    expected = contract_container.contract_type.source_id
+    # Is just a pass-through (via extras-model), but making sure it works.
+    assert actual == expected
```

### Comparing `eth-ape-0.7.9/tests/functional/test_contract_event.py` & `eth-ape-0.8.0/tests/functional/test_contract_event.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 import time
 from queue import Queue
 from typing import Optional
 
 import pytest
 from eth_pydantic_types import HexBytes
-from eth_utils import to_hex
 from ethpm_types import ContractType
 
 from ape.api import ReceiptAPI
 from ape.exceptions import ProviderError
 from ape.types import ContractLog
 
 
@@ -120,39 +119,39 @@
     assert len(logs) == 1, "Unexpected number of logs"
     assert_log_values(logs[0], 1)
 
 
 def test_contract_logs_range_by_address(
     mocker, chain, eth_tester_provider, test_accounts, contract_instance, owner, assert_log_values
 ):
-    get_logs_spy = mocker.spy(eth_tester_provider.web3.eth, "get_logs")
+    get_logs_spy = mocker.spy(eth_tester_provider.tester.ethereum_tester, "get_logs")
     contract_instance.setAddress(test_accounts[1], sender=owner)
     height = chain.blocks.height
     logs = [
         log
         for log in contract_instance.AddressChange.range(
             height, height + 1, search_topics={"newAddress": test_accounts[1]}
         )
     ]
 
     # NOTE: This spy assertion tests against a bug where address queries were not
     # 0x-prefixed. However, this was still valid in EthTester and thus was not causing
     # test failures.
-    height_arg = to_hex(chain.blocks.height)
-    get_logs_spy.assert_called_once_with(
-        {
-            "address": [contract_instance.address],
-            "fromBlock": height_arg,
-            "toBlock": height_arg,
-            "topics": [
-                "0x7ff7bacc6cd661809ed1ddce28d4ad2c5b37779b61b9e3235f8262be529101a9",
-                "0x00000000000000000000000070997970c51812dc3a010c7d01b50e0d17dc79c8",
-            ],
-        }
-    )
+    height_arg = chain.blocks.height
+    actual = get_logs_spy.call_args[-1]
+    expected = {
+        "address": [contract_instance.address],
+        "from_block": height_arg,
+        "to_block": height_arg,
+        "topics": [
+            "0x7ff7bacc6cd661809ed1ddce28d4ad2c5b37779b61b9e3235f8262be529101a9",
+            "0x00000000000000000000000070997970c51812dc3a010c7d01b50e0d17dc79c8",
+        ],
+    }
+    assert actual == expected
     assert logs == [contract_instance.AddressChange(newAddress=test_accounts[1])]
 
 
 def test_contracts_log_multiple_addresses(
     chain, contract_instance, contract_container, owner, assert_log_values
 ):
     another_instance = contract_container.deploy(0, sender=owner)
```

### Comparing `eth-ape-0.7.9/tests/functional/test_contract_instance.py` & `eth-ape-0.8.0/tests/functional/test_contract_instance.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 import re
-from typing import List, Tuple
 
 import pytest
 from eth_pydantic_types import HexBytes
 from eth_utils import is_checksum_address, to_hex
 from ethpm_types import BaseModel, ContractType
 
 from ape.api import TransactionAPI
@@ -291,21 +290,21 @@
     assert struct_2.foo == 2
     assert struct_2.t.a == owner
     assert is_checksum_address(struct_2.t.a)
 
 
 def test_get_empty_dyn_array_of_structs(contract_instance):
     actual = contract_instance.getEmptyDynArrayOfStructs()
-    expected: List = []
+    expected: list = []
     assert actual == expected
 
 
 def test_get_empty_tuple_of_dyn_array_structs(contract_instance):
     actual = contract_instance.getEmptyTupleOfDynArrayStructs()
-    expected: Tuple[List, List] = ([], [])
+    expected: tuple[list, list] = ([], [])
     assert actual == expected
 
 
 def test_get_empty_tuple_of_array_of_structs_and_dyn_array_of_structs(
     contract_instance, zero_address
 ):
     actual = contract_instance.getEmptyTupleOfArrayOfStructsAndDynArrayOfStructs()
@@ -322,15 +321,15 @@
     assert actual_int == 0
     assert len(actual_struct_array) == 5
     assert len(actual_struct_array[0]) == 6
 
 
 def test_get_empty_tuple_of_int_and_dyn_array(contract_instance):
     actual = contract_instance.getEmptyTupleOfIntAndDynArray()
-    expected: Tuple[List, List] = ([], [])
+    expected: tuple[list, list] = ([], [])
     assert actual == expected
 
 
 def test_vyper_structs_with_array(vyper_contract_instance):
     # NOTE: Vyper struct arrays <=0.3.3 don't include struct info
     actual = vyper_contract_instance.getStructWithArray()
     assert actual.foo == 1
@@ -535,31 +534,22 @@
 
 def test_call_transact(vyper_contract_instance, owner):
     receipt = vyper_contract_instance.myNumber.transact(sender=owner)
     assert receipt.sender == owner
     assert receipt.status == TransactionStatusEnum.NO_ERROR
 
 
-def test_receipt(contract_instance, owner):
-    receipt = contract_instance.receipt
+def test_creation_receipt(contract_instance, owner):
+    assert contract_instance.creation_metadata is not None
+    receipt = contract_instance.creation_metadata.receipt
     assert receipt.txn_hash == contract_instance.txn_hash
     assert receipt.contract_address == contract_instance.address
     assert receipt.sender == owner
 
 
-def test_receipt_when_needs_brute_force(vyper_contract_instance, owner):
-    # Force it to use the brute-force approach.
-    vyper_contract_instance._cached_receipt = None
-    vyper_contract_instance.txn_hash = None
-
-    actual = vyper_contract_instance.receipt.contract_address
-    expected = vyper_contract_instance.address
-    assert actual == expected
-
-
 def test_from_receipt_when_receipt_not_deploy(contract_instance, owner):
     receipt = contract_instance.setNumber(555, sender=owner)
     expected_err = (
         "Receipt missing 'contract_address' field. "
         "Was this from a deploy transaction (e.g. `project.MyContract.deploy()`)?"
     )
     with pytest.raises(ChainError, match=expected_err):
@@ -591,26 +581,26 @@
 
 def test_dir(vyper_contract_instance):
     actual = dir(vyper_contract_instance)
     expected = [
         # From base class
         "address",
         "balance",
+        "call_view_method",
         "code",
         "contract_type",
         "codesize",
-        "nonce",
-        "is_contract",
-        "provider",
-        "receipt",
-        "txn_hash",
+        "creation_metadata",
         "decode_input",
         "get_event_by_signature",
         "invoke_transaction",
-        "call_view_method",
+        "is_contract",
+        "nonce",
+        "provider",
+        "txn_hash",
         *vyper_contract_instance._events_,
         *vyper_contract_instance._mutable_methods_,
         *vyper_contract_instance._view_methods_,
     ]
     assert sorted(actual) == sorted(expected)
 
 
@@ -767,21 +757,20 @@
             "0x1a7c56fae0af54ebae73bc4699b9de9835e7bb86b050dff7e80695b633f17abd"
         ].selector
         == "FooHappened(uint256)"
     )
 
 
 def test_source_path(project_with_contract, owner):
-    contracts_folder = project_with_contract.contracts_folder
-    contract = project_with_contract.contracts["Contract"]
-    contract_instance = owner.deploy(project_with_contract.get_contract("Contract"))
-    expected = contracts_folder / contract.source_id
+    contract = project_with_contract.get_contract("Contract")
+    instance = owner.deploy(contract)
+    expected = project_with_contract.path / contract.source_id
 
-    assert contract_instance.source_path.is_file()
-    assert contract_instance.source_path == expected
+    assert instance.source_path.is_file()
+    assert instance.source_path == expected
 
 
 def test_fallback(fallback_contract, owner):
     """
     Test that shows __call__ uses the contract's defined fallback method.
     We know this is a successful test because otherwise you would get a
     ContractLogicError.
@@ -794,15 +783,15 @@
     vyper_fallback_contract, owner, vyper_fallback_contract_type
 ):
     """
     Test that shows when fallback is non-payable and there is no receive,
     and you try to send a value, it fails.
     """
     # Hack to set fallback as non-payable.
-    contract_type_data = vyper_fallback_contract_type.model_dump(mode="json")
+    contract_type_data = vyper_fallback_contract_type.model_dump()
     for abi in contract_type_data["abi"]:
         if abi.get("type") == "fallback":
             abi["stateMutability"] = "non-payable"
             break
 
     new_contract_type = ContractType.model_validate(contract_type_data)
     contract = owner.chain_manager.contracts.instance_at(
```

### Comparing `eth-ape-0.7.9/tests/functional/test_contract_method_handler.py` & `eth-ape-0.8.0/tests/functional/test_contract_method_handler.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/test_contracts_cache.py` & `eth-ape-0.8.0/tests/functional/test_contracts_cache.py`

 * *Files 2% similar despite different names*

```diff
@@ -142,15 +142,15 @@
     new_address = "0x4a986a6dca6dbF99Bc3D17F8d71aFB0D60E740F9"
     expected = (
         rf"Failed to get contract type for address '{new_address}'. "
         r"Current provider 'ethereum:local:test' has no associated explorer plugin. "
         "Try installing an explorer plugin using .*ape plugins install etherscan.*, "
         r"or using a network with explorer support\."
     )
-    with pytest.raises(IndexError, match=expected):
+    with pytest.raises(KeyError, match=expected):
         _ = chain.contracts[new_address]
 
 
 def test_deployments_mapping_cache_location(chain):
     # Arrange / Act
     mapping_location = chain.contracts._deployments_mapping_cache
     split_mapping_location = str(mapping_location).split("/")
@@ -307,34 +307,34 @@
         del chain.contracts[vyper_contract_instance.address]
 
     lowered_address = vyper_contract_instance.address.lower()
     chain.contracts[lowered_address] = vyper_contract_instance.contract_type
     assert chain.contracts[vyper_contract_instance.address] == vyper_contract_instance.contract_type
 
 
-def test_get_contract_receipt(chain, vyper_contract_instance):
+def test_get_creation_metadata(chain, vyper_contract_instance, owner):
     address = vyper_contract_instance.address
-    receipt = chain.contracts.get_creation_receipt(address)
-    assert receipt.contract_address == address
+    creation = chain.contracts.get_creation_metadata(address)
+    assert creation.deployer == owner.address
 
     chain.mine()
-    receipt = chain.contracts.get_creation_receipt(address)
-    assert receipt.contract_address == address
+    creation = chain.contracts.get_creation_metadata(address)
+    assert creation.deployer == owner.address
 
 
 def test_delete_contract(vyper_contract_instance, chain):
     # Ensure we start with it cached.
     if vyper_contract_instance.address not in chain.contracts:
         chain.contracts[vyper_contract_instance.address] = vyper_contract_instance
 
     del chain.contracts[vyper_contract_instance.address]
     assert vyper_contract_instance.address not in chain.contracts
 
     # Ensure we can't access it.
-    with pytest.raises(IndexError):
+    with pytest.raises(KeyError):
         _ = chain.contracts[vyper_contract_instance.address]
 
 
 def test_delete_proxy(vyper_contract_instance, chain, ethereum, owner):
     address = vyper_contract_instance.address
     container = _make_minimal_proxy(address=address.lower())
     proxy = container.deploy(sender=owner)
@@ -348,13 +348,13 @@
     if proxy_info.target not in chain.contracts:
         chain.contracts[proxy_info.target] = vyper_contract_instance
 
     del chain.contracts[proxy.address]
     assert proxy.address not in chain.contracts
 
     # Ensure we can't access it.
-    with pytest.raises(IndexError):
+    with pytest.raises(KeyError):
         _ = chain.contracts[proxy.address]
 
     # Ensure we can't access the target either.
-    with pytest.raises(IndexError):
+    with pytest.raises(KeyError):
         _ = chain.contracts[proxy_info.target]
```

### Comparing `eth-ape-0.7.9/tests/functional/test_coverage.py` & `eth-ape-0.8.0/tests/functional/test_coverage.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,12 +1,14 @@
 from pathlib import Path
-from typing import List
 
 import pytest
+from ethpm_types.source import ContractSource, Source
 
+from ape.pytest.config import ConfigWrapper
+from ape.pytest.coverage import CoverageData, CoverageTracker
 from ape.types.coverage import (
     ContractCoverage,
     ContractSourceCoverage,
     CoverageProject,
     CoverageReport,
     CoverageStatement,
     FunctionCoverage,
@@ -18,15 +20,15 @@
 
 
 @pytest.fixture
 def statements():
     return create_statements(20, 21, 21)
 
 
-def create_statements(*pcs) -> List[CoverageStatement]:
+def create_statements(*pcs) -> list[CoverageStatement]:
     return [
         CoverageStatement(pcs={pcs[0]}, hit_count=STMT_0_HIT),
         CoverageStatement(pcs={pcs[1]}, hit_count=STMT_1_HIT),
         CoverageStatement(pcs={pcs[2]}, hit_count=STMT_2_HIT),
     ]
 
 
@@ -153,7 +155,42 @@
         assert coverage_report.lines_covered == 8
 
     def test_miss_count(self, coverage_report):
         assert coverage_report.miss_count == 4
 
     def test_line_rate(self, coverage_report):
         assert coverage_report.line_rate == 2 / 3
+
+
+class TestCoverageData:
+    @pytest.fixture(scope="class")
+    def src(self):
+        return Source.model_validate("test")
+
+    @pytest.fixture(scope="class")
+    def contract_source(self, vyper_contract_type, src):
+        return ContractSource(contract_type=vyper_contract_type, source=src)
+
+    @pytest.fixture(scope="class")
+    def coverage_data(self, project, contract_source):
+        return CoverageData(project.path, (contract_source,))
+
+    def test_report(self, coverage_data):
+        actual = coverage_data.report
+        assert isinstance(actual, CoverageReport)
+
+
+class TestCoverageTracker:
+    @pytest.fixture
+    def pytest_config(self, mocker):
+        return mocker.MagicMock()
+
+    @pytest.fixture(scope="class")
+    def config_wrapper(self, pytest_config):
+        return ConfigWrapper(pytest_config)
+
+    def test_data(self, pytest_config):
+        tracker = CoverageTracker(pytest_config)
+        assert tracker.data is not None
+        actual = tracker.data.base_path
+        expected = tracker.local_project.path
+        assert actual == expected
```

### Comparing `eth-ape-0.7.9/tests/functional/test_default_sender_context_manager.py` & `eth-ape-0.8.0/tests/functional/test_default_sender_context_manager.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/test_ecosystem.py` & `eth-ape-0.8.0/tests/functional/test_ecosystem.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,17 +1,18 @@
 import copy
-from typing import Any, ClassVar, Dict
+from typing import Any, ClassVar, cast
 
 import pytest
 from eth_pydantic_types import HashBytes32, HexBytes
 from eth_typing import HexAddress, HexStr
+from ethpm_types import ContractType, ErrorABI
 from ethpm_types.abi import ABIType, EventABI, MethodABI
 
 from ape.api.networks import LOCAL_NETWORK_NAME, NetworkAPI
-from ape.exceptions import DecodingError, NetworkError, NetworkNotFoundError
+from ape.exceptions import CustomError, DecodingError, NetworkError, NetworkNotFoundError
 from ape.types import AddressType
 from ape.utils import DEFAULT_LOCAL_TRANSACTION_ACCEPTANCE_TIMEOUT
 from ape_ethereum.ecosystem import BLUEPRINT_HEADER, BaseEthereumConfig, Block
 from ape_ethereum.transactions import (
     DynamicFeeTransaction,
     Receipt,
     SharedBlobReceipt,
@@ -40,33 +41,33 @@
 
 @pytest.fixture
 def event_abi(vyper_contract_instance):
     return vyper_contract_instance.NumberChange.abi
 
 
 @pytest.fixture
-def custom_ecosystem_config(
-    custom_networks_config_dict, temp_config, networks, custom_network_name_0
+def configured_custom_ecosystem(
+    custom_networks_config_dict, project, networks, custom_network_name_0
 ):
     data = copy.deepcopy(custom_networks_config_dict)
     data["networks"]["custom"][0]["ecosystem"] = CUSTOM_ECOSYSTEM_NAME
 
     # Also ensure we can configure the custom ecosystem as if
     # it were from a plugin.
     data[CUSTOM_ECOSYSTEM_NAME] = {"default_network": custom_network_name_0}
 
-    with temp_config(data):
+    with project.temp_config(**data):
         yield
 
 
 def test_name(ethereum):
     assert ethereum.name == "ethereum"
 
 
-def test_name_when_custom(custom_ecosystem_config, networks):
+def test_name_when_custom(configured_custom_ecosystem, networks):
     ecosystem = networks.get_ecosystem(CUSTOM_ECOSYSTEM_NAME)
     actual = ecosystem.name
     expected = CUSTOM_ECOSYSTEM_NAME
     assert actual == expected
 
 
 @pytest.mark.parametrize(
@@ -149,43 +150,130 @@
             item_type("0xc5d246"),
         )
     )
     actual = ethereum.encode_calldata(abi, "0x0123", hexstr_array)
     assert isinstance(actual, bytes)
 
 
+def test_encode_calldata_nested_structs(ethereum):
+    abi = MethodABI(
+        type="function",
+        name="check",
+        stateMutability="view",
+        inputs=[
+            ABIType(
+                name="data",
+                type="tuple",
+                components=[
+                    ABIType(
+                        name="tokenIn", type="address", components=None, internal_type="address"
+                    ),
+                    ABIType(
+                        name="amountIn", type="uint256", components=None, internal_type="uint256"
+                    ),
+                    ABIType(
+                        name="minAmountOut",
+                        type="uint256",
+                        components=None,
+                        internal_type="uint256",
+                    ),
+                    ABIType(
+                        name="path",
+                        type="tuple",
+                        components=[
+                            ABIType(
+                                name="pairBinSteps",
+                                type="uint256[]",
+                                components=None,
+                                internal_type="uint256[]",
+                            ),
+                            ABIType(
+                                name="versions",
+                                type="uint8[]",
+                                components=None,
+                                internal_type="enum SwapWrapper.Version[]",
+                            ),
+                            ABIType(
+                                name="tokenPath",
+                                type="address[]",
+                                components=None,
+                                internal_type="address[]",
+                            ),
+                        ],
+                        internal_type="struct SwapWrapper.Path",
+                    ),
+                ],
+                internal_type="struct SwapWrapper.SwapData",
+            )
+        ],
+        outputs=[ABIType(name="", type="bool", components=None, internal_type="bool")],
+    )
+    calldata = {
+        "tokenIn": "0xB31f66AA3C1e785363F0875A1B74E27b85FD66c7",
+        "amountIn": 1000000000000000000,
+        "minAmountOut": 10000000,
+        "path": {
+            "pairBinSteps": [0],
+            "versions": [0],
+            "tokenPath": [
+                "0xB31f66AA3C1e785363F0875A1B74E27b85FD66c7",
+                "0xB97EF9Ef8734C71904D8002F8b6Bc66Dd9c48a6E",
+            ],
+        },
+    }
+    actual = ethereum.encode_calldata(abi, calldata)
+    expected = HexBytes(
+        "0x000000000000000000000000000000000000000000000000000000000000002"
+        "0000000000000000000000000b31f66aa3c1e785363f0875a1b74e27b85fd66c7"
+        "0000000000000000000000000000000000000000000000000de0b6b3a76400000"
+        "00000000000000000000000000000000000000000000000000000000098968000"
+        "00000000000000000000000000000000000000000000000000000000000080000"
+        "00000000000000000000000000000000000000000000000000000000000600000"
+        "0000000000000000000000000000000000000000000000000000000000a000000"
+        "000000000000000000000000000000000000000000000000000000000e0000000"
+        "00000000000000000000000000000000000000000000000000000000010000000"
+        "00000000000000000000000000000000000000000000000000000000000000000"
+        "00000000000000000000000000000000000000000000000000000001000000000"
+        "00000000000000000000000000000000000000000000000000000000000000000"
+        "00000000000000000000000000000000000000000000000000000200000000000"
+        "0000000000000b31f66aa3c1e785363f0875a1b74e27b85fd66c7000000000000"
+        "000000000000b97ef9ef8734c71904d8002f8b6bc66dd9c48a6e"
+    )
+    assert actual == expected
+
+
 def test_block_handles_snake_case_parent_hash(eth_tester_provider, sender, receiver):
     # Transaction to change parent hash of next block
     sender.transfer(receiver, "1 gwei")
 
     # Replace 'parentHash' key with 'parent_hash'
     latest_block = eth_tester_provider.get_block("latest")
-    latest_block_dict = eth_tester_provider.get_block("latest").model_dump(mode="json")
+    latest_block_dict = eth_tester_provider.get_block("latest").model_dump()
     latest_block_dict["parent_hash"] = latest_block_dict.pop("parentHash")
 
     redefined_block = Block.model_validate(latest_block_dict)
     assert redefined_block.parent_hash == latest_block.parent_hash
 
 
-def test_transaction_acceptance_timeout(temp_config, config, networks):
+def test_transaction_acceptance_timeout(project, networks):
     assert (
         networks.provider.network.transaction_acceptance_timeout
         == DEFAULT_LOCAL_TRANSACTION_ACCEPTANCE_TIMEOUT
     )
     new_value = DEFAULT_LOCAL_TRANSACTION_ACCEPTANCE_TIMEOUT + 1
     timeout_config = {"ethereum": {"local": {"transaction_acceptance_timeout": new_value}}}
-    with temp_config(timeout_config):
+    with project.temp_config(**timeout_config):
         assert networks.provider.network.transaction_acceptance_timeout == new_value
 
 
 def test_decode_logs(ethereum, vyper_contract_instance):
     abi = vyper_contract_instance.NumberChange.abi
     result = [x for x in ethereum.decode_logs([LOG], abi)]
     assert len(result) == 1
-    assert dict(result[0]) == {
+    assert result[0].model_dump() == {
         "event_name": "NumberChange",
         "contract_address": "0x274b028b03A250cA03644E6c578D81f019eE1323",
         "event_arguments": {
             "newNum": 6,
             "dynIndexed": HexBytes(
                 "0x9f3d45ac20ccf04b45028b8080bb191eab93e29f7898ed43acf480dd80bba94d"
             ),
@@ -266,15 +354,15 @@
             "4550e2cc369010139a1d3a5a6ec6d65910379e0ee35a7c3cdf24cb12a7"
         ),
     ]
 
 
 def test_decode_block_when_hash_is_none(ethereum):
     # When using some providers, such as hardhat, the hash of the pending block is None
-    block_data_with_none_hash: Dict[str, Any] = {
+    block_data_with_none_hash: dict[str, Any] = {
         "number": None,
         "hash": None,
         "parentHash": HexBytes(
             "0xcb94e150c06faee9ab2bf12a40b0937ac9eab1879c733ebe3249aafbba2f80b1"
         ),
         "nonce": None,
         "mixHash": None,
@@ -450,17 +538,17 @@
     )
     assert type(receipt) is Receipt  # NOTE: Purposely not using isinstance()
     assert receipt.type == 0
     assert receipt.max_fee == 0
     assert receipt.gas_price == 1499999989
 
 
-def test_decode_receipt_shared_blob(ethereum):
+@pytest.mark.parametrize("blob_gas_used", ("0x20000", 131072, 0, None))
+def test_decode_receipt_shared_blob(ethereum, blob_gas_used):
     blob_gas_price = "0x4d137e31b"
-    blob_gas_used = "0x20000"
 
     data = {
         "required_confirmations": 0,
         "blockHash": HexBytes("0x051fb508617fcbe0034538b7ee54c1dedbbbaa6f8d0aeb776edf81bafbc883bd"),
         "blockNumber": 10526428,
         "from": "0x194E22F49BC3f58903866d55488E1e9e8d69b517",
         "gas": 5500000,
@@ -495,58 +583,62 @@
         "status": 1,
         "transactionHash": HexBytes(
             "0xd2882bae0d79a6c8e0fbf0089bbcb4b2eef3a1365471ad9f779b06a41ba47d3c"
         ),
     }
     actual = ethereum.decode_receipt(data)
     assert isinstance(actual, SharedBlobReceipt)
-    assert actual.blob_gas_used == int(blob_gas_used, 16)
     assert actual.blob_gas_price == int(blob_gas_price, 16)
 
+    if blob_gas_used:
+        # all test-values are this when they exist.
+        assert actual.blob_gas_used == 131072
+    else:
+        # when None, should also default to 0.
+        assert actual.blob_gas_used == 0
 
-def test_default_transaction_type_not_connected_used_default_network(
-    temp_config, ethereum, networks
-):
+
+def test_default_transaction_type_not_connected_used_default_network(project, ethereum, networks):
     value = TransactionType.STATIC.value
     config_dict = {"ethereum": {"mainnet_fork": {"default_transaction_type": value}}}
     assert ethereum.default_transaction_type == TransactionType.DYNAMIC
 
-    with temp_config(config_dict):
+    with project.temp_config(**config_dict):
         ethereum._default_network = "mainnet-fork"
         provider = networks.active_provider
 
         # Disconnect so it uses default.
         networks.active_provider = None
         try:
             assert ethereum.default_network_name == "mainnet-fork"
             assert ethereum.default_transaction_type == TransactionType.STATIC
             ethereum._default_network = LOCAL_NETWORK_NAME
         finally:
             networks.active_provider = provider
 
 
 def test_default_transaction_type_configured_from_local_network(
-    eth_tester_provider, ethereum, temp_config
+    eth_tester_provider, ethereum, project
 ):
     _ = eth_tester_provider  # Connection required so 'ethereum' knows the network.
     value = TransactionType.STATIC.value
     config = {"ethereum": {LOCAL_NETWORK_NAME: {"default_transaction_type": value}}}
-    with temp_config(config):
+    with project.temp_config(**config):
         assert ethereum.default_transaction_type == TransactionType.STATIC
 
 
 def test_default_transaction_type_changed_at_class_level(ethereum):
     """
     Simulates an L2 plugin changing the default at the definition-level.
     """
 
-    class Subconfig(BaseEthereumConfig):
+    class L2NetworkConfig(BaseEthereumConfig):
         DEFAULT_TRANSACTION_TYPE: ClassVar[int] = TransactionType.STATIC.value
 
-    config = Subconfig()
+    config = L2NetworkConfig()
     assert config.local.default_transaction_type.value == 0
     assert config.mainnet.default_transaction_type.value == 0
     assert config.mainnet_fork.default_transaction_type.value == 0
 
 
 def test_default_transaction_type_configured_from_custom_network():
     pass
@@ -555,15 +647,15 @@
 @pytest.mark.parametrize("network_name", (LOCAL_NETWORK_NAME, "mainnet-fork", "mainnet_fork"))
 def test_gas_limit_local_networks(ethereum, network_name):
     network = ethereum.get_network(network_name)
     assert network.gas_limit == "max"
 
 
 def test_gas_limit_live_networks(ethereum):
-    network = ethereum.get_network("goerli")
+    network = ethereum.get_network("sepolia")
     assert network.gas_limit == "auto"
 
 
 def test_encode_blueprint_contract(ethereum, vyper_contract_type):
     actual = ethereum.encode_contract_blueprint(vyper_contract_type)
     ct_bytes = vyper_contract_type.deployment_bytecode.to_bytes()
 
@@ -760,78 +852,169 @@
     abi = vyper_contract_instance.contract_type.methods[0]
     actual = ethereum.encode_transaction(
         vyper_contract_instance.address, abi, sender=owner.address, type=tx_type.value
     )
     assert actual.gas_limit == eth_tester_provider.max_gas
 
 
-def test_set_default_network_not_exists(temp_config, ethereum):
+def test_set_default_network_not_exists(ethereum):
     bad_network = "NOT_EXISTS"
     expected = f"No network in 'ethereum' named '{bad_network}'. Options:.*"
     with pytest.raises(NetworkNotFoundError, match=expected):
         ethereum.set_default_network(bad_network)
 
 
 def test_networks(ethereum):
     actual = ethereum.networks
-    for net in ("goerli", "sepolia", "mainnet", LOCAL_NETWORK_NAME):
+    for net in ("sepolia", "mainnet", LOCAL_NETWORK_NAME):
         assert net in actual
         assert isinstance(actual[net], NetworkAPI)
 
 
 def test_networks_includes_custom_networks(
-    ethereum, custom_networks_config, custom_network_name_0, custom_network_name_1
+    ethereum, custom_networks_config_dict, project, custom_network_name_0, custom_network_name_1
 ):
-    actual = ethereum.networks
-    for net in (
-        "goerli",
-        "sepolia",
-        "mainnet",
-        LOCAL_NETWORK_NAME,
-        custom_network_name_0,
-        custom_network_name_1,
-    ):
-        assert net in actual
-        assert isinstance(actual[net], NetworkAPI)
+    with project.temp_config(**custom_networks_config_dict):
+        actual = ethereum.networks
+        for net in (
+            "sepolia",
+            "mainnet",
+            LOCAL_NETWORK_NAME,
+            custom_network_name_0,
+            custom_network_name_1,
+        ):
+            assert net in actual
+            assert isinstance(actual[net], NetworkAPI)
 
 
-def test_networks_when_custom_ecosystem(custom_ecosystem_config, networks, custom_network_name_0):
+def test_networks_when_custom_ecosystem(
+    configured_custom_ecosystem, networks, custom_network_name_0
+):
     obj = networks.custom_ecosystem
     actual = obj.networks
     assert obj.name == CUSTOM_ECOSYSTEM_NAME
     assert custom_network_name_0 in actual
     assert "mainnet" not in actual
 
 
-def test_networks_multiple_networks_with_same_name(
-    temp_config, custom_networks_config_dict, ethereum
-):
+def test_networks_multiple_networks_with_same_name(custom_networks_config_dict, ethereum, project):
     data = copy.deepcopy(custom_networks_config_dict)
     data["networks"]["custom"][0]["name"] = "mainnet"  # There already is a mainnet in "ethereum".
     expected = ".*More than one network named 'mainnet' in ecosystem 'ethereum'.*"
-    with temp_config(data):
+    with project.temp_config(**data):
         with pytest.raises(NetworkError, match=expected):
             _ = ethereum.networks
 
 
 def test_getattr(ethereum):
     assert ethereum.mainnet.name == "mainnet"
     assert isinstance(ethereum.mainnet, NetworkAPI)
 
 
-def test_getattr_custom_networks(ethereum, custom_networks_config, custom_network_name_0):
-    actual = getattr(ethereum, custom_network_name_0)
-    assert actual.name == custom_network_name_0
-    assert isinstance(actual, NetworkAPI)
+def test_getattr_custom_networks(
+    ethereum, custom_networks_config_dict, project, custom_network_name_0
+):
+    with project.temp_config(**custom_networks_config_dict):
+        actual = getattr(ethereum, custom_network_name_0)
+        assert actual.name == custom_network_name_0
+        assert isinstance(actual, NetworkAPI)
 
 
 def test_default_network(ethereum):
     assert ethereum.default_network_name == LOCAL_NETWORK_NAME
 
 
 def test_default_network_when_custom_and_set_in_config(
-    custom_ecosystem_config, networks, custom_network_name_0
+    configured_custom_ecosystem, networks, custom_network_name_0
 ):
     ecosystem = networks.get_ecosystem(CUSTOM_ECOSYSTEM_NAME)
     # Force it to use config value (in case was set from previous test)
     ecosystem._default_network = None
     assert ecosystem.default_network_name == custom_network_name_0
+
+
+def test_default_network_name_set_programmatically(ethereum):
+    ethereum._default_network = "testnet"
+    assert ethereum.default_network_name == "testnet"
+    ethereum._default_network = None
+
+
+def test_default_network_name_from_config(project, ethereum):
+    cfg = {"ethereum": {"default_network": "sepolia"}}
+    ethereum._default_network = None
+    with project.temp_config(**cfg):
+        assert ethereum.default_network_name == "sepolia"
+
+
+def test_default_network_name_when_not_set_uses_local(project, ethereum):
+    orig = project.config.ethereum
+    data = orig if isinstance(orig, dict) else orig.model_dump()
+    data = {k: v for k, v in data.items() if k not in ("default_network",)}
+    data["default_network"] = None
+    with project.temp_config(**data):
+        ethereum._default_network = None
+        assert ethereum.default_network_name == LOCAL_NETWORK_NAME
+
+
+def test_default_network_name_when_not_set_and_no_local_uses_only(
+    project, custom_networks_config_dict
+):
+    """
+    Tests a condition that is rare but when a default network is
+    not set but there is a single network. In this case, it
+    should use the single network by default.
+    """
+    net = copy.deepcopy(custom_networks_config_dict["networks"]["custom"][0])
+
+    # In a situation with an ecosystem with only a single network.
+    ecosystem_name = "acustomeco"
+    net["ecosystem"] = ecosystem_name
+
+    only_network = "onlynet"  # More obvious name for test.
+    net["name"] = only_network
+
+    with project.temp_config(networks={"custom": [net]}):
+        ecosystem = project.network_manager.get_ecosystem(ecosystem_name)
+        assert ecosystem.default_network_name == only_network
+
+
+def test_decode_custom_error(chain, ethereum):
+    data = HexBytes("0x6a12f104")
+    abi = [ErrorABI(type="error", name="InsufficientETH", inputs=[])]
+    contract_type = ContractType(abi=abi)
+    addr = cast(AddressType, "0x3fC91A3afd70395Cd496C647d5a6CC9D4B2b7FAD")
+
+    # Hack in contract-type.
+    chain.contracts._local_contract_types[addr] = contract_type
+
+    actual = ethereum.decode_custom_error(data, addr)
+    assert isinstance(actual, CustomError)
+
+
+def test_decode_custom_error_contract_type_not_found(ethereum):
+    data = HexBytes("0x6a12f104")
+    # not known
+    addr = cast(AddressType, "0x4fC92A3afd70395Cd496C647d5a6CC9D4B2b7FAD")
+    actual = ethereum.decode_custom_error(data, addr)
+    assert actual is None
+
+
+def test_decode_custom_error_tx_unsigned(ethereum):
+    data = HexBytes("0x6a12f104")
+    # not known
+    addr = cast(AddressType, "0x4fC92A3afd70395Cd496C647d5a6CC9D4B2b7FAD")
+    actual = ethereum.decode_custom_error(data, addr)
+    assert actual is None
+
+
+def test_decode_custom_error_selector_not_found(chain, ethereum):
+    data = HexBytes("0x6a12f104")
+    abi: list = []
+    contract_type = ContractType(abi=abi)
+    addr = cast(AddressType, "0x3fC91A3afd70395Cd496C647d5a6CC9D4B2b7FAD")
+
+    # Hack in contract-type.
+    chain.contracts._local_contract_types[addr] = contract_type
+
+    tx = ethereum.create_transaction()
+    actual = ethereum.decode_custom_error(data, addr, txn=tx)
+    assert actual is None
```

### Comparing `eth-ape-0.7.9/tests/functional/test_fixtures.py` & `eth-ape-0.8.0/tests/functional/test_fixtures.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/test_history.py` & `eth-ape-0.8.0/tests/functional/test_history.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/test_logging.py` & `eth-ape-0.8.0/tests/functional/test_logging.py`

 * *Files 8% similar despite different names*

```diff
@@ -17,84 +17,84 @@
 
 def test_info(simple_runner):
     @group_for_testing.command()
     @ape_cli_context()
     def cmd(cli_ctx):
         cli_ctx.logger.info("this is a test")
 
-    result = simple_runner.invoke(group_for_testing, ["cmd"])
+    result = simple_runner.invoke(group_for_testing, "cmd")
     assert "INFO" in result.output
     assert "this is a test" in result.output
 
 
 def test_info_level_higher(simple_runner):
     @group_for_testing.command()
     @ape_cli_context()
     def cmd(cli_ctx):
         cli_ctx.logger.info("this is a test")
 
-    result = simple_runner.invoke(group_for_testing, ["cmd", "-v", "WARNING"])
+    result = simple_runner.invoke(group_for_testing, ("cmd", "-v", "WARNING"))
 
     # You don't get INFO log when log level is higher
     assert "INFO" not in result.output
     assert "this is a test" not in result.output
 
 
 def test_warning(simple_runner):
     @group_for_testing.command()
     @ape_cli_context()
     def cmd(cli_ctx):
         cli_ctx.logger.warning("this is a test")
 
-    result = simple_runner.invoke(group_for_testing, ["cmd"])
+    result = simple_runner.invoke(group_for_testing, "cmd")
     assert "WARNING" in result.output
     assert "this is a test" in result.output
 
 
 def test_warning_level_higher(simple_runner):
     @group_for_testing.command()
     @ape_cli_context()
     def cmd(cli_ctx):
         cli_ctx.logger.warning("this is a test")
 
-    result = simple_runner.invoke(group_for_testing, ["cmd", "-v", "ERROR"])
+    result = simple_runner.invoke(group_for_testing, ("cmd", "-v", "ERROR"))
     assert "WARNING" not in result.output
     assert "this is a test" not in result.output
 
 
 def test_success(simple_runner):
     # Since the log level defaults to INFO,
     # this test also ensures that we get SUCCESS logs
     # without having to specify verbosity
     @group_for_testing.command()
     @ape_cli_context()
     def cmd(cli_ctx):
         cli_ctx.logger.success("this is a test")
 
-    result = simple_runner.invoke(group_for_testing, ["cmd"])
+    result = simple_runner.invoke(group_for_testing, "cmd")
     assert "SUCCESS" in result.output
     assert "this is a test" in result.output
 
 
 def test_success_level_higher(simple_runner):
     @group_for_testing.command()
     @ape_cli_context()
     def cmd(cli_ctx):
         cli_ctx.logger.success("this is a test")
 
-    result = simple_runner.invoke(group_for_testing, ["cmd", "-v", "WARNING"])
+    result = simple_runner.invoke(group_for_testing, ("cmd", "-v", "WARNING"))
     assert "SUCCESS" not in result.output
     assert "this is a test" not in result.output
 
 
 def test_format(simple_runner):
     @group_for_testing.command()
     @ape_cli_context()
     def cmd(cli_ctx):
         cli_ctx.logger.format(fmt="%(message)s")
         try:
             cli_ctx.logger.success("this is a test")
         finally:
             cli_ctx.logger.format()
 
-    result = simple_runner.invoke(group_for_testing, ["cmd", "-v", "SUCCESS"])
+    result = simple_runner.invoke(group_for_testing, ("cmd", "-v", "SUCCESS"))
     assert "SUCCESS" not in result.output
```

### Comparing `eth-ape-0.7.9/tests/functional/test_multicall.py` & `eth-ape-0.8.0/tests/functional/test_multicall.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,29 +1,29 @@
-from typing import List
+from typing import NamedTuple
 
 import pytest
 from eth_pydantic_types import HexBytes
 from ethpm_types import ContractType
 
 from ape.exceptions import APINotImplementedError
 from ape_ethereum.multicall import Call
 from ape_ethereum.multicall.constants import MULTICALL3_ADDRESS, MULTICALL3_CONTRACT_TYPE
 from ape_ethereum.multicall.exceptions import UnsupportedChainError
 
 RETURNDATA = HexBytes("0x4a821464")
 
 
-class ReturndataClass:
-    returnData: List[HexBytes] = [RETURNDATA]
+class ReturnData(NamedTuple):
+    success: bool
+    returnData: bytes
 
 
 RETURNDATA_PARAMS = {
-    "result": ReturndataClass(),
-    # Happens when using Call() for a single call.
-    "result_single": [False, RETURNDATA],
+    "result_ok": (ReturnData(True, RETURNDATA), RETURNDATA),
+    "result_fail": (ReturnData(False, RETURNDATA), None),
 }
 
 
 @pytest.fixture(scope="module")
 def undeployed_multicall(chain):
     # NOTE: Still has the ability to decode/encode inputs.
     return chain.contracts.instance_at(
@@ -49,25 +49,28 @@
 
     # The local test chain doesn't have the multicall contracts.
     with pytest.raises(UnsupportedChainError):
         next(call())
 
 
 def test_aggregate3_input(
-    aggregate3, call_handler_with_struct_input, struct_input_for_call, vyper_contract_instance
+    aggregate3,
+    call_handler_with_struct_input,
+    struct_input_for_call,
+    vyper_contract_instance,
 ):
     call = Call()
 
     # Use a real contract here so the target encoding works.
     call_handler_with_struct_input.contract = vyper_contract_instance
 
     call.add(call_handler_with_struct_input, *struct_input_for_call)
     actual = aggregate3.encode_input(call.calls)
     assert isinstance(actual, HexBytes)
 
 
 @pytest.mark.parametrize("returndata_key", RETURNDATA_PARAMS)
 def test_returndata(returndata_key):
-    returndata = RETURNDATA_PARAMS[returndata_key]
+    result, output = RETURNDATA_PARAMS[returndata_key]
     call = Call()
-    call._result = returndata  # type: ignore
-    assert call.returnData[0] == HexBytes("0x4a821464")
+    call._result = [result]  # type: ignore
+    assert call.returnData[0] == output
```

### Comparing `eth-ape-0.7.9/tests/functional/test_network_manager.py` & `eth-ape-0.8.0/tests/functional/test_network_manager.py`

 * *Files 5% similar despite different names*

```diff
@@ -15,35 +15,31 @@
         self.chain_id += 1
         return self.chain_id
 
 
 chain_id_factory = NewChainID()
 
 DEFAULT_CHOICES = {
-    "::geth",
+    "::node",
     "::test",
-    ":goerli",
-    ":goerli:geth",
     ":sepolia",
-    ":sepolia:geth",
+    ":sepolia:node",
     ":local",
     ":mainnet",
-    ":mainnet:geth",
+    ":mainnet:node",
     "ethereum",
     "ethereum::test",
-    "ethereum::geth",
-    "ethereum:goerli",
-    "ethereum:goerli:geth",
+    "ethereum::node",
     "ethereum:sepolia",
-    "ethereum:sepolia:geth",
+    "ethereum:sepolia:node",
     "ethereum:local",
-    "ethereum:local:geth",
+    "ethereum:local:node",
     "ethereum:local:test",
     "ethereum:mainnet",
-    "ethereum:mainnet:geth",
+    "ethereum:mainnet:node",
 }
 
 
 @pytest.fixture
 def get_provider_with_unused_chain_id(networks_connected_to_tester):
     networks = networks_connected_to_tester
 
@@ -66,28 +62,29 @@
         return networks_connected_to_tester.parse_network_choice("ethereum:local:test")
 
     return fn
 
 
 @pytest.fixture
 def network_with_no_providers(ethereum):
-    network = ethereum.get_network("goerli-fork")
+    network = ethereum.get_network("sepolia-fork")
     default_provider = network.default_provider
     providers = network.__dict__["providers"]
 
     if default_provider or providers:
         # Handle user running tests with forked-network plugins installed
         network._default_provider = None
         network.__dict__["providers"] = []
 
     yield network
 
     if default_provider or providers:
-        network._default_provider = default_provider
+        network._default_provider = default_provider.name
         network.__dict__["providers"] = providers
+        assert network.default_provider, "Tear-down failed - providers not set."
 
 
 def test_get_network_choices(networks, ethereum, mocker):
     # Simulate having a provider like foundry installed.
     mock_provider = mocker.MagicMock()
     mock_provider.name = "mock"
     ethereum.networks["mainnet-fork"].providers["mock"] = mock_provider
@@ -107,68 +104,68 @@
     assert DEFAULT_CHOICES.issubset(actual)
 
 
 def test_get_network_choices_filter_network(networks):
     actual = {c for c in networks.get_network_choices(network_filter="mainnet")}
     mainnet_choices = {
         ":mainnet",
-        ":mainnet:geth",
+        ":mainnet:node",
         "ethereum",
         "ethereum:mainnet",
-        "ethereum:mainnet:geth",
+        "ethereum:mainnet:node",
     }
     assert mainnet_choices.issubset(actual)
 
 
 def test_get_network_choices_filter_provider(networks):
     actual = {c for c in networks.get_network_choices(provider_filter="test")}
     expected = {"::test", ":local", "ethereum:local", "ethereum:local:test", "ethereum"}
     assert all(e in actual for e in expected)
 
 
 def test_get_provider_when_no_default(network_with_no_providers):
     expected = f"No default provider for network '{network_with_no_providers.name}'"
     with pytest.raises(NetworkError, match=expected):
-        # Not provider installed out-of-the-box for goerli-fork network
+        # Not provider installed out-of-the-box for sepolia-fork network
         provider = network_with_no_providers.get_provider()
         assert not provider, f"Provider should be None but got '{provider.name}'"
 
 
 def test_repr_connected_to_local(networks_connected_to_tester):
     actual = repr(networks_connected_to_tester)
-    expected = f"<NetworkManager active_provider=<test chain_id={DEFAULT_TEST_CHAIN_ID}>>"
+    expected = f"<NetworkManager active_provider=<Test chain_id={DEFAULT_TEST_CHAIN_ID}>>"
     assert actual == expected
 
     # Check individual network
     actual = repr(networks_connected_to_tester.provider.network)
     expected = f"<ethereum:local chain_id={DEFAULT_TEST_CHAIN_ID}>"
     assert actual == expected
 
 
 def test_repr_disconnected(networks_disconnected):
     assert repr(networks_disconnected) == "<NetworkManager>"
     assert repr(networks_disconnected.ethereum) == "<ethereum>"
     assert repr(networks_disconnected.ethereum.local) == "<ethereum:local>"
-    assert repr(networks_disconnected.ethereum.goerli) == "<ethereum:goerli chain_id=5>"
+    assert repr(networks_disconnected.ethereum.sepolia) == "<ethereum:sepolia chain_id=11155111>"
 
 
 def test_get_provider_from_choice_custom_provider(networks_connected_to_tester):
     uri = "https://geth:1234567890abcdef@geth.foo.bar/"
     provider = networks_connected_to_tester.get_provider_from_choice(f"ethereum:local:{uri}")
     assert uri in provider.connection_id
-    assert provider.name == "geth"
+    assert provider.name == "node"
     assert provider.uri == uri
     assert provider.network.name == "local"  # Network was specified to be local!
     assert provider.network.ecosystem.name == "ethereum"
 
 
 def test_get_provider_from_choice_custom_adhoc_ecosystem(networks_connected_to_tester):
     uri = "https://geth:1234567890abcdef@geth.foo.bar/"
     provider = networks_connected_to_tester.get_provider_from_choice(uri)
-    assert provider.name == "geth"
+    assert provider.name == "node"
     assert provider.uri == uri
     assert provider.network.name == "custom"
     assert provider.network.ecosystem.name == "ethereum"
 
 
 def test_parse_network_choice_same_provider(chain, networks_connected_to_tester, get_context):
     context = get_context()
@@ -221,40 +218,40 @@
 def test_parse_network_choice_multiple_contexts(
     eth_tester_provider, get_provider_with_unused_chain_id
 ):
     first_context = get_provider_with_unused_chain_id()
     assert (
         eth_tester_provider.chain_id == DEFAULT_TEST_CHAIN_ID
     ), "Test setup failed - expecting to start on default chain ID"
-    assert eth_tester_provider._make_request("eth_chainId") == DEFAULT_TEST_CHAIN_ID
+    assert eth_tester_provider.make_request("eth_chainId") == DEFAULT_TEST_CHAIN_ID
 
     with first_context:
         start_count = len(first_context.connected_providers)
         expected_next_count = start_count + 1
         second_context = get_provider_with_unused_chain_id()
         with second_context:
             # Second context should already know about connected providers
             assert len(first_context.connected_providers) == expected_next_count
             assert len(second_context.connected_providers) == expected_next_count
 
     assert eth_tester_provider.chain_id == DEFAULT_TEST_CHAIN_ID
-    assert eth_tester_provider._make_request("eth_chainId") == DEFAULT_TEST_CHAIN_ID
+    assert eth_tester_provider.make_request("eth_chainId") == DEFAULT_TEST_CHAIN_ID
 
 
 def test_getattr_ecosystem_with_hyphenated_name(networks, ethereum):
     networks.ecosystems["hyphen-in-name"] = networks.ecosystems["ethereum"]
     assert networks.hyphen_in_name  # Make sure does not raise AttributeError
     del networks.ecosystems["hyphen-in-name"]
 
 
-def test_getattr_custom_ecosystem(networks, custom_networks_config_dict, temp_config):
+def test_getattr_custom_ecosystem(networks, custom_networks_config_dict, project):
     data = copy.deepcopy(custom_networks_config_dict)
     data["networks"]["custom"][0]["ecosystem"] = "custom-ecosystem"
 
-    with temp_config(data):
+    with project.temp_config(**data):
         actual = getattr(networks, "custom_ecosystem")
         assert isinstance(actual, EcosystemAPI)
 
 
 @pytest.mark.parametrize("scheme", ("http", "https"))
 def test_create_custom_provider_http(networks, scheme):
     provider = networks.create_custom_provider(f"{scheme}://example.com")
@@ -278,18 +275,18 @@
 
 def test_ecosystems(networks):
     actual = networks.ecosystems
     assert "ethereum" in actual
     assert actual["ethereum"].name == "ethereum"
 
 
-def test_ecosystems_include_custom(networks, custom_networks_config_dict, temp_config):
+def test_ecosystems_include_custom(networks, custom_networks_config_dict, project):
     data = copy.deepcopy(custom_networks_config_dict)
     data["networks"]["custom"][0]["ecosystem"] = "custom-ecosystem"
-    with temp_config(data):
+    with project.temp_config(**data):
         actual = networks.ecosystems
 
     assert "custom-ecosystem" in actual
 
 
 def test_fork_network_not_forkable(networks, eth_tester_provider):
     """
@@ -355,15 +352,16 @@
 
 
 def test_fork_with_positive_block_number(networks, mock_sepolia, mock_fork_provider):
     block_id = 123
     with networks.fork(block_number=block_id):
         call = mock_fork_provider.partial_call
 
-    actual = call[1]["provider_settings"]["fork"]["ethereum"]["sepolia"]["block_number"]
+    settings = call[1]["provider_settings"]["fork"]["ethereum"]["sepolia"]
+    actual = settings["block_number"]
     assert actual == block_id
 
 
 def test_fork_with_negative_block_number(
     networks, mock_sepolia, mock_fork_provider, eth_tester_provider
 ):
     # Mine so we are past genesis.
@@ -380,7 +378,13 @@
 
 
 def test_fork_past_genesis(networks, mock_sepolia, mock_fork_provider, eth_tester_provider):
     block_id = -10_000_000_000
     with pytest.raises(NetworkError, match="Unable to fork past genesis block."):
         with networks.fork(block_number=block_id):
             pass
+
+
+def test_getitem(networks):
+    ethereum = networks["ethereum"]
+    assert ethereum.name == "ethereum"
+    assert isinstance(ethereum, EcosystemAPI)
```

### Comparing `eth-ape-0.7.9/tests/functional/test_plugins.py` & `eth-ape-0.8.0/tests/functional/test_plugins.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,84 +1,97 @@
-from typing import Set
 from unittest import mock
 
 import pytest
 
+from ape.api import TransactionAPI
+from ape.exceptions import PluginVersionError
+from ape.logging import LogLevel
+from ape.managers.plugins import _get_unimplemented_methods_warning
 from ape.plugins._utils import (
     ApePluginsRepr,
     ModifyPluginResultHandler,
     PluginGroup,
     PluginMetadata,
     PluginMetadataList,
     PluginType,
-    _PipFreeze,
+    _filter_plugins_from_dists,
     ape_version,
 )
-from ape_plugins.exceptions import PluginVersionError
 
 CORE_PLUGINS = ("run",)
 AVAILABLE_PLUGINS = ("available", "installed")
 INSTALLED_PLUGINS = ("installed", "thirdparty")
 THIRD_PARTY = ("thirdparty",)
 
 
 mark_specifiers_less_than_ape = pytest.mark.parametrize(
     "specifier",
     (f"<{ape_version[0]}", f">0.1,<{ape_version[0]}", f"==0.{int(ape_version[2]) - 1}"),
 )
+parametrize_pip_cmd = pytest.mark.parametrize(
+    "pip_command", [["python", "-m", "pip"], ["uv", "pip"]]
+)
+
+
+@pytest.fixture(autouse=True)
+def get_dists_patch(mocker):
+    return mocker.patch("ape.plugins._utils._get_distributions")
+
 
+@pytest.fixture
+def make_dist(mocker):
+    def fn(name, version):
+        mock_dist = mocker.MagicMock()
+        mock_dist.name = name
+        mock_dist.version = version
+        return mock_dist
 
-def get_pip_freeze_output(version: str):
-    return f"FOOFOO==1.1.1\n-e git+ssh://git@github.com/ApeWorX/ape-{INSTALLED_PLUGINS[0]}.git@aaaaaaaabbbbbb3343#egg=ape-{INSTALLED_PLUGINS[0]}\naiohttp==3.8.5\nape-{THIRD_PARTY[0]}=={version}\n"  # noqa: E501
+    return fn
 
 
 @pytest.fixture(autouse=True)
-def mock_pip_freeze(mocker):
+def mock_installed_packages(make_dist, get_dists_patch):
     def fn(version: str):
-        patch = mocker.patch("ape.plugins._utils._check_pip_freeze")
-        patch.return_value = get_pip_freeze_output(version)
-        return patch
+        get_dists_patch.return_value = (
+            make_dist("FOOFOO", "1.1.1"),
+            make_dist(f"ape-{INSTALLED_PLUGINS[0]}", version),
+            make_dist("aiohttp", "3.8.5"),
+            make_dist(f"ape-{THIRD_PARTY[0]}", version),
+        )
+        return get_dists_patch
 
     return fn
 
 
 @pytest.fixture(autouse=True)
-def plugin_test_env(mocker, mock_pip_freeze):
+def plugin_test_env(mocker, mock_installed_packages):
     root = "ape.plugins._utils"
 
     # Prevent calling out to GitHub
     gh_mock = mocker.patch(f"{root}._get_available_plugins")
     gh_mock.return_value = {f"ape_{x}" for x in AVAILABLE_PLUGINS}
 
-    # Used when testing PipFreeze object itself but also extra avoids
-    # actually calling out pip ever in tests.
-    mock_pip_freeze(ape_version.base)
-
-    # Prevent requiring plugins to be installed.
-    installed_mock = mocker.patch(f"{root}._pip_freeze_plugins")
-    installed_mock.return_value = {
-        f"ape-{INSTALLED_PLUGINS[0]}",
-        f"ape-{INSTALLED_PLUGINS[1]}=={ape_version.base}",
-    }
-
-    # Prevent version lookups.
-    version_mock = mocker.patch(f"{root}.get_package_version")
-    version_mock.return_value = ape_version.base
+    mock_installed_packages(ape_version.base)
 
 
 @pytest.fixture
-def package_names() -> Set[str]:
+def package_names() -> set[str]:
     return {
         f"ape-{x}" for x in [*CORE_PLUGINS, *AVAILABLE_PLUGINS, *INSTALLED_PLUGINS, *THIRD_PARTY]
     }
 
 
 @pytest.fixture
 def plugin_metadata(package_names) -> PluginMetadataList:
-    return PluginMetadataList.from_package_names(package_names)
+    names = {x for x in package_names}
+    names.remove("ape-installed")
+    names.add(f"ape-installed==0.{ape_version.minor}.0")
+    names.remove("ape-thirdparty")
+    names.add(f"ape-thirdparty==0.{ape_version.minor}.0")
+    return PluginMetadataList.from_package_names(names)
 
 
 class TestPluginMetadataList:
     def test_from_package_names(self, plugin_metadata):
         actual = plugin_metadata
         assert actual.core.plugin_names == list(CORE_PLUGINS)
         assert actual.third_party.plugin_names == list(THIRD_PARTY)
@@ -151,56 +164,103 @@
 
     def test_is_available(self):
         metadata = PluginMetadata(name=list(AVAILABLE_PLUGINS)[0])
         assert metadata.is_available
         metadata = PluginMetadata(name="foobar")
         assert not metadata.is_available
 
-    def test_prepare_install(self):
-        metadata = PluginMetadata(name=list(AVAILABLE_PLUGINS)[0])
+    @parametrize_pip_cmd
+    def test_prepare_install(self, pip_command):
+        metadata = PluginMetadata(name=list(AVAILABLE_PLUGINS)[0], pip_command=pip_command)
         actual = metadata._prepare_install(skip_confirmation=True)
         assert actual is not None
         arguments = actual.get("args", [])
-        expected = [
-            "-m",
+        shared = [
             "pip",
             "install",
             f"ape-available>=0.{ape_version.minor},<0.{ape_version.minor + 1}",
             "--quiet",
         ]
-        assert arguments[0].endswith("python")
-        assert arguments[1:] == expected
-
-    def test_prepare_install_upgrade(self):
-        metadata = PluginMetadata(name=list(AVAILABLE_PLUGINS)[0])
+        if arguments[0] == "uv":
+            expected = ["uv", *shared]
+            assert arguments == expected
+        else:
+            expected = ["-m", *shared]
+            assert "python" in arguments[0]
+            assert arguments[1:] == expected
+
+    @parametrize_pip_cmd
+    def test_prepare_install_upgrade(self, pip_command):
+        metadata = PluginMetadata(name=list(AVAILABLE_PLUGINS)[0], pip_command=pip_command)
         actual = metadata._prepare_install(upgrade=True, skip_confirmation=True)
         assert actual is not None
         arguments = actual.get("args", [])
-        expected = [
-            "-m",
+        shared = [
             "pip",
             "install",
             "--upgrade",
             f"ape-available>=0.{ape_version.minor},<0.{ape_version.minor + 1}",
             "--quiet",
         ]
-        assert arguments[0].endswith("python")
-        assert arguments[1:] == expected
+
+        if pip_command[0].startswith("uv"):
+            expected = ["uv", *shared]
+            assert arguments == expected
+
+        else:
+            expected = ["-m", *shared]
+            assert "python" in arguments[0]
+            assert arguments[1:] == expected
 
     @mark_specifiers_less_than_ape
     def test_prepare_install_version_smaller_than_ape(self, specifier, ape_caplog):
         metadata = PluginMetadata(name=list(AVAILABLE_PLUGINS)[0], version=specifier)
         expected = (
             r"Unable to install plugin\.\n"
             r"Reason: Doing so will downgrade Ape's version\.\n"
             r"To resolve: Downgrade Ape first\."
         )
         with pytest.raises(PluginVersionError, match=expected):
             metadata._prepare_install(skip_confirmation=True)
 
+    def test_check_installed_python_39(self, mocker, get_dists_patch):
+        mock_dist = mocker.MagicMock()
+        get_dists_patch.return_value = [mock_dist]
+        mock_dist.name = ""
+        mock_dist.metadata = {"Name": "ape-py39plugin"}
+
+        metadata = PluginMetadata(name="py39plugin")
+
+        # If the next line doesn't fail, the test passed.
+        # This triggers looping through the dist w/o a name attr.
+        assert metadata.check_installed()
+
+    @pytest.mark.parametrize(
+        "plugin,expected", [(list(INSTALLED_PLUGINS)[0], True), (list(AVAILABLE_PLUGINS)[0], False)]
+    )
+    def test_check_installed_python_310_or_greater(self, plugin, expected):
+        installed = PluginMetadata(name=plugin)
+        assert installed.check_installed() is expected
+
+    @parametrize_pip_cmd
+    def test_get_uninstall_args(self, pip_command):
+        metadata = PluginMetadata(name="dontmatter", pip_command=pip_command)
+        arguments = metadata._get_uninstall_args()
+        pip_cmd_len = len(metadata.pip_command)
+
+        for idx, pip_pt in enumerate(pip_command):
+            assert arguments[idx] == pip_pt
+
+        expected = ["uninstall"]
+        if pip_command[0] == "python":
+            expected.append("-y")
+
+        expected.extend(("ape-dontmatter", "--quiet"))
+        assert arguments[pip_cmd_len:] == expected
+
 
 class TestApePluginsRepr:
     def test_str(self, plugin_metadata):
         representation = ApePluginsRepr(plugin_metadata)
         actual = str(representation)
         expected = f"""
 Installed Plugins
@@ -261,51 +321,20 @@
         patch = mocker.patch("ape.plugins._utils.PluginGroup.name", new_callable=mock.PropertyMock)
         patch.side_effect = ValueError("repr fail test")
         group = PluginGroup(plugin_type=PluginType.INSTALLED)
 
         assert repr(group) == "<PluginGroup>"
 
 
-def test_pip_freeze_includes_version_when_available():
-    pip_freeze = _PipFreeze()
-    actual = pip_freeze.get_plugins(use_process=True)
-    expected = {f"ape-{INSTALLED_PLUGINS[0]}", f"ape-{THIRD_PARTY[0]}==0.{ape_version.minor}.0"}
-    assert actual == expected
-
-
-def test_handle_upgrade_result_when_upgrading_to_same_version(caplog, logger):
-    # NOTE: pip freeze mock also returns version 0.{minor}.0 (so upgrade to same).
-    logger.set_level("INFO")  # Required for test.
-    plugin = PluginMetadata(name=THIRD_PARTY[0])
-    handler = ModifyPluginResultHandler(plugin)
-    handler.handle_upgrade_result(0, f"0.{ape_version.minor}.0")
-    if records := caplog.records:
-        assert (
-            f"'{THIRD_PARTY[0]}' already has version '0.{ape_version.minor}.0'"
-            in records[-1].message
-        )
-    else:
-        version_at_end = plugin.pip_freeze_version
-        pytest.fail(
-            f"Missing logs when upgrading to same version 0.{ape_version.minor}.0. "
-            f"pip_freeze_version={version_at_end}"
-        )
-
-
-def test_handle_upgrade_result_when_no_pip_freeze_version_does_not_log(caplog):
-    plugin_no_version = INSTALLED_PLUGINS[0]  # Version not in pip-freeze
-    plugin = PluginMetadata(name=plugin_no_version)
+def test_handle_upgrade_result_when_upgrading_to_same_version(ape_caplog, logger):
+    plugin = PluginMetadata(name=THIRD_PARTY[0], version=f"0.{ape_version.minor}.0")
     handler = ModifyPluginResultHandler(plugin)
+    ape_caplog.set_levels(LogLevel.INFO)
     handler.handle_upgrade_result(0, f"0.{ape_version.minor}.0")
-
-    log_parts = ("already has version", "already up to date")
-    messages = [x.message for x in caplog.records]
-    for message in messages:
-        for pt in log_parts:
-            assert pt not in message
+    assert f"'{THIRD_PARTY[0]}' already has version '0.{ape_version.minor}.0'" in ape_caplog.head
 
 
 class TestApeVersion:
     def test_version_range(self):
         actual = ape_version.version_range
         expected = f">=0.{ape_version[2]},<0.{int(ape_version[2]) + 1}"
         assert actual == expected
@@ -319,7 +348,43 @@
         actual = ape_version.previous_version_range
         expected = f">=0.{int(ape_version[2]) - 2},<0.{int(ape_version[2]) - 1}"
         assert actual == expected
 
     @mark_specifiers_less_than_ape
     def test_would_be_downgraded(self, specifier):
         assert ape_version.would_get_downgraded(specifier)
+
+
+def test_filter_plugins_from_dists_py39(mocker):
+    def make_dist(name: str):
+        mock_dist = mocker.MagicMock()
+        mock_dist.name = ""
+        mock_dist.metadata = {"Name": f"ape-{name}"}
+        return mock_dist
+
+    plugins = [make_dist("solidity"), make_dist("vyper"), make_dist("optimism")]
+    actual = set(_filter_plugins_from_dists(plugins))
+    expected = {"ape-solidity", "ape-vyper", "ape-optimism"}
+    assert actual == expected
+
+
+def test_filter_plugins_from_dists_py310_and_greater(mocker):
+    def make_dist(name: str):
+        mock_dist = mocker.MagicMock()
+        mock_dist.name = f"ape-{name}"
+        return mock_dist
+
+    plugins = [make_dist("solidity"), make_dist("vyper"), make_dist("optimism")]
+    actual = set(_filter_plugins_from_dists(plugins))
+    expected = {"ape-solidity", "ape-vyper", "ape-optimism"}
+    assert actual == expected
+
+
+@pytest.mark.parametrize("abstract_methods", [("method1", "method2"), {"method1": 0, "method2": 0}])
+def test_get_unimplemented_methods_warning_list_containing_plugin(abstract_methods):
+    plugin_registration = ("foo", "bar", TransactionAPI)
+    actual = _get_unimplemented_methods_warning(plugin_registration, "p1")
+    expected = (
+        "'TransactionAPI' from 'p1' is not fully implemented. "
+        "Remaining abstract methods: 'serialize_transaction, txn_hash'."
+    )
+    assert actual == expected
```

### Comparing `eth-ape-0.7.9/tests/functional/test_project.py` & `eth-ape-0.8.0/tests/functional/test_project.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,620 +1,744 @@
-import os
-import random
+import json
 import shutil
-import string
-import tempfile
 from pathlib import Path
 
 import pytest
-import yaml
-from ethpm_types import Compiler
-from ethpm_types import ContractInstance as EthPMContractInstance
-from ethpm_types import ContractType, Source
-from ethpm_types.manifest import PackageManifest
+from ethpm_types import Compiler, ContractType, PackageManifest, Source
+from ethpm_types.manifest import PackageName
+from pydantic_core import Url
 
-from ape import Contract
+from ape import Project
+from ape.contracts import ContractContainer
 from ape.exceptions import ProjectError
 from ape.logging import LogLevel
-from ape.managers.project import BrownieProject
-
-WITH_DEPS_PROJECT = (
-    Path(__file__).parent.parent / "integration" / "cli" / "projects" / "with-dependencies"
-)
+from ape_pm import BrownieProject
+from tests.conftest import skip_if_plugin_installed
 
 
 @pytest.fixture
-def ape_project(project):
-    return project.local_project
+def project_with_contracts(with_dependencies_project_path):
+    return Project(with_dependencies_project_path)
 
 
 @pytest.fixture
-def bip122_chain_id(eth_tester_provider):
-    return eth_tester_provider.get_block(0).hash.hex()
+def tmp_project(with_dependencies_project_path):
+    real_project = Project(with_dependencies_project_path)
+    # Copies contracts and stuff into a temp folder
+    # and returns a project around the temp folder.
+    with real_project.isolate_in_tempdir() as tmp_project:
+        yield tmp_project
 
 
 @pytest.fixture
-def base_deployments_path(project, bip122_chain_id):
-    return project._package_deployments_folder / bip122_chain_id
+def contract_type():
+    return make_contract("FooContractFromManifest")
 
 
 @pytest.fixture
-def deployment_path(vyper_contract_instance, base_deployments_path):
-    file_name = f"{vyper_contract_instance.contract_type.name}.json"
-    return base_deployments_path / file_name
+def manifest(contract_type):
+    return make_manifest(contract_type)
 
 
 @pytest.fixture
 def contract_block_hash(eth_tester_provider, vyper_contract_instance):
-    block_number = vyper_contract_instance.receipt.block_number
+    block_number = vyper_contract_instance.creation_metadata.block
     return eth_tester_provider.get_block(block_number).hash.hex()
 
 
 @pytest.fixture
-def clean_deployments(base_deployments_path):
-    if base_deployments_path.is_dir():
-        shutil.rmtree(str(base_deployments_path))
+def project_from_manifest(manifest):
+    return Project.from_manifest(manifest)
 
-    yield
 
+def make_contract(name: str = "test") -> ContractType:
+    return ContractType.model_validate(
+        {
+            "contractName": name,
+            "sourceId": f"contracts/{name}.json",
+            "abi": [],
+        }
+    )
 
-@pytest.fixture
-def existing_manifest(ape_project):
-    return ape_project.create_manifest()
 
+def make_manifest(*contracts: ContractType, include_contract_type: bool = True) -> PackageManifest:
+    sources = {
+        ct.source_id: Source(content=ct.model_dump_json(by_alias=True, mode="json"))
+        for ct in contracts
+    }
+    model: dict = {"sources": sources}
+    if include_contract_type:
+        contract_types = {c.name: c for c in contracts}
+        model["contractTypes"] = contract_types
 
-@pytest.fixture(scope="session")
-def contract_type_0(vyper_contract_type):
-    return _make_new_contract(vyper_contract_type, "NewContract_0")
+    return PackageManifest.model_validate(model)
 
 
-@pytest.fixture(scope="session")
-def contract_type_1(vyper_contract_type):
-    return _make_new_contract(vyper_contract_type, "NewContract_1")
+def test_path(project):
+    assert project.path is not None
 
 
-@pytest.fixture(scope="session")
-def existing_source_path(vyper_contract_type, contract_type_0, contracts_folder):
-    source_path = contracts_folder / "NewContract_0.json"
-    source_path.touch()
-    source_path.write_text(contract_type_0.model_dump_json())
-    yield source_path
-    if source_path.is_file():
-        source_path.unlink()
+def test_name(project):
+    assert project.name == project.path.name
 
 
-@pytest.fixture
-def manifest_with_non_existent_sources(
-    existing_manifest, existing_source_path, contract_type_0, contract_type_1
-):
-    manifest = existing_manifest.model_copy()
-    manifest.contract_types["NewContract_0"] = contract_type_0
-    manifest.contract_types["NewContract_1"] = contract_type_1
-    # Previous refs shouldn't interfere (bugfix related)
-    manifest.sources["NewContract_0.json"] = Source(
-        content=contract_type_0.model_dump_json(), references=["NewContract_1.json"]
-    )
-    manifest.sources["NewContract_1.json"] = Source(content=contract_type_1.model_dump_json())
-    return manifest
+def test_name_from_config(project):
+    with project.temp_config(name="foo-bar"):
+        assert project.name == "foo-bar"
 
 
-@pytest.fixture
-def project_without_deployments(project):
-    if project._package_deployments_folder.is_dir():
-        shutil.rmtree(project._package_deployments_folder)
+def test_repr(project):
+    actual = repr(project)
+    # NOTE: tmp path is NOT relative to home.
+    expected_project_path = str(project.path).replace(str(Path.home()), "$HOME")
+    expected = f"<ProjectManager {expected_project_path}>"
+    assert actual == expected
 
-    return project
 
+@pytest.mark.parametrize("name", ("contracts", "sources"))
+def test_contracts_folder_from_config(project, name):
+    with project.temp_config(contracts_folder=name):
+        assert project.contracts_folder == project.path / name
 
-def _make_new_contract(existing_contract: ContractType, name: str):
-    source_text = existing_contract.model_dump_json()
-    source_text = source_text.replace(f"{existing_contract.name}.vy", f"{name}.json")
-    source_text = source_text.replace(existing_contract.name or "", name)
-    return ContractType.model_validate_json(source_text)
 
+def test_contracts_folder_same_as_root_path(project):
+    with project.temp_config(contracts_folder="."):
+        assert project.contracts_folder == project.path
 
-def test_extract_manifest(project_with_dependency_config):
-    # NOTE: Only setting dependency_config to ensure existence of project.
-    manifest = project_with_dependency_config.extract_manifest()
-    assert type(manifest) is PackageManifest
-    assert type(manifest.compilers) is list
-    assert manifest.meta == project_with_dependency_config.meta
-    assert manifest.compilers == project_with_dependency_config.compiler_data
-    assert manifest.deployments == project_with_dependency_config.tracked_deployments
 
+def test_contracts_folder_deduced(tmp_project):
+    new_project_path = tmp_project.path / "new"
+    new_project_path.mkdir()
+    contracts_folder = new_project_path / "sources"
+    contracts_folder.mkdir()
+    contract = contracts_folder / "tryme.json"
+    abi = [{"name": "foo", "type": "fallback", "stateMutability": "nonpayable"}]
+    contract.write_text(json.dumps(abi))
+    new_project = Project(new_project_path)
+    actual = new_project.contracts_folder
+    assert actual == contracts_folder
 
-def test_cached_manifest_when_sources_missing(
-    ape_project, manifest_with_non_existent_sources, existing_source_path, ape_caplog
-):
-    """
-    Show that if a source is missing, it is OK. This happens when changing branches
-    after compiling and sources are only present on one of the branches.
-    """
-    cache_location = ape_project._cache_folder / "__local__.json"
-    if cache_location.is_file():
-        cache_location.unlink()
-
-    cache_location.touch()
-    name = "NOTEXISTS"
-    source_id = f"{name}.json"
-    contract_type = ContractType.model_validate(
-        {"contractName": name, "abi": [], "sourceId": source_id}
-    )
-    path = ape_project._cache_folder / source_id
-    path.write_text(contract_type.model_dump_json())
-    cache_location.write_text(manifest_with_non_existent_sources.model_dump_json())
 
-    manifest = ape_project.cached_manifest
+def test_reconfigure(project):
+    project.reconfigure(compile={"exclude": ["first", "second"]})
+    assert {"first", "second"}.issubset(set(project.config.compile.exclude))
 
-    # Show the contract type does not get added and we don't get the corrupted manifest.
-    assert not any(ct.name == name for ct in manifest.contract_types.values())
-    assert not any("corrupted. Re-building" in msg for msg in ape_caplog.messages)
 
+def test_isolate_in_tempdir(project):
+    # Purposely not using `tmp_project` fixture.
+    with project.isolate_in_tempdir() as tmp_project:
+        assert tmp_project.path != project.path
+        assert tmp_project.in_tempdir
+        # Manifest should have been created by default.
+        assert not tmp_project.manifest_path.is_file()
 
-def test_create_manifest_when_file_changed_with_cached_references_that_no_longer_exist(
-    ape_project, manifest_with_non_existent_sources, existing_source_path
-):
-    """
-    This test is for the condition when you have a cached manifest containing references
-    from a source file however those references no longer exist and the source file has changes.
-    """
 
-    cache_location = ape_project._cache_folder / "__local__.json"
-    if cache_location.is_file():
-        cache_location.unlink()
+def test_in_tempdir(project, tmp_project):
+    assert not project.in_tempdir
+    assert tmp_project.in_tempdir
 
-    ape_project._cache_folder.mkdir(exist_ok=True)
-    cache_location.touch()
-    cache_location.write_text(manifest_with_non_existent_sources.model_dump_json())
 
-    # Change content
-    source_text = existing_source_path.read_text()
-    existing_source_path.unlink()
-    source_text = source_text.replace("uint256[20]", "uint256[25]")
-    existing_source_path.write_text(source_text)
+def test_getattr(tmp_project):
+    actual = tmp_project.Other
+    assert type(actual) is ContractContainer
 
-    manifest = ape_project.create_manifest()
-    assert manifest
 
+def test_getattr_not_exists(tmp_project):
+    with pytest.raises(AttributeError):
+        _ = tmp_project.nope
 
-def test_create_manifest_empty_files(compilers, mock_compiler, config, ape_caplog):
-    """
-    Tests again a bug where empty contracts would infinitely compile.
-    """
 
-    # Using a random name to prevent async conflicts.
-    letters = string.ascii_letters
-    name = "".join(random.choice(letters) for _ in range(10))
+def test_getattr_detects_changes(tmp_project):
+    source_id = tmp_project.Other.contract_type.source_id
+    new_abi = {
+        "inputs": [],
+        "name": "retrieve",
+        "outputs": [{"internalType": "uint256", "name": "", "type": "uint256"}],
+        "stateMutability": "view",
+        "type": "function",
+    }
+    content = json.dumps([new_abi])
+    path = tmp_project.sources.lookup(source_id)
+    assert path
+    path.unlink(missing_ok=True)
+    path.write_text(content)
+    # Should have re-compiled.
+    contract = tmp_project.Other
+    assert "retrieve" in contract.contract_type.methods
+
+
+def test_getattr_empty_contract(tmp_project):
+    """
+    Tests against a condition where would infinitely compile.
+    """
+    source_id = tmp_project.Other.contract_type.source_id
+    path = tmp_project.sources.lookup(source_id)
+    path.unlink(missing_ok=True)
+    path.write_text("")
+    # Should have re-compiled.
+    contract = tmp_project.Other
+    assert not contract.contract_type.methods
 
-    with tempfile.TemporaryDirectory() as temp_dir:
-        base_dir = Path(temp_dir)
-        contracts = base_dir / "contracts"
-        contracts.mkdir()
-        file_1 = contracts / f"{name}.__mock__"
-        file_1.write_text("")
 
-        with config.using_project(base_dir) as proj:
-            compilers.registered_compilers[".__mock__"] = mock_compiler
+@skip_if_plugin_installed("vyper", "solidity")
+def test_getattr_same_name_as_source_file(project_with_source_files_contract):
+    expected = (
+        r"'LocalProject' object has no attribute 'ContractA'\. "
+        r"Also checked extra\(s\) 'contracts'\. "
+        r"However, there is a source file named 'ContractA\.sol', "
+        r"did you mean to reference a contract name from this source file\? "
+        r"Else, could it be from one of the missing compilers for extensions: ."
+    )
+    with pytest.raises(AttributeError, match=expected):
+        _ = project_with_source_files_contract.ContractA
+
+
+@pytest.mark.parametrize("iypthon_attr_name", ("_repr_mimebundle_", "_ipython_display_"))
+def test_getattr_ipython(tmp_project, iypthon_attr_name):
+    # Remove contract types, if there for some reason is any.
+    tmp_project.manifest.contract_types = {}
+    getattr(tmp_project, iypthon_attr_name)
+    # Prove it did not compile looking for these names.
+    assert not tmp_project.manifest.contract_types
 
-            # NOTE: Set levels as close to the operation as possible
-            #  to lessen chance of caplog race conditions.
-            ape_caplog.set_levels(caplog_level=LogLevel.INFO)
 
-            # Run twice to show use_cache=False works.
-            proj.local_project.create_manifest()
-            manifest = proj.local_project.create_manifest(use_cache=False)
+def test_getattr_ipython_canary_check(tmp_project):
+    # Remove contract types, if there for some reason is any.
+    tmp_project.manifest.contract_types = {}
+    with pytest.raises(AttributeError):
+        getattr(tmp_project, "_ipython_canary_method_should_not_exist_")
 
-            assert name in manifest.contract_types
-            assert f"{name}.__mock__" in manifest.sources
+    # Prove it did not compile looking for this.
+    assert not tmp_project.manifest.contract_types
 
-            ape_caplog.assert_last_log(f"Compiling '{name}.__mock__'.")
-            ape_caplog.clear()
 
-            # Ensure is not double compiled!
-            proj.local_project.create_manifest()
-            assert f"Compiling '{name}.__mock__'." not in ape_caplog.head
+def test_getitem(tmp_project):
+    actual = tmp_project["Project"]
+    assert type(actual) is ContractContainer
 
 
-def test_meta(temp_config, project):
+def test_meta(project):
     meta_config = {
         "meta": {
-            "authors": ["Test Testerson"],
+            "authors": ["Apealicious Jones"],
             "license": "MIT",
-            "description": "test",
-            "keywords": ["testing"],
+            "description": "Zoologist meme protocol",
+            "keywords": ["Indiana", "Knight's Templar"],
             "links": {"apeworx.io": "https://apeworx.io"},
         }
     }
-    with temp_config(meta_config):
-        assert project.meta.authors == ["Test Testerson"]
+    with project.temp_config(**meta_config):
+        assert project.meta.authors == ["Apealicious Jones"]
         assert project.meta.license == "MIT"
-        assert project.meta.description == "test"
-        assert project.meta.keywords == ["testing"]
-
-        link = project.meta.links["apeworx.io"]
-        assert link.host == "apeworx.io"
-        assert link.scheme == "https"
-
-
-def test_brownie_project_configure(config, base_projects_directory):
-    project_path = base_projects_directory / "BrownieProject"
-    expected_config_file = project_path / "ape-config.yaml"
-    if expected_config_file.is_file():
-        # Left from previous run
-        expected_config_file.unlink()
-
-    project = BrownieProject(path=project_path, contracts_folder=Path("contracts"))
-    project.process_config_file()
-    assert expected_config_file.is_file()
-
-    with open(expected_config_file) as ape_config_file:
-        mapped_config_data = yaml.safe_load(ape_config_file)
-
-    # Ensure Solidity and dependencies configuration mapped correctly
-    assert mapped_config_data["solidity"]["version"] == "0.6.12"
-    assert mapped_config_data["solidity"]["import_remapping"] == [
-        "@openzeppelin/contracts=OpenZeppelin/3.1.0"
-    ]
-    assert mapped_config_data["dependencies"][0]["name"] == "OpenZeppelin"
-    assert mapped_config_data["dependencies"][0]["github"] == "OpenZeppelin/openzeppelin-contracts"
-    assert mapped_config_data["dependencies"][0]["version"] == "3.1.0"
-
-    expected_config_file.unlink()
-
-
-def test_track_deployment(
-    clean_deployments,
-    project_without_deployments,
-    vyper_contract_instance,
-    eth_tester_provider,
-    deployment_path,
-    contract_block_hash,
-    dummy_live_network,
-    bip122_chain_id,
-):
-    contract = vyper_contract_instance
-    receipt = contract.receipt
-    name = contract.contract_type.name
-    address = vyper_contract_instance.address
-
-    # Even though deployments should be 0, do this to in case x-dist affects it.
-    num_deployments_before = len(project_without_deployments.tracked_deployments)
-
-    project_without_deployments.track_deployment(vyper_contract_instance)
-
-    expected_block_hash = eth_tester_provider.get_block(receipt.block_number).hash.hex()
-    expected_uri = f"blockchain://{bip122_chain_id}/block/{expected_block_hash}"
-    expected_name = contract.contract_type.name
-    expected_code = contract.contract_type.runtime_bytecode
-    actual_from_file = EthPMContractInstance.model_validate_json(deployment_path.read_text())
-    actual_from_class = project_without_deployments.tracked_deployments[expected_uri][name]
-
-    assert actual_from_file.address == actual_from_class.address == address
-    assert actual_from_file.contract_type == actual_from_class.contract_type == expected_name
-    assert actual_from_file.transaction == actual_from_class.transaction == receipt.txn_hash
-    assert actual_from_file.runtime_bytecode == actual_from_class.runtime_bytecode == expected_code
-
-    # Use >= to handle xdist.
-    assert len(project_without_deployments.tracked_deployments) >= num_deployments_before + 1
-
-
-def test_track_deployment_from_previously_deployed_contract(
-    clean_deployments,
-    project_without_deployments,
-    vyper_contract_container,
-    eth_tester_provider,
-    dummy_live_network,
-    owner,
-    base_deployments_path,
-    bip122_chain_id,
-):
-    receipt = owner.deploy(vyper_contract_container, 0, required_confirmations=0).receipt
-    address = receipt.contract_address
-    contract = Contract(address, txn_hash=receipt.txn_hash)
-    name = contract.contract_type.name
-
-    # Even though deployments should be 0, do this to in case x-dist affects it.
-    num_deployments_before = len(project_without_deployments.tracked_deployments)
-
-    project_without_deployments.track_deployment(contract)
-
-    path = base_deployments_path / f"{contract.contract_type.name}.json"
-    expected_block_hash = eth_tester_provider.get_block(receipt.block_number).hash.hex()
-    expected_uri = f"blockchain://{bip122_chain_id}/block/{expected_block_hash}"
-    expected_name = contract.contract_type.name
-    expected_code = contract.contract_type.runtime_bytecode
-    actual_from_file = EthPMContractInstance.model_validate_json(path.read_text())
-    actual_from_class = project_without_deployments.tracked_deployments[expected_uri][name]
-    assert actual_from_file.address == actual_from_class.address == address
-    assert actual_from_file.contract_type == actual_from_class.contract_type == expected_name
-    assert actual_from_file.transaction == actual_from_class.transaction == receipt.txn_hash
-    assert actual_from_file.runtime_bytecode == actual_from_class.runtime_bytecode == expected_code
-
-    # Use >= to handle xdist.
-    assert len(project_without_deployments.tracked_deployments) >= num_deployments_before + 1
-
-
-def test_track_deployment_from_unknown_contract_missing_txn_hash(
-    clean_deployments,
-    dummy_live_network,
-    owner,
-    vyper_contract_container,
-    chain,
-    project,
-):
-    snapshot = chain.snapshot()
-    contract = owner.deploy(vyper_contract_container, 0, required_confirmations=0)
-    chain.restore(snapshot)
-
-    contract = Contract(contract.address)
-    with pytest.raises(
-        ProjectError,
-        match=f"Contract '{contract.contract_type.name}' transaction receipt is unknown.",
-    ):
-        project.track_deployment(contract)
-
-
-def test_track_deployment_from_unknown_contract_given_txn_hash(
-    clean_deployments,
-    project,
-    vyper_contract_instance,
-    dummy_live_network,
-    base_deployments_path,
-):
-    address = vyper_contract_instance.address
-    txn_hash = vyper_contract_instance.txn_hash
-    contract = Contract(address, txn_hash=txn_hash)
-    project.track_deployment(contract)
-    path = base_deployments_path / f"{contract.contract_type.name}.json"
-    actual = EthPMContractInstance.model_validate_json(path.read_text())
-    assert actual.address == address
-    assert actual.contract_type == contract.contract_type.name
-    assert actual.transaction == txn_hash
-    assert actual.runtime_bytecode == contract.contract_type.runtime_bytecode
-
-
-def test_compiler_data_and_update_cache(config, project_path, contracts_folder):
-    with config.using_project(project_path, contracts_folder=contracts_folder) as project:
-        compiler = Compiler(name="comp", version="1.0.0")
-        project.local_project.update_manifest(compilers=[compiler])
-        assert project.local_project.manifest.compilers == [compiler]
-        assert project.compiler_data == [compiler]
-
-
-def test_get_project_without_contracts_path(project):
-    project_path = WITH_DEPS_PROJECT / "default"
-    project = project.get_project(project_path)
-    assert project.contracts_folder == project_path / "contracts"
-
-
-def test_get_project_with_contracts_path(project):
-    project_path = WITH_DEPS_PROJECT / "renamed_contracts_folder_specified_in_config"
-    project = project.get_project(project_path, project_path / "my_contracts")
-    assert project.contracts_folder == project_path / "my_contracts"
-
-
-def test_get_project_figure_out_contracts_path(project):
-    """
-    Tests logic where `contracts` is not the contracts folder but it still is able
-    to figure it out.
-    """
-    project_path = WITH_DEPS_PROJECT / "renamed_contracts_folder"
-    (project_path / "ape-config.yaml").unlink(missing_ok=True)  # Clean from prior.
-
-    project = project.get_project(project_path)
-    assert project.contracts_folder == project_path / "sources"
-
-
-def test_lookup_path(project_with_source_files_contract):
-    project = project_with_source_files_contract
-    actual_from_str = project.lookup_path("ContractA.sol")
-    actual_from_path = project.lookup_path(Path("ContractA.sol"))
-    expected = project.contracts_folder / "ContractA.sol"
-    assert actual_from_str == actual_from_path == expected
+        assert project.meta.description == "Zoologist meme protocol"
+        assert project.meta.keywords == ["Indiana", "Knight's Templar"]
+        assert project.meta.links == {"apeworx.io": Url("https://apeworx.io")}
 
 
-def test_sources(project_with_source_files_contract):
-    project = project_with_source_files_contract
-    assert "ApeContract0.json" in project.sources
-    assert project.sources["ApeContract0.json"].content
+def test_extract_manifest(tmp_project, mock_sepolia, vyper_contract_instance):
+    contract_type = vyper_contract_instance.contract_type
+    tmp_project.manifest.contract_types = {contract_type.name: contract_type}
+    tmp_project.deployments.track(vyper_contract_instance)
 
+    manifest = tmp_project.extract_manifest()
+    assert type(manifest) is PackageManifest
+    assert manifest.meta == tmp_project.meta
+    assert PackageName("manifest-dependency") in (manifest.dependencies or {})
+    bip122_chain_id = tmp_project.provider.get_block(0).hash.hex()
+    expected_uri = f"blockchain://{bip122_chain_id[2:]}"
+    for key in manifest.deployments or {}:
+        if key.startswith(expected_uri):
+            return
 
-def test_contracts_folder(project, config):
-    # Relaxed to handle xdist resource sharing.
-    assert project.contracts_folder.name == "contracts"
-
-    # Show that even when None in the config, it won't be None here.
-    config.contracts_folder = None
-    assert config.contracts_folder is None
-    assert project.contracts_folder is not None
-
-
-def test_getattr_contract_not_exists(project):
-    expected = (
-        r"ProjectManager has no attribute or contract named "
-        r"'ThisIsNotAContractThatExists'. However, there is a source "
-        r"file named 'ThisIsNotAContractThatExists', did you mean to "
-        r"reference a contract name from this source file\? "
-        r"Else, could it be from one of the missing compilers for extensions:.*\?"
-    )
-    project.contracts_folder.mkdir(exist_ok=True)
-    contract = project.contracts_folder / "ThisIsNotAContractThatExists.foo"
-    contract.touch()
-    with pytest.raises(AttributeError, match=expected):
-        _ = project.ThisIsNotAContractThatExists
-
-
-@pytest.mark.parametrize("iypthon_attr_name", ("_repr_mimebundle_", "_ipython_display_"))
-def test_getattr_ipython(mocker, project, iypthon_attr_name):
-    spy = mocker.spy(project, "_get_contract")
-    getattr(project, iypthon_attr_name)
-    # Ensure it does not try to do anything with contracts.
-    assert spy.call_count == 0
-
-
-def test_getattr_ipython_canary_check(mocker, project):
-    spy = mocker.spy(project, "_get_contract")
-    with pytest.raises(AttributeError):
-        getattr(project, "_ipython_canary_method_should_not_exist_")
-
-    # Ensure it does not try to do anything with contracts.
-    assert spy.call_count == 0
-
-
-def test_build_file_only_modified_once(project_with_contract):
-    project = project_with_contract
-    artifact = project.path / ".build" / "__local__.json"
-    _ = project.contracts  # Ensure compiled.
-
-    # NOTE: This is how re-create the bug. Delete the underscore-prefixed
-    #  cached object and attempt to re-compile. Previously, the ProjectManager
-    #  was relying on an internal cache rather than the external one, and thus
-    #  caused the file to get unnecessarily re-made (modified).
-    project.local_project._cached_manifest = None
-
-    # Prove the file is not unnecessarily modified.
-    time_before = os.path.getmtime(artifact)
-    _ = project.contracts
-    time_after = os.path.getmtime(artifact)
-    assert time_before == time_after
+    assert False, "Failed to find expected deployment URI"
 
 
-def test_source_paths_excludes_cached_dependencies(project_with_contract):
+def test_extract_manifest_when_sources_missing(tmp_project):
     """
-    Dependencies are ignored from the project's sources.
-    Their used sources are imported and part of the final output,
-    but just not the input.
+    Show that if a source is missing, it is OK. This happens when changing branches
+    after compiling and sources are only present on one of the branches.
     """
-    contracts_folder = project_with_contract.contracts_folder
-    cache_dir = contracts_folder / ".cache"
-    cache_dir.mkdir(exist_ok=True)
-    cache_dep_folder = cache_dir / "dep" / "1.0.0"
-    cache_dep_folder.mkdir(parents=True, exist_ok=True)
-    contract = next(
-        x
-        for x in contracts_folder.iterdir()
-        if x.is_file() and x.suffix == ".json" and not x.stem.startswith("_")
-    )
-    dep_contract = cache_dep_folder / "contract.json"
-    shutil.copy(contract, dep_contract)
-    actual = project_with_contract.source_paths
-    assert dep_contract not in actual
+    contract = make_contract("notreallyhere")
+    tmp_project.manifest.contract_types = {contract.name: contract}
+    manifest = tmp_project.extract_manifest()
+
+    # Source is skipped because missing.
+    assert "notreallyhere" not in manifest.contract_types
+
+
+def test_extract_manifest_excludes_cache(tmp_project):
+    cachefile = tmp_project.contracts_folder / ".cache" / "CacheFile.json"
+    cachefile2 = tmp_project.contracts_folder / ".cache" / "subdir" / "Cache2.json"
+    cachefile2.parent.mkdir(parents=True)
+    cachefile.write_text("Doesn't matter")
+    cachefile2.write_text("Doesn't matter")
+    manifest = tmp_project.extract_manifest()
+    assert isinstance(manifest, PackageManifest)
+    assert ".cache/CacheFile.json" not in (manifest.sources or {})
+    assert ".cache/subdir/CacheFile.json" not in (manifest.sources or {})
+
+
+def test_exclusions(tmp_project):
+    exclusions = ["Other.json", "*Excl*"]
+    exclude_config = {"compile": {"exclude": exclusions}}
+    with tmp_project.temp_config(**exclude_config):
+        for exclusion in exclusions:
+            assert exclusion in tmp_project.exclusions
 
 
-def test_update_manifest_compilers(project):
+def test_update_manifest(tmp_project):
     compiler = Compiler(name="comp", version="1.0.0", contractTypes=["foo.txt"])
-    project.local_project.update_manifest(compilers=[compiler])
-    actual = project.local_project.manifest.compilers
+    tmp_project.update_manifest(compilers=[compiler])
+    actual = tmp_project.manifest.compilers
     assert actual == [compiler]
 
-    project.local_project.update_manifest(name="test", version="1.0.0")
-    assert project.local_project.manifest.name == "test"
-    assert project.local_project.manifest.version == "1.0.0"
+    tmp_project.update_manifest(name="test", version="1.0.0")
+    assert tmp_project.manifest.name == "test"
+    assert tmp_project.manifest.version == "1.0.0"
 
     # The compilers should not have changed.
-    actual = project.local_project.manifest.compilers
+    actual = tmp_project.manifest.compilers
     assert actual == [compiler]
 
-    # Add a new one.
-    # NOTE: `update_cache()` will override the fields entirely.
-    #   You must include existing fields if you want to merge.
-    compiler_2 = Compiler(name="test", version="2.0.0", contractTypes=["bar.txt"])
-    project.local_project.update_manifest(compilers=[compiler_2])
-    actual = project.local_project.manifest.compilers
-    assert actual == [compiler_2]
-
 
-def test_load_contracts(project_with_contract):
-    contracts = project_with_contract.load_contracts()
+def test_load_contracts(tmp_project):
+    contracts = tmp_project.load_contracts()
+    assert tmp_project.manifest_path.is_file()
     assert len(contracts) > 0
-    assert contracts == project_with_contract.contracts
+    contracts_forced = tmp_project.load_contracts(use_cache=False)
+    assert contracts_forced == contracts
+
+
+def test_load_contracts_detect_change(tmp_project, ape_caplog):
+    path = tmp_project.contracts_folder / "Other.json"
+    content = path.read_text()
+    assert "foo" in content, "Test setup failed. Unexpected file content."
+
+    # Must be compiled first.
+    with ape_caplog.at_level(LogLevel.INFO):
+        contracts = tmp_project.load_contracts()
+        assert "Other" in contracts
+        ape_caplog.assert_last_log("Compiling")
 
+        ape_caplog.clear()
 
-def test_load_contracts_after_deleting_same_named_contract(config, compilers, mock_compiler):
+        # No logs as it doesn't need to re-compile.
+        tmp_project.load_contracts()
+        assert not ape_caplog.head
+
+        # Make a change to the file.
+        new_content = content.replace("foo", "bar")
+        assert "bar" in new_content, "Test setup failed. Unexpected file content."
+        path.unlink()
+        path.write_text(new_content)
+
+        # Prove re-compiles.
+        contracts = tmp_project.load_contracts()
+        assert "Other" in contracts
+        ape_caplog.assert_last_log("Compiling")
+
+
+def test_load_contracts_after_deleting_same_named_contract(tmp_project, compilers, mock_compiler):
     """
     Tests against a scenario where you:
 
     1. Add and compile a contract
     2. Delete that contract
     3. Add a new contract with same name somewhere else
 
     Test such that we are able to compile successfully and not get a misleading
     collision error from deleted files.
     """
-
-    with tempfile.TemporaryDirectory() as temp_dir:
-        path = Path(temp_dir)
-        contracts = path / "contracts"
-        contracts.mkdir()
-        init_contract = contracts / "foo.__mock__"
-        init_contract.write_text("LALA")
-        with config.using_project(path) as proj:
-            compilers.registered_compilers[".__mock__"] = mock_compiler
-            result = proj.load_contracts()
-            assert "foo" in result
-
-            # Delete file
-            init_contract.unlink()
-
-            # Create new contract that yields same name as deleted one.
-            new_contract = contracts / "bar.__mock__"
-            new_contract.write_text("BAZ")
-            mock_compiler.overrides = {"contractName": "foo"}
-
-            result = proj.load_contracts()
-            assert "foo" in result
+    init_contract = tmp_project.contracts_folder / "foo.__mock__"
+    init_contract.write_text("LALA")
+    compilers.registered_compilers[".__mock__"] = mock_compiler
+    result = tmp_project.load_contracts()
+    assert "foo" in result
+
+    # Goodbye.
+    init_contract.unlink()
+
+    result = tmp_project.load_contracts()
+    assert "foo" not in result  # Was deleted.
+    # Also ensure it is gone from paths.
+    assert "foo.__mock__" not in [x.name for x in tmp_project.sources.paths]
+
+    # Create a new contract with the same name.
+    new_contract = tmp_project.contracts_folder / "bar.__mock__"
+    new_contract.write_text("BAZ")
+    mock_compiler.overrides = {"contractName": "foo"}
+    result = tmp_project.load_contracts()
+    assert "foo" in result
+
+
+def test_load_contracts_output_abi(tmp_project):
+    cfg = {"output_extra": ["ABI"]}
+    with tmp_project.temp_config(compile=cfg):
+        _ = tmp_project.load_contracts()
+        abi_folder = tmp_project.manifest_path.parent / "abi"
+        assert abi_folder.is_dir()
+        files = [x for x in abi_folder.iterdir()]
+        assert len(files) > 0
+        for file in files:
+            assert file.suffix == ".json"
+
+
+def test_manifest_path(tmp_project):
+    assert tmp_project.manifest_path == tmp_project.path / ".build" / "__local__.json"
+
+
+def test_clean(tmp_project):
+    tmp_project.load_contracts()
+    assert tmp_project.manifest_path.is_file()
+
+    tmp_project.clean()
+    assert not tmp_project.manifest_path.is_file()
+    assert tmp_project._manifest.contract_types is None
+    assert tmp_project.sources._path_cache is None
 
 
 def test_add_compiler_data(project_with_dependency_config):
     # NOTE: Using different project than default to lessen
     #   chance of race-conditions from multi-process test runners.
     project = project_with_dependency_config
 
     # Load contracts so that any compilers that may exist are present.
     project.load_contracts()
-    start_compilers = project.local_project.manifest.compilers or []
+    start_compilers = project.manifest.compilers or []
 
     # NOTE: Pre-defining things to lessen chance of race condition.
-    compiler = Compiler(name="comp", version="1.0.0", contractTypes=["foo"])
-    compiler_2 = Compiler(name="test", version="2.0.0", contractTypes=["bar", "stay"])
+    compiler = Compiler(
+        name="comp",
+        version="1.0.0",
+        contractTypes=["foo"],
+        settings={"outputSelection": {"path/to/Foo.sol": "*"}},
+    )
+    compiler_2 = Compiler(
+        name="test",
+        version="2.0.0",
+        contractTypes=["bar", "stay"],
+        settings={"outputSelection": {"path/to/Bar.vy": "*", "stay.vy": "*"}},
+    )
 
     # NOTE: Has same contract as compiler 2 and thus replaces the contract.
-    compiler_3 = Compiler(name="test", version="3.0.0", contractTypes=["bar"])
+    compiler_3 = Compiler(
+        name="test",
+        version="3.0.0",
+        contractTypes=["bar"],
+        settings={"outputSelection": {"path/to/Bar.vy": "*"}},
+    )
 
-    proj = project.local_project
     argument = [compiler]
     second_arg = [compiler_2]
     third_arg = [compiler_3]
     first_exp = [*start_compilers, compiler]
     final_exp = [*first_exp, compiler_2]
 
+    # Ensure types are in manifest for type-source-id lookup.
+    bar = ContractType(contractName="bar", sourceId="path/to/Bar.vy")
+    foo = ContractType(contractName="foo", sourceId="path/to/Foo.sol")
+    project._manifest = PackageManifest(
+        contractTypes={"bar": bar, "foo": foo},
+        sources={"path/to/Bar.vy": Source(), "path/to/Foo.vy": Source()},
+    )
+    project._contracts = project._manifest.contract_types
+    assert project._manifest.contract_types, "Setup failed - need manifest contract types"
+
     # Add twice to show it's only added once.
-    proj.add_compiler_data(argument)
-    proj.add_compiler_data(argument)
-    assert proj.manifest.compilers == first_exp
+    project.add_compiler_data(argument)
+    project.add_compiler_data(argument)
+    assert project.manifest.compilers == first_exp
 
     # NOTE: `add_compiler_data()` will not override existing compilers.
     #   Use `update_cache()` for that.
-    proj.add_compiler_data(second_arg)
-    assert proj.manifest.compilers == final_exp
-
-    proj.add_compiler_data(third_arg)
-    comp = [c for c in proj.manifest.compilers if c.name == "test" and c.version == "2.0.0"][0]
+    project.add_compiler_data(second_arg)
+    assert project.manifest.compilers == final_exp
+    project.add_compiler_data(third_arg)
+    comp = [c for c in project.manifest.compilers if c.name == "test" and c.version == "2.0.0"][0]
     assert "bar" not in comp.contractTypes
+    assert "path/to/Bar.vy" not in comp.settings["outputSelection"]
+    new_comp = [c for c in project.manifest.compilers if c.name == "test" and c.version == "3.0.0"][
+        0
+    ]
+    assert "bar" in new_comp.contractTypes
+    assert "path/to/Bar.vy" in new_comp.settings["outputSelection"]
 
     # Show that compilers without contract types go away.
     (compiler_3.contractTypes or []).append("stay")
-    proj.add_compiler_data(third_arg)
-    comp_check = [c for c in proj.manifest.compilers if c.name == "test" and c.version == "2.0.0"]
+    project.add_compiler_data(third_arg)
+    comp_check = [
+        c for c in project.manifest.compilers if c.name == "test" and c.version == "2.0.0"
+    ]
     assert not comp_check
 
     # Show error on multiple of same compiler.
     compiler_4 = Compiler(name="test123", version="3.0.0", contractTypes=["bar"])
     compiler_5 = Compiler(name="test123", version="3.0.0", contractTypes=["baz"])
     with pytest.raises(ProjectError, match=r".*was given multiple of the same compiler.*"):
-        proj.add_compiler_data([compiler_4, compiler_5])
+        project.add_compiler_data([compiler_4, compiler_5])
 
     # Show error when contract type collision (only happens with inputs, else latter replaces).
     compiler_4 = Compiler(name="test321", version="3.0.0", contractTypes=["bar"])
     compiler_5 = Compiler(name="test456", version="9.0.0", contractTypes=["bar"])
     with pytest.raises(ProjectError, match=r".*'bar' collision across compilers.*"):
-        proj.add_compiler_data([compiler_4, compiler_5])
+        project.add_compiler_data([compiler_4, compiler_5])
+
+
+class TestProject:
+    """
+    All tests related to ``ape.Project``.
+    """
+
+    def test_init(self, with_dependencies_project_path):
+        # Purpose not using `project_with_contracts` fixture.
+        project = Project(with_dependencies_project_path)
+        project.manifest_path.unlink(missing_ok=True)
+        assert project.path == with_dependencies_project_path
+        # Manifest should have been created by default.
+        assert not project.manifest_path.is_file()
+
+    def test_config_override(self, with_dependencies_project_path):
+        contracts_folder = with_dependencies_project_path / "my_contracts"
+        config = {"contracts_folder": contracts_folder.name}
+        project = Project(with_dependencies_project_path, config_override=config)
+        assert project.contracts_folder == contracts_folder
+
+    def test_from_manifest(self, manifest):
+        # Purposely not using `project_from_manifest` fixture.
+        project = Project.from_manifest(manifest)
+        assert isinstance(project, Project)
+        assert project.manifest == manifest
+
+    def test_from_manifest_contracts_iter(self, contract_type, project_from_manifest):
+        actual = set(iter(project_from_manifest.contracts))
+        assert actual == {"FooContractFromManifest"}
+
+    def test_from_manifest_getattr(self, contract_type, project_from_manifest):
+        expected = ContractContainer(contract_type)
+        actual = project_from_manifest.FooContractFromManifest
+        assert isinstance(actual, ContractContainer)
+        assert actual == expected
+
+    def test_from_manifest_getitem(self, contract_type, project_from_manifest):
+        expected = ContractContainer(contract_type)
+        assert project_from_manifest["FooContractFromManifest"] == expected
+
+    def test_from_manifest_load_contracts(self, contract_type):
+        """
+        Show if contract-types are missing but sources set,
+        compiling will add contract-types.
+        """
+        manifest = make_manifest(contract_type, include_contract_type=False)
+        project = Project.from_manifest(manifest)
+        assert not project.manifest.contract_types, "Setup failed"
+
+        # Returns containers, not types.
+        actual = project.load_contracts()
+        assert actual[contract_type.name].contract_type == contract_type
+
+        # Also, show it got set on the manifest.
+        assert project.manifest.contract_types == {contract_type.name: contract_type}
+
+
+class TestBrownieProject:
+    """
+    Tests related to the brownie implementation of the ProjectAPI.
+    """
+
+    @pytest.fixture
+    def brownie_project(self, base_projects_directory):
+        project_path = base_projects_directory / "BrownieProject"
+        return BrownieProject(path=project_path)
+
+    def test_configure(self, config, brownie_project):
+        config = brownie_project.extract_config()
+
+        # Ensure contracts_folder works.
+        assert config.contracts_folder == "contractsrenamed"
+
+        # Ensure Solidity and dependencies configuration mapped correctly
+        assert config.solidity.version == "0.6.12"
+
+        # NOTE: `contracts/` is not part of the import key as it is
+        # usually included in the import statements.
+        assert [str(x) for x in config.solidity.import_remapping] == [
+            "@openzeppelin=openzeppelin/3.1.0"
+        ]
+        assert config.dependencies[0]["name"] == "openzeppelin"
+        assert config.dependencies[0]["github"] == "OpenZeppelin/openzeppelin-contracts"
+        assert config.dependencies[0]["version"] == "3.1.0"
+
+
+class TestSourceManager:
+    def test_lookup(self, tmp_project):
+        source_id = tmp_project.Other.contract_type.source_id
+        path = tmp_project.sources.lookup(source_id)
+        assert path == tmp_project.path / source_id
+
+    def test_lookup_missing_extension(self, tmp_project):
+        source_id = tmp_project.Other.contract_type.source_id
+        source_id_wo_ext = ".".join(source_id.split(".")[:-1])
+        path = tmp_project.sources.lookup(source_id_wo_ext)
+        assert path == tmp_project.path / source_id
+
+    def test_lookup_mismatched_extension(self, tmp_project):
+        source_id = tmp_project.Other.contract_type.source_id
+        source_id = source_id.replace(".json", ".js")
+        path = tmp_project.sources.lookup(source_id)
+        assert path is None
+
+    def test_lookup_closest_match(self, project_with_source_files_contract):
+        pm = project_with_source_files_contract
+        source_path = pm.contracts_folder / "Contract.json"
+        temp_dir_a = pm.contracts_folder / "temp"
+        temp_dir_b = temp_dir_a / "tempb"
+        nested_source_a = temp_dir_a / "Contract.json"
+        nested_source_b = temp_dir_b / "Contract.json"
+
+        def clean():
+            # NOTE: Will also delete temp_dir_b.
+            if temp_dir_a.is_dir():
+                shutil.rmtree(temp_dir_a)
+
+        clean()
+
+        # NOTE: Will also make temp_dir_a.
+        temp_dir_b.mkdir(parents=True)
+
+        try:
+            # Duplicate contract so that there are multiple with the same name.
+            for nested_src in (nested_source_a, nested_source_b):
+                nested_src.touch()
+                nested_src.write_text(source_path.read_text())
+
+            # Top-level match.
+            for base in (source_path, str(source_path), "Contract", "Contract.json"):
+                assert pm.sources.lookup(base) == source_path, f"Failed to lookup {base}"
+
+            # Nested: 1st level
+            for closest in (
+                nested_source_a,
+                str(nested_source_a),
+                "temp/Contract",
+                "temp/Contract.json",
+            ):
+                actual = pm.sources.lookup(closest)
+                expected = nested_source_a
+                assert actual == expected, f"Failed to lookup {closest}"
+
+            # Nested: 2nd level
+            for closest in (
+                nested_source_b,
+                str(nested_source_b),
+                "temp/tempb/Contract",
+                "temp/tempb/Contract.json",
+            ):
+                actual = pm.sources.lookup(closest)
+                expected = nested_source_b
+                assert actual == expected, f"Failed to lookup {closest}"
+
+        finally:
+            clean()
+
+    def test_lookup_not_found(self, tmp_project):
+        assert tmp_project.sources.lookup("madeup.json") is None
+
+    def test_lookup_missing_contracts_prefix(self, project_with_source_files_contract):
+        """
+        Show we can exclude the `contracts/` prefix in a source ID.
+        """
+        project = project_with_source_files_contract
+        actual_from_str = project.sources.lookup("ContractA.sol")
+        actual_from_path = project.sources.lookup(Path("ContractA.sol"))
+        expected = project.contracts_folder / "ContractA.sol"
+        assert actual_from_str == actual_from_path == expected
+        assert actual_from_str.is_absolute()
+        assert actual_from_path.is_absolute()
+
+    def test_paths_exclude(self, tmp_project):
+        exclude_config = {"compile": {"exclude": ["Other.json"]}}
+        with tmp_project.temp_config(**exclude_config):
+            # Show default excludes also work, such as a .DS_Store file.
+            ds_store = tmp_project.contracts_folder / ".DS_Store"
+            ds_store.write_bytes(b"asdfasf")
+
+            # Show anything in compiler-cache is ignored.
+            cache = tmp_project.contracts_folder / ".cache"
+            cache.mkdir(exist_ok=True)
+            random_file = cache / "dontmindme.json"
+            random_file.write_text("what, this isn't json?!")
+
+            path_ids = {
+                f"{tmp_project.contracts_folder.name}/{src.name}"
+                for src in tmp_project.sources.paths
+            }
+            excluded = {".DS_Store", "Other.json", ".cache/dontmindme.json"}
+            for actual in (path_ids, tmp_project.sources):
+                for exclusion in excluded:
+                    expected = f"{tmp_project.contracts_folder.name}/{exclusion}"
+                    assert expected not in actual
+
+    def test_is_excluded(self, project_with_contracts):
+        exclude_cfg = {"compile": {"exclude": ["exclude_dir/*", "Excl*.json"]}}
+        source_ids = ("contracts/exclude_dir/UnwantedContract.json", "contracts/Exclude.json")
+        with project_with_contracts.temp_config(**exclude_cfg):
+            for source_id in source_ids:
+                path = project_with_contracts.path / source_id
+                assert project_with_contracts.sources.is_excluded(path)
+
+    def test_items(self, project_with_contracts):
+        actual = list(project_with_contracts.sources.items())
+        assert len(actual) > 0
+        assert isinstance(actual[0], tuple)
+        assert "contracts/Other.json" in [x[0] for x in actual]
+        assert isinstance(actual[0][1], Source)
+
+    def test_keys(self, project_with_contracts):
+        actual = list(project_with_contracts.sources.keys())
+        assert "contracts/Other.json" in actual
+
+    def test_values(self, project_with_contracts):
+        actual = list(project_with_contracts.sources.values())
+        assert all(isinstance(x, Source) for x in actual)
+
+
+class TestContractManager:
+    def test_iter(self, tmp_project):
+        actual = set(iter(tmp_project.contracts))
+        assert actual == {"Project", "Other"}
+
+    def test_compile(self, tmp_project):
+        actual = list(tmp_project.contracts._compile("contracts/Project.json"))
+        assert len(actual) == 1
+        assert actual[0].contract_type.name == "Project"
+
+        # Show it can happen again.
+        actual = list(tmp_project.contracts._compile("contracts/Project.json"))
+        assert len(actual) == 1
+        assert actual[0].contract_type.name == "Project"
+
+
+class TestDeploymentManager:
+    @pytest.fixture
+    def project(self, tmp_project, vyper_contract_instance, mock_sepolia):
+        contract_type = vyper_contract_instance.contract_type
+        tmp_project.manifest.contract_types = {contract_type.name: contract_type}
+        return tmp_project
+
+    def test_track(self, project, vyper_contract_instance, mock_sepolia):
+        project.deployments.track(vyper_contract_instance)
+        deployment = next(iter(project.deployments), None)
+        contract_type = vyper_contract_instance.contract_type
+        assert deployment is not None
+        assert deployment.contract_type == f"{contract_type.source_id}:{contract_type.name}"
+
+    def test_instance_map(self, project, vyper_contract_instance, mock_sepolia):
+        project.deployments.track(vyper_contract_instance)
+        assert project.deployments.instance_map != {}
+
+        bip122_chain_id = project.provider.get_block(0).hash.hex()
+        expected_uri = f"blockchain://{bip122_chain_id[2:]}/block/"
+        for key in project.deployments.instance_map.keys():
+            if key.startswith(expected_uri):
+                return
+
+        assert False, "Failed to find expected URI"
```

### Comparing `eth-ape-0.7.9/tests/functional/test_provider.py` & `eth-ape-0.8.0/tests/functional/test_provider.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,28 +1,30 @@
+import os
 from unittest import mock
 
 import pytest
 from eth_pydantic_types import HashBytes32
 from eth_tester.exceptions import TransactionFailed  # type: ignore
 from eth_typing import HexStr
 from eth_utils import ValidationError
 from hexbytes import HexBytes
+from requests import HTTPError
 from web3.exceptions import ContractPanicError
 
 from ape.exceptions import (
     APINotImplementedError,
     BlockNotFoundError,
     ContractLogicError,
     ProviderError,
     TransactionError,
     TransactionNotFoundError,
 )
 from ape.types import LogFilter
 from ape.utils import DEFAULT_TEST_CHAIN_ID
-from ape_ethereum.provider import _sanitize_web3_url
+from ape_ethereum.provider import WEB3_PROVIDER_URI_ENV_VAR_NAME, Web3Provider, _sanitize_web3_url
 from ape_ethereum.transactions import TransactionStatusEnum, TransactionType
 
 
 def test_uri(eth_tester_provider):
     assert not eth_tester_provider.http_uri
     assert not eth_tester_provider.ws_uri
 
@@ -105,15 +107,15 @@
         eth_tester_provider.connect()
 
 
 def test_get_receipt_not_exists_with_timeout(eth_tester_provider):
     unknown_txn = "0x053cba5c12172654d894f66d5670bab6215517a94189a9ffc09bc40a589ec04d"
     expected = (
         f"Transaction '{unknown_txn}' not found. "
-        rf"Error: Transaction HexBytes\('{unknown_txn}'\) "
+        rf"Error: Transaction '{unknown_txn}' "
         "is not in the chain after 0 seconds"
     )
     with pytest.raises(TransactionNotFoundError, match=expected):
         eth_tester_provider.get_receipt(unknown_txn, timeout=0)
 
 
 def test_get_receipt_exists_with_timeout(eth_tester_provider, vyper_contract_instance, owner):
@@ -197,21 +199,26 @@
     """
     balance = networks.provider.get_balance(accounts.test_accounts[0].address)
 
     assert type(balance) is int
     assert balance == 1000000000000000000000000
 
 
-def test_set_timestamp(eth_tester_provider):
-    pending_at_start = eth_tester_provider.get_block("pending").timestamp
-    expected = pending_at_start + 100
-    eth_tester_provider.set_timestamp(expected)
-    eth_tester_provider.mine()
-    actual = eth_tester_provider.get_block("pending").timestamp
-    assert actual == expected + 1  # Mining adds another second.
+def test_set_timestamp(ethereum):
+    # NOTE: Using a different eth-tester for multi-processing ease.
+    with ethereum.local.use_provider(
+        "test", provider_settings={"chain_id": 919191912828283}
+    ) as provider:
+        pending_at_start = provider.get_block("pending").timestamp
+        new_ts = pending_at_start + 100
+        expected = new_ts + 1  # Mining adds another second.
+        provider.set_timestamp(new_ts)
+        provider.mine()
+        actual = provider.get_block("pending").timestamp
+        assert actual == expected
 
 
 def test_set_timestamp_to_same_time(eth_tester_provider):
     """
     Eth tester normally fails when setting the timestamp to the same time.
     However, in Ape, we treat it as a no-op and let it pass.
     """
@@ -284,20 +291,14 @@
 def test_no_comma_in_rpc_url():
     test_url = "URI: http://127.0.0.1:8545,"
     sanitised_url = _sanitize_web3_url(test_url)
 
     assert "," not in sanitised_url
 
 
-def test_use_provider_using_provider_instance(eth_tester_provider):
-    network = eth_tester_provider.network
-    with network.use_provider(eth_tester_provider) as provider:
-        assert id(provider) == id(eth_tester_provider)
-
-
 def test_send_transaction_when_no_error_and_receipt_fails(
     mock_transaction, mock_web3, eth_tester_provider, owner, vyper_contract_instance
 ):
     start_web3 = eth_tester_provider._web3
     eth_tester_provider._web3 = mock_web3
 
     try:
@@ -353,38 +354,68 @@
 
 
 def test_make_request_not_exists(eth_tester_provider):
     with pytest.raises(
         APINotImplementedError,
         match="RPC method 'ape_thisDoesNotExist' is not implemented by this node instance.",
     ):
-        eth_tester_provider._make_request("ape_thisDoesNotExist")
+        eth_tester_provider.make_request("ape_thisDoesNotExist")
 
 
 @pytest.mark.parametrize("msg", ("Method not found", "Method ape_thisDoesNotExist not found"))
 def test_make_request_not_exists_dev_nodes(eth_tester_provider, mock_web3, msg):
     """
-    Simulate what *most* of the dev providers do, like hardhat, anvil, and ganache.
+    Handle an issue found from Base-sepolia where not-implemented RPCs
+    caused HTTPErrors.
     """
     real_web3 = eth_tester_provider._web3
     mock_web3.eth = real_web3.eth
-    eth_tester_provider._web3 = mock_web3
 
     def custom_make_request(rpc, params):
         if rpc == "ape_thisDoesNotExist":
             return {"error": {"message": msg}}
 
         return real_web3.provider.make_request(rpc, params)
 
     mock_web3.provider.make_request.side_effect = custom_make_request
-    with pytest.raises(
-        APINotImplementedError,
-        match="RPC method 'ape_thisDoesNotExist' is not implemented by this node instance.",
-    ):
-        eth_tester_provider._make_request("ape_thisDoesNotExist")
+
+    eth_tester_provider._web3 = mock_web3
+    try:
+        with pytest.raises(
+            APINotImplementedError,
+            match="RPC method 'ape_thisDoesNotExist' is not implemented by this node instance.",
+        ):
+            eth_tester_provider.make_request("ape_thisDoesNotExist")
+    finally:
+        eth_tester_provider._web3 = real_web3
+
+
+def test_make_request_handles_http_error_method_not_allowed(eth_tester_provider, mock_web3):
+    """
+    Simulate what *most* of the dev providers do, like hardhat, anvil, and ganache.
+    """
+    real_web3 = eth_tester_provider._web3
+    mock_web3.eth = real_web3.eth
+
+    def custom_make_request(rpc, params):
+        if rpc == "ape_thisDoesNotExist":
+            raise HTTPError("Client error: Method Not Allowed")
+
+        return real_web3.provider.make_request(rpc, params)
+
+    mock_web3.provider.make_request.side_effect = custom_make_request
+    eth_tester_provider._web3 = mock_web3
+    try:
+        with pytest.raises(
+            APINotImplementedError,
+            match="RPC method 'ape_thisDoesNotExist' is not implemented by this node instance.",
+        ):
+            eth_tester_provider.make_request("ape_thisDoesNotExist")
+    finally:
+        eth_tester_provider._web3 = real_web3
 
 
 def test_base_fee(eth_tester_provider):
     actual = eth_tester_provider.base_fee
     assert actual > 0
 
     # NOTE: Mostly doing this to ensure we are calling the fee history
@@ -393,7 +424,54 @@
     assert "baseFeePerGas" in actual
 
 
 def test_create_access_list(eth_tester_provider, vyper_contract_instance, owner):
     tx = vyper_contract_instance.setNumber.as_transaction(123, sender=owner)
     with pytest.raises(APINotImplementedError):
         eth_tester_provider.create_access_list(tx)
+
+
+def test_auto_mine(eth_tester_provider):
+    eth_tester_provider.auto_mine = False
+    assert not eth_tester_provider.auto_mine
+
+    # Ensure can still manually mine.
+    block = eth_tester_provider.get_block("latest").number
+    eth_tester_provider.mine()
+    next_block = eth_tester_provider.get_block("latest").number
+    assert next_block > block
+
+    eth_tester_provider.auto_mine = True
+    assert eth_tester_provider.auto_mine
+
+
+def test_new_when_web3_provider_uri_set():
+    """
+    Tests against a confusing case where having an env var
+    $WEB3_PROVIDER_URI caused web3.py to only ever use that RPC
+    URL regardless of what was said in Ape's --network or config.
+    Now, we raise an error to avoid having users think Ape's
+    network system is broken.
+    """
+    os.environ[WEB3_PROVIDER_URI_ENV_VAR_NAME] = "TEST"
+    expected = (
+        rf"Ape does not support Web3\.py's environment variable "
+        rf"\${WEB3_PROVIDER_URI_ENV_VAR_NAME}\. If you are using this environment "
+        r"variable name incidentally, please use a different name\. If you are "
+        r"trying to set the network in Web3\.py, please use Ape's `ape-config\.yaml` "
+        r"or `--network` option instead\."
+    )
+
+    class MyProvider(Web3Provider):
+        def connect(self):
+            raise NotImplementedError()
+
+        def disconnect(self):
+            raise NotImplementedError()
+
+    try:
+        with pytest.raises(ProviderError, match=expected):
+            _ = MyProvider(data_folder=None, name=None, network=None, request_header=None)
+
+    finally:
+        if WEB3_PROVIDER_URI_ENV_VAR_NAME in os.environ:
+            del os.environ[WEB3_PROVIDER_URI_ENV_VAR_NAME]
```

### Comparing `eth-ape-0.7.9/tests/functional/test_query.py` & `eth-ape-0.8.0/tests/functional/test_query.py`

 * *Files 4% similar despite different names*

```diff
@@ -25,17 +25,17 @@
         "difficulty",
         "gas_limit",
         "gas_used",
         "hash",
         "num_transactions",
         "number",
         "parent_hash",
-        "size",
         "timestamp",
         "total_difficulty",
+        "uncles",
     ]
 
 
 def test_relative_block_query(chain, eth_tester_provider):
     start_block = chain.blocks.height
     chain.mine(10)
     df = chain.blocks.query("*", start_block=-8, stop_block=-2)
```

### Comparing `eth-ape-0.7.9/tests/functional/test_receipt.py` & `eth-ape-0.8.0/tests/functional/test_receipt.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,41 +1,61 @@
 import pytest
+from rich.table import Table
+from rich.tree import Tree
 
 from ape.api import ReceiptAPI
-from ape.exceptions import APINotImplementedError, ContractLogicError, OutOfGasError
+from ape.exceptions import ContractLogicError, OutOfGasError
 from ape.utils import ManagerAccessMixin
-from ape_ethereum.transactions import Receipt, TransactionStatusEnum
+from ape_ethereum.transactions import DynamicFeeTransaction, Receipt, TransactionStatusEnum
 
 
 @pytest.fixture
 def deploy_receipt(vyper_contract_instance):
-    return vyper_contract_instance.receipt
+    return vyper_contract_instance.creation_metadata.receipt
 
 
 @pytest.fixture
 def invoke_receipt(vyper_contract_instance, owner):
     return vyper_contract_instance.setNumber(1, sender=owner)
 
 
+@pytest.fixture
+def trace_print_capture(mocker, chain):
+    console_factory = mocker.MagicMock()
+    capture = mocker.MagicMock()
+    console_factory.return_value = capture
+    orig = chain._reports._get_console
+    chain._reports._get_console = console_factory
+    try:
+        yield capture.print
+    finally:
+        chain._reports._get_console = orig
+
+
 def test_receipt_properties(chain, invoke_receipt):
     assert invoke_receipt.block_number == chain.blocks.head.number
     assert invoke_receipt.timestamp == chain.blocks.head.timestamp
     assert invoke_receipt.datetime == chain.blocks.head.datetime
 
 
-def test_show_trace(invoke_receipt):
-    # See trace-supported provider plugin tests for better tests (e.g. ape-hardhat)
-    with pytest.raises(APINotImplementedError):
-        invoke_receipt.show_trace()
+def test_show_trace(trace_print_capture, invoke_receipt):
+    invoke_receipt.show_trace()
+    actual = trace_print_capture.call_args[0][0]
+    assert isinstance(actual, Tree)
+    label = f"{actual.label}"
+    assert "VyperContract" in label
+    assert "setNumber" in label
+    assert f"[{invoke_receipt.gas_used} gas]" in label
 
 
-def test_show_gas_report(invoke_receipt):
-    # See trace-supported provider plugin tests for better tests (e.g. ape-hardhat)
-    with pytest.raises(APINotImplementedError):
-        invoke_receipt.show_gas_report()
+def test_show_gas_report(trace_print_capture, invoke_receipt):
+    invoke_receipt.show_gas_report()
+    actual = trace_print_capture.call_args[0][0]
+    assert isinstance(actual, Table)
+    assert actual.title == "VyperContract Gas"
 
 
 def test_decode_logs_specify_abi(invoke_receipt, vyper_contract_instance):
     abi = vyper_contract_instance.NumberChange.abi
     logs = invoke_receipt.decode_logs(abi=abi)
     assert len(logs) == 1
     assert logs[0].newNum == 1
@@ -194,7 +214,31 @@
     assert mock_runner.track_coverage.call_count == 0
     ManagerAccessMixin._test_runner = original
 
 
 def test_access_from_tx(deploy_receipt):
     actual = deploy_receipt.transaction.receipt
     assert actual == deploy_receipt
+
+
+def test_transaction_validated_from_dict(ethereum, owner, deploy_receipt):
+    tx = ethereum.create_transaction(sender=owner.address, value=123, data=b"hello")
+    tx_data = tx.model_dump()
+    receipt_data = deploy_receipt.model_dump(by_alias=True)
+    receipt_data["transaction"] = tx_data
+    receipt = Receipt.model_validate(receipt_data)
+    assert isinstance(receipt.transaction, DynamicFeeTransaction)
+    assert receipt.transaction.sender == owner.address
+    assert receipt.transaction.value == 123
+    assert receipt.transaction.data == b"hello"
+
+
+def test_return_value(owner, vyper_contract_instance):
+    """
+    ``.return_value`` still works when using EthTester provider!
+    It works by using eth_call to get the result rather than
+    tracing-RPCs.
+    """
+    receipt = vyper_contract_instance.getNestedArrayMixedDynamic.transact(sender=owner)
+    actual = receipt.return_value
+    assert len(actual) == 5
+    assert actual[1][1] == [[0], [0, 1], [0, 1, 2]]
```

### Comparing `eth-ape-0.7.9/tests/functional/test_reverts_context_manager.py` & `eth-ape-0.8.0/tests/functional/test_reverts_context_manager.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/functional/test_transaction.py` & `eth-ape-0.8.0/tests/functional/test_transaction.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,7 +1,8 @@
+import re
 import warnings
 
 import pytest
 from eth_pydantic_types import HexBytes
 from hexbytes import HexBytes as BaseHexBytes
 
 from ape.exceptions import SignatureError
@@ -243,14 +244,15 @@
     txn = owner.prepare_transaction(txn)
     txn = owner.sign_transaction(txn)
 
     # Hack to make access_list raw. I am not sure how a user would get
     # to this state, but somehow they have.
     txn.access_list = ACCESS_LIST_HEXBYTES
 
+    # Ignore the Pydantic warning from access-list being the wrong type.
     with warnings.catch_warnings():
         warnings.simplefilter("ignore")
         actual = txn.txn_hash.hex()
 
     assert actual.startswith("0x")
 
 
@@ -260,18 +262,18 @@
     txn = StaticFeeTransaction.model_validate(txn_dict)
     assert txn.data == data, "Whitespace should not be removed from data"
 
 
 def test_model_dump_excludes_none_values():
     txn = StaticFeeTransaction()
     txn.value = 1000000
-    actual = txn.model_dump(mode="json")
+    actual = txn.model_dump()
     assert "value" in actual
     txn.value = None  # type: ignore
-    actual = txn.model_dump(mode="json")
+    actual = txn.model_dump()
     assert "value" not in actual
 
 
 def test_model_dump_access_list():
     # Data directly from eth_createAccessList RPC
     access_list = [
         {
@@ -299,14 +301,24 @@
 
 
 def test_receipt_when_none(ethereum):
     txn = ethereum.create_transaction(data=HexBytes("0x123"))
     assert txn.receipt is None
 
 
+def test_repr(ethereum):
+    txn = ethereum.create_transaction(data=HexBytes("0x123"))
+    actual = repr(txn)
+    expected = (
+        r"<DynamicFeeTransaction chainId=\d*, "
+        r"gas=\d*, value=0, data=0x\d*, type=2, accessList=\[\]>"
+    )
+    assert re.match(expected, actual)
+
+
 # NOTE: Some of these values are needed for signing to work.
 @pytest.mark.parametrize(
     "tx_kwargs",
     [
         {"data": HexBytes("0x123"), "nonce": 0, "gas_price": 0},
         {"gasLimit": 100, "nonce": 0, "max_fee": 0, "max_priority_fee": 0},
         {"access_list": ACCESS_LIST, "nonce": 0, "gasPrice": 0},  # NOTE: show camelCase works
```

### Comparing `eth-ape-0.7.9/tests/functional/test_types.py` & `eth-ape-0.8.0/tests/functional/test_types.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-from typing import Dict
-
 import pytest
 from eth_utils import to_hex
 from ethpm_types.abi import EventABI
 from hexbytes import HexBytes
 from pydantic import BaseModel
 
 from ape.types import (
@@ -18,15 +16,15 @@
 
 TXN_HASH = "0xaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa222222222222222222222222"
 BLOCK_HASH = "0x999999998d4f99f68db9999999999da27ed049458b139999999999e910155b99"
 BLOCK_NUMBER = 323423
 EVENT_NAME = "MyEvent"
 LOG_INDEX = 7
 TXN_INDEX = 2
-RAW_LOG: Dict = {
+RAW_LOG: dict = {
     "block_hash": BLOCK_HASH,
     "block_number": BLOCK_NUMBER,
     "contract_address": ZERO_ADDRESS,
     "event_arguments": {"foo": 0, "bar": 1},
     "log_index": LOG_INDEX,
     "event_name": EVENT_NAME,
     "transaction_hash": TXN_HASH,
@@ -71,26 +69,26 @@
 
 @pytest.fixture
 def signature(owner, signable_message):
     return owner.sign_message(signable_message)
 
 
 def test_contract_log_serialization(log, zero_address):
-    obj = ContractLog.model_validate(log.model_dump(mode="json"))
+    obj = ContractLog.model_validate(log.model_dump())
     assert obj.contract_address == zero_address
     assert obj.block_hash == BLOCK_HASH
     assert obj.block_number == BLOCK_NUMBER
     assert obj.event_name == EVENT_NAME
     assert obj.log_index == 7
     assert obj.transaction_hash == TXN_HASH
     assert obj.transaction_index == TXN_INDEX
 
 
 def test_contract_log_serialization_with_hex_strings_and_non_checksum_addresses(log, zero_address):
-    data = log.model_dump(mode="json")
+    data = log.model_dump()
     data["log_index"] = to_hex(log.log_index)
     data["transaction_index"] = to_hex(log.transaction_index)
     data["block_number"] = to_hex(log.block_number)
     data["contract_address"] = log.contract_address.lower()
 
     obj = ContractLog(**data)
 
@@ -100,20 +98,20 @@
     assert obj.event_name == EVENT_NAME
     assert obj.log_index == 7
     assert obj.transaction_hash == TXN_HASH
     assert obj.transaction_index == TXN_INDEX
 
 
 def test_contract_log_str(log):
-    obj = ContractLog.model_validate(log.model_dump(mode="json"))
+    obj = ContractLog.model_validate(log.model_dump())
     assert str(obj) == "MyEvent(foo=0 bar=1)"
 
 
 def test_contract_log_repr(log):
-    obj = ContractLog.model_validate(log.model_dump(mode="json"))
+    obj = ContractLog.model_validate(log.model_dump())
     assert repr(obj) == "<MyEvent foo=0 bar=1>"
 
 
 def test_contract_log_access(log):
     assert "foo" in log
     assert "bar" in log
     assert log.foo == log["foo"] == log.get("foo") == 0
```

### Comparing `eth-ape-0.7.9/tests/functional/utils/test_misc.py` & `eth-ape-0.8.0/tests/functional/utils/test_misc.py`

 * *Files 3% similar despite different names*

```diff
@@ -8,14 +8,15 @@
     ZERO_ADDRESS,
     _dict_overlay,
     add_padding_to_strings,
     extract_nested_value,
     get_package_version,
     is_evm_precompile,
     is_zero_hex,
+    log_instead_of_fail,
     pragma_str_to_specifier_set,
     raises_not_implemented,
     run_until_complete,
     to_int,
 )
 
 
@@ -155,7 +156,16 @@
     assert "two" in mapping["b"]
     assert mapping["b"]["two"] == 2
     assert "three" in mapping["b"]
     assert mapping["b"]["three"] is None
     assert "c" in mapping
     assert isinstance(mapping["c"], dict)
     assert "four" in mapping["c"]
+
+
+def test_log_instead_of_fail(ape_caplog):
+    @log_instead_of_fail()
+    def my_method():
+        raise ValueError("Oh no!")
+
+    my_method()
+    assert "Oh no!" in ape_caplog.head
```

### Comparing `eth-ape-0.7.9/tests/integration/cli/projects/geth/ape-config.yaml` & `eth-ape-0.8.0/tests/integration/cli/projects/geth/ape-config.yaml`

 * *Files 16% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 ethereum:
   local:
-    default_provider: geth
+    default_provider: node
 
 # Change the default URI for one of the networks to
 # ensure that the default values of the other networks
 # remain unchanged.
-geth:
+node:
   ethereum:
     mainnet:
       uri: http://localhost:5000
     local:
       uri: http://127.0.0.1:5550  # NOTE: Has to be same as tests/conftest.py::GETH_URI
       extra_funded_accounts:
         - 0x63c7f11162dBFC374DC6f5C0B3Aa26C618846a85  # Test account 100.
```

### Comparing `eth-ape-0.7.9/tests/integration/cli/projects/geth/contracts/TokenA.json` & `eth-ape-0.8.0/tests/integration/cli/projects/geth/contracts/TokenA.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/integration/cli/projects/geth/contracts/TokenB.json` & `eth-ape-0.8.0/tests/integration/cli/projects/geth/contracts/TokenB.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/integration/cli/projects/geth/contracts/VyperContract.json` & `eth-ape-0.8.0/tests/integration/cli/projects/geth/contracts/VyperContract.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/integration/cli/projects/geth/tests/test_using_local_geth.py` & `eth-ape-0.8.0/tests/integration/cli/projects/geth/tests/test_using_local_geth.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import pytest
 
 
 def test_provider(project, networks):
     """
     Tests that the network gets set from ape-config.yaml.
     """
-    assert networks.provider.name == "geth"
+    assert networks.provider.name == "node"
     assert networks.provider.is_connected
 
 
 def test_extra_account(chain):
     """
     Show we can fund accounts from the config option.
     """
```

### Comparing `eth-ape-0.7.9/tests/integration/cli/projects/script/contracts/VyperContract.json` & `eth-ape-0.8.0/tests/integration/cli/projects/script/contracts/VyperContract.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/integration/cli/projects/test/tests/test_fixture_isolation.py` & `eth-ape-0.8.0/tests/integration/cli/projects/test/tests/test_fixture_isolation.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/integration/cli/projects/test/tests/test_fixtures.py` & `eth-ape-0.8.0/tests/integration/cli/projects/test/tests/test_fixtures.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/integration/cli/projects/test/tests/test_networks.py` & `eth-ape-0.8.0/tests/integration/cli/projects/test/tests/test_networks.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/contracts/ContractA.json` & `eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/contracts/ContractA.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/contracts/RawSolidityOutput.json` & `eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/contracts/RawSolidityOutput.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/contracts/RawVyperOutput.json` & `eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/contracts/RawVyperOutput.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/dep/contracts/RawVyperOutputDep.json` & `eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/dep/contracts/RawVyperOutputDep.json`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/integration/cli/projects/with-contracts/tests/test_contract.py` & `eth-ape-0.8.0/tests/integration/cli/projects/with-contracts/tests/test_contract.py`

 * *Files identical despite different names*

### Comparing `eth-ape-0.7.9/tests/integration/cli/test_accounts.py` & `eth-ape-0.8.0/tests/integration/cli/test_accounts.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 import json
 import re
-from typing import List, Optional
+from typing import Optional
 
 import pytest
 from eth_account import Account
 from eth_account.hdaccount import ETHEREUM_DEFAULT_PATH
 
 from ape.logging import HIDDEN_MESSAGE
 from tests.integration.cli.utils import assert_failure, run_once
@@ -13,34 +13,31 @@
 PASSWORD = "asdf1234"
 PRIVATE_KEY = "0000000000000000000000000000000000000000000000000000000000000001"
 MNEMONIC = "test test test test test test test test test test test junk"
 INVALID_MNEMONIC = "test test"
 CUSTOM_HDPATH = "m/44'/61'/0'/0/0"  # Ethereum Classic ($ETC) HDPath
 
 
-def extract_mnemonic(output: str) -> Optional[List[str]]:
+def extract_mnemonic(output: str) -> Optional[list[str]]:
     found = re.search(r"Newly generated mnemonic is: ([a-z ]+)", output)
     if found:
         try:
             mnemonic_string = found.group(1)
             return mnemonic_string.split(" ")
         except IndexError:
             pass
     return None
 
 
 @pytest.fixture(autouse=True)
-def temp_keyfile_path(temp_accounts_path):
-    test_keyfile_path = temp_accounts_path / f"{ALIAS}.json"
-
-    if test_keyfile_path.is_file():
-        # Corrupted from a previous test
-        test_keyfile_path.unlink()
-
-    return test_keyfile_path
+def temp_keyfile_path(config):
+    # NOTE: Is a fresh account for each use.
+    path = config.DATA_FOLDER / "accounts" / f"{ALIAS}.json"
+    path.unlink(missing_ok=True)
+    return path
 
 
 @pytest.fixture
 def temp_keyfile(temp_keyfile_path, keyparams):
     temp_keyfile_path.write_text(json.dumps(keyparams))
 
     yield temp_keyfile_path
@@ -68,71 +65,71 @@
 
 @run_once
 def test_import_valid_private_key(ape_cli, runner, temp_account, temp_keyfile_path):
     assert not temp_keyfile_path.is_file()
     # Add account from valid private key
     result = runner.invoke(
         ape_cli,
-        ["accounts", "import", ALIAS],
+        ("accounts", "import", ALIAS),
         input="\n".join([f"0x{PRIVATE_KEY}", PASSWORD, PASSWORD]),
     )
     assert result.exit_code == 0, result.output
     assert temp_account.address in result.output
     assert ALIAS in result.output
     assert temp_keyfile_path.is_file()
 
 
 @run_once
 def test_import_alias_is_private_key(ape_cli, runner):
     # Attempt using private key as the alias.
     key_alias = f"0x{PRIVATE_KEY}"
     result = runner.invoke(
         ape_cli,
-        ["accounts", "import", key_alias],
+        ("accounts", "import", key_alias),
         input="\n".join([f"0x{PRIVATE_KEY}", PASSWORD, PASSWORD]),
     )
     assert result.exit_code != 0, result.output
     expected = "ERROR: (AccountsError) Longer aliases cannot be hex strings.\n"
-    assert result.output == expected
+    assert expected in result.output
 
 
 @run_once
 def test_import_alias_is_really_long(ape_cli, runner):
     """
     For entropy related use-cases regarding alias, we
     must ensure long aliases are supported.
     """
 
     long_alias = "this is a long alias that i am going to use and you cant stop me"
     result = runner.invoke(
         ape_cli,
-        ["accounts", "import", long_alias],
+        ("accounts", "import", long_alias),
         input="\n".join([f"0x{PRIVATE_KEY}", PASSWORD, PASSWORD]),
     )
     assert result.exit_code == 0
 
 
 @run_once
 def test_import_invalid_private_key(ape_cli, runner):
     # Add account from invalid private key
     result = runner.invoke(
         ape_cli,
-        ["accounts", "import", ALIAS],
+        ("accounts", "import", ALIAS),
         input="\n".join(["0xhello", PASSWORD, PASSWORD]),
     )
     assert result.exit_code == 1, result.output
     assert_failure(result, "Key can't be imported: Non-hexadecimal digit found")
 
 
 @run_once
 def test_import_alias_already_in_use(ape_cli, runner):
     def invoke_import():
         return runner.invoke(
             ape_cli,
-            ["accounts", "import", ALIAS],
+            ("accounts", "import", ALIAS),
             input="\n".join([f"0x{PRIVATE_KEY}", PASSWORD, PASSWORD]),
         )
 
     result = invoke_import()
     assert result.exit_code == 0, result.output
     result = invoke_import()
     assert_failure(result, f"Account with alias '{ALIAS}' already in use")
@@ -140,29 +137,29 @@
 
 @run_once
 def test_import_account_instantiation_failure(mocker, ape_cli, runner):
     eth_account_from_key_patch = mocker.patch("ape_accounts._cli.EthAccount.from_key")
     eth_account_from_key_patch.side_effect = Exception("Can't instantiate this account!")
     result = runner.invoke(
         ape_cli,
-        ["accounts", "import", ALIAS],
+        ("accounts", "import", ALIAS),
         input="\n".join([f"0x{PRIVATE_KEY}", PASSWORD, PASSWORD]),
     )
     assert_failure(result, "Key can't be imported: Can't instantiate this account!")
 
 
 @run_once
 def test_import_mnemonic_default_hdpath(
     ape_cli, runner, temp_account_mnemonic_default_hdpath, temp_keyfile_path
 ):
     assert not temp_keyfile_path.is_file()
     # Add account from mnemonic with default hdpath of ETHEREUM_DEFAULT_PATH
     result = runner.invoke(
         ape_cli,
-        ["accounts", "import", "--use-mnemonic", ALIAS],
+        ("accounts", "import", "--use-mnemonic", ALIAS),
         input="\n".join([MNEMONIC, PASSWORD, PASSWORD]),
     )
     assert result.exit_code == 0, result.output
     assert temp_account_mnemonic_default_hdpath.address in result.output
     assert ALIAS in result.output
     assert temp_keyfile_path.is_file()
 
@@ -171,29 +168,29 @@
 def test_import_mnemonic_custom_hdpath(
     ape_cli, runner, temp_account_mnemonic_custom_hdpath, temp_keyfile_path
 ):
     assert not temp_keyfile_path.is_file()
     # Add account from mnemonic with custom hdpath
     result = runner.invoke(
         ape_cli,
-        ["accounts", "import", ALIAS, "--use-mnemonic", "--hd-path", CUSTOM_HDPATH],
+        ("accounts", "import", ALIAS, "--use-mnemonic", "--hd-path", CUSTOM_HDPATH),
         input="\n".join([MNEMONIC, PASSWORD, PASSWORD]),
     )
     assert result.exit_code == 0, result.output
     assert temp_account_mnemonic_custom_hdpath.address in result.output
     assert ALIAS in result.output
     assert temp_keyfile_path.is_file()
 
 
 @run_once
 def test_export(ape_cli, runner, temp_keyfile, keyfile_account, test_accounts):
     # export key
     result = runner.invoke(
         ape_cli,
-        ["accounts", "export", ALIAS],
+        ("accounts", "export", ALIAS),
         input="\n".join([PASSWORD, PASSWORD]),
     )
     assert result.exit_code == 0, result.output
     # NOTE: temp_keyfile uses the same address as the keyfile account.
     assert keyfile_account.address in result.output
     # NOTE: Both of these accounts are the same as the first
     #   test account.
@@ -201,15 +198,15 @@
 
 
 @run_once
 def test_import_invalid_mnemonic(ape_cli, runner):
     # Add account from invalid mnemonic
     result = runner.invoke(
         ape_cli,
-        ["accounts", "import", "--use-mnemonic", ALIAS],
+        ("accounts", "import", "--use-mnemonic", ALIAS),
         input="\n".join([INVALID_MNEMONIC, PASSWORD, PASSWORD]),
     )
     assert result.exit_code == 1, result.output
     assert_failure(result, "Seed phrase can't be imported")
     assert HIDDEN_MESSAGE in result.output
     assert INVALID_MNEMONIC not in result.output
 
@@ -217,15 +214,15 @@
 @run_once
 def test_generate_default(ape_cli, runner, temp_keyfile_path):
     assert not temp_keyfile_path.is_file()
     # Generate new private key
     show_mnemonic = ""
     result = runner.invoke(
         ape_cli,
-        ["accounts", "generate", ALIAS],
+        ("accounts", "generate", ALIAS),
         input="\n".join(["random entropy", show_mnemonic, PASSWORD, PASSWORD]),
     )
     assert result.exit_code == 0, result.output
     mnemonic = extract_mnemonic(result.output)
     assert mnemonic is not None
     mnemonic_length = len(mnemonic)
     assert mnemonic_length == 12
@@ -237,15 +234,15 @@
 @run_once
 def test_generate_hide_mnemonic_prompt(ape_cli, runner, temp_keyfile_path):
     assert not temp_keyfile_path.is_file()
     # Generate new private key
     show_mnemonic = "n"
     result = runner.invoke(
         ape_cli,
-        ["accounts", "generate", ALIAS],
+        ("accounts", "generate", ALIAS),
         input="\n".join(["random entropy", show_mnemonic, PASSWORD, PASSWORD]),
     )
     assert result.exit_code == 0, result.output
     assert "Newly generated mnemonic is" not in result.output
     assert ETHEREUM_DEFAULT_PATH in result.output
     assert ALIAS in result.output
     assert temp_keyfile_path.is_file()
@@ -253,15 +250,15 @@
 
 @run_once
 def test_generate_hide_mnemonic_option(ape_cli, runner, temp_keyfile_path):
     assert not temp_keyfile_path.is_file()
     # Generate new private key
     result = runner.invoke(
         ape_cli,
-        ["accounts", "generate", ALIAS, "--hide-mnemonic"],
+        ("accounts", "generate", ALIAS, "--hide-mnemonic"),
         input="\n".join(["random entropy", PASSWORD, PASSWORD]),
     )
     assert result.exit_code == 0, result.output
     assert "Newly generated mnemonic is" not in result.output
     assert ETHEREUM_DEFAULT_PATH in result.output
     assert ALIAS in result.output
     assert temp_keyfile_path.is_file()
@@ -271,15 +268,15 @@
 def test_generate_24_words(ape_cli, runner, temp_keyfile_path):
     assert not temp_keyfile_path.is_file()
     # Generate new private key
     show_mnemonic = ""
     word_count = 24
     result = runner.invoke(
         ape_cli,
-        ["accounts", "generate", ALIAS, "--word-count", word_count],
+        ("accounts", "generate", ALIAS, "--word-count", word_count),
         input="\n".join(["random entropy", show_mnemonic, PASSWORD, PASSWORD]),
     )
     assert result.exit_code == 0, result.output
     mnemonic = extract_mnemonic(result.output)
     assert mnemonic is not None
     mnemonic_length = len(mnemonic)
     assert mnemonic_length == word_count
@@ -291,15 +288,15 @@
 @run_once
 def test_generate_custom_hdpath(ape_cli, runner, temp_keyfile_path):
     assert not temp_keyfile_path.is_file()
     # Generate new private key
     show_mnemonic = ""
     result = runner.invoke(
         ape_cli,
-        ["accounts", "generate", ALIAS, "--hd-path", CUSTOM_HDPATH],
+        ("accounts", "generate", ALIAS, "--hd-path", CUSTOM_HDPATH),
         input="\n".join(["random entropy", show_mnemonic, PASSWORD, PASSWORD]),
     )
     assert result.exit_code == 0, result.output
     mnemonic = extract_mnemonic(result.output)
     assert mnemonic is not None
     mnemonic_length = len(mnemonic)
     assert mnemonic_length == 12
@@ -312,15 +309,15 @@
 def test_generate_24_words_and_custom_hdpath(ape_cli, runner, temp_keyfile_path):
     assert not temp_keyfile_path.is_file()
     # Generate new private key
     show_mnemonic = ""
     word_count = 24
     result = runner.invoke(
         ape_cli,
-        ["accounts", "generate", ALIAS, "--word-count", word_count, "--hd-path", CUSTOM_HDPATH],
+        ("accounts", "generate", ALIAS, "--word-count", word_count, "--hd-path", CUSTOM_HDPATH),
         input="\n".join(["random entropy", show_mnemonic, PASSWORD, PASSWORD]),
     )
     assert result.exit_code == 0, result.output
     mnemonic = extract_mnemonic(result.output)
     assert mnemonic is not None
     mnemonic_length = len(mnemonic)
     assert mnemonic_length == word_count
@@ -331,51 +328,51 @@
 
 @run_once
 def test_generate_alias_already_in_use(ape_cli, runner):
     def invoke_generate():
         show_mnemonic = ""
         return runner.invoke(
             ape_cli,
-            ["accounts", "generate", ALIAS],
+            ("accounts", "generate", ALIAS),
             input="\n".join(["random entropy", show_mnemonic, PASSWORD, PASSWORD]),
         )
 
     result = invoke_generate()
     assert result.exit_code == 0, result.output
     result = invoke_generate()
     assert_failure(result, f"Account with alias '{ALIAS}' already in use")
 
 
 @run_once
 def test_list(ape_cli, runner, keyfile_account):
-    result = runner.invoke(ape_cli, ["accounts", "list"], catch_exceptions=False)
+    result = runner.invoke(ape_cli, ("accounts", "list"), catch_exceptions=False)
     assert keyfile_account.alias in result.output
     assert keyfile_account.address in result.output
 
 
 @run_once
 def test_list_all(ape_cli, runner, keyfile_account):
-    result = runner.invoke(ape_cli, ["accounts", "list", "--all"], catch_exceptions=False)
+    result = runner.invoke(ape_cli, ("accounts", "list", "--all"), catch_exceptions=False)
     assert keyfile_account.alias in result.output
     assert keyfile_account.address in result.output
 
 
 @run_once
 def test_change_password(ape_cli, runner, temp_keyfile):
     assert temp_keyfile.is_file()
     # Delete Account (`N` for "Leave unlocked?")
     valid_input = [PASSWORD, "N", "password2", "password2"]
     result = runner.invoke(
         ape_cli,
-        ["accounts", "change-password", ALIAS],
+        ("accounts", "change-password", ALIAS),
         input="\n".join(valid_input) + "\n",
     )
     assert result.exit_code == 0, result.output
 
 
 @run_once
 def test_delete(ape_cli, runner, temp_keyfile):
     assert temp_keyfile.is_file()
     # Delete Account
-    result = runner.invoke(ape_cli, ["accounts", "delete", ALIAS], input=f"{PASSWORD}\n")
+    result = runner.invoke(ape_cli, ("accounts", "delete", ALIAS), input=f"{PASSWORD}\n")
     assert result.exit_code == 0, result.output
     assert not temp_keyfile.is_file()
```

### Comparing `eth-ape-0.7.9/tests/integration/cli/test_compile.py` & `eth-ape-0.8.0/tests/integration/cli/test_compile.py`

 * *Files 15% similar despite different names*

```diff
@@ -4,21 +4,21 @@
 import pytest
 
 from ape.contracts import ContractContainer
 
 from .utils import skip_projects, skip_projects_except
 
 skip_non_compilable_projects = skip_projects(
+    "bad-contracts",
     "empty-config",
     "no-config",
-    "script",
     "only-dependencies",
-    "bad-contracts",
+    "only-script-subdirs",
+    "script",
     "test",
-    "geth",
 )
 
 
 @skip_projects(
     "geth",
     "multiple-interfaces",
     "only-dependencies",
@@ -27,51 +27,30 @@
     "script",
     "with-dependencies",
     "with-contracts",
 )
 def test_compile_missing_contracts_dir(ape_cli, runner, project):
     arg_lists = [["compile"], ["compile", "--include-dependencies"]]
     for arg_list in arg_lists:
+        arg_list.extend(("--project", f"{project.path}"))
         result = runner.invoke(ape_cli, arg_list)
         assert result.exit_code == 0, result.output
-        assert "WARNING" in result.output, f"Detected contracts folder in '{project.path.name}'"
-        assert "Nothing to compile" in result.output
-
-
-@skip_projects_except("bad-contracts")
-def test_skip_contracts_and_missing_compilers(ape_cli, runner, project, switch_config):
-    result = runner.invoke(ape_cli, ["compile", "--force"])
-    assert "INFO: Compiling 'subdir/tsconfig.json'." not in result.output
-    assert "INFO: Compiling 'package.json'." not in result.output
-
-    # NOTE: `.md` should NOT appear in this list!
-    assert (
-        "WARNING: Missing compilers for the following file types: '.foo, .foobar, .test'. "
-        "Possibly, a compiler plugin is not installed or is installed but not loading correctly."
-    ) in result.output
-
-    # Simulate configuring Ape to not ignore tsconfig.json for some reason.
-    content = """
-    compile:
-      exclude:
-        - "*package.json"
-    """
-    with switch_config(project, content):
-        result = runner.invoke(ape_cli, ["compile", "--force"])
-        assert "INFO: Compiling 'subdir/tsconfig.json'." in result.output
 
 
 @skip_non_compilable_projects
 def test_compile(ape_cli, runner, project, clean_cache):
-    result = runner.invoke(ape_cli, ["compile"], catch_exceptions=False)
+    assert not project.manifest.contract_types, "Setup failed - expecting clean start"
+    cmd = ("compile", "--project", f"{project.path}")
+    result = runner.invoke(ape_cli, cmd, catch_exceptions=False)
     assert result.exit_code == 0, result.output
+    assert project.manifest.contract_types
 
     # First time it compiles, it compiles the files with registered compilers successfully.
     # Files with multiple extensions are currently not supported.
-    all_files = [f for f in project.path.glob("contracts/**/*")]
+    all_files = [f for f in project.path.glob("contracts/**/*") if f.is_file()]
 
     # Don't expect directories that may happen to have `.json` in name
     # as well as hidden files, such as `.gitkeep`. Both examples are present
     # in the test project!
     excluded = (
         "Exclude.json",
         "UnwantedContract.json",
@@ -83,90 +62,120 @@
         f
         for f in all_files
         if f.name.count(".") == 1
         and f.is_file()
         and not f.name.startswith(".")
         and f.name not in excluded
         and f.suffix == ".json"
+        and ".cache" not in [p.name for p in f.parents]
     ]
     unexpected_files = [f for f in all_files if f not in expected_files]
 
+    # Extract manifest (note: same project is used in 2 instances here).
     manifest = project.extract_manifest()
+
     non_json = [f for f in expected_files if f.suffix != ".json"]
     if len(non_json) > 0:
         assert manifest.compilers
     for file in expected_files:
-        assert file.name in manifest.sources
+        assert f"{project.contracts_folder.name}/{file.name}" in manifest.sources
 
     missing = [f.name for f in expected_files if f.stem not in result.output]
+
     assert not missing, f"Missing: {', '.join(missing)}"
-    assert not any(f.stem in result.output for f in unexpected_files)
+
+    for file in unexpected_files:
+        assert file.stem not in result.output, f"Shouldn't have compiled {file.name}"
 
     # Copy in .build to show that those file won't compile.
     # (Anything in a .build is ignored, even if in a contracts folder to prevent accidents).
-    shutil.copytree(project.path / ".build", project.contracts_folder / ".build")
+    build_path = project.path / ".build"
+    if project.path != project.contracts_folder:
+        shutil.copytree(build_path, project.contracts_folder / ".build")
 
+    assert build_path.is_dir()
     try:
-        result = runner.invoke(ape_cli, ["compile"], catch_exceptions=False)
+        result = runner.invoke(ape_cli, cmd, catch_exceptions=False)
         assert result.exit_code == 0, result.output
+        assert "__local__.json" not in result.output
         # First time it compiles, it caches
         for file in project.path.glob("contracts/**/*"):
-            assert file.stem not in result.output
+            if file.is_file():
+                assert file.name not in result.output
 
     finally:
         shutil.rmtree(project.contracts_folder / ".build", ignore_errors=True)
 
 
 @skip_projects_except("multiple-interfaces")
 def test_compile_when_sources_change(ape_cli, runner, project, clean_cache):
-    result = runner.invoke(ape_cli, ["compile"], catch_exceptions=False)
+    source_path = project.contracts_folder / "Interface.json"
+    content = source_path.read_text()
+    assert "bar" in content, "Test setup failed - unexpected content"
+
+    result = runner.invoke(
+        ape_cli, ("compile", "--project", f"{project.path}"), catch_exceptions=False
+    )
     assert result.exit_code == 0, result.output
-    assert "Compiling 'Interface.json'" in result.output
+    assert "contracts/Interface.json" in result.output
+    assert "SUCCESS: 'local project' compiled." in result.output
 
-    # Change the contents of a file
+    # Change the contents of a file.
     source_path = project.contracts_folder / "Interface.json"
-    modified_source_text = source_path.read_text().replace("foo", "bar")
+    modified_source_text = source_path.read_text().replace("bar", "foo")
     source_path.unlink()
     source_path.touch()
     source_path.write_text(modified_source_text)
-
-    result = runner.invoke(ape_cli, ["compile"], catch_exceptions=False)
+    result = runner.invoke(
+        ape_cli, ("compile", "--project", f"{project.path}"), catch_exceptions=False
+    )
     assert result.exit_code == 0, result.output
-    assert "Compiling 'Interface.json'" in result.output
+    assert "contracts/Interface.json" in result.output
+    assert "SUCCESS: 'local project' compiled." in result.output
 
     # Verify that the next time, it does not need to recompile (no changes)
-    result = runner.invoke(ape_cli, ["compile"], catch_exceptions=False)
+    result = runner.invoke(
+        ape_cli, ("compile", "--project", f"{project.path}"), catch_exceptions=False
+    )
     assert result.exit_code == 0, result.output
-    assert "Compiling 'Interface.json'" not in result.output
+    assert "contracts/Interface.json" not in result.output
 
 
 @skip_projects_except("multiple-interfaces")
 def test_compile_when_contract_type_collision(ape_cli, runner, project, clean_cache):
     source_path = project.contracts_folder / "Interface.json"
     temp_dir = project.contracts_folder / "temp"
+
+    def clean():
+        if temp_dir.is_dir():
+            shutil.rmtree(temp_dir)
+
+    clean()
     source_copy = temp_dir / "Interface.json"
     expected = (
-        r"ERROR: \(CompilerError\) ContractType collision between sources '"
-        r"([\w\/]+\.json)' and '([\w\/]+\.json)'\."
+        r"ERROR: \(CompilerError\) ContractType collision\. "
+        r"Contracts '(.*\.json)' and '(.*\.json)' share the name 'Interface'\."
     )
     temp_dir.mkdir()
     try:
         source_copy.touch()
         source_copy.write_text(source_path.read_text())
-        result = runner.invoke(ape_cli, ["compile"], catch_exceptions=False)
+        result = runner.invoke(
+            ape_cli, ("compile", "--project", f"{project.path}"), catch_exceptions=False
+        )
         assert result.exit_code == 1
         actual = result.output
         search_result = re.search(expected, actual)
         assert search_result, actual
         groups = search_result.groups()
-        assert {groups[0], groups[1]} == {"Interface.json", "temp/Interface.json"}
+        expected_group = {"contracts/Interface.json", "contracts/temp/Interface.json"}
+        assert set(groups) == expected_group
 
     finally:
-        if temp_dir.is_dir():
-            shutil.rmtree(temp_dir)
+        clean()
 
 
 @skip_projects_except("multiple-interfaces")
 def test_compile_when_source_contains_return_characters(ape_cli, runner, project, clean_cache):
     """
     This tests a bugfix where a source file contained return-characters
     and that triggered endless re-compiles because it technically contains extra
@@ -174,78 +183,69 @@
     """
     source_path = project.contracts_folder / "Interface.json"
     # Change the contents of a file to contain the '\r' character.
     modified_source_text = f"{source_path.read_text()}\r"
     source_path.unlink()
     source_path.touch()
     source_path.write_text(modified_source_text)
-
-    result = runner.invoke(ape_cli, ["compile"], catch_exceptions=False)
+    arguments = ("compile", "--project", f"{project.path}")
+    result = runner.invoke(ape_cli, arguments, catch_exceptions=False)
     assert result.exit_code == 0, result.output
-    assert "Compiling 'Interface.json'" in result.output
+    assert "contracts/Interface.json" in result.output
 
     # Verify that the next time, it does not need to recompile (no changes)
-    result = runner.invoke(ape_cli, ["compile"], catch_exceptions=False)
+    result = runner.invoke(ape_cli, arguments, catch_exceptions=False)
     assert result.exit_code == 0, result.output
-    assert "Compiling 'Interface.json'" not in result.output
+    assert "contracts/Interface.json" not in result.output
 
 
 @skip_projects_except("multiple-interfaces")
 def test_can_access_contracts(project, clean_cache):
     # This test does not use the CLI but still requires a project or run off of.
     assert project.Interface, "Unable to access contract when needing to compile"
     assert project.Interface, "Unable to access contract when not needing to compile"
 
 
 @skip_projects_except("multiple-interfaces")
 @pytest.mark.parametrize(
     "contract_path",
-    ("Interface", "Interface.json", "contracts/Interface", "contracts/Interface.json"),
+    ("Interface.json", "Interface", "contracts/Interface.json", "contracts/Interface"),
 )
 def test_compile_specified_contracts(ape_cli, runner, project, contract_path, clean_cache):
-    result = runner.invoke(ape_cli, ["compile", contract_path], catch_exceptions=False)
+    arguments = ("compile", contract_path, "--project", f"{project.path}")
+    result = runner.invoke(ape_cli, arguments, catch_exceptions=False)
     assert result.exit_code == 0, result.output
-    assert "Compiling 'Interface.json'" in result.output
+    assert "contracts/Interface.json" in result.output
 
     # Already compiled.
-    result = runner.invoke(ape_cli, ["compile", contract_path], catch_exceptions=False)
+    result = runner.invoke(ape_cli, arguments, catch_exceptions=False)
     assert result.exit_code == 0, result.output
-    assert "Compiling 'Interface.json'" not in result.output
+    assert "contracts/Interface.json" not in result.output
 
     # Force recompile.
-    result = runner.invoke(ape_cli, ["compile", contract_path, "--force"], catch_exceptions=False)
+    result = runner.invoke(ape_cli, [*arguments, "--force"], catch_exceptions=False)
     assert result.exit_code == 0, result.output
-    assert "Compiling 'Interface.json'" in result.output
+    assert "contracts/Interface.json" in result.output
 
 
 @skip_projects_except("multiple-interfaces")
 def test_compile_unknown_extension_does_not_compile(ape_cli, runner, project, clean_cache):
-    result = runner.invoke(
-        ape_cli, ["compile", "Interface.js"], catch_exceptions=False
-    )  # Suffix to existing extension
+    arguments = ("compile", "Interface.js", "--project", f"{project.path}")
+    result = runner.invoke(ape_cli, arguments, catch_exceptions=False)
     assert result.exit_code == 2, result.output
-    assert "Error: Contract 'Interface.js' not found." in result.output
-
-
-@skip_projects_except()
-def test_compile_contracts(ape_cli, runner, project):
-    result = runner.invoke(ape_cli, ["compile", "--size"], catch_exceptions=False)
-    assert result.exit_code == 0, result.output
-    # Still caches but displays bytecode size
-    for file in project.path.glob("contracts/**/*"):
-        assert file.stem in result.output
+    assert "Error: Source file 'Interface.js' not found." in result.output
 
 
 @skip_projects_except("with-dependencies")
 @pytest.mark.parametrize(
     "contract_path",
     (None, "contracts/", "Project", "contracts/Project.json"),
 )
 def test_compile_with_dependency(ape_cli, runner, project, contract_path):
-    cmd = ["compile", "--force"]
+    cmd = ["compile", "--force", "--project", f"{project.path}"]
 
     if contract_path:
         cmd.append(contract_path)
 
     result = runner.invoke(ape_cli, cmd, catch_exceptions=False)
     assert result.exit_code == 0, result.output
     for name in (
@@ -259,101 +259,81 @@
         assert name in list(project.dependencies.keys())
         dependency = project.dependencies[name]["local"]
         assert isinstance(dependency[name], ContractContainer)
 
 
 @skip_projects_except("with-dependencies")
 def test_compile_individual_contract_excludes_other_contract(ape_cli, runner, project):
-    result = runner.invoke(ape_cli, ["compile", "Project", "--force"], catch_exceptions=False)
+    arguments = ("compile", "Project", "--force", "--project", f"{project.path}")
+    result = runner.invoke(ape_cli, arguments, catch_exceptions=False)
     assert result.exit_code == 0, result.output
     assert "Other" not in result.output
 
 
 @skip_projects_except("with-dependencies")
 def test_compile_non_ape_project_deletes_ape_config_file(ape_cli, runner, project):
     ape_config = project.path / "default" / "ape-config.yaml"
     if ape_config.is_file():
         # Corrupted from a previous test.
         ape_config.unlink()
 
-    result = runner.invoke(ape_cli, ["compile", "Project", "--force"], catch_exceptions=False)
+    arguments = ("compile", "Project", "--force", "--project", f"{project.path}")
+    result = runner.invoke(ape_cli, arguments, catch_exceptions=False)
     assert result.exit_code == 0, result.output
-    assert "ape-config.yaml" not in [f.name for f in (project.path / "default").iterdir()]
 
 
 @skip_projects_except("only-dependencies")
-def test_compile_only_dependency(ape_cli, runner, project, clean_cache, caplog):
-    expected_log_message = "Compiling 'DependencyInProjectOnly.json'"
-    dependency_cache = project.path / "renamed_contracts_folder" / ".build"
-    if dependency_cache.is_dir():
-        shutil.rmtree(str(dependency_cache))
+def test_compile_only_dependency(ape_cli, runner, project, clean_cache, ape_caplog):
+    expected_log_message = "Compiling sources/DependencyInProjectOnly.json"
 
-    result = runner.invoke(ape_cli, ["compile", "--force"], catch_exceptions=False)
+    # Compile w/o --include-dependencies flag (nothing happens but it doesn't fail).
+    arguments: tuple[str, ...] = ("compile", "--force", "--project", f"{project.path}")
+    result = runner.invoke(ape_cli, arguments, catch_exceptions=False)
     assert result.exit_code == 0, result.output
-
-    # Dependencies are not compiled automatically
     assert expected_log_message not in result.output
 
-    # Trigger actual dependency compilation
-    dependency = project.dependencies["dependency-in-project-only"]["local"]
-    _ = dependency.DependencyInProjectOnly
-
-    # Pop the log record off here so we can check the tail again below.
-    length_before = len(caplog.records)
-    assert expected_log_message in caplog.messages[-1]
-
-    # It should not need to compile again.
-    _ = dependency.DependencyInProjectOnly
-    if caplog.records:
-        if expected_log_message in caplog.messages[-1]:
-            length_after = len(caplog.records)
-            # The only way it should be the same log is if there
-            # were not additional logs.
-            assert length_after == length_before
+    # Now, actually compile (using --include-dependencies)
+    arguments = ("compile", "--force", "--project", f"{project.path}", "--include-dependencies")
+    result = runner.invoke(ape_cli, arguments, catch_exceptions=False)
+    assert expected_log_message in result.output
+
+    # It should not need to compile again (no force).
+    arguments = ("compile", "--project", f"{project.path}", "--include-dependencies")
+    result = runner.invoke(ape_cli, arguments, catch_exceptions=False)
+    assert expected_log_message not in result.output
 
-        else:
-            pytest.fail("Compiled twice!")
+    # Ensure config reading works. Note: have to edit file here
+    # because in-memory config updates only works when on the subprocess,
+    # and the CLI has to reload the project.
+    config_path = project.path / "ape-config.yaml"
+    project.config.compile.include_dependencies = True
+    project.config.write_to_disk(config_path, replace=True)
 
-    # Force a re-compile and trigger the dependency to compile via CLI
-    result = runner.invoke(
-        ape_cli, ["compile", "--force", "--include-dependencies"], catch_exceptions=False
-    )
+    arguments = ("compile", "--force", "--project", f"{project.path}", "--include-dependencies")
+    result = runner.invoke(ape_cli, arguments, catch_exceptions=False)
     assert result.exit_code == 0, result.output
     assert expected_log_message in result.output
 
-    # Make sure the config option works
-    config_file = project.path / "ape-config.yaml"
-    text = config_file.read_text()
-    try:
-        text = text.replace("  include_dependencies: false", "  include_dependencies: true")
-        config_file.unlink()
-        config_file.write_text(text)
-        project.config_manager.load(force_reload=True)
-        result = runner.invoke(ape_cli, ["compile", "--force"], catch_exceptions=False)
-        assert result.exit_code == 0, result.output
-        assert expected_log_message in result.output
-    finally:
-        text.replace("  include_dependencies: true", "  include_dependencies: false")
-        project.config_manager.load(force_reload=True)
-
 
 @skip_projects_except("with-contracts")
-def test_raw_compiler_output_bytecode(ape_cli, runner, project):
+def test_raw_compiler_output_bytecode(project):
     assert project.RawVyperOutput.contract_type.runtime_bytecode.bytecode
     assert project.RawSolidityOutput.contract_type.deployment_bytecode.bytecode
 
 
 @skip_projects_except("with-contracts")
-def test_compile_after_deleting_cache_file(project):
-    assert project.RawVyperOutput
-    path = project.local_project._cache_folder / "RawVyperOutput.json"
-    path.unlink()
-
-    # Should still work (will have to figure it out its missing and put back).
-    assert project.RawVyperOutput
-
-
-@skip_projects_except("with-contracts")
 def test_compile_exclude(ape_cli, runner):
-    result = runner.invoke(ape_cli, ["compile", "--force"], catch_exceptions=False)
+    result = runner.invoke(ape_cli, ("compile", "--force"), catch_exceptions=False)
     assert "Compiling 'Exclude.json'" not in result.output
     assert "Compiling 'exclude_dir/UnwantedContract.json'" not in result.output
+
+
+@skip_projects_except("with-contracts")
+def test_compile_config_override(ape_cli, runner):
+    arguments = (
+        "compile",
+        "--force",
+        "--config-override",
+        '{"compile": {"exclude": ["*ContractA*"]}}',
+    )
+    result = runner.invoke(ape_cli, arguments, catch_exceptions=False)
+    assert "Compiling 'ContractA.json'" not in result.output
```

### Comparing `eth-ape-0.7.9/tests/integration/cli/test_console.py` & `eth-ape-0.8.0/tests/integration/cli/test_console.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,13 +1,22 @@
+from pathlib import Path
+
 import pytest
 
 from ape import __all__
 from tests.integration.cli.utils import skip_projects, skip_projects_except
 
-data_and_project_folders = pytest.mark.parametrize("folder", ["PROJECT_FOLDER", "DATA_FOLDER"])
+
+@pytest.fixture(params=("path", "root"))
+def extras_base_path(project, request):
+    if request.param == "path":
+        yield project.path
+    else:
+        yield project.config_manager.DATA_FOLDER
+
 
 # Simple single namespace example
 EXTRAS_SCRIPT_1 = """
 A = 1
 def a():
     return A
 """
@@ -47,107 +56,108 @@
     return (
         "NameError" not in result.output
         and "AssertionError" not in result.output
         and "ModuleNotFoundError" not in result.output
     )
 
 
-def write_ape_console_extras(project, folder, contents):
-    extras_file = getattr(project.config_manager, folder).joinpath("ape_console_extras.py")
+def write_ape_console_extras(base_path, contents):
+    extras_file = base_path.joinpath("ape_console_extras.py")
     extras_file.write_text(contents)
     return extras_file
 
 
 @pytest.fixture(autouse=True)
 def clean_console_rc_write(project):
     yield
 
     global_extras = project.config_manager.DATA_FOLDER.joinpath("ape_console_extras.py")
     if global_extras.is_file():
         global_extras.unlink()
 
-    project_extras = project.config_manager.PROJECT_FOLDER.joinpath("ape_console_extras.py")
+    project_extras = project.path.joinpath("ape_console_extras.py")
     if project_extras.is_file():
         project_extras.unlink()
 
 
 # NOTE: We export `__all__` into the IPython session that the console runs in
 @skip_projects("geth")
 @pytest.mark.parametrize("item", __all__)
-def test_console(ape_cli, runner, item):
-    result = runner.invoke(ape_cli, ["console"], input=f"{item}\nexit\n", catch_exceptions=False)
+def test_console(ape_cli, runner, item, project):
+    arguments = ["console", "--project", f"{project.path}"]
+    result = runner.invoke(ape_cli, arguments, input=f"{item}\nexit\n", catch_exceptions=False)
     assert result.exit_code == 0, result.output
     assert no_console_error(result), result.output
+    arguments.extend(("-v", "debug"))
     result = runner.invoke(
         ape_cli,
-        ["console", "-v", "debug"],
+        arguments,
         input=f"{item}\nexit\n",
         catch_exceptions=False,
     )
     assert result.exit_code == 0, result.output
     assert no_console_error(result), result.output
 
 
 @skip_projects("geth")
-@data_and_project_folders
-def test_console_extras(project, folder, ape_cli, runner):
-    write_ape_console_extras(project, folder, EXTRAS_SCRIPT_1)
+def test_console_extras(project, extras_base_path, ape_cli, runner):
+    write_ape_console_extras(extras_base_path, EXTRAS_SCRIPT_1)
+    arguments = ("console", "--project", f"{project.path}")
 
     result = runner.invoke(
         ape_cli,
-        ["console"],
+        arguments,
         input="\n".join(["assert A == 1", "exit"]) + "\n",
         catch_exceptions=False,
     )
     assert result.exit_code == 0, result.output
     assert no_console_error(result), result.output
 
     result = runner.invoke(
         ape_cli,
-        ["console"],
+        arguments,
         input="\n".join(["assert a() == 1", "exit"]) + "\n",
         catch_exceptions=False,
     )
     assert result.exit_code == 0, result.output
     assert no_console_error(result), result.output
 
 
 @skip_projects("geth")
-@data_and_project_folders
-def test_console_init_extras(project, folder, ape_cli, runner):
-    write_ape_console_extras(project, folder, EXTRAS_SCRIPT_2)
+def test_console_init_extras(project, extras_base_path, ape_cli, runner):
+    write_ape_console_extras(extras_base_path, EXTRAS_SCRIPT_2)
+    arguments = ("console", "--project", f"{project.path}")
     result = runner.invoke(
         ape_cli,
-        ["console"],
+        arguments,
         input="print('a:', A)\nassert A == 2\nexit\n",
         catch_exceptions=False,
     )
     assert result.exit_code == 0, result.output
     assert no_console_error(result), result.output
 
 
 @skip_projects("geth")
-@data_and_project_folders
-def test_console_init_extras_kwargs(project, folder, ape_cli, runner):
-    write_ape_console_extras(project, folder, EXTRAS_SCRIPT_3)
-
-    result = runner.invoke(ape_cli, ["console"], input="exit\n", catch_exceptions=False)
+def test_console_init_extras_kwargs(project, extras_base_path, ape_cli, runner):
+    write_ape_console_extras(extras_base_path, EXTRAS_SCRIPT_3)
+    arguments = ("console", "--project", f"{project.path}")
+    result = runner.invoke(ape_cli, arguments, input="exit\n", catch_exceptions=False)
     assert result.exit_code == 0, result.output
     assert no_console_error(result), result.output
 
 
 @skip_projects("geth")
-@data_and_project_folders
-def test_console_init_extras_return(project, folder, ape_cli, runner):
-    write_ape_console_extras(project, folder, EXTRAS_SCRIPT_4)
+def test_console_init_extras_return(project, extras_base_path, ape_cli, runner):
+    write_ape_console_extras(extras_base_path, EXTRAS_SCRIPT_4)
+    arguments = ("console", "--project", f"{project.path}")
 
     # Test asserts returned A exists and B is not overwritten
     result = runner.invoke(
         ape_cli,
-        ["console"],
+        arguments,
         input="\n".join(
             [
                 "assert A == 1, 'unexpected A'",
                 # symbols from ape_init_extras should apply before file namespace
                 "assert B == 2, 'unexpected B'",
                 "exit",
             ]
@@ -157,92 +167,99 @@
     )
     assert result.exit_code == 0, result.output
     assert no_console_error(result), result.output
 
 
 @skip_projects_except("only-dependencies")
 def test_console_import_local_path(project, ape_cli, runner):
+    # NOTE: Don't use temp-path! Temp-path projects do not copy Python modules.
+    path = Path(__file__).parent / "projects" / "only-dependencies"
+    arguments = ("console", "--project", f"{path}")
     result = runner.invoke(
         ape_cli,
-        ["console"],
+        arguments,
         input="\n".join(["from dependency_in_project_only.importme import import_me", "exit"])
         + "\n",
     )
     assert result.exit_code == 0, result.output
     assert no_console_error(result), result.output
 
 
 @skip_projects_except("only-dependencies")
-def test_console_import_local_path_in_extras_file(project, ape_cli, runner):
-    write_ape_console_extras(project, "PROJECT_FOLDER", EXTRAS_SCRIPT_5)
-
+def test_console_import_local_path_in_extras_file(project, extras_base_path, ape_cli, runner):
+    # NOTE: Don't use tmp path! Temp projects do not copy Python modules.
+    path = Path(__file__).parent / "projects" / "only-dependencies"
+    write_ape_console_extras(extras_base_path, EXTRAS_SCRIPT_5)
+    arguments = ("console", "--project", f"{path}")
     result = runner.invoke(
         ape_cli,
-        ["console"],
+        arguments,
         input="exit\n",
         catch_exceptions=False,
     )
     assert result.exit_code == 0, result.output
     assert no_console_error(result), result.output
 
 
 @skip_projects_except("only-dependencies")
-def test_console_ape_magic(ape_cli, runner):
+def test_console_ape_magic(project, ape_cli, runner):
+    arguments = ("console", "--project", f"{project.path}")
     result = runner.invoke(
         ape_cli,
-        ["console"],
+        arguments,
         input="%load_ext ape_console.plugin\n%ape--help\nexit\n",
         catch_exceptions=False,
     )
     assert result.exit_code == 0, result.output
     assert no_console_error(result), result.output
 
 
 @skip_projects_except("only-dependencies")
-def test_console_bal_magic(ape_cli, runner, keyfile_account):
+def test_console_bal_magic(project, ape_cli, runner, keyfile_account):
+    arguments = ("console", "--project", f"{project.path}")
     cases = (
         "%load_ext ape_console.plugin",
         "%bal acct",
         "%bal acct.alias",
         "%bal acct.address",
         "%bal int(acct.address, 16)",
     )
     cmd_ls = [f"acct = accounts.load('{keyfile_account.alias}')", *cases, "exit"]
     cmd_str = "\n".join(cmd_ls)
     result = runner.invoke(
         ape_cli,
-        ["console"],
+        arguments,
         input=f"{cmd_str}\n",
         catch_exceptions=False,
     )
     assert result.exit_code == 0, result.output
     assert no_console_error(result), result.output
 
 
 @skip_projects_except("with-contracts")
-def test_uncaught_txn_err(ape_cli, runner, mocker):
+def test_uncaught_txn_err(project, ape_cli, runner, mocker):
     # For some reason, not showing in result.output, so captured another way.
     handler = mocker.patch("ape_console.plugin.handle_ape_exception")
     cmd_ls = [
         "%load_ext ape_console.plugin",
         "account = accounts.test_accounts[0]",
         "contract = account.deploy(project.ContractA)",
         "receipt = contract.setNumber(5, sender=account)",
         "print(receipt)",
         "exit",
     ]
     cmd_str = "\n".join(cmd_ls)
+    arguments = ("console", "--project", f"{project.path}")
     runner.invoke(
         ape_cli,
-        ["console"],
+        arguments,
         input=f"{cmd_str}\n",
         catch_exceptions=False,
     )
     err = handler.call_args[0][0]
     assert str(err) == "Transaction failed."
 
 
-def test_console_none_network(ape_cli, runner):
-    result = runner.invoke(
-        ape_cli, ["console", "--network", "None"], input="exit\n", catch_exceptions=False
-    )
+def test_console_none_network(project, ape_cli, runner):
+    arguments = ("console", "--project", f"{project.path}", "--network", "None")
+    result = runner.invoke(ape_cli, arguments, input="exit\n", catch_exceptions=False)
     assert result.exit_code == 0
```

### Comparing `eth-ape-0.7.9/tests/integration/cli/test_init.py` & `eth-ape-0.8.0/tests/integration/cli/test_init.py`

 * *Files 4% similar despite different names*

```diff
@@ -21,15 +21,15 @@
 
     # Changes cwd to a temporary directory
     project_folder_path = project.path / "init_success"
     project_folder_path.mkdir()
     os.chdir(str(project_folder_path))
 
     try:
-        result = runner.invoke(ape_cli, ["init"], input="\n".join(["init_success"]))
+        result = runner.invoke(ape_cli, ("init",), input="\n".join(["init_success"]))
 
         assert result.exit_code == 0, result.output
         # checks if the directory exist
         for folder_name in ["contracts", "tests", "scripts"]:
             folder = project_folder_path / folder_name
             assert folder.is_dir()
 
@@ -56,20 +56,18 @@
     project_folder_path.mkdir()
     os.chdir(str(project_folder_path))
 
     try:
         for folder_name in ["contracts", "tests", "scripts"]:
             # Create target Directory
             folder = project_folder_path / folder_name
-            if folder.exists():
-                pass
-            else:
+            if not folder.exists():
                 folder.mkdir(exist_ok=False)
 
-        result = runner.invoke(ape_cli, ["init"], input="\n".join(["init_fail"]))
+        result = runner.invoke(ape_cli, ("init",), input="\n".join(["init_fail"]))
         # checks if the directory existence
         assert result.exit_code == 0, result.output
         assert "contracts' exists" in result.output
         assert "scripts' exists" in result.output
         assert "tests' exists" in result.output
 
     finally:
```

### Comparing `eth-ape-0.7.9/tests/integration/cli/test_misc.py` & `eth-ape-0.8.0/tests/integration/cli/test_misc.py`

 * *Files 16% similar despite different names*

```diff
@@ -4,29 +4,29 @@
 
 from tests.integration.cli.utils import run_once
 
 
 @run_once
 @pytest.mark.parametrize(
     "args",
-    (
-        [],
-        ["--version"],
-        ["--config"],
-    ),
+    [
+        (),
+        ("--version",),
+        ("--config",),
+    ],
 )
 def test_invocation(ape_cli, runner, args):
     result = runner.invoke(ape_cli, args)
     assert result.exit_code == 0, result.output
 
 
 @run_once
 def test_help(ape_cli, runner):
     result = runner.invoke(ape_cli, "--help")
     assert result.exit_code == 0, result.output
-    anything = r"[.\n\s\w`/\-,\)\(:\]\[]*"
+    anything = r"[.\n\s\w`/\-,\)\(:\]\[']*"
     expected = (
         rf"{anything}Core Commands:\n  accounts  "
         rf"Manage local accounts{anything}  "
         rf"test\s*Launches pytest{anything}"
     )
     assert re.match(expected.strip(), result.output)
```

### Comparing `eth-ape-0.7.9/tests/integration/cli/test_networks.py` & `eth-ape-0.8.0/tests/integration/cli/test_networks.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,88 +1,91 @@
+import pytest
+
 from ape.api.networks import LOCAL_NETWORK_NAME
-from tests.conftest import GETH_URI, geth_process_test
+from tests.conftest import ApeSubprocessRunner, geth_process_test
 
 from .utils import run_once, skip_projects_except
 
 _DEFAULT_NETWORKS_TREE = """
 ethereum  (default)
- goerli
-    geth  (default)
  local  (default)
-    geth
+    node
     test  (default)
  mainnet
     test  (default)
  sepolia
-     geth  (default)
+     node  (default)
 """
 _DEFAULT_NETWORKS_YAML = """
 ecosystems:
 - isDefault: true
   name: ethereum
   networks:
-  - name: goerli
-    providers:
-    - isDefault: true
-      name: geth
-  - name: goerli-fork
-    providers: []
   - isDefault: true
     name: local
     providers:
-    - name: geth
+    - name: node
     - isDefault: true
       name: test
   - name: mainnet
     providers:
     - isDefault: true
-      name: geth
+      name: node
   - name: mainnet-fork
     providers: []
   - name: sepolia
     providers:
     - isDefault: true
-      name: geth
+      name: node
   - name: sepolia-fork
     providers: []
 """
-_GETH_NETWORKS_TREE = """
+_NODE_NETWORKS_TREE = """
 ethereum  (default)
- goerli
-    geth  (default)
  local  (default)
-    geth  (default)
- mainnet
-     geth  (default)
+    node  (default)
+ mainnet
+    node  (default)
+ sepolia
+     node  (default)
 """
 _TEST_PROVIDER_TREE_OUTPUT = """
 ethereum  (default)
  local  (default)
      test  (default)
 """
-_GOERLI_NETWORK_TREE_OUTPUT = """
+_SEPOLIA_NETWORK_TREE_OUTPUT = """
 ethereum  (default)
- goerli
-     geth  (default)
+ sepolia
+     node  (default)
 """
 _CUSTOM_NETWORKS_TREE = """
 ethereum  (default)
  apenet
-    geth  (default)
+    node  (default)
  apenet1
-    geth  (default)
- goerli
-    geth  (default)
+    node  (default)
  local  (default)
-    geth  (default)
- mainnet
-     geth  (default)
+    node  (default)
+ mainnet
+    node  (default)
+ sepolia
+     node  (default)
 """
 
 
+@pytest.fixture
+def networks_runner(config):
+    class NetworksSubprocessRunner(ApeSubprocessRunner):
+        def __init__(self):
+            super().__init__("networks", data_folder=config.DATA_FOLDER)
+
+    return NetworksSubprocessRunner()
+
+
 def assert_rich_text(actual: str, expected: str):
     """
     The output from `rich` causes a bunch of extra spaces to
     appear at the end of each line. For easier testing, we remove those here.
     Also, we ignore whether the expected line is at the end or in the middle
     of the output to handle cases when the test-runner has additional plugins
     installed.
@@ -98,27 +101,26 @@
 
     for expected_line in expected_lines:
         assert expected_line in actual_lines
 
 
 @run_once
 def test_list(ape_cli, runner):
-    result = runner.invoke(ape_cli, ["networks", "list"])
+    result = runner.invoke(ape_cli, ("networks", "list"))
+    assert result.exit_code == 0
 
     # Grab ethereum
     actual = "ethereum  (default)\n" + "".join(result.output.split("ethereum  (default)\n")[-1])
 
     assert_rich_text(actual, _DEFAULT_NETWORKS_TREE)
 
 
 @run_once
 def test_list_yaml(ape_cli, runner):
-    result = runner.invoke(
-        ape_cli, ["networks", "list", "--format", "yaml"], catch_exceptions=False
-    )
+    result = runner.invoke(ape_cli, ("networks", "list", "--format", "yaml"))
     expected_lines = _DEFAULT_NETWORKS_YAML.strip().split("\n")
 
     for expected_line in expected_lines:
         if expected_line.lstrip() == "providers: []":
             # Skip these lines in case test-runner has installed providers
             continue
 
@@ -131,77 +133,79 @@
             expected_line = expected_line.lstrip(" -")
 
         assert expected_line in result.output, result.output
 
 
 @skip_projects_except("geth")
 def test_list_geth(ape_cli, runner, networks, project):
-    result = runner.invoke(ape_cli, ["networks", "list"])
+    result = runner.invoke(ape_cli, ("networks", "list"))
+    assert result.exit_code == 0
 
     # Grab ethereum
     actual = "ethereum  (default)\n" + "".join(result.output.split("ethereum  (default)\n")[-1])
 
-    assert_rich_text(actual, _GETH_NETWORKS_TREE)
+    assert_rich_text(actual, _NODE_NETWORKS_TREE)
 
     # Assert that URI still exists for local network
     # (was bug where one network's URI disappeared when setting different network's URI)
-    geth_provider = networks.get_provider_from_choice(f"ethereum:{LOCAL_NETWORK_NAME}:geth")
+    geth_provider = networks.get_provider_from_choice(f"ethereum:{LOCAL_NETWORK_NAME}:node")
     actual_uri = geth_provider.uri
-    assert actual_uri == GETH_URI
+    assert actual_uri.startswith("http")
 
 
 @run_once
 def test_list_filter_networks(ape_cli, runner, networks):
-    result = runner.invoke(ape_cli, ["networks", "list", "--network", "goerli"])
+    result = runner.invoke(ape_cli, ("networks", "list", "--network", "sepolia"))
+    assert result.exit_code == 0
 
     # Grab ethereum
     actual = "ethereum  (default)\n" + "".join(result.output.split("ethereum  (default)\n")[-1])
 
-    assert_rich_text(actual, _GOERLI_NETWORK_TREE_OUTPUT)
+    assert_rich_text(actual, _SEPOLIA_NETWORK_TREE_OUTPUT)
 
 
 @run_once
 def test_list_filter_providers(ape_cli, runner, networks):
-    result = runner.invoke(ape_cli, ["networks", "list", "--provider", "test"])
+    result = runner.invoke(ape_cli, ("networks", "list", "--provider", "test"))
+    assert result.exit_code == 0
 
     # Grab ethereum
     actual = "ethereum  (default)\n" + "".join(result.output.split("ethereum  (default)\n")[-1])
 
     assert_rich_text(actual, _TEST_PROVIDER_TREE_OUTPUT)
 
 
 @skip_projects_except("geth")
-def test_list_custom_networks(ape_cli, runner):
-    result = runner.invoke(ape_cli, ["networks", "list"])
+def test_list_custom_networks(project, networks_runner):
+    networks_runner.project = project
+    result = networks_runner.invoke("list")
+    assert result.exit_code == 0
     actual = "ethereum  (default)\n" + "".join(result.output.split("ethereum  (default)\n")[-1])
     assert_rich_text(actual, _CUSTOM_NETWORKS_TREE)
 
 
 @run_once
-def test_run_not_subprocess_provider(ape_cli, runner):
-    cmd = ("networks", "run", "--network", "ethereum:local:test")
-    result = runner.invoke(ape_cli, cmd)
+def test_run_not_subprocess_provider(networks_runner):
+    cmd = ("run", "--network", "ethereum:local:test")
+    result = networks_runner.invoke(*cmd)
+    expected = "`ape networks run` requires a provider that manages a process, not 'test'."
     assert result.exit_code != 0
-    assert (
-        result.output
-        == "ERROR: `ape networks run` requires a provider that manages a process, not 'test'.\n"
-    )
+    assert expected in result.output
 
 
 @run_once
 def test_run_custom_network(ape_cli, runner):
     cmd = ("networks", "run", "--network", "ethereum:local:test")
     result = runner.invoke(ape_cli, cmd)
+    expected = "`ape networks run` requires a provider that manages a process, not 'test'"
     assert result.exit_code != 0
-    assert (
-        result.output
-        == "ERROR: `ape networks run` requires a provider that manages a process, not 'test'.\n"
-    )
+    assert expected in result.output
 
 
 @geth_process_test
 @skip_projects_except("geth")
-def test_run_already_running(ape_cli, runner, geth_provider):
-    cmd = ("networks", "run", "--network", f"ethereum:{LOCAL_NETWORK_NAME}:geth")
-    result = runner.invoke(ape_cli, cmd)
+def test_run_already_running(networks_runner, project, geth_provider):
+    networks_runner.project = project
+    cmd = ("run", "--network", f"ethereum:{LOCAL_NETWORK_NAME}:node")
+    result = networks_runner.invoke(*cmd)
     assert result.exit_code != 0
     assert "ERROR: Process already running." in result.output
```

### Comparing `eth-ape-0.7.9/tests/integration/cli/test_plugins.py` & `eth-ape-0.8.0/tests/integration/cli/test_plugins.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,31 +1,29 @@
-from typing import List, Tuple
-
 import pytest
 
 from tests.integration.cli.utils import github_xfail, run_once
 
 TEST_PLUGIN_NAME = "tokens"
 TEST_PLUGIN_NAME_2 = "optimism"
 
 
 class PluginsList(list):
-    def __init__(self, header: str, lines: List[str]):
+    def __init__(self, header: str, lines: list[str]):
         self.header = header
         self.contains_version = len(lines[0].split(" ")) > 1 if lines else False
         names = [x.split(" ")[0].strip() for x in lines]
         super().__init__(names)
 
 
 class ListResult:
     CORE_KEY = "Core Plugins"
     INSTALLED_KEY = "Installed Plugins"
     AVAILABLE_KEY = "Available Plugins"
 
-    def __init__(self, lines: List[str]):
+    def __init__(self, lines: list[str]):
         self._lines = lines
 
     @classmethod
     def parse_output(cls, output: str) -> "ListResult":
         lines = [x.strip() for x in output.split("\n") if x.strip()]
 
         # Any line that may start the output
@@ -66,19 +64,19 @@
         if self.AVAILABLE_KEY not in self._lines:
             return PluginsList(self.AVAILABLE_KEY, [])
 
         start = self._lines.index(self.AVAILABLE_KEY) + 1
         plugins = _clean(self._lines[start:])
         return PluginsList(self.AVAILABLE_KEY, plugins)
 
-    def _get_next_index(self, start_options: Tuple[str, ...], default: int = 0) -> int:
+    def _get_next_index(self, start_options: tuple[str, ...], default: int = 0) -> int:
         return _get_next_index(self._lines, start_options=start_options, default=default)
 
 
-def _get_next_index(lines: List[str], start_options: Tuple[str, ...], default: int = 0) -> int:
+def _get_next_index(lines: list[str], start_options: tuple[str, ...], default: int = 0) -> int:
     for index, line in enumerate(lines):
         if line in start_options:
             return index
 
     return default
 
 
@@ -87,84 +85,89 @@
 
 
 @pytest.fixture(scope="module")
 def installed_plugin(ape_plugins_runner):
     plugin_installed = TEST_PLUGIN_NAME in ape_plugins_runner.invoke_list().installed_plugins
     did_install = False
     if not plugin_installed:
-        install_result = ape_plugins_runner.invoke(["install", TEST_PLUGIN_NAME])
+        install_result = ape_plugins_runner.invoke(
+            (
+                "install",
+                TEST_PLUGIN_NAME,
+            )
+        )
         list_result = ape_plugins_runner.invoke_list()
         plugins_list_output = list_result.installed_plugins
         did_install = TEST_PLUGIN_NAME in plugins_list_output
         msg = f"Failed to install plugin necessary for tests: {install_result.output}"
         assert did_install, msg
 
     yield
 
     if did_install:
-        ape_plugins_runner.invoke(["uninstall", TEST_PLUGIN_NAME])
+        ape_plugins_runner.invoke(("uninstall", TEST_PLUGIN_NAME))
 
 
 @github_xfail()
 def test_list_excludes_core_plugins(ape_plugins_runner):
     result = ape_plugins_runner.invoke_list()
     message = "{} should not be in installed plugins".format
     assert not result.core_plugins
     assert not result.available_plugins
     assert "console" not in result.installed_plugins, message("console")
     assert "networks" not in result.installed_plugins, message("networks")
-    assert "geth" not in result.installed_plugins, message("geth")
+    assert "node" not in result.installed_plugins, message("node")
 
 
 @github_xfail()
 def test_list_include_version(ape_plugins_runner, installed_plugin):
     result = ape_plugins_runner.invoke_list()
     assert result.installed_plugins.contains_version, "version is not in output"
 
 
 @github_xfail()
 def test_list_does_not_repeat(ape_plugins_runner, installed_plugin):
-    result = ape_plugins_runner.invoke_list(["--all"])
+    result = ape_plugins_runner.invoke_list(("--all",))
     assert "ethereum" in result.core_plugins
     assert "ethereum" not in result.installed_plugins
     assert "ethereum" not in result.available_plugins
 
 
 @pytest.mark.pip
 @run_once
-def test_upgrade(ape_plugins_runner, installed_plugin):
-    result = ape_plugins_runner.invoke(["install", TEST_PLUGIN_NAME, "--upgrade"])
+def test_install_upgrade(ape_plugins_runner, installed_plugin):
+    result = ape_plugins_runner.invoke(("install", TEST_PLUGIN_NAME, "--upgrade"))
     assert result.exit_code == 0
 
 
 @pytest.mark.pip
 @run_once
-def test_upgrade_failure(ape_plugins_runner):
-    result = ape_plugins_runner.invoke(["install", "NOT_EXISTS", "--upgrade"])
+def test_install_upgrade_failure(ape_plugins_runner):
+    result = ape_plugins_runner.invoke(("install", "NOT_EXISTS", "--upgrade"))
     assert result.exit_code == 1
 
 
 @pytest.mark.pip
 @run_once
 def test_install_multiple_in_one_str(ape_plugins_runner):
-    result = ape_plugins_runner.invoke(["install", f"{TEST_PLUGIN_NAME} {TEST_PLUGIN_NAME_2}"])
+    result = ape_plugins_runner.invoke(("install", f"{TEST_PLUGIN_NAME} {TEST_PLUGIN_NAME_2}"))
     assert result.exit_code == 0
 
 
 @pytest.mark.pip
 @run_once
 def test_install_from_config_file(ape_cli, runner, temp_config):
     plugins_config = {"plugins": [{"name": TEST_PLUGIN_NAME}]}
     with temp_config(plugins_config):
-        result = runner.invoke(ape_cli, ["plugins", "install", "."], catch_exceptions=False)
+        result = runner.invoke(ape_cli, ("plugins", "install", "."), catch_exceptions=False)
         assert result.exit_code == 0, result.output
         assert TEST_PLUGIN_NAME in result.stdout
 
 
 @pytest.mark.pip
 @run_once
 def test_uninstall(ape_cli, runner, installed_plugin):
     result = runner.invoke(
-        ape_cli, ["plugins", "uninstall", TEST_PLUGIN_NAME, "--yes"], catch_exceptions=False
+        ape_cli, ("plugins", "uninstall", TEST_PLUGIN_NAME, "--yes"), catch_exceptions=False
     )
     assert result.exit_code == 0, result.output
     assert TEST_PLUGIN_NAME in result.output
```

### Comparing `eth-ape-0.7.9/tests/integration/cli/test_pm.py` & `eth-ape-0.8.0/tests/integration/cli/test_run.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,217 +1,214 @@
-from pathlib import Path
+import sys
 
-from tests.integration.cli.utils import github_xfail, run_once, skip_projects_except
+import pytest
 
-EXPECTED_FAIL_MESSAGE = "Unknown package '{}'."
+from tests.conftest import ApeSubprocessRunner
 
+from .utils import skip_projects_except
 
-@run_once
-def test_install_path_not_exists(ape_cli, runner):
-    path = "path/to/nowhere"
-    result = runner.invoke(ape_cli, ["pm", "install", path])
-    assert result.exit_code != 0, result.output
-    assert EXPECTED_FAIL_MESSAGE.format(path) in result.output
-
-
-@run_once
-def test_install_path_to_local_package(ape_cli, runner, project):
-    project_name = "with-contracts"
-    path = Path(__file__).parent / "projects" / project_name
-    name = path.stem
-    result = runner.invoke(ape_cli, ["pm", "install", path.as_posix(), "--name", project_name])
-    assert result.exit_code == 0, result.output
-    assert f"Package '{path.as_posix()}' installed."
-
-    # Ensure was installed correctly.
-    assert (project.dependency_manager.DATA_FOLDER / "packages" / name).is_dir()
-
-
-@run_once
-def test_install_path_to_local_config_file(ape_cli, runner):
-    project = "with-contracts"
-    path = Path(__file__).parent / "projects" / project / "ape-config.yaml"
-    result = runner.invoke(
-        ape_cli, ["pm", "install", path.as_posix(), "--name", project], catch_exceptions=False
-    )
-    assert result.exit_code == 0, result.output
-    assert f"Package '{path.parent.as_posix()}' installed."
-
-
-@skip_projects_except("test", "with-contracts")
-def test_install_local_project_dependencies(ape_cli, runner):
-    result = runner.invoke(ape_cli, ["pm", "install"])
-    assert result.exit_code == 0
-    assert "All project packages installed." in result.output
-
-
-@run_once
-def test_install_force(ape_cli, runner):
-    result = runner.invoke(ape_cli, ["pm", "install", "--force"])
-    assert result.exit_code == 0
-    assert "All project packages installed." in result.output
-
-
-@github_xfail()
-def test_install_github_dependency_with_version(ape_cli, runner):
-    result = runner.invoke(
-        ape_cli,
-        [
-            "pm",
-            "install",
-            "gh:OpenZeppelin/openzeppelin-contracts",
-            "--name",
-            "OpenZeppelin",
-            "--version",
-            "4.6.0",
-        ],
-    )
-    assert result.exit_code == 0, result.output
-    assert "Package 'OpenZeppelin@4.6.0' installed."
-
-
-@github_xfail()
-def test_install_github_dependency_with_ref(ape_cli, runner):
-    result = runner.invoke(
-        ape_cli,
-        [
-            "pm",
-            "install",
-            "gh:OpenZeppelin/openzeppelin-contracts",
-            "--name",
-            "OpenZeppelin",
-            "--ref",
-            "master",
-        ],
-    )
-    assert result.exit_code == 0, result.output
-    assert "Package 'OpenZeppelin@master' installed."
-
-
-@run_once
-def test_compile_package_not_exists(ape_cli, runner):
-    name = "NOT_EXISTS"
-    result = runner.invoke(ape_cli, ["pm", "compile", name])
-    expected = f"Dependency '{name}' unknown. Is it installed?"
-    assert result.exit_code != 0, result.output
-    assert expected in result.output
-
-
-@skip_projects_except("with-contracts", "with-dependencies")
-def test_compile(ape_cli, runner, project):
-    result = runner.invoke(ape_cli, ["pm", "compile", "--force"])
-    assert result.exit_code == 0, result.output
-
-    if project.path.as_posix().endswith("with-contracts"):
-        assert "Package 'foodep' compiled." in result.output
-    else:
-        # Tests against a bug where we couldn't have hyphens in
-        # dependency project contracts.
-        assert "Compiling 'hyphen-DependencyContract.json'" in result.output
+BAD_COMMAND = "not-a-name"
+
+
+@pytest.fixture
+def scripts_runner(config):
+    class ScriptsSubprocessRunner(ApeSubprocessRunner):
+        def __init__(self):
+            super().__init__("run", data_folder=config.DATA_FOLDER)
+
+    return ScriptsSubprocessRunner()
+
+
+@skip_projects_except("script")
+def test_run_unknown_script(scripts_runner, project):
+    scripts_runner.project = project
+    result = scripts_runner.invoke(BAD_COMMAND)
+    assert result.exit_code == 2
+    assert f"No such command '{BAD_COMMAND}'." in result._completed_process.stderr
+
+
+@skip_projects_except("script")
+def test_run(scripts_runner, project):
+    scripts_runner.project = project
+    result = scripts_runner.invoke()
+    assert result.exit_code == 0, result.output
+    # By default, no commands are run
+    assert "Super secret script output" not in result.output
+
+    not_part_of_test = ("output_contract_view_methods",)
+    scripts = [
+        s
+        for s in project.scripts_folder.glob("*.py")
+        if not s.name.startswith("error") and s.stem not in not_part_of_test
+    ]
+    for script_file in scripts:
+        result = scripts_runner.invoke(script_file.stem)
+        assert (
+            result.exit_code == 0
+        ), f"Unexpected exit code for '{script_file.name}'\n{result.output}"
+
+        if script_file.stem.startswith("_"):
+            assert "Super secret script output" not in result.output
+
+        else:
+            assert "Super secret script output" in result.output
+
+
+@skip_projects_except("script")
+def test_run_with_verbosity(scripts_runner, project):
+    scripts_runner.project = project
+    result = scripts_runner.invoke("click", "--verbosity", "DEBUG")
+    assert result.exit_code == 0, result.output or result._completed_process.stderr
+
+
+@skip_projects_except("script")
+def test_run_subdirectories(scripts_runner, project):
+    scripts_runner.project = project
+    result = scripts_runner.invoke()
+    assert result.exit_code == 0, result.output
+    # By default, no commands are run
+    assert "Super secret script output" not in result.output
+    subdirectory_scripts = [
+        s
+        for s in (project.scripts_folder / "subdirectory").rglob("*.py")
+        if not s.name.startswith("error")
+    ]
+    for each in subdirectory_scripts:
+        result = scripts_runner.invoke("subdirectory", each.stem)
+        assert result.exit_code == 0
+        assert "Super secret script output" in result.output
+
+
+@skip_projects_except("only-script-subdirs")
+def test_run_only_subdirs(scripts_runner, project):
+    scripts_runner.project = project
+    result = scripts_runner.invoke()
+    assert result.exit_code == 0, result.output
+    # By default, no commands are run
+    assert "Super secret script output" not in result.output
+    subdirectory_scripts = [
+        s
+        for s in (project.scripts_folder / "subdirectory").rglob("*.py")
+        if not s.name.startswith("error")
+    ]
+    for each in subdirectory_scripts:
+        result = scripts_runner.invoke("subdirectory", each.stem)
+        assert result.exit_code == 0, f"Unexpected exit code for '{each.name}'"
+        assert "Super secret script output" in result.output
+
+
+@skip_projects_except("script")
+def test_run_when_script_errors(scripts_runner, project):
+    scripts_runner.project = project
+    scripts = [
+        s
+        for s in project.scripts_folder.glob("*.py")
+        if s.name.startswith("error") and not s.name.endswith("forgot_click.py")
+    ]
+    for script_file in scripts:
+        result = scripts_runner.invoke(
+            script_file.stem,
+        )
+        assert (
+            result.exit_code != 0
+        ), f"Unexpected exit code for '{script_file.name}'.\n{result.output}"
+        assert "Expected exception" in result._completed_process.stderr
+
+
+@skip_projects_except("script")
+def test_run_interactive(scripts_runner, project):
+    scripts_runner.project = project
+    scripts = [
+        project.scripts_folder / f"{s}.py" for s in ("error_main", "error_cli", "error_no_def")
+    ]
+
+    # Show that the variable namespace from the script is available in the console.
+    user_input = "local_variable\nape.chain.provider.mine()\nape.chain.blocks.head\nexit\n"
+
+    result = scripts_runner.invoke("--interactive", scripts[0].stem, input=user_input)
+    assert result.exit_code == 0, result.output
+
+    # From script: local_variable = "test foo bar"
+    assert "test foo bar" in result.output
+    assert "timestamp=123123123123123" in result.output
+
+
+@skip_projects_except("script")
+def test_run_custom_provider(scripts_runner, project):
+    scripts_runner.project = project
+    result = scripts_runner.invoke("deploy", "--network", "ethereum:mainnet:http://127.0.0.1:9545")
+
+    # Show that it attempts to connect
+    assert result.exit_code == 1, result.output
+    assert "No (supported) node found on 'http://127.0.0.1:9545" in result.output
+
+
+@skip_projects_except("script")
+def test_run_custom_network(scripts_runner, project):
+    scripts_runner.project = project
+    result = scripts_runner.invoke("deploy", "--network", "http://127.0.0.1:9545")
+
+    # Show that it attempts to connect
+    assert result.exit_code == 1, result.output
+    assert "No (supported) node found on 'http://127.0.0.1:9545" in result.output
+
+
+@skip_projects_except("script")
+def test_try_run_script_missing_cli_decorator(scripts_runner, project):
+    """
+    Shows that we cannot run a script defining a `cli()` method without
+    it being a click command. The script is not recognized, so you get
+    a usage error.
+    """
+    scripts_runner.project = project
+    result = scripts_runner.invoke("error_forgot_click")
+    assert "Usage: ape run" in result._completed_process.stderr
 
 
 @skip_projects_except("with-contracts")
-def test_compile_dependency(ape_cli, runner, project):
-    name = "foodep"
-    result = runner.invoke(ape_cli, ["pm", "compile", name])
-    assert result.exit_code == 0, result.output
-    assert f"Package '{name}' compiled." in result.output
-
-
-@skip_projects_except("only-dependencies")
-def test_remove(ape_cli, runner, project):
-    package_name = "dependency-in-project-only"
-
-    # Install packages
-    runner.invoke(ape_cli, ["pm", "install", ".", "--force"])
-
-    result = runner.invoke(ape_cli, ["pm", "remove", package_name], input="y\n")
-    expected_message = f"Version 'local' of package '{package_name}' removed."
-    assert result.exit_code == 0, result.output
-    assert expected_message in result.output
-
-
-@skip_projects_except("only-dependencies")
-def test_remove_not_exists(ape_cli, runner, project):
-    package_name = "_this_does_not_exist_"
-    result = runner.invoke(ape_cli, ["pm", "remove", package_name])
-    expected_message = f"ERROR: Package '{package_name}' is not installed."
-    assert result.exit_code != 0, result.output
-    assert expected_message in result.output
-
-
-@skip_projects_except("only-dependencies")
-def test_remove_specific_version(ape_cli, runner, project):
-    package_name = "dependency-in-project-only"
-    version = "local"
-
-    # Install packages
-    runner.invoke(ape_cli, ["pm", "install", ".", "--force"])
-
-    result = runner.invoke(ape_cli, ["pm", "remove", package_name], input="y\n")
-    expected_message = f"Version '{version}' of package '{package_name}' removed."
-    assert result.exit_code == 0, result.output
-    assert expected_message in result.output
-
-
-@skip_projects_except("only-dependencies")
-def test_remove_all_versions_with_y(ape_cli, runner):
-    # Install packages
-    runner.invoke(ape_cli, ["pm", "install", ".", "--force"])
-
-    package_name = "dependency-in-project-only"
-    result = runner.invoke(ape_cli, ["pm", "remove", package_name, "-y"])
-    expected_message = f"SUCCESS: Version 'local' of package '{package_name}' removed."
-    assert result.exit_code == 0, result.output
-    assert expected_message in result.output
-
-
-@skip_projects_except("only-dependencies")
-def test_remove_specific_version_with_y(ape_cli, runner):
-    # Install packages
-    runner.invoke(ape_cli, ["pm", "install", ".", "--force"])
-
-    package_name = "dependency-in-project-only"
-    version = "local"
-    result = runner.invoke(ape_cli, ["pm", "remove", package_name, version, "-y"])
-    expected_message = f"Version '{version}' of package '{package_name}' removed."
-    assert result.exit_code == 0, result.output
-    assert expected_message in result.output
-
-
-@skip_projects_except("only-dependencies")
-def test_remove_cancel(ape_cli, runner):
-    # Install packages
-    runner.invoke(ape_cli, ["pm", "install", ".", "--force"])
-
-    package_name = "dependency-in-project-only"
-    version = "local"
-    result = runner.invoke(ape_cli, ["pm", "remove", package_name, version], input="n\n")
-    assert result.exit_code == 0, result.output
-    expected_message = f"Version '{version}' of package '{package_name}' removed."
-    assert expected_message not in result.output
-
-
-@skip_projects_except("only-dependencies")
-def test_remove_invalid_version(ape_cli, runner, project):
-    package_name = "dependency-in-project-only"
-
-    # Install packages
-    runner.invoke(ape_cli, ["pm", "install", ".", "--force"])
-
-    # Ensure was installed correctly.
-    assert package_name in project.dependencies
-    assert (project.dependency_manager.DATA_FOLDER / "packages" / package_name).is_dir()
-
-    invalid_version = "0.0.0"
-    result = runner.invoke(ape_cli, ["pm", "remove", package_name, invalid_version])
-
-    expected_message = f"Version '{invalid_version}' of package '{package_name}' is not installed."
-    assert expected_message in result.output
-
-
-@skip_projects_except("only-dependencies")
-def test_list(ape_cli, runner):
-    package_name = "dependency-in-project-only"
-    result = runner.invoke(ape_cli, ["pm", "list"])
-    assert result.exit_code == 0, result.output
-    assert package_name in result.output
+def test_uncaught_tx_err(scripts_runner, project):
+    scripts_runner.project = project
+    result = scripts_runner.invoke("txerr")
+    assert '/scripts/txerr.py", line 12, in main' in result.output
+    assert "contract.setNumber(5, sender=account)" in result.output
+    assert "ERROR: (ContractLogicError) Transaction failed." in result.output
+
+
+@skip_projects_except("script")
+def test_scripts_module_already_installed(project, scripts_runner, mocker):
+    """
+    Make sure that if there is for some reason a python module names `scripts`
+    installed, it does not interfere with Ape's scripting mechanism.
+    """
+    scripts_runner.project = project
+    mock_scripts = mocker.MagicMock()
+    mock_path = mocker.MagicMock()
+    mock_path._path = "path/to/scripts"
+    mock_scripts.__file__ = None
+    mock_scripts.__path__ = mock_path
+    sys.modules["scripts"] = mock_scripts
+    result = scripts_runner.invoke()
+    assert result.exit_code == 0, result.output
+    del sys.modules["scripts"]
+
+
+@skip_projects_except("script")
+def test_run_recompiles_if_needed(runner, ape_cli, scripts_runner, project):
+    """
+    Ensure that when a change is made to a contract,
+    when we run a script, it re-compiles the script first.
+    """
+    scripts_runner.project = project
+
+    # Ensure we begin compiled.
+    runner.invoke(ape_cli, ("compile", "--force", "--project", f"{project.path}"))
+
+    # Make a change to the contract.
+    contract = project.contracts_folder / "VyperContract.json"
+    method_name = project.VyperContract.contract_type.view_methods[0].name
+    new_method_name = f"f__{method_name}__"
+    new_contract_text = contract.read_text().replace(method_name, new_method_name)
+    contract.write_text(new_contract_text)
+
+    # Run the script. It better recompile first!
+    result = scripts_runner.invoke("output_contract_view_methods")
+    assert new_method_name in result.output
```

### Comparing `eth-ape-0.7.9/tests/integration/cli/test_test.py` & `eth-ape-0.8.0/tests/integration/cli/test_test.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,9 @@
 import io
+import os
 import re
 from pathlib import Path
 from typing import Optional
 
 import pytest
 
 from ape.pytest.fixtures import PytestApeFixtures
@@ -36,15 +37,15 @@
  +
   __init__ +\d +\d+ + \d+ + \d+ + \d+
   balanceOf +\d +\d+ + \d+ + \d+ + \d+
   transfer +\d +\d+ + \d+ + \d+ + \d+
 {TOKEN_B_GAS_REPORT}
 """
 GETH_LOCAL_CONFIG = f"""
-geth:
+node:
   ethereum:
     local:
       uri: {GETH_URI}
 """
 
 
 def filter_expected_methods(*methods_to_remove: str) -> str:
@@ -52,55 +53,80 @@
     for name in methods_to_remove:
         line = f"\n  {name} +\\d +\\d+ + \\d+ + \\d+ + \\d+"
         expected = expected.replace(line, "")
 
     return expected
 
 
+@pytest.fixture(autouse=True, scope="session")
+def path_check():
+    # Fix annoying issue where path cwd doesn't exist
+    # Something something temp path.
+    try:
+        os.getcwd()
+    except Exception:
+        os.chdir(f"{Path(__file__).parent}")
+
+
 @pytest.fixture(autouse=True)
 def load_dependencies(project):
     """Ensure these are loaded before setting up pytester."""
-    project.load_dependencies()
+    project.dependencies.install()
 
 
 @pytest.fixture
-def setup_pytester(pytester):
-    def setup(project_name: str):
-        project_path = BASE_PROJECTS_PATH / project_name
+def setup_pytester(pytester, owner):
+    # Mine to a new block so we are not capturing old transactions
+    # in the tests.
+    owner.transfer(owner, 0)
+
+    def setup(project):
+        project_path = BASE_PROJECTS_PATH / project.path.name
         tests_path = project_path / "tests"
 
         # Assume all tests should pass
         num_passes = 0
         num_failed = 0
         test_files = {}
-        for file_path in tests_path.iterdir():
-            if file_path.name.startswith("test_") and file_path.suffix == ".py":
-                content = file_path.read_text()
-                test_files[file_path.name] = content
-                num_passes += len(
-                    [
-                        x
-                        for x in content.split("\n")
-                        if x.startswith("def test_") and not x.startswith("def test_fail_")
-                    ]
-                )
-                num_failed += len(
-                    [x for x in content.split("\n") if x.startswith("def test_fail_")]
-                )
+        if tests_path.is_dir():
+            for file_path in tests_path.iterdir():
+                if file_path.name.startswith("test_") and file_path.suffix == ".py":
+                    content = file_path.read_text()
+                    test_files[file_path.name] = content
+                    num_passes += len(
+                        [
+                            x
+                            for x in content.splitlines()
+                            if x.startswith("def test_") and not x.startswith("def test_fail_")
+                        ]
+                    )
+                    num_failed += len(
+                        [x for x in content.splitlines() if x.startswith("def test_fail_")]
+                    )
 
-        pytester.makepyfile(**test_files)
+            pytester.makepyfile(**test_files)
 
         # Make other files
         def _make_all_files(base: Path, prefix: Optional[Path] = None):
+            if not base.is_dir():
+                return
+
             for file in base.iterdir():
                 if file.is_dir() and not file.name == "tests":
                     _make_all_files(file, prefix=Path(file.name))
                 elif file.is_file():
                     name = (prefix / file.name).as_posix() if prefix else file.name
-                    src = {name: file.read_text().splitlines()}
+
+                    if name == "ape-config.yaml":
+                        # Hack in in-memory overrides for testing purposes.
+                        text = str(project.config)
+                    else:
+                        text = file.read_text()
+
+                    src = {name: text.splitlines()}
                     pytester.makefile(file.suffix, **src)
 
         _make_all_files(project_path)
 
         # Check for a conftest.py
         conftest = tests_path / "conftest.py"
         if conftest.is_file():
@@ -120,15 +146,15 @@
     )
     gas_header_line_index = None
     for index, line in enumerate(result.outlines):
         if "Gas Profile" in line:
             gas_header_line_index = index
 
     assert gas_header_line_index is not None, "'Gas Profile' not in output."
-    expected = expected_report.split("\n")[1:]
+    expected = [x for x in expected_report.rstrip().split("\n")[1:]]
     start_index = gas_header_line_index + 1
     end_index = start_index + len(expected)
     actual = [x.rstrip() for x in result.outlines[start_index:end_index]]
     assert "WARNING: No gas usage data found." not in actual, "Gas data missing!"
 
     actual_len = len(actual)
     expected_len = len(expected)
@@ -144,190 +170,206 @@
         message = f"'{actual_line}' does not match pattern '{expected_line}'."
         assert re.match(expected_line, actual_line), message
 
 
 @skip_projects_except("test", "with-contracts")
 def test_test(setup_pytester, project, pytester, eth_tester_provider):
     _ = eth_tester_provider  # Ensure using EthTester for this test.
-    passed, failed = setup_pytester(project.path.name)
+    passed, failed = setup_pytester(project)
     from ape.logging import logger
 
     logger.set_level("DEBUG")
-    result = pytester.runpytest()
-    result.assert_outcomes(passed=passed, failed=failed), "\n".join(result.outlines)
+    result = pytester.runpytest_subprocess()
+    try:
+        result.assert_outcomes(passed=passed, failed=failed), "\n".join(result.outlines)
+    except ValueError:
+        pytest.fail(str(result.stderr))
 
 
 @skip_projects_except("with-contracts")
 def test_uncaught_txn_err(setup_pytester, project, pytester, eth_tester_provider):
     _ = eth_tester_provider  # Ensure using EthTester for this test.
-    setup_pytester(project.path.name)
-    result = pytester.runpytest()
+    setup_pytester(project)
+    result = pytester.runpytest_subprocess()
     expected = """
     contract_in_test.setNumber(5, sender=owner)
 E   ape.exceptions.ContractLogicError: Transaction failed.
     """.strip()
     assert expected in str(result.stdout)
 
 
 @skip_projects_except("with-contracts")
 def test_show_internal(setup_pytester, project, pytester, eth_tester_provider):
     _ = eth_tester_provider  # Ensure using EthTester for this test.
-    setup_pytester(project.path.name)
-    result = pytester.runpytest("--showinternal")
+    setup_pytester(project)
+    result = pytester.runpytest_subprocess("--show-internal")
     expected = """
     raise vm_err from err
 E   ape.exceptions.ContractLogicError: Transaction failed.
     """.strip()
     assert expected in str(result.stdout)
 
 
 @skip_projects_except("test", "with-contracts")
 def test_test_isolation_disabled(setup_pytester, project, pytester, eth_tester_provider):
     # check the disable isolation option actually disables built-in isolation
     _ = eth_tester_provider  # Ensure using EthTester for this test.
-    setup_pytester(project.path.name)
-    result = pytester.runpytest("--disable-isolation", "--setup-show")
+    setup_pytester(project)
+    result = pytester.runpytest_subprocess("--disable-isolation", "--setup-show")
     assert "F _function_isolation" not in "\n".join(result.outlines)
 
 
 @skip_projects_except("test", "with-contracts")
 def test_fixture_docs(setup_pytester, project, pytester, eth_tester_provider):
     _ = eth_tester_provider  # Ensure using EthTester for this test.
-    result = pytester.runpytest("-q", "--fixtures")
+    result = pytester.runpytest_subprocess("-q", "--fixtures")
     actual = "\n".join(result.outlines)
 
     # 'accounts', 'networks', 'chain', and 'project' (etc.)
     fixtures = [prop for n, prop in vars(PytestApeFixtures).items() if not n.startswith("_")]
     for fixture in fixtures:
         # The doc str of the fixture shows in the CLI output
         for doc_str in fixture.__doc__.splitlines():
             assert doc_str.strip() in actual
 
 
 @skip_projects_except("with-contracts")
 def test_gas_flag_when_not_supported(setup_pytester, project, pytester, eth_tester_provider):
     _ = eth_tester_provider  # Ensure using EthTester for this test.
-    setup_pytester(project.path.name)
+    setup_pytester(project)
     path = f"{project.path}/tests/test_contract.py::test_contract_interaction_in_tests"
     result = pytester.runpytest(path, "--gas")
-    assert (
+    actual = "\n".join(result.outlines)
+    expected = (
         "Provider 'test' does not support transaction tracing. "
         "The gas profile is limited to receipt-level data."
-    ) in "\n".join(result.outlines)
+    )
+    assert expected in actual
 
 
 @geth_process_test
 @skip_projects_except("geth")
-def test_gas_flag_in_tests(geth_provider, setup_pytester, project, pytester):
-    passed, failed = setup_pytester(project.path.name)
-    result = pytester.runpytest("--gas")
+def test_gas_flag_in_tests(geth_provider, setup_pytester, project, pytester, owner):
+    owner.transfer(owner, "1 wei")  # Do this to force a clean slate.
+    passed, failed = setup_pytester(project)
+    result = pytester.runpytest_subprocess("--gas", "--network", "ethereum:local:node")
     run_gas_test(result, passed, failed)
 
 
 @geth_process_test
 @skip_projects_except("geth")
-def test_gas_flag_set_in_config(geth_provider, setup_pytester, project, pytester, switch_config):
-    passed, failed = setup_pytester(project.path.name)
-    config_content = f"""
-    geth:
-      ethereum:
-        local:
-          uri: {GETH_URI}
-
-    ethereum:
-      local:
-        default_provider: geth
-
-    test:
-      disconnect_providers_after: false
-      gas:
-        show: true
-    """
+def test_gas_flag_set_in_config(geth_provider, setup_pytester, project, pytester, geth_account):
+    geth_account.transfer(geth_account, "1 wei")  # Force a clean block.
+    cfg = project.config.model_dump(by_alias=True, mode="json")
+    cfg["test"]["gas"] = {"reports": ["terminal"]}
+    with project.temp_config(**cfg):
+        passed, failed = setup_pytester(project)
+        result = pytester.runpytest_subprocess("--network", "ethereum:local:node")
+        run_gas_test(result, passed, failed)
+
 
-    with switch_config(project, config_content):
-        result = pytester.runpytest()
+@geth_process_test
+@skip_projects_except("geth")
+def test_gas_when_estimating(geth_provider, setup_pytester, project, pytester, geth_account):
+    """
+    Shows that gas reports still work when estimating gas.
+    """
+    cfg = project.config.model_dump(by_alias=True, mode="json")
+    cfg["test"]["gas"] = {"reports": ["terminal"]}
+    geth_account.transfer(geth_account, "1 wei")  # Force a clean block.
+    with project.temp_config(**cfg):
+        passed, failed = setup_pytester(project)
+        result = pytester.runpytest_subprocess()
         run_gas_test(result, passed, failed)
 
 
 @geth_process_test
 @skip_projects_except("geth")
-def test_gas_flag_exclude_using_cli_option(geth_provider, setup_pytester, project, pytester):
-    passed, failed = setup_pytester(project.path.name)
+def test_gas_flag_exclude_using_cli_option(
+    geth_provider, setup_pytester, project, pytester, geth_account
+):
+    geth_account.transfer(geth_account, "1 wei")  # Force a clean block.
+    passed, failed = setup_pytester(project)
     # NOTE: Includes both a mutable and a view method.
     expected = filter_expected_methods("fooAndBar", "myNumber")
     # Also ensure can filter out whole class
     expected = expected.replace(TOKEN_B_GAS_REPORT, "")
-    result = pytester.runpytest("--gas", "--gas-exclude", "*:fooAndBar,*:myNumber,tokenB:*")
+    result = pytester.runpytest_subprocess(
+        "--gas",
+        "--gas-exclude",
+        "*:fooAndBar,*:myNumber,tokenB:*",
+        "--network",
+        "ethereum:local:node",
+    )
     run_gas_test(result, passed, failed, expected_report=expected)
 
 
 @geth_process_test
 @skip_projects_except("geth")
 def test_gas_flag_exclusions_set_in_config(
-    geth_provider, setup_pytester, project, pytester, switch_config
+    geth_provider, setup_pytester, project, pytester, geth_account
 ):
-    passed, failed = setup_pytester(project.path.name)
+    geth_account.transfer(geth_account, "1 wei")  # Force a clean block.
     # NOTE: Includes both a mutable and a view method.
     expected = filter_expected_methods("fooAndBar", "myNumber")
     # Also ensure can filter out whole class
     expected = expected.replace(TOKEN_B_GAS_REPORT, "")
-    config_content = rf"""
-    geth:
-      ethereum:
-        local:
-          uri: {GETH_URI}
-
-    ethereum:
-      local:
-        default_provider: geth
-
-    test:
-      disconnect_providers_after: false
-      gas:
-        exclude:
-          - method_name: fooAndBar
-          - method_name: myNumber
-          - contract_name: TokenB
-    """
-    with switch_config(project, config_content):
-        result = pytester.runpytest("--gas")
+    cfg = project.config.model_dump(by_alias=True, mode="json")
+    cfg["test"]["gas"] = {
+        "exclude": [
+            {"method_name": "fooAndBar"},
+            {"method_name": "myNumber"},
+            {"contract_name": "TokenB"},
+        ]
+    }
+    with project.temp_config(**cfg):
+        passed, failed = setup_pytester(project)
+        result = pytester.runpytest_subprocess("--gas", "--network", "ethereum:local:node")
         run_gas_test(result, passed, failed, expected_report=expected)
 
 
 @geth_process_test
 @skip_projects_except("geth")
-def test_gas_flag_excluding_contracts(geth_provider, setup_pytester, project, pytester):
-    passed, failed = setup_pytester(project.path.name)
-    result = pytester.runpytest("--gas", "--gas-exclude", "VyperContract,TokenA")
+def test_gas_flag_excluding_contracts(
+    geth_provider, setup_pytester, project, pytester, geth_account
+):
+    geth_account.transfer(geth_account, "1 wei")  # Force a clean block.
+    passed, failed = setup_pytester(project)
+    result = pytester.runpytest_subprocess(
+        "--gas", "--gas-exclude", "VyperContract,TokenA", "--network", "ethereum:local:node"
+    )
     run_gas_test(result, passed, failed, expected_report=TOKEN_B_GAS_REPORT)
 
 
 @geth_process_test
 @skip_projects_except("geth")
-def test_coverage(geth_provider, setup_pytester, project, pytester):
+def test_coverage(geth_provider, setup_pytester, project, pytester, geth_account):
     """
     Ensures the --coverage flag works.
     For better coverage tests, see ape-vyper because the Vyper
     plugin is what implements the `trace_source()` method which does the bulk
     of the coverage work.
     """
-    passed, failed = setup_pytester(project.path.name)
-    result = pytester.runpytest("--coverage", "--showinternal")
+    geth_account.transfer(geth_account, "1 wei")  # Force a clean block.
+    passed, failed = setup_pytester(project)
+    result = pytester.runpytest_subprocess(
+        "--coverage", "--show-internal", "--network", "ethereum:local:node"
+    )
     result.assert_outcomes(passed=passed, failed=failed)
 
 
 @skip_projects_except("with-contracts")
 def test_interactive(eth_tester_provider, project, pytester, monkeypatch):
     secret = "__ 123 super secret 123 __"
     test = f"""
 def test_fails():
     foo = "{secret}"
     raise Exception("__FAIL__")
 """
     pytester.makepyfile(test)
     stdin = "print(foo)\nexit\n"
     monkeypatch.setattr("sys.stdin", io.StringIO(stdin))
-    result = pytester.runpytest_subprocess("--interactive", "-s")
+    result = pytester.runpytest("--interactive", "-s")
     result.assert_outcomes(failed=1)
     actual = str(result.stdout)
     assert secret in actual
     assert "__FAIL__" in actual
```

### Comparing `eth-ape-0.7.9/tests/integration/cli/utils.py` & `eth-ape-0.8.0/tests/integration/cli/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
+from collections.abc import Callable
 from pathlib import Path
-from typing import Callable, Dict
 
 import pytest
 
 __projects_directory__ = Path(__file__).parent / "projects"
 __project_names__ = [
     p.stem for p in __projects_directory__.iterdir() if p.is_dir() and not p.stem.startswith(".")
 ]
@@ -37,15 +37,15 @@
 class ProjectSkipper:
     """
     A class that contains stateful information about
     which projects to skip tests for.
     """
 
     def __init__(self):
-        self.projects: Dict[str, Dict] = {n: {} for n in __project_names__}
+        self.projects: dict[str, dict] = {n: {} for n in __project_names__}
 
     def __iter__(self):
         return iter(self.projects)
 
     def do_skip(self, project: str, module: str, test: str) -> bool:
         """
         Returns ``True`` if a test has been marked to be
```

